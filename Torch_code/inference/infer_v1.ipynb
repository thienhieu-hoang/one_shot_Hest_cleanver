{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import CNN models\n",
    "import map-based data\n",
    "\n",
    "loop over number of data samples\n",
    "    apply CNN model to data\n",
    "    de-normalize\n",
    "    calculate NMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load min, max variables for normalize and denormalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowss = '1500_1509_3916_3920'\n",
    "save_path = '../model/static/CNN/BS16/'+ rowss + '/'\n",
    "snr = 0\n",
    "variables = torch.load(save_path + str(snr) + 'dB/CNN_1_variable.pth')\n",
    "\n",
    "trainData_LS_min = variables['train_min_LS']\n",
    "trainData_LS_max = variables['train_max_LS']\n",
    "trainData_LI_min = variables['train_min_LI']\n",
    "trainData_LI_max = variables['train_min_LI']\n",
    "trainLabels_min  = variables['train_label_min']\n",
    "trainLabels_max  = variables['train_label_max']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../helper')\n",
    "from utils import CNN_Est\n",
    "import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Est(\n",
       "  (normalization): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv5): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LS_CNN = CNN_Est()\n",
    "\n",
    "checkpoint_LS = torch.load(save_path + str(snr) + 'dB/CNN_1_LS_CNN_model.pth')\n",
    "model_LS_CNN.load_state_dict(checkpoint_LS['model_state_dict'])\n",
    "\n",
    "model_LS_CNN.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Est(\n",
       "  (normalization): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv5): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LS_LI_CNN = CNN_Est()\n",
    "\n",
    "\n",
    "checkpoint_LI = torch.load(save_path + str(snr) + 'dB/CNN_1_LS_CNN_model.pth')\n",
    "model_LS_LI_CNN.load_state_dict(checkpoint_LI['model_state_dict'])\n",
    "\n",
    "model_LS_LI_CNN.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ETS map-based data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 2, 14, 612)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapBaseData_path = '../../CDL Customization/Data/ver1/' + str(snr) + 'dB/1_mapBaseData.mat'\n",
    "file = h5py.File(mapBaseData_path, 'r')\n",
    "file['H_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "        \n",
    "H_true = np.concatenate((H_true, np.transpose(np.array(file['H_data']), (0,1,3,2))) , axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "H_equal = np.concatenate((H_equal, np.transpose(np.array(file['H_equalized_data']), (0,1,3,2))), axis = 0)\n",
    "H_linear = np.concatenate((H_linear, np.transpose(np.array(file['H_linear_data']), (0,1,3,2))), axis=0)\n",
    "\n",
    "H_true = torch.from_numpy(H_true)\n",
    "H_equal = torch.from_numpy(H_equal)\n",
    "H_linear = torch.from_numpy(H_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data and Make test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "trainData_LS_min = variables['train_min_LS']\n",
    "trainData_LS_max = variables['train_max_LS']\n",
    "trainData_LI_min = variables['train_min_LI']\n",
    "trainData_LI_max = variables['train_min_LI']\n",
    "trainLabels_min  = variables['val_min']\n",
    "trainLabels_max  = variables['val_max']\n",
    "\n",
    "testData_LS_normd   = (H_equal - trainData_LS_min)/ (trainData_LS_max - trainData_LS_min)\n",
    "testData_LI_normd   = (H_linear - trainData_LI_min)/ (trainData_LI_max - trainData_LI_min)\n",
    "\n",
    "testData_LS_normd = testData_LS_normd.to(device, dtype=torch.float)\n",
    "testData_LI_normd = testData_LI_normd.to(device, dtype=torch.float)\n",
    "H_true = H_true.to(device, dtype=torch.float)\n",
    "\n",
    "# Create a DataLoader for dataset\n",
    "test_dataset = TensorDataset(testData_LS_normd, testData_LI_normd, H_true)  # [nSamples, 2, 612, 14]\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/23\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'builtin_function_or_method' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m LS_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((LS_outputs_real, LS_outputs_imag), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# 32x2x612x14\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# De-normalized\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m LS_outputs_denormd \u001b[38;5;241m=\u001b[39m LS_outputs \u001b[38;5;241m*\u001b[39m (\u001b[43mtrainLabels_max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainLabels_min\u001b[49m) \u001b[38;5;241m+\u001b[39m trainLabels_min\n\u001b[1;32m     30\u001b[0m LS_outputs_complex \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcomplex(LS_outputs_real, LS_outputs_imag)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate the mean squared error\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'builtin_function_or_method' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "SNR = [0] # np.arange(0, 31, 5) # 0:5:30 dB\n",
    "average_nmse_LS_LI = []\n",
    "average_nmse_LI_NN = []\n",
    "average_nmse_LS_NN = []\n",
    "\n",
    "for snr in SNR:\n",
    "    with torch.no_grad():\n",
    "        nmse_LS_LI = []\n",
    "        nmse_LS_NN = []\n",
    "        nmse_LI_NN = []\n",
    "        for batch_idx, (LS_inputs, LI_inputs, test_targets) in enumerate(test_loader):\n",
    "            print(f\"Batch {batch_idx + 1}/{len(test_loader)}\")\n",
    "            \n",
    "            LS_inputs_real = LS_inputs[:,0,:,:].unsqueeze(1)\n",
    "            LS_inputs_imag = LS_inputs[:,1,:,:].unsqueeze(1)\n",
    "            \n",
    "            LI_inputs_real = LI_inputs[:,0,:,:].unsqueeze(1)\n",
    "            LI_inputs_imag = LI_inputs[:,1,:,:].unsqueeze(1)\n",
    "            \n",
    "            # Calculate the variance of the targets\n",
    "            test_targets_complex = torch.complex(test_targets[:,0,:,:], test_targets[:,1,:,:])\n",
    "            variance = torch.var(test_targets_complex)\n",
    "            \n",
    "            # NMSE of LS+NN\n",
    "            LS_outputs_real = model_LS_CNN(LS_inputs_real) # 32x1x612x14\n",
    "            LS_outputs_imag = model_LS_CNN(LS_inputs_imag) \n",
    "            LS_outputs = torch.cat((LS_outputs_real, LS_outputs_imag), dim=1) # 32x2x612x14\n",
    "            # De-normalized\n",
    "            LS_outputs_denormd = LS_outputs * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "            LS_outputs_complex = torch.complex(LS_outputs_real, LS_outputs_imag)\n",
    "            # Calculate the mean squared error\n",
    "            mse_LS_NN = torch.mean(torch.abs(test_targets_complex - LS_outputs_complex) ** 2)\n",
    "            nmse_LS_NN.append(mse_LS_NN / variance)\n",
    "            \n",
    "            # NMSE of LS+LI\n",
    "            # De-normalized\n",
    "            LS_LI_outputs_denormd = LI_inputs * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "            LS_LI_outputs_complex = torch.complex(LI_inputs[:,:,0,:], LI_inputs[:,:,1,:])\n",
    "            # Calculate the mean squared error\n",
    "            mse_LS_LI = torch.mean(torch.abs(test_targets_complex - LS_LI_outputs_complex) ** 2)\n",
    "            nmse_LS_LI.append(mse_LS_LI / variance)\n",
    "            \n",
    "            # NMSE of LS+LI+NN\n",
    "            LI_NN_outputs_real = model_LS_LI_CNN(LI_inputs_real)    # 32x1x612x14\n",
    "            LI_NN_outputs_imag = model_LS_LI_CNN(LI_inputs_imag)\n",
    "            LI_NN_outputs = torch.cat((LI_NN_outputs_real, LI_NN_outputs_imag), dim=1) # 32x2x612x14\n",
    "            # De-normalized\n",
    "            LI_NN_outputs_denormd = LI_NN_outputs * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "            LI_NN_outputs_complex = torch.complex(LI_NN_outputs_real, LI_NN_outputs_imag)\n",
    "            # Calculate the mean squared error\n",
    "            mse_LI_NN = torch.mean(torch.abs(test_targets_complex - LI_NN_outputs_complex) ** 2)\n",
    "            nmse_LI_NN.append(mse_LI_NN / variance)\n",
    "            \n",
    "        average_nmse_LS_LI.append(sum(nmse_LS_LI)/len(nmse_LS_LI))\n",
    "        average_nmse_LS_NN.append(sum(nmse_LS_NN)/len(nmse_LS_NN))\n",
    "        average_nmse_LI_NN.append(sum(nmse_LI_NN)/len(nmse_LI_NN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
