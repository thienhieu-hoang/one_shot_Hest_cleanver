{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver3_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver3_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# create readme.txt file\n",
    "content = \"\"\"Generated by file 'train/static_CNN_lr1e-5_v4_r3500_3516_3p4_instance_min_max.ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows 3500_3516,\n",
    "DeepMIMOv2/DeepMIMO_Dta_Static_BS16/freq_sym_1ant_612sub_ver4,\n",
    "Using min-max scaler for each sample\"\"\"\n",
    "\n",
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "\n",
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/20, Loss: 0.0812702713924092 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.020730934613807636\n",
      "SNR: 0/30, LS+LI, Epoch 2/20, Loss: 0.012764761026753762 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.009032018165188756\n",
      "SNR: 0/30, LS+LI, Epoch 3/20, Loss: 0.006078710778194025 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.003508613159118051\n",
      "SNR: 0/30, LS+LI, Epoch 4/20, Loss: 0.0019350983479959067 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.001311112184670161\n",
      "SNR: 0/30, LS+LI, Epoch 5/20, Loss: 0.0009242373555533176 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0007432343634057113\n",
      "SNR: 0/30, LS+LI, Epoch 6/20, Loss: 0.0005773833992100473 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0005075349935478615\n",
      "SNR: 0/30, LS+LI, Epoch 7/20, Loss: 0.00040687343341211764 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0003533607788002965\n",
      "SNR: 0/30, LS+LI, Epoch 8/20, Loss: 0.0002789718157653751 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0002471483081039465\n",
      "SNR: 0/30, LS+LI, Epoch 9/20, Loss: 0.00021809488164361155 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00020775213091507214\n",
      "SNR: 0/30, LS+LI, Epoch 10/20, Loss: 0.00018687326037040695 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.000183074276719708\n",
      "SNR: 0/30, LS+LI, Epoch 11/20, Loss: 0.00017191213386425706 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016927185325502333\n",
      "SNR: 0/30, LS+LI, Epoch 12/20, Loss: 0.00016161867473741485 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016081342519927685\n",
      "SNR: 0/30, LS+LI, Epoch 13/20, Loss: 0.00015470586896658778 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0001580700038837015\n",
      "SNR: 0/30, LS+LI, Epoch 14/20, Loss: 0.0001496969646321431 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0001520291787693912\n",
      "SNR: 0/30, LS+LI, Epoch 15/20, Loss: 0.0001434539223504713 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00014881010197727434\n",
      "SNR: 0/30, LS+LI, Epoch 16/20, Loss: 0.00013879420556233611 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00013893848881707527\n",
      "SNR: 0/30, LS+LI, Epoch 17/20, Loss: 0.0001355107102257492 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00013558555689418097\n",
      "SNR: 0/30, LS+LI, Epoch 18/20, Loss: 0.00013198096179579342 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0001319130893865473\n",
      "SNR: 0/30, LS+LI, Epoch 19/20, Loss: 0.00013011740744797525 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0001319375316432508\n",
      "SNR: 0/30, LS+LI, Epoch 20/20, Loss: 0.00012695854791165275 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00012819096049166876\n",
      "LS+LI NMSE: 0.08204425126314163\n",
      "LS+LI+CNN NMSE: 0.0057044182904064655\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/20, Loss: 0.11404223925282442 \n",
      "SNR: 0/30, LS, Val Loss: 0.03362443602897904\n",
      "SNR: 0/30, LS, Epoch 2/20, Loss: 0.02454565106999389 \n",
      "SNR: 0/30, LS, Val Loss: 0.02042114476419308\n",
      "SNR: 0/30, LS, Epoch 3/20, Loss: 0.018025384002993274 \n",
      "SNR: 0/30, LS, Val Loss: 0.01694095570763404\n",
      "SNR: 0/30, LS, Epoch 4/20, Loss: 0.012517229169282282 \n",
      "SNR: 0/30, LS, Val Loss: 0.007802076976407658\n",
      "SNR: 0/30, LS, Epoch 5/20, Loss: 0.0029733465699516887 \n",
      "SNR: 0/30, LS, Val Loss: 0.0010842924450778148\n",
      "SNR: 0/30, LS, Epoch 6/20, Loss: 0.0008491190735164077 \n",
      "SNR: 0/30, LS, Val Loss: 0.0007891834644727747\n",
      "SNR: 0/30, LS, Epoch 7/20, Loss: 0.0006900802002556427 \n",
      "SNR: 0/30, LS, Val Loss: 0.0006581508152356201\n",
      "SNR: 0/30, LS, Epoch 8/20, Loss: 0.0005907988958169034 \n",
      "SNR: 0/30, LS, Val Loss: 0.0005710613781543957\n",
      "SNR: 0/30, LS, Epoch 9/20, Loss: 0.0005168196725588681 \n",
      "SNR: 0/30, LS, Val Loss: 0.0005047539598308504\n",
      "SNR: 0/30, LS, Epoch 10/20, Loss: 0.0004624251048161843 \n",
      "SNR: 0/30, LS, Val Loss: 0.00045417601755947214\n",
      "SNR: 0/30, LS, Epoch 11/20, Loss: 0.0004176623262410854 \n",
      "SNR: 0/30, LS, Val Loss: 0.0004192530389197848\n",
      "SNR: 0/30, LS, Epoch 12/20, Loss: 0.0003869599487759758 \n",
      "SNR: 0/30, LS, Val Loss: 0.00038241778251672673\n",
      "SNR: 0/30, LS, Epoch 13/20, Loss: 0.0003621231686380735 \n",
      "SNR: 0/30, LS, Val Loss: 0.0003615867304192348\n",
      "SNR: 0/30, LS, Epoch 14/20, Loss: 0.0003466982532192433 \n",
      "SNR: 0/30, LS, Val Loss: 0.00035206198861653155\n",
      "SNR: 0/30, LS, Epoch 15/20, Loss: 0.0003302983704786531 \n",
      "SNR: 0/30, LS, Val Loss: 0.00033856697105379266\n",
      "SNR: 0/30, LS, Epoch 16/20, Loss: 0.0003210900176782161 \n",
      "SNR: 0/30, LS, Val Loss: 0.00032451119146902454\n",
      "SNR: 0/30, LS, Epoch 17/20, Loss: 0.0003098488149441627 \n",
      "SNR: 0/30, LS, Val Loss: 0.0003353891449726441\n",
      "SNR: 0/30, LS, Epoch 18/20, Loss: 0.0003020362382812891 \n",
      "SNR: 0/30, LS, Val Loss: 0.0003035953116275116\n",
      "SNR: 0/30, LS, Epoch 19/20, Loss: 0.00029571679074568997 \n",
      "SNR: 0/30, LS, Val Loss: 0.00031208397294077173\n",
      "SNR: 0/30, LS, Epoch 20/20, Loss: 0.00028570652783707563 \n",
      "SNR: 0/30, LS, Val Loss: 0.00029249862365593964\n",
      "LS+CNN NMSE: 0.01292248535901308\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/20, Loss: 0.08681140844385292 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.019485903057185085\n",
      "SNR: 5/30, LS+LI, Epoch 2/20, Loss: 0.00971320582835307 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.003947652971626006\n",
      "SNR: 5/30, LS+LI, Epoch 3/20, Loss: 0.0016962680593403706 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.000965969562953846\n",
      "SNR: 5/30, LS+LI, Epoch 4/20, Loss: 0.0007180017016443619 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0005980473083168777\n",
      "SNR: 5/30, LS+LI, Epoch 5/20, Loss: 0.00045361680159383173 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00038218127420722425\n",
      "SNR: 5/30, LS+LI, Epoch 6/20, Loss: 0.000299250258459049 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00026438949796349994\n",
      "SNR: 5/30, LS+LI, Epoch 7/20, Loss: 0.00020520504598565357 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00018655054009286687\n",
      "SNR: 5/30, LS+LI, Epoch 8/20, Loss: 0.0001536969704703065 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0001490702125011012\n",
      "SNR: 5/30, LS+LI, Epoch 9/20, Loss: 0.0001243242033186022 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00012392083689602177\n",
      "SNR: 5/30, LS+LI, Epoch 10/20, Loss: 0.00010484726247573976 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00010467078523519872\n",
      "SNR: 5/30, LS+LI, Epoch 11/20, Loss: 9.215003801939527e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 9.43365794228157e-05\n",
      "SNR: 5/30, LS+LI, Epoch 12/20, Loss: 8.204440625779043e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 8.310105262022593e-05\n",
      "SNR: 5/30, LS+LI, Epoch 13/20, Loss: 7.313470359804342e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 7.570844983010002e-05\n",
      "SNR: 5/30, LS+LI, Epoch 14/20, Loss: 6.690186665066501e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 6.940806832228026e-05\n",
      "SNR: 5/30, LS+LI, Epoch 15/20, Loss: 6.256039155549694e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 6.602324190845883e-05\n",
      "SNR: 5/30, LS+LI, Epoch 16/20, Loss: 5.896648326597642e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 6.242588807998055e-05\n",
      "SNR: 5/30, LS+LI, Epoch 17/20, Loss: 5.652762055708377e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.9951374417075634e-05\n",
      "SNR: 5/30, LS+LI, Epoch 18/20, Loss: 5.380396481107942e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.656010100872002e-05\n",
      "SNR: 5/30, LS+LI, Epoch 19/20, Loss: 5.221107113716561e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.4853432381853715e-05\n",
      "SNR: 5/30, LS+LI, Epoch 20/20, Loss: 5.023941814088598e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.283162384082309e-05\n",
      "LS+LI NMSE: 0.02582520805299282\n",
      "LS+LI+CNN NMSE: 0.0023429400753229856\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/20, Loss: 0.1093774729971449 \n",
      "SNR: 5/30, LS, Val Loss: 0.03483299182897264\n",
      "SNR: 5/30, LS, Epoch 2/20, Loss: 0.025052709504961967 \n",
      "SNR: 5/30, LS, Val Loss: 0.020917885852130978\n",
      "SNR: 5/30, LS, Epoch 3/20, Loss: 0.019022491376110635 \n",
      "SNR: 5/30, LS, Val Loss: 0.018724733116951855\n",
      "SNR: 5/30, LS, Epoch 4/20, Loss: 0.015597916045767624 \n",
      "SNR: 5/30, LS, Val Loss: 0.012954297687181017\n",
      "SNR: 5/30, LS, Epoch 5/20, Loss: 0.007525418424805583 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031143457745201886\n",
      "SNR: 5/30, LS, Epoch 6/20, Loss: 0.0014266754983826865 \n",
      "SNR: 5/30, LS, Val Loss: 0.0009384934779849242\n",
      "SNR: 5/30, LS, Epoch 7/20, Loss: 0.0007329617544391387 \n",
      "SNR: 5/30, LS, Val Loss: 0.0006632795491234654\n",
      "SNR: 5/30, LS, Epoch 8/20, Loss: 0.0005433620605143978 \n",
      "SNR: 5/30, LS, Val Loss: 0.0004950042824599553\n",
      "SNR: 5/30, LS, Epoch 9/20, Loss: 0.00041214575389329734 \n",
      "SNR: 5/30, LS, Val Loss: 0.00039563689378238365\n",
      "SNR: 5/30, LS, Epoch 10/20, Loss: 0.00034082378133885063 \n",
      "SNR: 5/30, LS, Val Loss: 0.0003310575590479526\n",
      "SNR: 5/30, LS, Epoch 11/20, Loss: 0.0002886009163820174 \n",
      "SNR: 5/30, LS, Val Loss: 0.00028413880764591425\n",
      "SNR: 5/30, LS, Epoch 12/20, Loss: 0.0002485773017491907 \n",
      "SNR: 5/30, LS, Val Loss: 0.00024471162429439244\n",
      "SNR: 5/30, LS, Epoch 13/20, Loss: 0.00021868802625333976 \n",
      "SNR: 5/30, LS, Val Loss: 0.00021824823621004313\n",
      "SNR: 5/30, LS, Epoch 14/20, Loss: 0.00019619849364633325 \n",
      "SNR: 5/30, LS, Val Loss: 0.00019854847745260815\n",
      "SNR: 5/30, LS, Epoch 15/20, Loss: 0.00018029095114142427 \n",
      "SNR: 5/30, LS, Val Loss: 0.00018471079436659983\n",
      "SNR: 5/30, LS, Epoch 16/20, Loss: 0.00016759111404521823 \n",
      "SNR: 5/30, LS, Val Loss: 0.00017369444255812348\n",
      "SNR: 5/30, LS, Epoch 17/20, Loss: 0.00015889941045485145 \n",
      "SNR: 5/30, LS, Val Loss: 0.0001630142528897109\n",
      "SNR: 5/30, LS, Epoch 18/20, Loss: 0.00015247316493281857 \n",
      "SNR: 5/30, LS, Val Loss: 0.000156308787237239\n",
      "SNR: 5/30, LS, Epoch 19/20, Loss: 0.00014529403254760667 \n",
      "SNR: 5/30, LS, Val Loss: 0.0001508988243585918\n",
      "SNR: 5/30, LS, Epoch 20/20, Loss: 0.00014402647693079713 \n",
      "SNR: 5/30, LS, Val Loss: 0.0001480394719030962\n",
      "LS+CNN NMSE: 0.006567730102688074\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/20, Loss: 0.0916543240106643 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.015009265054355968\n",
      "SNR: 10/30, LS+LI, Epoch 2/20, Loss: 0.004548092910121087 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0011524373760700903\n",
      "SNR: 10/30, LS+LI, Epoch 3/20, Loss: 0.0007633493347215293 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0005481705672784963\n",
      "SNR: 10/30, LS+LI, Epoch 4/20, Loss: 0.00042582581616358746 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0003220668070505119\n",
      "SNR: 10/30, LS+LI, Epoch 5/20, Loss: 0.00026015849238488994 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0002023395129733465\n",
      "SNR: 10/30, LS+LI, Epoch 6/20, Loss: 0.00017062151100828994 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00013639573245944285\n",
      "SNR: 10/30, LS+LI, Epoch 7/20, Loss: 0.00011991031199211775 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0001020214552805886\n",
      "SNR: 10/30, LS+LI, Epoch 8/20, Loss: 9.369509817313587e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 8.255772594235499e-05\n",
      "SNR: 10/30, LS+LI, Epoch 9/20, Loss: 7.708403173574181e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 6.930801282578614e-05\n",
      "SNR: 10/30, LS+LI, Epoch 10/20, Loss: 6.49703400741537e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 5.876623832922302e-05\n",
      "SNR: 10/30, LS+LI, Epoch 11/20, Loss: 5.6123418564607695e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 5.228377879327375e-05\n",
      "SNR: 10/30, LS+LI, Epoch 12/20, Loss: 4.933892963636872e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 4.524280021459245e-05\n",
      "SNR: 10/30, LS+LI, Epoch 13/20, Loss: 4.379387265480757e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 4.0632762234467506e-05\n",
      "SNR: 10/30, LS+LI, Epoch 14/20, Loss: 3.9527359445475117e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.639310373480178e-05\n",
      "SNR: 10/30, LS+LI, Epoch 15/20, Loss: 3.583880577427281e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.3313227917956695e-05\n",
      "SNR: 10/30, LS+LI, Epoch 16/20, Loss: 3.273772389822921e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.0405145067065447e-05\n",
      "SNR: 10/30, LS+LI, Epoch 17/20, Loss: 3.0174448109518868e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.804968037459978e-05\n",
      "SNR: 10/30, LS+LI, Epoch 18/20, Loss: 2.7816388410428772e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.62712915586731e-05\n",
      "SNR: 10/30, LS+LI, Epoch 19/20, Loss: 2.5741592136994788e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.4125005190646995e-05\n",
      "SNR: 10/30, LS+LI, Epoch 20/20, Loss: 2.4100124360408042e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.2975662266782653e-05\n",
      "LS+LI NMSE: 0.008204040117561817\n",
      "LS+LI+CNN NMSE: 0.001096115680411458\n",
      " Training for LS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14873/356020929.py:251: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 10/30, LS, Epoch 1/20, Loss: 0.07184783547986733 \n",
      "SNR: 10/30, LS, Val Loss: 0.027561669999902897\n",
      "SNR: 10/30, LS, Epoch 2/20, Loss: 0.02152283821623166 \n",
      "SNR: 10/30, LS, Val Loss: 0.017852712380276484\n",
      "SNR: 10/30, LS, Epoch 3/20, Loss: 0.015407361999847168 \n",
      "SNR: 10/30, LS, Val Loss: 0.010695408246564593\n",
      "SNR: 10/30, LS, Epoch 4/20, Loss: 0.0049010094327630125 \n",
      "SNR: 10/30, LS, Val Loss: 0.0010495187201410192\n",
      "SNR: 10/30, LS, Epoch 5/20, Loss: 0.0007918711965240343 \n",
      "SNR: 10/30, LS, Val Loss: 0.0005887817863946442\n",
      "SNR: 10/30, LS, Epoch 6/20, Loss: 0.00048742112148618107 \n",
      "SNR: 10/30, LS, Val Loss: 0.00037348341059193694\n",
      "SNR: 10/30, LS, Epoch 7/20, Loss: 0.0003325679973322833 \n",
      "SNR: 10/30, LS, Val Loss: 0.0002770819264696911\n",
      "SNR: 10/30, LS, Epoch 8/20, Loss: 0.0002494180966899622 \n",
      "SNR: 10/30, LS, Val Loss: 0.00020723290667361155\n",
      "SNR: 10/30, LS, Epoch 9/20, Loss: 0.00018978399350808739 \n",
      "SNR: 10/30, LS, Val Loss: 0.0001614784268895164\n",
      "SNR: 10/30, LS, Epoch 10/20, Loss: 0.00015647264411009653 \n",
      "SNR: 10/30, LS, Val Loss: 0.00013664562952313148\n",
      "SNR: 10/30, LS, Epoch 11/20, Loss: 0.0001347518160020077 \n",
      "SNR: 10/30, LS, Val Loss: 0.00012012694754627195\n",
      "SNR: 10/30, LS, Epoch 12/20, Loss: 0.00011963093222516892 \n",
      "SNR: 10/30, LS, Val Loss: 0.00010771066312868656\n",
      "SNR: 10/30, LS, Epoch 13/20, Loss: 0.00010859744344448108 \n",
      "SNR: 10/30, LS, Val Loss: 9.828273257219486e-05\n",
      "SNR: 10/30, LS, Epoch 14/20, Loss: 0.0001009965099635951 \n",
      "SNR: 10/30, LS, Val Loss: 9.254917081720619e-05\n",
      "SNR: 10/30, LS, Epoch 15/20, Loss: 9.240146099791462e-05 \n",
      "SNR: 10/30, LS, Val Loss: 8.43433349059937e-05\n",
      "SNR: 10/30, LS, Epoch 16/20, Loss: 8.582914070693943e-05 \n",
      "SNR: 10/30, LS, Val Loss: 8.680239658464085e-05\n",
      "SNR: 10/30, LS, Epoch 17/20, Loss: 7.968161102072308e-05 \n",
      "SNR: 10/30, LS, Val Loss: 7.241969764105637e-05\n",
      "SNR: 10/30, LS, Epoch 18/20, Loss: 7.284937376869832e-05 \n",
      "SNR: 10/30, LS, Val Loss: 7.438817308204968e-05\n",
      "SNR: 10/30, LS, Epoch 19/20, Loss: 6.954144951017698e-05 \n",
      "SNR: 10/30, LS, Val Loss: 6.070395002924752e-05\n",
      "SNR: 10/30, LS, Epoch 20/20, Loss: 6.198257482918602e-05 \n",
      "SNR: 10/30, LS, Val Loss: 5.897825096987865e-05\n",
      "LS+CNN NMSE: 0.0027817883528769016\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/20, Loss: 0.10954519675308189 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.014100802046331492\n",
      "SNR: 15/30, LS+LI, Epoch 2/20, Loss: 0.005116869873830204 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0009230567428114062\n",
      "SNR: 15/30, LS+LI, Epoch 3/20, Loss: 0.000583142647587391 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0004265196714021096\n",
      "SNR: 15/30, LS+LI, Epoch 4/20, Loss: 0.0003452467712503316 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00025397986147171736\n",
      "SNR: 15/30, LS+LI, Epoch 5/20, Loss: 0.00020051608213222163 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00014548415823479775\n",
      "SNR: 15/30, LS+LI, Epoch 6/20, Loss: 0.00012180715693407258 \n",
      "SNR: 15/30, LS+LI, Val Loss: 9.619023859903047e-05\n",
      "SNR: 15/30, LS+LI, Epoch 7/20, Loss: 8.73736576385306e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 7.362696107355242e-05\n",
      "SNR: 15/30, LS+LI, Epoch 8/20, Loss: 6.659593190158565e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 5.563779152659911e-05\n",
      "SNR: 15/30, LS+LI, Epoch 9/20, Loss: 5.016268259232463e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 4.17682688500711e-05\n",
      "SNR: 15/30, LS+LI, Epoch 10/20, Loss: 3.7974566196701976e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 3.1642573379609864e-05\n",
      "SNR: 15/30, LS+LI, Epoch 11/20, Loss: 2.941735739261995e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 2.4846112038093533e-05\n",
      "SNR: 15/30, LS+LI, Epoch 12/20, Loss: 2.35790146499037e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 2.021579021774497e-05\n",
      "SNR: 15/30, LS+LI, Epoch 13/20, Loss: 1.951225499396969e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.692505272578935e-05\n",
      "SNR: 15/30, LS+LI, Epoch 14/20, Loss: 1.6454015902254047e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.4238470240260623e-05\n",
      "SNR: 15/30, LS+LI, Epoch 15/20, Loss: 1.398094380864106e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.217726085914447e-05\n",
      "SNR: 15/30, LS+LI, Epoch 16/20, Loss: 1.2066223372278537e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.0537852073288047e-05\n",
      "SNR: 15/30, LS+LI, Epoch 17/20, Loss: 1.0634323260536232e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 9.405551901925884e-06\n",
      "SNR: 15/30, LS+LI, Epoch 18/20, Loss: 9.55054695380166e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 8.456999466943671e-06\n",
      "SNR: 15/30, LS+LI, Epoch 19/20, Loss: 8.748378543841258e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 7.858171308974057e-06\n",
      "SNR: 15/30, LS+LI, Epoch 20/20, Loss: 8.173630822797308e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 7.373798036331374e-06\n",
      "LS+LI NMSE: 0.0025981953367590904\n",
      "LS+LI+CNN NMSE: 0.00035731433308683336\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/20, Loss: 0.11621042000952848 \n",
      "SNR: 15/30, LS, Val Loss: 0.03264521096240391\n",
      "SNR: 15/30, LS, Epoch 2/20, Loss: 0.024533629828934058 \n",
      "SNR: 15/30, LS, Val Loss: 0.018764006185599348\n",
      "SNR: 15/30, LS, Epoch 3/20, Loss: 0.018794215777022547 \n",
      "SNR: 15/30, LS, Val Loss: 0.016285943692888726\n",
      "SNR: 15/30, LS, Epoch 4/20, Loss: 0.014976577882026864 \n",
      "SNR: 15/30, LS, Val Loss: 0.010621539592234925\n",
      "SNR: 15/30, LS, Epoch 5/20, Loss: 0.006089239984988993 \n",
      "SNR: 15/30, LS, Val Loss: 0.0019098921382630413\n",
      "SNR: 15/30, LS, Epoch 6/20, Loss: 0.0012014449606541284 \n",
      "SNR: 15/30, LS, Val Loss: 0.0008406971914651381\n",
      "SNR: 15/30, LS, Epoch 7/20, Loss: 0.0006868324361316492 \n",
      "SNR: 15/30, LS, Val Loss: 0.000518215067462403\n",
      "SNR: 15/30, LS, Epoch 8/20, Loss: 0.0004748941817440006 \n",
      "SNR: 15/30, LS, Val Loss: 0.000368890972987918\n",
      "SNR: 15/30, LS, Epoch 9/20, Loss: 0.0003421432304813332 \n",
      "SNR: 15/30, LS, Val Loss: 0.00027306815900374204\n",
      "SNR: 15/30, LS, Epoch 10/20, Loss: 0.0002534829560148822 \n",
      "SNR: 15/30, LS, Val Loss: 0.00020343550865866499\n",
      "SNR: 15/30, LS, Epoch 11/20, Loss: 0.0001935167936946612 \n",
      "SNR: 15/30, LS, Val Loss: 0.0001553901493025478\n",
      "SNR: 15/30, LS, Epoch 12/20, Loss: 0.0001542279163025574 \n",
      "SNR: 15/30, LS, Val Loss: 0.00012974613160953265\n",
      "SNR: 15/30, LS, Epoch 13/20, Loss: 0.00012750523836625372 \n",
      "SNR: 15/30, LS, Val Loss: 0.00010886279778787866\n",
      "SNR: 15/30, LS, Epoch 14/20, Loss: 0.00010925443606284652 \n",
      "SNR: 15/30, LS, Val Loss: 9.44081948546227e-05\n",
      "SNR: 15/30, LS, Epoch 15/20, Loss: 9.763526615516153e-05 \n",
      "SNR: 15/30, LS, Val Loss: 8.458092336447656e-05\n",
      "SNR: 15/30, LS, Epoch 16/20, Loss: 8.48955667733694e-05 \n",
      "SNR: 15/30, LS, Val Loss: 8.59405312935864e-05\n",
      "SNR: 15/30, LS, Epoch 17/20, Loss: 7.732731790933623e-05 \n",
      "SNR: 15/30, LS, Val Loss: 6.57908589015609e-05\n",
      "SNR: 15/30, LS, Epoch 18/20, Loss: 6.849368035249808e-05 \n",
      "SNR: 15/30, LS, Val Loss: 5.9106178510277957e-05\n",
      "SNR: 15/30, LS, Epoch 19/20, Loss: 6.356276427923572e-05 \n",
      "SNR: 15/30, LS, Val Loss: 5.4647826221877373e-05\n",
      "SNR: 15/30, LS, Epoch 20/20, Loss: 6.0246876760069174e-05 \n",
      "SNR: 15/30, LS, Val Loss: 5.0230166214698165e-05\n",
      "LS+CNN NMSE: 0.0024335472844541073\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/20, Loss: 0.07824989596143538 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.012912348717112433\n",
      "SNR: 20/30, LS+LI, Epoch 2/20, Loss: 0.004682204525695767 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001022586847697808\n",
      "SNR: 20/30, LS+LI, Epoch 3/20, Loss: 0.0005988903771097728 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0003898915429917079\n",
      "SNR: 20/30, LS+LI, Epoch 4/20, Loss: 0.00031483802216149173 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0002476804121132855\n",
      "SNR: 20/30, LS+LI, Epoch 5/20, Loss: 0.0001869494687504579 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00013564637133227237\n",
      "SNR: 20/30, LS+LI, Epoch 6/20, Loss: 0.00010959380580420974 \n",
      "SNR: 20/30, LS+LI, Val Loss: 9.011425804188052e-05\n",
      "SNR: 20/30, LS+LI, Epoch 7/20, Loss: 7.97886880105199e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 7.016804325262042e-05\n",
      "SNR: 20/30, LS+LI, Epoch 8/20, Loss: 6.320188149825405e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 5.6506138207623735e-05\n",
      "SNR: 20/30, LS+LI, Epoch 9/20, Loss: 5.09134326928815e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.4814806229127996e-05\n",
      "SNR: 20/30, LS+LI, Epoch 10/20, Loss: 3.910723433702599e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 3.3720961834081784e-05\n",
      "SNR: 20/30, LS+LI, Epoch 11/20, Loss: 2.962653424706226e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 2.585837542441864e-05\n",
      "SNR: 20/30, LS+LI, Epoch 12/20, Loss: 2.2283307940639598e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.9353888174836438e-05\n",
      "SNR: 20/30, LS+LI, Epoch 13/20, Loss: 1.6915220464588222e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.5023906929524276e-05\n",
      "SNR: 20/30, LS+LI, Epoch 14/20, Loss: 1.3333732922123894e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.2079645867660558e-05\n",
      "SNR: 20/30, LS+LI, Epoch 15/20, Loss: 1.0811240113176863e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 9.926476609094111e-06\n",
      "SNR: 20/30, LS+LI, Epoch 16/20, Loss: 8.954154763223203e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 8.444330019714966e-06\n",
      "SNR: 20/30, LS+LI, Epoch 17/20, Loss: 7.5452575042300995e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 7.098284620290294e-06\n",
      "SNR: 20/30, LS+LI, Epoch 18/20, Loss: 6.454250603573475e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 6.114048801464378e-06\n",
      "SNR: 20/30, LS+LI, Epoch 19/20, Loss: 5.609446980299761e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 5.379560269085976e-06\n",
      "SNR: 20/30, LS+LI, Epoch 20/20, Loss: 4.9978044354395744e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.8604114123339635e-06\n",
      "LS+LI NMSE: 0.0008193871472030878\n",
      "LS+LI+CNN NMSE: 0.0002212731196777895\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/20, Loss: 0.10752637257669555 \n",
      "SNR: 20/30, LS, Val Loss: 0.02997798023914749\n",
      "SNR: 20/30, LS, Epoch 2/20, Loss: 0.021814554945977276 \n",
      "SNR: 20/30, LS, Val Loss: 0.018867323513735424\n",
      "SNR: 20/30, LS, Epoch 3/20, Loss: 0.01573080903590592 \n",
      "SNR: 20/30, LS, Val Loss: 0.013034402435137466\n",
      "SNR: 20/30, LS, Epoch 4/20, Loss: 0.007703357001192608 \n",
      "SNR: 20/30, LS, Val Loss: 0.003439830340953036\n",
      "SNR: 20/30, LS, Epoch 5/20, Loss: 0.0018326138473808938 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012685209830206904\n",
      "SNR: 20/30, LS, Epoch 6/20, Loss: 0.0009398539185112472 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008090169258966026\n",
      "SNR: 20/30, LS, Epoch 7/20, Loss: 0.0006629910196859909 \n",
      "SNR: 20/30, LS, Val Loss: 0.0005884573779026555\n",
      "SNR: 20/30, LS, Epoch 8/20, Loss: 0.0004920953316857691 \n",
      "SNR: 20/30, LS, Val Loss: 0.0004362861628496003\n",
      "SNR: 20/30, LS, Epoch 9/20, Loss: 0.0003604659417083725 \n",
      "SNR: 20/30, LS, Val Loss: 0.0003247354841071435\n",
      "SNR: 20/30, LS, Epoch 10/20, Loss: 0.0002775858320515105 \n",
      "SNR: 20/30, LS, Val Loss: 0.00025948745182673025\n",
      "SNR: 20/30, LS, Epoch 11/20, Loss: 0.000225798813622786 \n",
      "SNR: 20/30, LS, Val Loss: 0.00021615069338374516\n",
      "SNR: 20/30, LS, Epoch 12/20, Loss: 0.00019116171562589358 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001866189433547499\n",
      "SNR: 20/30, LS, Epoch 13/20, Loss: 0.00016687826170054058 \n",
      "SNR: 20/30, LS, Val Loss: 0.00016509220652303404\n",
      "SNR: 20/30, LS, Epoch 14/20, Loss: 0.00014855583977742057 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001480389867290135\n",
      "SNR: 20/30, LS, Epoch 15/20, Loss: 0.00013366154438022762 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001337468555985569\n",
      "SNR: 20/30, LS, Epoch 16/20, Loss: 0.0001189518897749516 \n",
      "SNR: 20/30, LS, Val Loss: 0.00012125174775560895\n",
      "SNR: 20/30, LS, Epoch 17/20, Loss: 0.00010837442189154518 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001100687550206203\n",
      "SNR: 20/30, LS, Epoch 18/20, Loss: 9.964344953491385e-05 \n",
      "SNR: 20/30, LS, Val Loss: 0.00010192709570136768\n",
      "SNR: 20/30, LS, Epoch 19/20, Loss: 9.33869351197351e-05 \n",
      "SNR: 20/30, LS, Val Loss: 9.532338133960201e-05\n",
      "SNR: 20/30, LS, Epoch 20/20, Loss: 8.468777096548069e-05 \n",
      "SNR: 20/30, LS, Val Loss: 8.617716131001626e-05\n",
      "LS+CNN NMSE: 0.00385263841599226\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/20, Loss: 0.10083094934478055 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.016794701445509087\n",
      "SNR: 25/30, LS+LI, Epoch 2/20, Loss: 0.006657696759184758 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008387278992979026\n",
      "SNR: 25/30, LS+LI, Epoch 3/20, Loss: 0.0005124587485117318 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004148724269312383\n",
      "SNR: 25/30, LS+LI, Epoch 4/20, Loss: 0.00033487757460788154 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00027775221017443323\n",
      "SNR: 25/30, LS+LI, Epoch 5/20, Loss: 0.00021605080076179272 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0001634019030131061\n",
      "SNR: 25/30, LS+LI, Epoch 6/20, Loss: 0.00011896759945578429 \n",
      "SNR: 25/30, LS+LI, Val Loss: 8.837675440273333e-05\n",
      "SNR: 25/30, LS+LI, Epoch 7/20, Loss: 7.403380006804201e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 6.349927819180515e-05\n",
      "SNR: 25/30, LS+LI, Epoch 8/20, Loss: 5.57683847863552e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 4.860775615353222e-05\n",
      "SNR: 25/30, LS+LI, Epoch 9/20, Loss: 4.3396244151619274e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 3.813857950841669e-05\n",
      "SNR: 25/30, LS+LI, Epoch 10/20, Loss: 3.42235615218754e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 3.01053258391965e-05\n",
      "SNR: 25/30, LS+LI, Epoch 11/20, Loss: 2.69954449153332e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 2.3509506056804888e-05\n",
      "SNR: 25/30, LS+LI, Epoch 12/20, Loss: 2.10168712561257e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.8295943763488058e-05\n",
      "SNR: 25/30, LS+LI, Epoch 13/20, Loss: 1.6360180515496108e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.4273208431735508e-05\n",
      "SNR: 25/30, LS+LI, Epoch 14/20, Loss: 1.2812166412617824e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.1413346659206912e-05\n",
      "SNR: 25/30, LS+LI, Epoch 15/20, Loss: 1.0128937484021367e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 8.98818044251212e-06\n",
      "SNR: 25/30, LS+LI, Epoch 16/20, Loss: 8.123019203467689e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 7.281364415493127e-06\n",
      "SNR: 25/30, LS+LI, Epoch 17/20, Loss: 6.613359399252235e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 6.086723157171615e-06\n",
      "SNR: 25/30, LS+LI, Epoch 18/20, Loss: 5.537652869798178e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 5.0751505940835076e-06\n",
      "SNR: 25/30, LS+LI, Epoch 19/20, Loss: 4.699408391441593e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 4.403829455606518e-06\n",
      "SNR: 25/30, LS+LI, Epoch 20/20, Loss: 4.0649373286320294e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 3.878537923314567e-06\n",
      "LS+LI NMSE: 0.00026034945040009916\n",
      "LS+LI+CNN NMSE: 0.00016704201698303223\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/20, Loss: 0.09694370931707495 \n",
      "SNR: 25/30, LS, Val Loss: 0.031983874907547775\n",
      "SNR: 25/30, LS, Epoch 2/20, Loss: 0.021805754369991118 \n",
      "SNR: 25/30, LS, Val Loss: 0.0196616742759943\n",
      "SNR: 25/30, LS, Epoch 3/20, Loss: 0.014507475108731278 \n",
      "SNR: 25/30, LS, Val Loss: 0.010406601285053925\n",
      "SNR: 25/30, LS, Epoch 4/20, Loss: 0.0038102784060039235 \n",
      "SNR: 25/30, LS, Val Loss: 0.000972052348184992\n",
      "SNR: 25/30, LS, Epoch 5/20, Loss: 0.0006665808072876791 \n",
      "SNR: 25/30, LS, Val Loss: 0.000580402165227993\n",
      "SNR: 25/30, LS, Epoch 6/20, Loss: 0.0004585394537655723 \n",
      "SNR: 25/30, LS, Val Loss: 0.00042273102338764477\n",
      "SNR: 25/30, LS, Epoch 7/20, Loss: 0.000330086426148164 \n",
      "SNR: 25/30, LS, Val Loss: 0.00029553434763908047\n",
      "SNR: 25/30, LS, Epoch 8/20, Loss: 0.00023686918406341182 \n",
      "SNR: 25/30, LS, Val Loss: 0.00022654381080594084\n",
      "SNR: 25/30, LS, Epoch 9/20, Loss: 0.00018283088261235862 \n",
      "SNR: 25/30, LS, Val Loss: 0.00017267878138227388\n",
      "SNR: 25/30, LS, Epoch 10/20, Loss: 0.00014519417738991379 \n",
      "SNR: 25/30, LS, Val Loss: 0.0001494787115503145\n",
      "SNR: 25/30, LS, Epoch 11/20, Loss: 0.00012249946612005155 \n",
      "SNR: 25/30, LS, Val Loss: 0.00011843909570333463\n",
      "SNR: 25/30, LS, Epoch 12/20, Loss: 0.00010680501272449768 \n",
      "SNR: 25/30, LS, Val Loss: 0.00010561644839154641\n",
      "SNR: 25/30, LS, Epoch 13/20, Loss: 9.641407793191488e-05 \n",
      "SNR: 25/30, LS, Val Loss: 9.900122677208856e-05\n",
      "SNR: 25/30, LS, Epoch 14/20, Loss: 8.914579524740517e-05 \n",
      "SNR: 25/30, LS, Val Loss: 9.559173221615228e-05\n",
      "SNR: 25/30, LS, Epoch 15/20, Loss: 8.344039682459308e-05 \n",
      "SNR: 25/30, LS, Val Loss: 8.306651712204753e-05\n",
      "SNR: 25/30, LS, Epoch 16/20, Loss: 7.847348688512791e-05 \n",
      "SNR: 25/30, LS, Val Loss: 7.975593061101708e-05\n",
      "SNR: 25/30, LS, Epoch 17/20, Loss: 7.254362292790807e-05 \n",
      "SNR: 25/30, LS, Val Loss: 7.623303694841029e-05\n",
      "SNR: 25/30, LS, Epoch 18/20, Loss: 6.936202175153127e-05 \n",
      "SNR: 25/30, LS, Val Loss: 6.854547163212291e-05\n",
      "SNR: 25/30, LS, Epoch 19/20, Loss: 6.485401168309942e-05 \n",
      "SNR: 25/30, LS, Val Loss: 6.41098581995307e-05\n",
      "SNR: 25/30, LS, Epoch 20/20, Loss: 6.203369316925852e-05 \n",
      "SNR: 25/30, LS, Val Loss: 6.226319832917811e-05\n",
      "LS+CNN NMSE: 0.0026301085017621517\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/20, Loss: 0.08845843680116326 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.016055837908590383\n",
      "SNR: 30/30, LS+LI, Epoch 2/20, Loss: 0.007046645185043819 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.001139658667274158\n",
      "SNR: 30/30, LS+LI, Epoch 3/20, Loss: 0.0005642883117489387 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003484327700624073\n",
      "SNR: 30/30, LS+LI, Epoch 4/20, Loss: 0.00029371251315920784 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002062707889391194\n",
      "SNR: 30/30, LS+LI, Epoch 5/20, Loss: 0.0001541809787192696 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00010263254344780844\n",
      "SNR: 30/30, LS+LI, Epoch 6/20, Loss: 8.753202674534106e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 7.053320454856889e-05\n",
      "SNR: 30/30, LS+LI, Epoch 7/20, Loss: 6.609942188650927e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 5.624143242047549e-05\n",
      "SNR: 30/30, LS+LI, Epoch 8/20, Loss: 5.37104362254383e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 4.6258800383921795e-05\n",
      "SNR: 30/30, LS+LI, Epoch 9/20, Loss: 4.424514766067786e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 3.8128948455612935e-05\n",
      "SNR: 30/30, LS+LI, Epoch 10/20, Loss: 3.6022407140651835e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 3.0055938953988846e-05\n",
      "SNR: 30/30, LS+LI, Epoch 11/20, Loss: 2.7832611934616918e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 2.296531337461519e-05\n",
      "SNR: 30/30, LS+LI, Epoch 12/20, Loss: 2.1485978640009496e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.8067461827410046e-05\n",
      "SNR: 30/30, LS+LI, Epoch 13/20, Loss: 1.7036896927725878e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.438670051356894e-05\n",
      "SNR: 30/30, LS+LI, Epoch 14/20, Loss: 1.3783720072920956e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.17345376069848e-05\n",
      "SNR: 30/30, LS+LI, Epoch 15/20, Loss: 1.1273130619587771e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 9.60422436368059e-06\n",
      "SNR: 30/30, LS+LI, Epoch 16/20, Loss: 9.280290100832644e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 7.980545640087009e-06\n",
      "SNR: 30/30, LS+LI, Epoch 17/20, Loss: 7.681747624066997e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 6.5899796068565175e-06\n",
      "SNR: 30/30, LS+LI, Epoch 18/20, Loss: 6.430995302591412e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 5.561494059623907e-06\n",
      "SNR: 30/30, LS+LI, Epoch 19/20, Loss: 5.4643129249936546e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 4.748775960582531e-06\n",
      "SNR: 30/30, LS+LI, Epoch 20/20, Loss: 4.692450127729602e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 4.105442681892865e-06\n",
      "LS+LI NMSE: 8.275514846900478e-05\n",
      "LS+LI+CNN NMSE: 0.0001966974523384124\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/20, Loss: 0.10456707431436625 \n",
      "SNR: 30/30, LS, Val Loss: 0.0315285005860708\n",
      "SNR: 30/30, LS, Epoch 2/20, Loss: 0.023925500651171733 \n",
      "SNR: 30/30, LS, Val Loss: 0.018246326680210503\n",
      "SNR: 30/30, LS, Epoch 3/20, Loss: 0.017517465605335528 \n",
      "SNR: 30/30, LS, Val Loss: 0.014214250640096989\n",
      "SNR: 30/30, LS, Epoch 4/20, Loss: 0.010485137422937293 \n",
      "SNR: 30/30, LS, Val Loss: 0.004589674761518836\n",
      "SNR: 30/30, LS, Epoch 5/20, Loss: 0.0024183370040318126 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012630924095653675\n",
      "SNR: 30/30, LS, Epoch 6/20, Loss: 0.000875222245583224 \n",
      "SNR: 30/30, LS, Val Loss: 0.000540986997128295\n",
      "SNR: 30/30, LS, Epoch 7/20, Loss: 0.00043283687519697406 \n",
      "SNR: 30/30, LS, Val Loss: 0.0003074677244347351\n",
      "SNR: 30/30, LS, Epoch 8/20, Loss: 0.00026441579816597623 \n",
      "SNR: 30/30, LS, Val Loss: 0.00020126710858841596\n",
      "SNR: 30/30, LS, Epoch 9/20, Loss: 0.00018512306100049945 \n",
      "SNR: 30/30, LS, Val Loss: 0.00015137617810978554\n",
      "SNR: 30/30, LS, Epoch 10/20, Loss: 0.00014528878742820842 \n",
      "SNR: 30/30, LS, Val Loss: 0.00012556323732000735\n",
      "SNR: 30/30, LS, Epoch 11/20, Loss: 0.00012246678615642745 \n",
      "SNR: 30/30, LS, Val Loss: 0.00010863839700257152\n",
      "SNR: 30/30, LS, Epoch 12/20, Loss: 0.00010851958215298933 \n",
      "SNR: 30/30, LS, Val Loss: 9.60593712410297e-05\n",
      "SNR: 30/30, LS, Epoch 13/20, Loss: 9.733855160955627e-05 \n",
      "SNR: 30/30, LS, Val Loss: 8.597629229453477e-05\n",
      "SNR: 30/30, LS, Epoch 14/20, Loss: 8.754681976126956e-05 \n",
      "SNR: 30/30, LS, Val Loss: 7.706618916100442e-05\n",
      "SNR: 30/30, LS, Epoch 15/20, Loss: 7.708609068368936e-05 \n",
      "SNR: 30/30, LS, Val Loss: 6.904475561565381e-05\n",
      "SNR: 30/30, LS, Epoch 16/20, Loss: 6.946236752873818e-05 \n",
      "SNR: 30/30, LS, Val Loss: 6.099890941351821e-05\n",
      "SNR: 30/30, LS, Epoch 17/20, Loss: 6.408700702977936e-05 \n",
      "SNR: 30/30, LS, Val Loss: 5.6026898660506546e-05\n",
      "SNR: 30/30, LS, Epoch 18/20, Loss: 5.410770148067291e-05 \n",
      "SNR: 30/30, LS, Val Loss: 4.846418001265688e-05\n",
      "SNR: 30/30, LS, Epoch 19/20, Loss: 4.949035538566234e-05 \n",
      "SNR: 30/30, LS, Val Loss: 4.6146261576557826e-05\n",
      "SNR: 30/30, LS, Epoch 20/20, Loss: 4.390316328067985e-05 \n",
      "SNR: 30/30, LS, Val Loss: 3.772843344697983e-05\n",
      "LS+CNN NMSE: 0.0018187676323577762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, norm_approach)\n",
    "\n",
    "    # model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    learning_rate = 0.00001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = valData.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI, index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN, index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    plotfig.figTrueChan(H_equal[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, val_loader = loader.genLoader(H_equal, H_true, train_size, BATCH_SIZE, device)\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    learning_rate = 0.00001\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN, index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
