{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 0.00001 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver4_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver4_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# create readme.txt file\n",
    "content = \"\"\"Generated by file 'train/static_CNN_lr1e-5_v4_r3500_3516_3p4_instance_min_max.ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows 3500_3516,\n",
    "DeepMIMOv2/DeepMIMO_Dta_Static_BS16/freq_sym_1ant_612sub_ver4,\n",
    "Using min-max scaler for each sample\"\"\"\n",
    "\n",
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "\n",
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5, 10, 15, 20, 25, 30])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr = 0\n",
    "# [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/20, Loss: 0.18215912303259207 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.052179346877065574\n",
      "SNR: 0/30, LS+LI, Epoch 2/20, Loss: 0.04452896236203784 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.037077769806439224\n",
      "SNR: 0/30, LS+LI, Epoch 3/20, Loss: 0.030027720736079785 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.029166504740715027\n",
      "SNR: 0/30, LS+LI, Epoch 4/20, Loss: 0.027057851074523357 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027803220447491516\n",
      "SNR: 0/30, LS+LI, Epoch 5/20, Loss: 0.026562017572740484 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027508287013254383\n",
      "SNR: 0/30, LS+LI, Epoch 6/20, Loss: 0.026409313954456254 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02785106198015538\n",
      "SNR: 0/30, LS+LI, Epoch 7/20, Loss: 0.02643789465235936 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0276088502088731\n",
      "SNR: 0/30, LS+LI, Epoch 8/20, Loss: 0.02628115700492852 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.028025697070089253\n",
      "SNR: 0/30, LS+LI, Epoch 9/20, Loss: 0.026256235159370443 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0273417311466553\n",
      "SNR: 0/30, LS+LI, Epoch 10/20, Loss: 0.026138806905120958 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027626321651041508\n",
      "SNR: 0/30, LS+LI, Epoch 11/20, Loss: 0.02613508618480071 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027094412425702267\n",
      "SNR: 0/30, LS+LI, Epoch 12/20, Loss: 0.026010054948761366 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027057141150263222\n",
      "SNR: 0/30, LS+LI, Epoch 13/20, Loss: 0.026029259350887218 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02742754684930498\n",
      "SNR: 0/30, LS+LI, Epoch 14/20, Loss: 0.02593834121538283 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0270379361781207\n",
      "SNR: 0/30, LS+LI, Epoch 15/20, Loss: 0.02585130429631749 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027012388475916603\n",
      "SNR: 0/30, LS+LI, Epoch 16/20, Loss: 0.025768270104213856 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027116475203497845\n",
      "SNR: 0/30, LS+LI, Epoch 17/20, Loss: 0.025738709259691628 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026846972802145916\n",
      "SNR: 0/30, LS+LI, Epoch 18/20, Loss: 0.02567404979125185 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026645358228548008\n",
      "SNR: 0/30, LS+LI, Epoch 19/20, Loss: 0.025625750021792428 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026840014044534077\n",
      "SNR: 0/30, LS+LI, Epoch 20/20, Loss: 0.02558017793371407 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02658592655577443\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 111\u001b[0m\n\u001b[1;32m    107\u001b[0m figure_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder_fig, \u001b[38;5;28mstr\u001b[39m(snr) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdB\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m    109\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(figure_save_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 111\u001b[0m \u001b[43mplotfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_save\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_LS_LI_Loss.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# True channel\u001b[39;00m\n\u001b[1;32m    115\u001b[0m H_val_true \u001b[38;5;241m=\u001b[39m valLabels\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:6\u001b[0m, in \u001b[0;36mfigLoss\u001b[0;34m(train_loss, val_loss, index_save, figure_save_path, name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfigLoss\u001b[39m(train_loss, val_loss, index_save, figure_save_path, name):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_loss) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(x,train_loss, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "        # of valLabels\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = H_linear_train.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI, index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN, index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    plotfig.figTrueChan(H_equal_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN, index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
