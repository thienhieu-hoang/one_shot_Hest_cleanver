{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 0.00001 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver4_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver4_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# create readme.txt file\n",
    "content = \"\"\"Generated by file 'train/static_CNN_lr1e-5_v4_r3500_3516_3p4_instance_min_max.ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows 3500_3516,\n",
    "DeepMIMOv2/DeepMIMO_Dta_Static_BS16/freq_sym_1ant_612sub_ver4,\n",
    "Using min-max scaler for each sample\"\"\"\n",
    "\n",
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "\n",
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5, 10, 15, 20, 25, 30])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr = 0\n",
    "# [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/20, Loss: 0.18383328772561494 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.050281547009944916\n",
      "SNR: 0/30, LS+LI, Epoch 2/20, Loss: 0.04864660806434099 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.03799135669727217\n",
      "SNR: 0/30, LS+LI, Epoch 3/20, Loss: 0.034907598622403176 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02491906052455306\n",
      "SNR: 0/30, LS+LI, Epoch 4/20, Loss: 0.02815565404070671 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02327575898644599\n",
      "SNR: 0/30, LS+LI, Epoch 5/20, Loss: 0.027440981425041724 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02263125927526165\n",
      "SNR: 0/30, LS+LI, Epoch 6/20, Loss: 0.027188914465219823 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.022362281737679787\n",
      "SNR: 0/30, LS+LI, Epoch 7/20, Loss: 0.027138715658640098 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02233770371160724\n",
      "SNR: 0/30, LS+LI, Epoch 8/20, Loss: 0.026825778457054566 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02249901470812884\n",
      "SNR: 0/30, LS+LI, Epoch 9/20, Loss: 0.026767239618916496 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023643837437372316\n",
      "SNR: 0/30, LS+LI, Epoch 10/20, Loss: 0.026738055348179714 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.022364493713460186\n",
      "SNR: 0/30, LS+LI, Epoch 11/20, Loss: 0.026738997299743945 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021949669325046918\n",
      "SNR: 0/30, LS+LI, Epoch 12/20, Loss: 0.0264943640971513 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.022184630559588022\n",
      "SNR: 0/30, LS+LI, Epoch 13/20, Loss: 0.026442485736942915 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02220879759724167\n",
      "SNR: 0/30, LS+LI, Epoch 14/20, Loss: 0.02636146098158734 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021920751060613176\n",
      "SNR: 0/30, LS+LI, Epoch 15/20, Loss: 0.026233806691760588 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.022565193050964313\n",
      "SNR: 0/30, LS+LI, Epoch 16/20, Loss: 0.026196977486400756 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021449958990243347\n",
      "SNR: 0/30, LS+LI, Epoch 17/20, Loss: 0.02616397895157164 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02249979297630489\n",
      "SNR: 0/30, LS+LI, Epoch 18/20, Loss: 0.02613614068561515 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021329512798481366\n",
      "SNR: 0/30, LS+LI, Epoch 19/20, Loss: 0.02601859958430882 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021241394506598062\n",
      "SNR: 0/30, LS+LI, Epoch 20/20, Loss: 0.02587431004855695 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.021444673925130206\n",
      "LS+LI NMSE: 0.08209261298179626\n",
      "LS+LI+CNN NMSE: 0.06511245667934418\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/20, Loss: 0.3163476456389871 \n",
      "SNR: 0/30, LS, Val Loss: 0.2778377675197341\n",
      "SNR: 0/30, LS, Epoch 2/20, Loss: 0.23209236181059548 \n",
      "SNR: 0/30, LS, Val Loss: 0.1328629512678493\n",
      "SNR: 0/30, LS, Epoch 3/20, Loss: 0.04936252640516952 \n",
      "SNR: 0/30, LS, Val Loss: 0.024808796715329994\n",
      "SNR: 0/30, LS, Epoch 4/20, Loss: 0.021130477663042935 \n",
      "SNR: 0/30, LS, Val Loss: 0.018363833596760578\n",
      "SNR: 0/30, LS, Epoch 5/20, Loss: 0.016771024342106526 \n",
      "SNR: 0/30, LS, Val Loss: 0.015038243918256327\n",
      "SNR: 0/30, LS, Epoch 6/20, Loss: 0.01382719784390268 \n",
      "SNR: 0/30, LS, Val Loss: 0.012680243531411345\n",
      "SNR: 0/30, LS, Epoch 7/20, Loss: 0.011655995129542641 \n",
      "SNR: 0/30, LS, Val Loss: 0.010584762658585201\n",
      "SNR: 0/30, LS, Epoch 8/20, Loss: 0.01006980971324929 \n",
      "SNR: 0/30, LS, Val Loss: 0.009362683758478273\n",
      "SNR: 0/30, LS, Epoch 9/20, Loss: 0.008769557832978492 \n",
      "SNR: 0/30, LS, Val Loss: 0.008354944028806958\n",
      "SNR: 0/30, LS, Epoch 10/20, Loss: 0.007748075427899007 \n",
      "SNR: 0/30, LS, Val Loss: 0.007473570633340965\n",
      "SNR: 0/30, LS, Epoch 11/20, Loss: 0.007024688104730706 \n",
      "SNR: 0/30, LS, Val Loss: 0.006571604341099208\n",
      "SNR: 0/30, LS, Epoch 12/20, Loss: 0.006594693992113651 \n",
      "SNR: 0/30, LS, Val Loss: 0.00618348611434075\n",
      "SNR: 0/30, LS, Epoch 13/20, Loss: 0.006392073617208489 \n",
      "SNR: 0/30, LS, Val Loss: 0.006187850228426131\n",
      "SNR: 0/30, LS, Epoch 14/20, Loss: 0.0062313649186128105 \n",
      "SNR: 0/30, LS, Val Loss: 0.00605056826448576\n",
      "SNR: 0/30, LS, Epoch 15/20, Loss: 0.006093000668252624 \n",
      "SNR: 0/30, LS, Val Loss: 0.005837341918694702\n",
      "SNR: 0/30, LS, Epoch 16/20, Loss: 0.005963133079497967 \n",
      "SNR: 0/30, LS, Val Loss: 0.005712460091506893\n",
      "SNR: 0/30, LS, Epoch 17/20, Loss: 0.005967928053334702 \n",
      "SNR: 0/30, LS, Val Loss: 0.00606424869461493\n",
      "SNR: 0/30, LS, Epoch 18/20, Loss: 0.005828541773912865 \n",
      "SNR: 0/30, LS, Val Loss: 0.005503457653420893\n",
      "SNR: 0/30, LS, Epoch 19/20, Loss: 0.0057431338463238505 \n",
      "SNR: 0/30, LS, Val Loss: 0.0055635550313375215\n",
      "SNR: 0/30, LS, Epoch 20/20, Loss: 0.0056801463888828145 \n",
      "SNR: 0/30, LS, Val Loss: 0.005701329135759311\n",
      "LS+CNN NMSE: 0.01608910597860813\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/20, Loss: 0.17210425993124412 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.036820911887017166\n",
      "SNR: 5/30, LS+LI, Epoch 2/20, Loss: 0.031022040812341972 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.02002784533595497\n",
      "SNR: 5/30, LS+LI, Epoch 3/20, Loss: 0.014658497998404295 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009703283896669745\n",
      "SNR: 5/30, LS+LI, Epoch 4/20, Loss: 0.011160774857650489 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009309457678517158\n",
      "SNR: 5/30, LS+LI, Epoch 5/20, Loss: 0.010862035787837622 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009049113458869133\n",
      "SNR: 5/30, LS+LI, Epoch 6/20, Loss: 0.010761368307718185 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008863725720650771\n",
      "SNR: 5/30, LS+LI, Epoch 7/20, Loss: 0.010614973541652395 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008798522895879367\n",
      "SNR: 5/30, LS+LI, Epoch 8/20, Loss: 0.010543768007178293 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00877181379209188\n",
      "SNR: 5/30, LS+LI, Epoch 9/20, Loss: 0.010494117822693012 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008571275425228205\n",
      "SNR: 5/30, LS+LI, Epoch 10/20, Loss: 0.010340340080844281 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008447051429274407\n",
      "SNR: 5/30, LS+LI, Epoch 11/20, Loss: 0.010267069587635612 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008470243943685835\n",
      "SNR: 5/30, LS+LI, Epoch 12/20, Loss: 0.010188120568907538 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0085471405393698\n",
      "SNR: 5/30, LS+LI, Epoch 13/20, Loss: 0.01014189275663866 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008323428094048391\n",
      "SNR: 5/30, LS+LI, Epoch 14/20, Loss: 0.01010018301218055 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008229509440504691\n",
      "SNR: 5/30, LS+LI, Epoch 15/20, Loss: 0.010066474931379564 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008285107895393263\n",
      "SNR: 5/30, LS+LI, Epoch 16/20, Loss: 0.00999770607517729 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008420531722632322\n",
      "SNR: 5/30, LS+LI, Epoch 17/20, Loss: 0.009985581202822369 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00833586561070247\n",
      "SNR: 5/30, LS+LI, Epoch 18/20, Loss: 0.010046365806226467 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008108322191136804\n",
      "SNR: 5/30, LS+LI, Epoch 19/20, Loss: 0.009916760520143219 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00812532890334048\n",
      "SNR: 5/30, LS+LI, Epoch 20/20, Loss: 0.00988069419521665 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00823527441190725\n",
      "LS+LI NMSE: 0.02595227211713791\n",
      "LS+LI+CNN NMSE: 0.021540915593504906\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/20, Loss: 0.3058028883885506 \n",
      "SNR: 5/30, LS, Val Loss: 0.24755990911613812\n",
      "SNR: 5/30, LS, Epoch 2/20, Loss: 0.20546139213581419 \n",
      "SNR: 5/30, LS, Val Loss: 0.12485484474084595\n",
      "SNR: 5/30, LS, Epoch 3/20, Loss: 0.041904627767846335 \n",
      "SNR: 5/30, LS, Val Loss: 0.022684999572282486\n",
      "SNR: 5/30, LS, Epoch 4/20, Loss: 0.018867063839638303 \n",
      "SNR: 5/30, LS, Val Loss: 0.01719724175266244\n",
      "SNR: 5/30, LS, Epoch 5/20, Loss: 0.015103100073458843 \n",
      "SNR: 5/30, LS, Val Loss: 0.015034789261831478\n",
      "SNR: 5/30, LS, Epoch 6/20, Loss: 0.012557896114019461 \n",
      "SNR: 5/30, LS, Val Loss: 0.011804891496219418\n",
      "SNR: 5/30, LS, Epoch 7/20, Loss: 0.010406455155028853 \n",
      "SNR: 5/30, LS, Val Loss: 0.009637872434475205\n",
      "SNR: 5/30, LS, Epoch 8/20, Loss: 0.008263569861260612 \n",
      "SNR: 5/30, LS, Val Loss: 0.007491692710159855\n",
      "SNR: 5/30, LS, Epoch 9/20, Loss: 0.006568207881998184 \n",
      "SNR: 5/30, LS, Val Loss: 0.006190628511831164\n",
      "SNR: 5/30, LS, Epoch 10/20, Loss: 0.005395099006290006 \n",
      "SNR: 5/30, LS, Val Loss: 0.0051309616431932555\n",
      "SNR: 5/30, LS, Epoch 11/20, Loss: 0.0047239982780220725 \n",
      "SNR: 5/30, LS, Val Loss: 0.004562064645473252\n",
      "SNR: 5/30, LS, Epoch 12/20, Loss: 0.004298286900996382 \n",
      "SNR: 5/30, LS, Val Loss: 0.004084292449988425\n",
      "SNR: 5/30, LS, Epoch 13/20, Loss: 0.0040311015679414365 \n",
      "SNR: 5/30, LS, Val Loss: 0.004046223338016055\n",
      "SNR: 5/30, LS, Epoch 14/20, Loss: 0.0038466464530481676 \n",
      "SNR: 5/30, LS, Val Loss: 0.003672298710708591\n",
      "SNR: 5/30, LS, Epoch 15/20, Loss: 0.0036981475775043457 \n",
      "SNR: 5/30, LS, Val Loss: 0.0034972901075062427\n",
      "SNR: 5/30, LS, Epoch 16/20, Loss: 0.0035966658236480558 \n",
      "SNR: 5/30, LS, Val Loss: 0.003389761232855645\n",
      "SNR: 5/30, LS, Epoch 17/20, Loss: 0.003444334498855697 \n",
      "SNR: 5/30, LS, Val Loss: 0.0035809027136896143\n",
      "SNR: 5/30, LS, Epoch 18/20, Loss: 0.003373760337464858 \n",
      "SNR: 5/30, LS, Val Loss: 0.00324831111356616\n",
      "SNR: 5/30, LS, Epoch 19/20, Loss: 0.0033432195859224817 \n",
      "SNR: 5/30, LS, Val Loss: 0.003338054256429049\n",
      "SNR: 5/30, LS, Epoch 20/20, Loss: 0.003227195893360172 \n",
      "SNR: 5/30, LS, Val Loss: 0.0030757473802871323\n",
      "LS+CNN NMSE: 0.008743886835873127\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/20, Loss: 0.15393880163427703 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.030189837583086708\n",
      "SNR: 10/30, LS+LI, Epoch 2/20, Loss: 0.01959588489397754 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.007424876813522794\n",
      "SNR: 10/30, LS+LI, Epoch 3/20, Loss: 0.005518339950656302 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00458018719853664\n",
      "SNR: 10/30, LS+LI, Epoch 4/20, Loss: 0.004777292761583488 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004235445251900025\n",
      "SNR: 10/30, LS+LI, Epoch 5/20, Loss: 0.004661578698581908 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004157639987004752\n",
      "SNR: 10/30, LS+LI, Epoch 6/20, Loss: 0.004596223257384588 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004206987447105348\n",
      "SNR: 10/30, LS+LI, Epoch 7/20, Loss: 0.00453419447470413 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004093519226774912\n",
      "SNR: 10/30, LS+LI, Epoch 8/20, Loss: 0.004511336017627442 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003997824461707337\n",
      "SNR: 10/30, LS+LI, Epoch 9/20, Loss: 0.004480951230128317 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0039319919887930155\n",
      "SNR: 10/30, LS+LI, Epoch 10/20, Loss: 0.0044089776036048 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004019981043794277\n",
      "SNR: 10/30, LS+LI, Epoch 11/20, Loss: 0.00435824454139355 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0038633578435771847\n",
      "SNR: 10/30, LS+LI, Epoch 12/20, Loss: 0.004310038145144232 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003876276732295413\n",
      "SNR: 10/30, LS+LI, Epoch 13/20, Loss: 0.004291628219382187 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003873201521028849\n",
      "SNR: 10/30, LS+LI, Epoch 14/20, Loss: 0.004240628859829591 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004004117397760803\n",
      "SNR: 10/30, LS+LI, Epoch 15/20, Loss: 0.004202940881652974 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003691246023994278\n",
      "SNR: 10/30, LS+LI, Epoch 16/20, Loss: 0.004142637084357354 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003617421284698966\n",
      "SNR: 10/30, LS+LI, Epoch 17/20, Loss: 0.004125246316530244 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003591486131137406\n",
      "SNR: 10/30, LS+LI, Epoch 18/20, Loss: 0.0040554164646215045 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037715103720653465\n",
      "SNR: 10/30, LS+LI, Epoch 19/20, Loss: 0.004061154181917393 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003516097060955045\n",
      "SNR: 10/30, LS+LI, Epoch 20/20, Loss: 0.003968895384554513 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003486162575427443\n",
      "LS+LI NMSE: 0.008193016983568668\n",
      "LS+LI+CNN NMSE: 0.010328483767807484\n",
      " Training for LS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 10/30, LS, Epoch 1/20, Loss: 0.29672583452490875 \n",
      "SNR: 10/30, LS, Val Loss: 0.2337618659843098\n",
      "SNR: 10/30, LS, Epoch 2/20, Loss: 0.2007665978094866 \n",
      "SNR: 10/30, LS, Val Loss: 0.14792067591439595\n",
      "SNR: 10/30, LS, Epoch 3/20, Loss: 0.0563722331683303 \n",
      "SNR: 10/30, LS, Val Loss: 0.01901371099732139\n",
      "SNR: 10/30, LS, Epoch 4/20, Loss: 0.016189324707442592 \n",
      "SNR: 10/30, LS, Val Loss: 0.013680250722576271\n",
      "SNR: 10/30, LS, Epoch 5/20, Loss: 0.012226142000060442 \n",
      "SNR: 10/30, LS, Val Loss: 0.010562592016702349\n",
      "SNR: 10/30, LS, Epoch 6/20, Loss: 0.009445728054595029 \n",
      "SNR: 10/30, LS, Val Loss: 0.008094178385693918\n",
      "SNR: 10/30, LS, Epoch 7/20, Loss: 0.007219504093924581 \n",
      "SNR: 10/30, LS, Val Loss: 0.006117593729868531\n",
      "SNR: 10/30, LS, Epoch 8/20, Loss: 0.005472173297041377 \n",
      "SNR: 10/30, LS, Val Loss: 0.0046720166309652\n",
      "SNR: 10/30, LS, Epoch 9/20, Loss: 0.004227956158628817 \n",
      "SNR: 10/30, LS, Val Loss: 0.0036183127773587\n",
      "SNR: 10/30, LS, Epoch 10/20, Loss: 0.0034121970610888025 \n",
      "SNR: 10/30, LS, Val Loss: 0.003039606296542016\n",
      "SNR: 10/30, LS, Epoch 11/20, Loss: 0.0029716963803958756 \n",
      "SNR: 10/30, LS, Val Loss: 0.002707460471852259\n",
      "SNR: 10/30, LS, Epoch 12/20, Loss: 0.002684404165213278 \n",
      "SNR: 10/30, LS, Val Loss: 0.0026158006565476007\n",
      "SNR: 10/30, LS, Epoch 13/20, Loss: 0.002474289299476199 \n",
      "SNR: 10/30, LS, Val Loss: 0.0023364124353975058\n",
      "SNR: 10/30, LS, Epoch 14/20, Loss: 0.0023906504245323323 \n",
      "SNR: 10/30, LS, Val Loss: 0.0021708866009827366\n",
      "SNR: 10/30, LS, Epoch 15/20, Loss: 0.002300373829500533 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020967051915993743\n",
      "SNR: 10/30, LS, Epoch 16/20, Loss: 0.0021768524176116254 \n",
      "SNR: 10/30, LS, Val Loss: 0.002030143879396333\n",
      "SNR: 10/30, LS, Epoch 17/20, Loss: 0.0020913620422550933 \n",
      "SNR: 10/30, LS, Val Loss: 0.0021363177537833426\n",
      "SNR: 10/30, LS, Epoch 18/20, Loss: 0.0020825700864174164 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019586205334317956\n",
      "SNR: 10/30, LS, Epoch 19/20, Loss: 0.001982965746889064 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019469485110179944\n",
      "SNR: 10/30, LS, Epoch 20/20, Loss: 0.001968122570001152 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018550741422752087\n",
      "LS+CNN NMSE: 0.00527166249230504\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/20, Loss: 0.15234766973095926 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.02878427878022194\n",
      "SNR: 15/30, LS+LI, Epoch 2/20, Loss: 0.016073966279712526 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0043347581945867705\n",
      "SNR: 15/30, LS+LI, Epoch 3/20, Loss: 0.002754318022959714 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002287522461053661\n",
      "SNR: 15/30, LS+LI, Epoch 4/20, Loss: 0.0022553889281224718 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002205670626029711\n",
      "SNR: 15/30, LS+LI, Epoch 5/20, Loss: 0.0021490730747288135 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002055349468719214\n",
      "SNR: 15/30, LS+LI, Epoch 6/20, Loss: 0.0020750710811076123 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001972124927719547\n",
      "SNR: 15/30, LS+LI, Epoch 7/20, Loss: 0.0020182459482511635 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001956250502685593\n",
      "SNR: 15/30, LS+LI, Epoch 8/20, Loss: 0.0019371344005353315 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018398907374251974\n",
      "SNR: 15/30, LS+LI, Epoch 9/20, Loss: 0.001874452542789757 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018108474429358137\n",
      "SNR: 15/30, LS+LI, Epoch 10/20, Loss: 0.0018098975029546595 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017632937233429402\n",
      "SNR: 15/30, LS+LI, Epoch 11/20, Loss: 0.0017695558903099925 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016540211165027524\n",
      "SNR: 15/30, LS+LI, Epoch 12/20, Loss: 0.0017263715373363 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016005927569825542\n",
      "SNR: 15/30, LS+LI, Epoch 13/20, Loss: 0.0016515363592567833 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015352736227214336\n",
      "SNR: 15/30, LS+LI, Epoch 14/20, Loss: 0.0016143119539984306 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015742607277140698\n",
      "SNR: 15/30, LS+LI, Epoch 15/20, Loss: 0.001573592003740825 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015633559034375305\n",
      "SNR: 15/30, LS+LI, Epoch 16/20, Loss: 0.0015316862869482531 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014435022841842676\n",
      "SNR: 15/30, LS+LI, Epoch 17/20, Loss: 0.0015213616526696485 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016280926144893535\n",
      "SNR: 15/30, LS+LI, Epoch 18/20, Loss: 0.0015098098103704235 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014624321140052582\n",
      "SNR: 15/30, LS+LI, Epoch 19/20, Loss: 0.0014732451923326914 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015435497070112351\n",
      "SNR: 15/30, LS+LI, Epoch 20/20, Loss: 0.0014640844212493015 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014413505189374766\n",
      "LS+LI NMSE: 0.00259132357314229\n",
      "LS+LI+CNN NMSE: 0.0039118933491408825\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/20, Loss: 0.2957628877876803 \n",
      "SNR: 15/30, LS, Val Loss: 0.22709699787876822\n",
      "SNR: 15/30, LS, Epoch 2/20, Loss: 0.19626125572032707 \n",
      "SNR: 15/30, LS, Val Loss: 0.16125464270060713\n",
      "SNR: 15/30, LS, Epoch 3/20, Loss: 0.07575445896187841 \n",
      "SNR: 15/30, LS, Val Loss: 0.01938548032194376\n",
      "SNR: 15/30, LS, Epoch 4/20, Loss: 0.015095468285645163 \n",
      "SNR: 15/30, LS, Val Loss: 0.01270297791978175\n",
      "SNR: 15/30, LS, Epoch 5/20, Loss: 0.010657403672243966 \n",
      "SNR: 15/30, LS, Val Loss: 0.00925098101354458\n",
      "SNR: 15/30, LS, Epoch 6/20, Loss: 0.0076629215347862175 \n",
      "SNR: 15/30, LS, Val Loss: 0.006650261072949929\n",
      "SNR: 15/30, LS, Epoch 7/20, Loss: 0.005478813245264423 \n",
      "SNR: 15/30, LS, Val Loss: 0.004818193931979212\n",
      "SNR: 15/30, LS, Epoch 8/20, Loss: 0.003925127124814533 \n",
      "SNR: 15/30, LS, Val Loss: 0.0035306109665808353\n",
      "SNR: 15/30, LS, Epoch 9/20, Loss: 0.002981260293000919 \n",
      "SNR: 15/30, LS, Val Loss: 0.0027801651211286135\n",
      "SNR: 15/30, LS, Epoch 10/20, Loss: 0.002480870929037676 \n",
      "SNR: 15/30, LS, Val Loss: 0.002390936461531303\n",
      "SNR: 15/30, LS, Epoch 11/20, Loss: 0.0021853365435882278 \n",
      "SNR: 15/30, LS, Val Loss: 0.0021398562874475665\n",
      "SNR: 15/30, LS, Epoch 12/20, Loss: 0.002021824534262292 \n",
      "SNR: 15/30, LS, Val Loss: 0.002092707669362426\n",
      "SNR: 15/30, LS, Epoch 13/20, Loss: 0.0018607606944833818 \n",
      "SNR: 15/30, LS, Val Loss: 0.0018614454522982917\n",
      "SNR: 15/30, LS, Epoch 14/20, Loss: 0.0017555272612764046 \n",
      "SNR: 15/30, LS, Val Loss: 0.0018143110686320472\n",
      "SNR: 15/30, LS, Epoch 15/20, Loss: 0.0016922618196140108 \n",
      "SNR: 15/30, LS, Val Loss: 0.001717744649133899\n",
      "SNR: 15/30, LS, Epoch 16/20, Loss: 0.001585830319104283 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016294528031721711\n",
      "SNR: 15/30, LS, Epoch 17/20, Loss: 0.0015314502998926612 \n",
      "SNR: 15/30, LS, Val Loss: 0.00157281269044192\n",
      "SNR: 15/30, LS, Epoch 18/20, Loss: 0.0014730654751643711 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015409298304637725\n",
      "SNR: 15/30, LS, Epoch 19/20, Loss: 0.0014164304904921285 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014697506875646386\n",
      "SNR: 15/30, LS, Epoch 20/20, Loss: 0.001366462511806424 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014257289585657418\n",
      "LS+CNN NMSE: 0.003913134802132845\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/20, Loss: 0.15262511773251516 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.02636189056052403\n",
      "SNR: 20/30, LS+LI, Epoch 2/20, Loss: 0.013819277660141504 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.003485292767767202\n",
      "SNR: 20/30, LS+LI, Epoch 3/20, Loss: 0.002054616203802356 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0015864140057766979\n",
      "SNR: 20/30, LS+LI, Epoch 4/20, Loss: 0.001483268273363518 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001396443954118612\n",
      "SNR: 20/30, LS+LI, Epoch 5/20, Loss: 0.001335098201390031 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012705816929651933\n",
      "SNR: 20/30, LS+LI, Epoch 6/20, Loss: 0.0012534957773019668 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012006668680855496\n",
      "SNR: 20/30, LS+LI, Epoch 7/20, Loss: 0.0011977885242654444 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0011390421105633404\n",
      "SNR: 20/30, LS+LI, Epoch 8/20, Loss: 0.0011482574549898895 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010719428590329533\n",
      "SNR: 20/30, LS+LI, Epoch 9/20, Loss: 0.001071242532330067 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010237490668342534\n",
      "SNR: 20/30, LS+LI, Epoch 10/20, Loss: 0.0010369058463554613 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009933493512851949\n",
      "SNR: 20/30, LS+LI, Epoch 11/20, Loss: 0.000989514980045537 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009384921921247786\n",
      "SNR: 20/30, LS+LI, Epoch 12/20, Loss: 0.0009476572930336345 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000976894669954411\n",
      "SNR: 20/30, LS+LI, Epoch 13/20, Loss: 0.0009033962482516112 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008583890475248071\n",
      "SNR: 20/30, LS+LI, Epoch 14/20, Loss: 0.0008832880050122608 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008412369325841693\n",
      "SNR: 20/30, LS+LI, Epoch 15/20, Loss: 0.0008371322829314226 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008010508291507987\n",
      "SNR: 20/30, LS+LI, Epoch 16/20, Loss: 0.0008133014601108423 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007826348724351687\n",
      "SNR: 20/30, LS+LI, Epoch 17/20, Loss: 0.0007880053971623352 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007274806716437029\n",
      "SNR: 20/30, LS+LI, Epoch 18/20, Loss: 0.0007609539024997503 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007707321386657317\n",
      "SNR: 20/30, LS+LI, Epoch 19/20, Loss: 0.0007281257690750821 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006921892371875318\n",
      "SNR: 20/30, LS+LI, Epoch 20/20, Loss: 0.0006957854359846584 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007104886939156462\n",
      "LS+LI NMSE: 0.0008137261611409485\n",
      "LS+LI+CNN NMSE: 0.0020139962434768677\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/20, Loss: 0.3010990159629389 \n",
      "SNR: 20/30, LS, Val Loss: 0.22586823119358582\n",
      "SNR: 20/30, LS, Epoch 2/20, Loss: 0.20363358893366748 \n",
      "SNR: 20/30, LS, Val Loss: 0.17756980183449658\n",
      "SNR: 20/30, LS, Epoch 3/20, Loss: 0.12656984062388885 \n",
      "SNR: 20/30, LS, Val Loss: 0.04469098116863857\n",
      "SNR: 20/30, LS, Epoch 4/20, Loss: 0.02132484694769563 \n",
      "SNR: 20/30, LS, Val Loss: 0.014764792455190962\n",
      "SNR: 20/30, LS, Epoch 5/20, Loss: 0.013080605110803317 \n",
      "SNR: 20/30, LS, Val Loss: 0.010923892936923287\n",
      "SNR: 20/30, LS, Epoch 6/20, Loss: 0.009812617769226605 \n",
      "SNR: 20/30, LS, Val Loss: 0.008275531105358492\n",
      "SNR: 20/30, LS, Epoch 7/20, Loss: 0.007424489456921989 \n",
      "SNR: 20/30, LS, Val Loss: 0.00618464762175625\n",
      "SNR: 20/30, LS, Epoch 8/20, Loss: 0.005486399761054578 \n",
      "SNR: 20/30, LS, Val Loss: 0.0045295270815999674\n",
      "SNR: 20/30, LS, Epoch 9/20, Loss: 0.003972337965658585 \n",
      "SNR: 20/30, LS, Val Loss: 0.0032451956702226944\n",
      "SNR: 20/30, LS, Epoch 10/20, Loss: 0.0029239184656288733 \n",
      "SNR: 20/30, LS, Val Loss: 0.0024807384629225867\n",
      "SNR: 20/30, LS, Epoch 11/20, Loss: 0.0023104082454580726 \n",
      "SNR: 20/30, LS, Val Loss: 0.002008743658238514\n",
      "SNR: 20/30, LS, Epoch 12/20, Loss: 0.0019878933644788556 \n",
      "SNR: 20/30, LS, Val Loss: 0.0017805696380409327\n",
      "SNR: 20/30, LS, Epoch 13/20, Loss: 0.001791611302990553 \n",
      "SNR: 20/30, LS, Val Loss: 0.0016347180088897321\n",
      "SNR: 20/30, LS, Epoch 14/20, Loss: 0.0016471110873173404 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015846003026870842\n",
      "SNR: 20/30, LS, Epoch 15/20, Loss: 0.001561759675306073 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014374372813935306\n",
      "SNR: 20/30, LS, Epoch 16/20, Loss: 0.0014496695339614742 \n",
      "SNR: 20/30, LS, Val Loss: 0.00134835563684729\n",
      "SNR: 20/30, LS, Epoch 17/20, Loss: 0.0014023213541719975 \n",
      "SNR: 20/30, LS, Val Loss: 0.001361701933836395\n",
      "SNR: 20/30, LS, Epoch 18/20, Loss: 0.0013144595120751926 \n",
      "SNR: 20/30, LS, Val Loss: 0.001229924332371659\n",
      "SNR: 20/30, LS, Epoch 19/20, Loss: 0.0012440496421456987 \n",
      "SNR: 20/30, LS, Val Loss: 0.001194784031461247\n",
      "SNR: 20/30, LS, Epoch 20/20, Loss: 0.0012118631261834052 \n",
      "SNR: 20/30, LS, Val Loss: 0.001150785170135681\n",
      "LS+CNN NMSE: 0.003115266328677535\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/20, Loss: 0.14570729556861658 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.022718592038886112\n",
      "SNR: 25/30, LS+LI, Epoch 2/20, Loss: 0.012040110406476658 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.003862572918561372\n",
      "SNR: 25/30, LS+LI, Epoch 3/20, Loss: 0.001837575113059693 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001162536415821788\n",
      "SNR: 25/30, LS+LI, Epoch 4/20, Loss: 0.0010911419302046428 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0009822117730932819\n",
      "SNR: 25/30, LS+LI, Epoch 5/20, Loss: 0.0009533193945169969 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008591752689839764\n",
      "SNR: 25/30, LS+LI, Epoch 6/20, Loss: 0.0008413684036620611 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007559189676116644\n",
      "SNR: 25/30, LS+LI, Epoch 7/20, Loss: 0.000740420890039342 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006664447242986749\n",
      "SNR: 25/30, LS+LI, Epoch 8/20, Loss: 0.0006532340652653189 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005765965814300051\n",
      "SNR: 25/30, LS+LI, Epoch 9/20, Loss: 0.0005701231273760218 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005053091802189804\n",
      "SNR: 25/30, LS+LI, Epoch 10/20, Loss: 0.0005111760914333837 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00045415936619974673\n",
      "SNR: 25/30, LS+LI, Epoch 11/20, Loss: 0.00046150182437444063 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00044467666091143406\n",
      "SNR: 25/30, LS+LI, Epoch 12/20, Loss: 0.00042462490159249323 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004032006704206155\n",
      "SNR: 25/30, LS+LI, Epoch 13/20, Loss: 0.00039141502413766045 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003430598047667776\n",
      "SNR: 25/30, LS+LI, Epoch 14/20, Loss: 0.0003691295342557782 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00033298760139256376\n",
      "SNR: 25/30, LS+LI, Epoch 15/20, Loss: 0.0003350864266563846 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00031224980392091146\n",
      "SNR: 25/30, LS+LI, Epoch 16/20, Loss: 0.00032663418333381847 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0002873520087715323\n",
      "SNR: 25/30, LS+LI, Epoch 17/20, Loss: 0.0003128890970147886 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00026804310354319483\n",
      "SNR: 25/30, LS+LI, Epoch 18/20, Loss: 0.0002952297094621869 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0002562362788012251\n",
      "SNR: 25/30, LS+LI, Epoch 19/20, Loss: 0.00027787494138126846 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0002451476737571118\n",
      "SNR: 25/30, LS+LI, Epoch 20/20, Loss: 0.00027381770319892854 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00023504022564421493\n",
      "LS+LI NMSE: 0.00026055818307213485\n",
      "LS+LI+CNN NMSE: 0.0006574952276423573\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/20, Loss: 0.29256934923834577 \n",
      "SNR: 25/30, LS, Val Loss: 0.22277275066484103\n",
      "SNR: 25/30, LS, Epoch 2/20, Loss: 0.19711023655741713 \n",
      "SNR: 25/30, LS, Val Loss: 0.16420771147717128\n",
      "SNR: 25/30, LS, Epoch 3/20, Loss: 0.09192203199707491 \n",
      "SNR: 25/30, LS, Val Loss: 0.029968975535170597\n",
      "SNR: 25/30, LS, Epoch 4/20, Loss: 0.02050219362515003 \n",
      "SNR: 25/30, LS, Val Loss: 0.016202706843614578\n",
      "SNR: 25/30, LS, Epoch 5/20, Loss: 0.01363840693239729 \n",
      "SNR: 25/30, LS, Val Loss: 0.011841645294969732\n",
      "SNR: 25/30, LS, Epoch 6/20, Loss: 0.010214508673566025 \n",
      "SNR: 25/30, LS, Val Loss: 0.008882614402947102\n",
      "SNR: 25/30, LS, Epoch 7/20, Loss: 0.007619065684699561 \n",
      "SNR: 25/30, LS, Val Loss: 0.006603528491475366\n",
      "SNR: 25/30, LS, Epoch 8/20, Loss: 0.005625180131214303 \n",
      "SNR: 25/30, LS, Val Loss: 0.004839988192543387\n",
      "SNR: 25/30, LS, Epoch 9/20, Loss: 0.0038700950627085255 \n",
      "SNR: 25/30, LS, Val Loss: 0.0032406280198219147\n",
      "SNR: 25/30, LS, Epoch 10/20, Loss: 0.0028397193642842127 \n",
      "SNR: 25/30, LS, Val Loss: 0.0025984528950754216\n",
      "SNR: 25/30, LS, Epoch 11/20, Loss: 0.0023993053818717166 \n",
      "SNR: 25/30, LS, Val Loss: 0.0023313628043979406\n",
      "SNR: 25/30, LS, Epoch 12/20, Loss: 0.002161006454031828 \n",
      "SNR: 25/30, LS, Val Loss: 0.0020679486174644394\n",
      "SNR: 25/30, LS, Epoch 13/20, Loss: 0.0019657227967400104 \n",
      "SNR: 25/30, LS, Val Loss: 0.001917281510858712\n",
      "SNR: 25/30, LS, Epoch 14/20, Loss: 0.0018178096188632988 \n",
      "SNR: 25/30, LS, Val Loss: 0.0017592383823780851\n",
      "SNR: 25/30, LS, Epoch 15/20, Loss: 0.0016888900535441068 \n",
      "SNR: 25/30, LS, Val Loss: 0.001641368207691068\n",
      "SNR: 25/30, LS, Epoch 16/20, Loss: 0.001600864390723494 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015906286690468814\n",
      "SNR: 25/30, LS, Epoch 17/20, Loss: 0.0014962350190238117 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015025971171615477\n",
      "SNR: 25/30, LS, Epoch 18/20, Loss: 0.0014302902025858286 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014536197572438555\n",
      "SNR: 25/30, LS, Epoch 19/20, Loss: 0.0013499573728632788 \n",
      "SNR: 25/30, LS, Val Loss: 0.0013209044859236615\n",
      "SNR: 25/30, LS, Epoch 20/20, Loss: 0.001301596789258034 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012743844550145282\n",
      "LS+CNN NMSE: 0.0033337066415697336\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/20, Loss: 0.1480748035056993 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.02734006077728488\n",
      "SNR: 30/30, LS+LI, Epoch 2/20, Loss: 0.0145068951614396 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0032541545065627856\n",
      "SNR: 30/30, LS+LI, Epoch 3/20, Loss: 0.0017102144504247538 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0011213637348687785\n",
      "SNR: 30/30, LS+LI, Epoch 4/20, Loss: 0.0009930314087352261 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008555535856761377\n",
      "SNR: 30/30, LS+LI, Epoch 5/20, Loss: 0.0008010679333427445 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007007396832870489\n",
      "SNR: 30/30, LS+LI, Epoch 6/20, Loss: 0.0006481767581304708 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005556851882085374\n",
      "SNR: 30/30, LS+LI, Epoch 7/20, Loss: 0.0005092952746646154 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004347051118119535\n",
      "SNR: 30/30, LS+LI, Epoch 8/20, Loss: 0.0004021907093268711 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003515897736757655\n",
      "SNR: 30/30, LS+LI, Epoch 9/20, Loss: 0.00032817292120916836 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00029045669361948967\n",
      "SNR: 30/30, LS+LI, Epoch 10/20, Loss: 0.00027586308207774407 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002400758702688935\n",
      "SNR: 30/30, LS+LI, Epoch 11/20, Loss: 0.00024133533470164768 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00020871451521419328\n",
      "SNR: 30/30, LS+LI, Epoch 12/20, Loss: 0.00021234401060081477 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00018878914389378306\n",
      "SNR: 30/30, LS+LI, Epoch 13/20, Loss: 0.00019906292572011088 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001730629585588097\n",
      "SNR: 30/30, LS+LI, Epoch 14/20, Loss: 0.0001813261084418289 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00016341012219940737\n",
      "SNR: 30/30, LS+LI, Epoch 15/20, Loss: 0.0001732118303046919 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001532148751059801\n",
      "SNR: 30/30, LS+LI, Epoch 16/20, Loss: 0.00016501125317644924 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001744173119236207\n",
      "SNR: 30/30, LS+LI, Epoch 17/20, Loss: 0.00015848167712710862 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00014418980010139586\n",
      "SNR: 30/30, LS+LI, Epoch 18/20, Loss: 0.00015637101509931854 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00013422913980321027\n",
      "SNR: 30/30, LS+LI, Epoch 19/20, Loss: 0.00014794681340200166 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001409638008970598\n",
      "SNR: 30/30, LS+LI, Epoch 20/20, Loss: 0.0001475680740462172 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001349040179444604\n",
      "LS+LI NMSE: 8.252305269706994e-05\n",
      "LS+LI+CNN NMSE: 0.00037919258465990424\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/20, Loss: 0.3000489165789859 \n",
      "SNR: 30/30, LS, Val Loss: 0.21846954321319406\n",
      "SNR: 30/30, LS, Epoch 2/20, Loss: 0.20076029895003453 \n",
      "SNR: 30/30, LS, Val Loss: 0.1655627726153894\n",
      "SNR: 30/30, LS, Epoch 3/20, Loss: 0.09716804025608093 \n",
      "SNR: 30/30, LS, Val Loss: 0.027005726132880558\n",
      "SNR: 30/30, LS, Epoch 4/20, Loss: 0.018004330275796874 \n",
      "SNR: 30/30, LS, Val Loss: 0.01392015382986177\n",
      "SNR: 30/30, LS, Epoch 5/20, Loss: 0.011855062963657601 \n",
      "SNR: 30/30, LS, Val Loss: 0.010194127744233067\n",
      "SNR: 30/30, LS, Epoch 6/20, Loss: 0.008720556298422432 \n",
      "SNR: 30/30, LS, Val Loss: 0.007364336443556981\n",
      "SNR: 30/30, LS, Epoch 7/20, Loss: 0.006069932319765347 \n",
      "SNR: 30/30, LS, Val Loss: 0.004785851046273654\n",
      "SNR: 30/30, LS, Epoch 8/20, Loss: 0.003701110994497444 \n",
      "SNR: 30/30, LS, Val Loss: 0.0028762315526943316\n",
      "SNR: 30/30, LS, Epoch 9/20, Loss: 0.0024899284126572744 \n",
      "SNR: 30/30, LS, Val Loss: 0.0021713585275310006\n",
      "SNR: 30/30, LS, Epoch 10/20, Loss: 0.0020223289726811005 \n",
      "SNR: 30/30, LS, Val Loss: 0.0018765758035111833\n",
      "SNR: 30/30, LS, Epoch 11/20, Loss: 0.0018057678866763274 \n",
      "SNR: 30/30, LS, Val Loss: 0.001690564608328383\n",
      "SNR: 30/30, LS, Epoch 12/20, Loss: 0.001639018558117366 \n",
      "SNR: 30/30, LS, Val Loss: 0.0015679919346108693\n",
      "SNR: 30/30, LS, Epoch 13/20, Loss: 0.0015106704553080246 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014434822475198996\n",
      "SNR: 30/30, LS, Epoch 14/20, Loss: 0.0014095493290454237 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013725493468386544\n",
      "SNR: 30/30, LS, Epoch 15/20, Loss: 0.0013220689498391652 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013536894217726183\n",
      "SNR: 30/30, LS, Epoch 16/20, Loss: 0.001255489991393027 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012036104347895491\n",
      "SNR: 30/30, LS, Epoch 17/20, Loss: 0.0011927340153285281 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012115238959350709\n",
      "SNR: 30/30, LS, Epoch 18/20, Loss: 0.001125968647186731 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011252412117425013\n",
      "SNR: 30/30, LS, Epoch 19/20, Loss: 0.001076314365491271 \n",
      "SNR: 30/30, LS, Val Loss: 0.001065853909081356\n",
      "SNR: 30/30, LS, Epoch 20/20, Loss: 0.0010178432221860127 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009684250504836779\n",
      "LS+CNN NMSE: 0.0025647347792983055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "        # of valLabels\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = H_linear_val.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    calculate variance of each target sample \n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI, index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN, index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    H_LS_train = H_equal_train.cpu()\n",
    "    plotfig.figTrueChan(H_LS_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN, index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add code for generating NMSE over SNR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
