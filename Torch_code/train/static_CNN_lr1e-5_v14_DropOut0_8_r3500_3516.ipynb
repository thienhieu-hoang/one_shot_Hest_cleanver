{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 1e-5 \n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                        '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "lower_range = -1 \n",
    "    # if norm_approach = 'minmax': \n",
    "        # =  0 for scaling to  [0 1]\n",
    "        # = -1 for scaling to [-1 1]\n",
    "    # if norm_approach = 'std': can be any value, but need to be defined\n",
    "    \n",
    "if norm_approach == 'minmax':\n",
    "    if lower_range == 0:\n",
    "        norm_txt = 'Using min-max [0 1]'\n",
    "    elif lower_range ==-1:\n",
    "        norm_txt = 'Using min-max [-1 1]'\n",
    "elif norm_approach == 'no':\n",
    "    norm_txt = 'No'\n",
    "    \n",
    "CNN_activation = 'Tanh'\n",
    "CNN_DropOut = 0.8\n",
    "if CNN_DropOut != 0:\n",
    "    dropOut_txt = f'Add p={CNN_DropOut} DropOut'\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'train/static_CNN_lr1e-5_v14_(...).ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows {rowss},\n",
    "Data got from {outer_file_path},\n",
    "Learning rate {learning_rate}, {NUM_EPOCHS} epochs\n",
    "{norm_txt} scaler for each sample\n",
    "Using {CNN_activation} as activation function of CNN\n",
    "{dropOut_txt}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver18_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver18_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/50, Loss: 0.12745772449429646 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.042601778764616356\n",
      "SNR: 0/30, LS+LI, Epoch 2/50, Loss: 0.06501037839713485 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.03153541438620199\n",
      "SNR: 0/30, LS+LI, Epoch 3/50, Loss: 0.05366720688031163 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.03035654838789593\n",
      "SNR: 0/30, LS+LI, Epoch 4/50, Loss: 0.04864318081892507 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.030253020199862393\n",
      "SNR: 0/30, LS+LI, Epoch 5/50, Loss: 0.04542452209564143 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.028856397691098126\n",
      "SNR: 0/30, LS+LI, Epoch 6/50, Loss: 0.0429946634225374 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.030166418037631294\n",
      "SNR: 0/30, LS+LI, Epoch 7/50, Loss: 0.0413652295138427 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.028648351573131302\n",
      "SNR: 0/30, LS+LI, Epoch 8/50, Loss: 0.039937774250067254 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.028371394357898018\n",
      "SNR: 0/30, LS+LI, Epoch 9/50, Loss: 0.038859943859279156 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02826974718746814\n",
      "SNR: 0/30, LS+LI, Epoch 10/50, Loss: 0.037599719811750705 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02777646371925419\n",
      "SNR: 0/30, LS+LI, Epoch 11/50, Loss: 0.036823398541919024 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027725785632025112\n",
      "SNR: 0/30, LS+LI, Epoch 12/50, Loss: 0.036102533979384704 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027912330051714725\n",
      "SNR: 0/30, LS+LI, Epoch 13/50, Loss: 0.03553379307565994 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027590708807110786\n",
      "SNR: 0/30, LS+LI, Epoch 14/50, Loss: 0.03484354356607033 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02811844100837003\n",
      "SNR: 0/30, LS+LI, Epoch 15/50, Loss: 0.034306527137063274 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027457436377351933\n",
      "SNR: 0/30, LS+LI, Epoch 16/50, Loss: 0.033766280502340824 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02743182195858522\n",
      "SNR: 0/30, LS+LI, Epoch 17/50, Loss: 0.0336566376283245 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027553817934610626\n",
      "SNR: 0/30, LS+LI, Epoch 18/50, Loss: 0.033199425591805644 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027291474271227013\n",
      "SNR: 0/30, LS+LI, Epoch 19/50, Loss: 0.032614946018817814 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027597258460115303\n",
      "SNR: 0/30, LS+LI, Epoch 20/50, Loss: 0.03210593484948541 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027255131566727705\n",
      "SNR: 0/30, LS+LI, Epoch 21/50, Loss: 0.0320642298130795 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02727624549615112\n",
      "SNR: 0/30, LS+LI, Epoch 22/50, Loss: 0.03185648979012703 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.029032889922911472\n",
      "SNR: 0/30, LS+LI, Epoch 23/50, Loss: 0.031620511059584314 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0272442161698233\n",
      "SNR: 0/30, LS+LI, Epoch 24/50, Loss: 0.031174603589745456 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0276863481849432\n",
      "SNR: 0/30, LS+LI, Epoch 25/50, Loss: 0.03105989107212355 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027271368286826393\n",
      "SNR: 0/30, LS+LI, Epoch 26/50, Loss: 0.030942728277295828 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02709847680208358\n",
      "SNR: 0/30, LS+LI, Epoch 27/50, Loss: 0.030631470786364273 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027032308873127808\n",
      "SNR: 0/30, LS+LI, Epoch 28/50, Loss: 0.03046950781284723 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027271793054586106\n",
      "SNR: 0/30, LS+LI, Epoch 29/50, Loss: 0.030113884908428718 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027006748555736107\n",
      "SNR: 0/30, LS+LI, Epoch 30/50, Loss: 0.029915312359239474 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027005362493748016\n",
      "SNR: 0/30, LS+LI, Epoch 31/50, Loss: 0.029777237874737312 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02695898919112303\n",
      "SNR: 0/30, LS+LI, Epoch 32/50, Loss: 0.02968758619715308 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02711284664374861\n",
      "SNR: 0/30, LS+LI, Epoch 33/50, Loss: 0.02974360749168798 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027324769645929337\n",
      "SNR: 0/30, LS+LI, Epoch 34/50, Loss: 0.02949841559842922 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026944791601801462\n",
      "SNR: 0/30, LS+LI, Epoch 35/50, Loss: 0.02921379184307054 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02709816447035833\n",
      "SNR: 0/30, LS+LI, Epoch 36/50, Loss: 0.029146101867216966 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02715018137612126\n",
      "SNR: 0/30, LS+LI, Epoch 37/50, Loss: 0.029213270789748707 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026911860543557188\n",
      "SNR: 0/30, LS+LI, Epoch 38/50, Loss: 0.028871509046185503 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02694051560353149\n",
      "SNR: 0/30, LS+LI, Epoch 39/50, Loss: 0.029026198038441496 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027465218424119732\n",
      "SNR: 0/30, LS+LI, Epoch 40/50, Loss: 0.02863535487504546 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027070061007345266\n",
      "SNR: 0/30, LS+LI, Epoch 41/50, Loss: 0.028496958207079145 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0268307889981026\n",
      "SNR: 0/30, LS+LI, Epoch 42/50, Loss: 0.02868592070935424 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026823704003949057\n",
      "SNR: 0/30, LS+LI, Epoch 43/50, Loss: 0.028407918040229137 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027424328875812618\n",
      "SNR: 0/30, LS+LI, Epoch 44/50, Loss: 0.02844518652662288 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026992167515510864\n",
      "SNR: 0/30, LS+LI, Epoch 45/50, Loss: 0.028204331087858178 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026833020319992847\n",
      "SNR: 0/30, LS+LI, Epoch 46/50, Loss: 0.028360650279061046 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026869110424410213\n",
      "SNR: 0/30, LS+LI, Epoch 47/50, Loss: 0.028006592191495868 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027046174403618683\n",
      "SNR: 0/30, LS+LI, Epoch 48/50, Loss: 0.02814972681144989 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02679928798567165\n",
      "SNR: 0/30, LS+LI, Epoch 49/50, Loss: 0.027891422849321782 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026957246009260416\n",
      "SNR: 0/30, LS+LI, Epoch 50/50, Loss: 0.028010696746668843 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026860174934633753\n",
      "LI+NN NMSE: 0.07362320274114609\n",
      "LS+LI NMSE: 0.0819208025932312\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/50, Loss: 0.27621162972997787 \n",
      "SNR: 0/30, LS, Val Loss: 0.12531102685765785\n",
      "SNR: 0/30, LS, Epoch 2/50, Loss: 0.028875186925667318 \n",
      "SNR: 0/30, LS, Val Loss: 0.011292392599650404\n",
      "SNR: 0/30, LS, Epoch 3/50, Loss: 0.010360791101553586 \n",
      "SNR: 0/30, LS, Val Loss: 0.009616547645154324\n",
      "SNR: 0/30, LS, Epoch 4/50, Loss: 0.00968259151721763 \n",
      "SNR: 0/30, LS, Val Loss: 0.00844408095475625\n",
      "SNR: 0/30, LS, Epoch 5/50, Loss: 0.00915509776407203 \n",
      "SNR: 0/30, LS, Val Loss: 0.00791454670781439\n",
      "SNR: 0/30, LS, Epoch 6/50, Loss: 0.00869726448666391 \n",
      "SNR: 0/30, LS, Val Loss: 0.007969751890579408\n",
      "SNR: 0/30, LS, Epoch 7/50, Loss: 0.008564615622162819 \n",
      "SNR: 0/30, LS, Val Loss: 0.0073880220721052456\n",
      "SNR: 0/30, LS, Epoch 8/50, Loss: 0.008243387020842801 \n",
      "SNR: 0/30, LS, Val Loss: 0.007351911288093437\n",
      "SNR: 0/30, LS, Epoch 9/50, Loss: 0.008222521607612455 \n",
      "SNR: 0/30, LS, Val Loss: 0.0070630147079513836\n",
      "SNR: 0/30, LS, Epoch 10/50, Loss: 0.008241519112638089 \n",
      "SNR: 0/30, LS, Val Loss: 0.007729433286427097\n",
      "SNR: 0/30, LS, Epoch 11/50, Loss: 0.007969649570864127 \n",
      "SNR: 0/30, LS, Val Loss: 0.006906159095127474\n",
      "SNR: 0/30, LS, Epoch 12/50, Loss: 0.007658297862034551 \n",
      "SNR: 0/30, LS, Val Loss: 0.006979141278531064\n",
      "SNR: 0/30, LS, Epoch 13/50, Loss: 0.007635665794856153 \n",
      "SNR: 0/30, LS, Val Loss: 0.006985999749634753\n",
      "SNR: 0/30, LS, Epoch 14/50, Loss: 0.0076686382472385154 \n",
      "SNR: 0/30, LS, Val Loss: 0.008074552646245469\n",
      "SNR: 0/30, LS, Epoch 15/50, Loss: 0.007568673122414323 \n",
      "SNR: 0/30, LS, Val Loss: 0.006541566288268024\n",
      "SNR: 0/30, LS, Epoch 16/50, Loss: 0.007599720723255602 \n",
      "SNR: 0/30, LS, Val Loss: 0.006432560124349865\n",
      "SNR: 0/30, LS, Epoch 17/50, Loss: 0.007384774681224033 \n",
      "SNR: 0/30, LS, Val Loss: 0.0063198312736031685\n",
      "SNR: 0/30, LS, Epoch 18/50, Loss: 0.007380105563179525 \n",
      "SNR: 0/30, LS, Val Loss: 0.00643217618661848\n",
      "SNR: 0/30, LS, Epoch 19/50, Loss: 0.007468391599696736 \n",
      "SNR: 0/30, LS, Val Loss: 0.006301404315639626\n",
      "SNR: 0/30, LS, Epoch 20/50, Loss: 0.007283053117219445 \n",
      "SNR: 0/30, LS, Val Loss: 0.00644279940223152\n",
      "SNR: 0/30, LS, Epoch 21/50, Loss: 0.007130690501071513 \n",
      "SNR: 0/30, LS, Val Loss: 0.006084932310676033\n",
      "SNR: 0/30, LS, Epoch 22/50, Loss: 0.006925896251422548 \n",
      "SNR: 0/30, LS, Val Loss: 0.006062769373370843\n",
      "SNR: 0/30, LS, Epoch 23/50, Loss: 0.006930267422048505 \n",
      "SNR: 0/30, LS, Val Loss: 0.006529565710066395\n",
      "SNR: 0/30, LS, Epoch 24/50, Loss: 0.006967130534047651 \n",
      "SNR: 0/30, LS, Val Loss: 0.006099323636259545\n",
      "SNR: 0/30, LS, Epoch 25/50, Loss: 0.007088751112500769 \n",
      "SNR: 0/30, LS, Val Loss: 0.0063089436047117815\n",
      "SNR: 0/30, LS, Epoch 26/50, Loss: 0.0068326722668094 \n",
      "SNR: 0/30, LS, Val Loss: 0.006757907865738327\n",
      "SNR: 0/30, LS, Epoch 27/50, Loss: 0.006833589635789394 \n",
      "SNR: 0/30, LS, Val Loss: 0.006042791403491388\n",
      "SNR: 0/30, LS, Epoch 28/50, Loss: 0.006971129419303737 \n",
      "SNR: 0/30, LS, Val Loss: 0.005781476026062261\n",
      "SNR: 0/30, LS, Epoch 29/50, Loss: 0.006882856794914534 \n",
      "SNR: 0/30, LS, Val Loss: 0.0058538406156003475\n",
      "SNR: 0/30, LS, Epoch 30/50, Loss: 0.006748964168066376 \n",
      "SNR: 0/30, LS, Val Loss: 0.006586445389654149\n",
      "SNR: 0/30, LS, Epoch 31/50, Loss: 0.006779069893148749 \n",
      "SNR: 0/30, LS, Val Loss: 0.00586292939260602\n",
      "SNR: 0/30, LS, Epoch 32/50, Loss: 0.006819380466219818 \n",
      "SNR: 0/30, LS, Val Loss: 0.007094528949396176\n",
      "SNR: 0/30, LS, Epoch 33/50, Loss: 0.006977025257033664 \n",
      "SNR: 0/30, LS, Val Loss: 0.0056312088007954035\n",
      "SNR: 0/30, LS, Epoch 34/50, Loss: 0.006680343459836792 \n",
      "SNR: 0/30, LS, Val Loss: 0.0055608011104843836\n",
      "SNR: 0/30, LS, Epoch 35/50, Loss: 0.006559931984452834 \n",
      "SNR: 0/30, LS, Val Loss: 0.005929623963311315\n",
      "SNR: 0/30, LS, Epoch 36/50, Loss: 0.0064875062874539995 \n",
      "SNR: 0/30, LS, Val Loss: 0.005549025848846544\n",
      "SNR: 0/30, LS, Epoch 37/50, Loss: 0.006342897178107049 \n",
      "SNR: 0/30, LS, Val Loss: 0.005579390351406552\n",
      "SNR: 0/30, LS, Epoch 38/50, Loss: 0.0066686030179478745 \n",
      "SNR: 0/30, LS, Val Loss: 0.005671413276683201\n",
      "SNR: 0/30, LS, Epoch 39/50, Loss: 0.006485827324023947 \n",
      "SNR: 0/30, LS, Val Loss: 0.005397291092032736\n",
      "SNR: 0/30, LS, Epoch 40/50, Loss: 0.006438674083044536 \n",
      "SNR: 0/30, LS, Val Loss: 0.005379965211349455\n",
      "SNR: 0/30, LS, Epoch 41/50, Loss: 0.00636981520260316 \n",
      "SNR: 0/30, LS, Val Loss: 0.005309596784751524\n",
      "SNR: 0/30, LS, Epoch 42/50, Loss: 0.00633054543124122 \n",
      "SNR: 0/30, LS, Val Loss: 0.005338969322937456\n",
      "SNR: 0/30, LS, Epoch 43/50, Loss: 0.006267472189244663 \n",
      "SNR: 0/30, LS, Val Loss: 0.00682492429305884\n",
      "SNR: 0/30, LS, Epoch 44/50, Loss: 0.006261926657401112 \n",
      "SNR: 0/30, LS, Val Loss: 0.006179070565849543\n",
      "SNR: 0/30, LS, Epoch 45/50, Loss: 0.006347340650769861 \n",
      "SNR: 0/30, LS, Val Loss: 0.006637335204603997\n",
      "SNR: 0/30, LS, Epoch 46/50, Loss: 0.006287760393650726 \n",
      "SNR: 0/30, LS, Val Loss: 0.006180136676200412\n",
      "SNR: 0/30, LS, Epoch 47/50, Loss: 0.006347845825583263 \n",
      "SNR: 0/30, LS, Val Loss: 0.00540149497630244\n",
      "SNR: 0/30, LS, Epoch 48/50, Loss: 0.00623329165716504 \n",
      "SNR: 0/30, LS, Val Loss: 0.005776951830326157\n",
      "SNR: 0/30, LS, Epoch 49/50, Loss: 0.006115822204074628 \n",
      "SNR: 0/30, LS, Val Loss: 0.0051056519574062395\n",
      "SNR: 0/30, LS, Epoch 50/50, Loss: 0.0061204954548630605 \n",
      "SNR: 0/30, LS, Val Loss: 0.005145205502313646\n",
      "LS+LI NMSE: 0.014286622405052185\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/50, Loss: 0.10628299798469903 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.020989516241983933\n",
      "SNR: 5/30, LS+LI, Epoch 2/50, Loss: 0.048628667261191576 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01360337304967371\n",
      "SNR: 5/30, LS+LI, Epoch 3/50, Loss: 0.03847406869537608 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011213204251940955\n",
      "SNR: 5/30, LS+LI, Epoch 4/50, Loss: 0.033690047851048927 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01062212185934186\n",
      "SNR: 5/30, LS+LI, Epoch 5/50, Loss: 0.030511357594108165 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010682516434991901\n",
      "SNR: 5/30, LS+LI, Epoch 6/50, Loss: 0.02831034733762228 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010227710961110213\n",
      "SNR: 5/30, LS+LI, Epoch 7/50, Loss: 0.026639085392965826 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00971842953003943\n",
      "SNR: 5/30, LS+LI, Epoch 8/50, Loss: 0.024998215417009452 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009858098770068451\n",
      "SNR: 5/30, LS+LI, Epoch 9/50, Loss: 0.024142053129887858 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009443378372287209\n",
      "SNR: 5/30, LS+LI, Epoch 10/50, Loss: 0.02307123825127302 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0092989900149405\n",
      "SNR: 5/30, LS+LI, Epoch 11/50, Loss: 0.022220147362108842 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00917721715417098\n",
      "SNR: 5/30, LS+LI, Epoch 12/50, Loss: 0.021484044315510018 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00927986587736417\n",
      "SNR: 5/30, LS+LI, Epoch 13/50, Loss: 0.02089361646104344 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009212465364147316\n",
      "SNR: 5/30, LS+LI, Epoch 14/50, Loss: 0.020317761660661807 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009203076277944174\n",
      "SNR: 5/30, LS+LI, Epoch 15/50, Loss: 0.01974478721900215 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011401716408065775\n",
      "SNR: 5/30, LS+LI, Epoch 16/50, Loss: 0.019385358302442486 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00889794443818656\n",
      "SNR: 5/30, LS+LI, Epoch 17/50, Loss: 0.01900423186029806 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01012096200561659\n",
      "SNR: 5/30, LS+LI, Epoch 18/50, Loss: 0.018734444495896962 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00907157118093561\n",
      "SNR: 5/30, LS+LI, Epoch 19/50, Loss: 0.01824556446504281 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008806314382871444\n",
      "SNR: 5/30, LS+LI, Epoch 20/50, Loss: 0.018033017680525433 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009668712927536531\n",
      "SNR: 5/30, LS+LI, Epoch 21/50, Loss: 0.017707970572722165 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008763254598968408\n",
      "SNR: 5/30, LS+LI, Epoch 22/50, Loss: 0.017349252168652275 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008803571510890668\n",
      "SNR: 5/30, LS+LI, Epoch 23/50, Loss: 0.017190005462400095 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009040557525374672\n",
      "SNR: 5/30, LS+LI, Epoch 24/50, Loss: 0.016970773985566096 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009037095439535651\n",
      "SNR: 5/30, LS+LI, Epoch 25/50, Loss: 0.016787454464234585 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008844717257571492\n",
      "SNR: 5/30, LS+LI, Epoch 26/50, Loss: 0.016453518034067263 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008771223524077372\n",
      "SNR: 5/30, LS+LI, Epoch 27/50, Loss: 0.016296191807013263 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008840426315807483\n",
      "SNR: 5/30, LS+LI, Epoch 28/50, Loss: 0.016262722174572045 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010133971883492037\n",
      "SNR: 5/30, LS+LI, Epoch 29/50, Loss: 0.01603177426989342 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008781359022991224\n",
      "SNR: 5/30, LS+LI, Epoch 30/50, Loss: 0.015757391651615847 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008676063766787675\n",
      "SNR: 5/30, LS+LI, Epoch 31/50, Loss: 0.015948604158840553 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009198837765407834\n",
      "SNR: 5/30, LS+LI, Epoch 32/50, Loss: 0.01555765544194295 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009356325661594217\n",
      "SNR: 5/30, LS+LI, Epoch 33/50, Loss: 0.015361043332187935 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008621569902805442\n",
      "SNR: 5/30, LS+LI, Epoch 34/50, Loss: 0.015455770143849213 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011247534770518541\n",
      "SNR: 5/30, LS+LI, Epoch 35/50, Loss: 0.01519054866959016 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008791082453998652\n",
      "SNR: 5/30, LS+LI, Epoch 36/50, Loss: 0.014983096013798616 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008617141717960212\n",
      "SNR: 5/30, LS+LI, Epoch 37/50, Loss: 0.01480290968902409 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008682515345175158\n",
      "SNR: 5/30, LS+LI, Epoch 38/50, Loss: 0.014826132585619425 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00887020571495999\n",
      "SNR: 5/30, LS+LI, Epoch 39/50, Loss: 0.014765226173886033 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008862337393855507\n",
      "SNR: 5/30, LS+LI, Epoch 40/50, Loss: 0.014659538751381427 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009558308594436809\n",
      "SNR: 5/30, LS+LI, Epoch 41/50, Loss: 0.01464919513091445 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008553035970015282\n",
      "SNR: 5/30, LS+LI, Epoch 42/50, Loss: 0.014558377372490805 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009091854391788895\n",
      "SNR: 5/30, LS+LI, Epoch 43/50, Loss: 0.01447289960112336 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009068043182858011\n",
      "SNR: 5/30, LS+LI, Epoch 44/50, Loss: 0.014348955608384555 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008821844588965178\n",
      "SNR: 5/30, LS+LI, Epoch 45/50, Loss: 0.014198617148754556 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008556732749143108\n",
      "SNR: 5/30, LS+LI, Epoch 46/50, Loss: 0.014138796485873848 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0085686660181223\n",
      "SNR: 5/30, LS+LI, Epoch 47/50, Loss: 0.014265323577578677 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008717767174609682\n",
      "SNR: 5/30, LS+LI, Epoch 48/50, Loss: 0.01413102962921352 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00934643450785767\n",
      "SNR: 5/30, LS+LI, Epoch 49/50, Loss: 0.014051391542780884 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.008632522827776318\n",
      "SNR: 5/30, LS+LI, Epoch 50/50, Loss: 0.013956899294456425 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009081935256042263\n",
      "LI+NN NMSE: 0.02606792375445366\n",
      "LS+LI NMSE: 0.02585790492594242\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/50, Loss: 0.2443834187592878 \n",
      "SNR: 5/30, LS, Val Loss: 0.07116344604979861\n",
      "SNR: 5/30, LS, Epoch 2/50, Loss: 0.01760671217655113 \n",
      "SNR: 5/30, LS, Val Loss: 0.0073084440928968515\n",
      "SNR: 5/30, LS, Epoch 3/50, Loss: 0.007303737880943646 \n",
      "SNR: 5/30, LS, Val Loss: 0.005726030075245283\n",
      "SNR: 5/30, LS, Epoch 4/50, Loss: 0.006446203655498319 \n",
      "SNR: 5/30, LS, Val Loss: 0.005023514756678857\n",
      "SNR: 5/30, LS, Epoch 5/50, Loss: 0.005984398790873414 \n",
      "SNR: 5/30, LS, Val Loss: 0.004832668917846273\n",
      "SNR: 5/30, LS, Epoch 6/50, Loss: 0.005852312404597395 \n",
      "SNR: 5/30, LS, Val Loss: 0.004856318002566695\n",
      "SNR: 5/30, LS, Epoch 7/50, Loss: 0.005617801659079919 \n",
      "SNR: 5/30, LS, Val Loss: 0.005219202753241089\n",
      "SNR: 5/30, LS, Epoch 8/50, Loss: 0.005727937175664877 \n",
      "SNR: 5/30, LS, Val Loss: 0.004336456852880391\n",
      "SNR: 5/30, LS, Epoch 9/50, Loss: 0.005088100438601835 \n",
      "SNR: 5/30, LS, Val Loss: 0.0037836016854271293\n",
      "SNR: 5/30, LS, Epoch 10/50, Loss: 0.005222275904596372 \n",
      "SNR: 5/30, LS, Val Loss: 0.005373417505655776\n",
      "SNR: 5/30, LS, Epoch 11/50, Loss: 0.0049231319964408524 \n",
      "SNR: 5/30, LS, Val Loss: 0.00369006633462215\n",
      "SNR: 5/30, LS, Epoch 12/50, Loss: 0.004843745199248715 \n",
      "SNR: 5/30, LS, Val Loss: 0.003922720439732075\n",
      "SNR: 5/30, LS, Epoch 13/50, Loss: 0.004921571181025789 \n",
      "SNR: 5/30, LS, Val Loss: 0.0036785168869590216\n",
      "SNR: 5/30, LS, Epoch 14/50, Loss: 0.004607687013895186 \n",
      "SNR: 5/30, LS, Val Loss: 0.0033598320177671585\n",
      "SNR: 5/30, LS, Epoch 15/50, Loss: 0.004899265569483125 \n",
      "SNR: 5/30, LS, Val Loss: 0.0037791109961372886\n",
      "SNR: 5/30, LS, Epoch 16/50, Loss: 0.004666106677939033 \n",
      "SNR: 5/30, LS, Val Loss: 0.0033964816988869147\n",
      "SNR: 5/30, LS, Epoch 17/50, Loss: 0.004549553421553398 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031822996362197127\n",
      "SNR: 5/30, LS, Epoch 18/50, Loss: 0.004471258238651032 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031774708239192314\n",
      "SNR: 5/30, LS, Epoch 19/50, Loss: 0.004553516228889051 \n",
      "SNR: 5/30, LS, Val Loss: 0.003370975747450509\n",
      "SNR: 5/30, LS, Epoch 20/50, Loss: 0.0045064955078022075 \n",
      "SNR: 5/30, LS, Val Loss: 0.0032628952546722508\n",
      "SNR: 5/30, LS, Epoch 21/50, Loss: 0.00445327140407117 \n",
      "SNR: 5/30, LS, Val Loss: 0.003040872217917984\n",
      "SNR: 5/30, LS, Epoch 22/50, Loss: 0.004378797111458816 \n",
      "SNR: 5/30, LS, Val Loss: 0.0035545856861228294\n",
      "SNR: 5/30, LS, Epoch 23/50, Loss: 0.004295850789910832 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029852472944185138\n",
      "SNR: 5/30, LS, Epoch 24/50, Loss: 0.004319014992878967 \n",
      "SNR: 5/30, LS, Val Loss: 0.003071194091303782\n",
      "SNR: 5/30, LS, Epoch 25/50, Loss: 0.0043102038366351885 \n",
      "SNR: 5/30, LS, Val Loss: 0.0039014691719785333\n",
      "SNR: 5/30, LS, Epoch 26/50, Loss: 0.0044377579673215055 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029996266186406665\n",
      "SNR: 5/30, LS, Epoch 27/50, Loss: 0.004360908504337246 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031332448336549783\n",
      "SNR: 5/30, LS, Epoch 28/50, Loss: 0.004399460336994813 \n",
      "SNR: 5/30, LS, Val Loss: 0.0032026821493425154\n",
      "SNR: 5/30, LS, Epoch 29/50, Loss: 0.004035817093735691 \n",
      "SNR: 5/30, LS, Val Loss: 0.002882295129397376\n",
      "SNR: 5/30, LS, Epoch 30/50, Loss: 0.004046310888614159 \n",
      "SNR: 5/30, LS, Val Loss: 0.002865573454817588\n",
      "SNR: 5/30, LS, Epoch 31/50, Loss: 0.004189105588011444 \n",
      "SNR: 5/30, LS, Val Loss: 0.0037106993735175242\n",
      "SNR: 5/30, LS, Epoch 32/50, Loss: 0.004112163505809338 \n",
      "SNR: 5/30, LS, Val Loss: 0.003087800747545605\n",
      "SNR: 5/30, LS, Epoch 33/50, Loss: 0.004112485777261818 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029344087127934804\n",
      "SNR: 5/30, LS, Epoch 34/50, Loss: 0.004099044541362673 \n",
      "SNR: 5/30, LS, Val Loss: 0.002672474418597465\n",
      "SNR: 5/30, LS, Epoch 35/50, Loss: 0.004069364402269901 \n",
      "SNR: 5/30, LS, Val Loss: 0.002919330208731646\n",
      "SNR: 5/30, LS, Epoch 36/50, Loss: 0.003954056722144488 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026655707677656956\n",
      "SNR: 5/30, LS, Epoch 37/50, Loss: 0.0040138044372894045 \n",
      "SNR: 5/30, LS, Val Loss: 0.003046957828866487\n",
      "SNR: 5/30, LS, Epoch 38/50, Loss: 0.0040736823846304485 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029577916297553616\n",
      "SNR: 5/30, LS, Epoch 39/50, Loss: 0.0039032736189425167 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026009510779245334\n",
      "SNR: 5/30, LS, Epoch 40/50, Loss: 0.0037831429156561405 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026500201254913754\n",
      "SNR: 5/30, LS, Epoch 41/50, Loss: 0.0038745911814932993 \n",
      "SNR: 5/30, LS, Val Loss: 0.002906435031697831\n",
      "SNR: 5/30, LS, Epoch 42/50, Loss: 0.0038630978683507895 \n",
      "SNR: 5/30, LS, Val Loss: 0.002769150358455425\n",
      "SNR: 5/30, LS, Epoch 43/50, Loss: 0.003952119998947912 \n",
      "SNR: 5/30, LS, Val Loss: 0.0028336662481623616\n",
      "SNR: 5/30, LS, Epoch 44/50, Loss: 0.003764523427424476 \n",
      "SNR: 5/30, LS, Val Loss: 0.002542011408050629\n",
      "SNR: 5/30, LS, Epoch 45/50, Loss: 0.004129217363634082 \n",
      "SNR: 5/30, LS, Val Loss: 0.003254977711053057\n",
      "SNR: 5/30, LS, Epoch 46/50, Loss: 0.0037318238918128055 \n",
      "SNR: 5/30, LS, Val Loss: 0.002632458890068599\n",
      "SNR: 5/30, LS, Epoch 47/50, Loss: 0.0038383012003980056 \n",
      "SNR: 5/30, LS, Val Loss: 0.002610246587375348\n",
      "SNR: 5/30, LS, Epoch 48/50, Loss: 0.003714947866514152 \n",
      "SNR: 5/30, LS, Val Loss: 0.002454423102211546\n",
      "SNR: 5/30, LS, Epoch 49/50, Loss: 0.003820343699771911 \n",
      "SNR: 5/30, LS, Val Loss: 0.0025254089110107584\n",
      "SNR: 5/30, LS, Epoch 50/50, Loss: 0.004040654316858583 \n",
      "SNR: 5/30, LS, Val Loss: 0.0028927019924264064\n",
      "LS+LI NMSE: 0.008229153230786324\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/50, Loss: 0.11475119035864292 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.01843666099011898\n",
      "SNR: 10/30, LS+LI, Epoch 2/50, Loss: 0.04734133441694254 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.008243243315849792\n",
      "SNR: 10/30, LS+LI, Epoch 3/50, Loss: 0.035228395802077164 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.006345708050172438\n",
      "SNR: 10/30, LS+LI, Epoch 4/50, Loss: 0.029852352938939664 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.007003235101530498\n",
      "SNR: 10/30, LS+LI, Epoch 5/50, Loss: 0.026368920680482025 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.006485049358823083\n",
      "SNR: 10/30, LS+LI, Epoch 6/50, Loss: 0.0238618926296747 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.006244569593532519\n",
      "SNR: 10/30, LS+LI, Epoch 7/50, Loss: 0.021869613994779283 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0046884345250542865\n",
      "SNR: 10/30, LS+LI, Epoch 8/50, Loss: 0.020433017388419357 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005431191413663328\n",
      "SNR: 10/30, LS+LI, Epoch 9/50, Loss: 0.01913915302734389 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005207718805071305\n",
      "SNR: 10/30, LS+LI, Epoch 10/50, Loss: 0.018086991424477377 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00442824965681542\n",
      "SNR: 10/30, LS+LI, Epoch 11/50, Loss: 0.01710391359750268 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004460093851031905\n",
      "SNR: 10/30, LS+LI, Epoch 12/50, Loss: 0.016415679399573873 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004165165920064531\n",
      "SNR: 10/30, LS+LI, Epoch 13/50, Loss: 0.01566510104444311 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0042509400306946854\n",
      "SNR: 10/30, LS+LI, Epoch 14/50, Loss: 0.015272207000444448 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00410199772820554\n",
      "SNR: 10/30, LS+LI, Epoch 15/50, Loss: 0.014543782026225398 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004105759900994599\n",
      "SNR: 10/30, LS+LI, Epoch 16/50, Loss: 0.014091067887885972 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003979121292517943\n",
      "SNR: 10/30, LS+LI, Epoch 17/50, Loss: 0.01365693136075035 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004207020921801979\n",
      "SNR: 10/30, LS+LI, Epoch 18/50, Loss: 0.013337215533220145 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.006333817833695899\n",
      "SNR: 10/30, LS+LI, Epoch 19/50, Loss: 0.012908456148579717 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004104646928185089\n",
      "SNR: 10/30, LS+LI, Epoch 20/50, Loss: 0.0126240304021468 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004536930185912008\n",
      "SNR: 10/30, LS+LI, Epoch 21/50, Loss: 0.01214477003465385 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004189397557638586\n",
      "SNR: 10/30, LS+LI, Epoch 22/50, Loss: 0.011923759320187707 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003850335244682025\n",
      "SNR: 10/30, LS+LI, Epoch 23/50, Loss: 0.011681371877446424 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003905608752657744\n",
      "SNR: 10/30, LS+LI, Epoch 24/50, Loss: 0.011496143729620895 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0039837024894289\n",
      "SNR: 10/30, LS+LI, Epoch 25/50, Loss: 0.011141907288368011 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0038666992173106833\n",
      "SNR: 10/30, LS+LI, Epoch 26/50, Loss: 0.010924985437372397 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004825616816312752\n",
      "SNR: 10/30, LS+LI, Epoch 27/50, Loss: 0.011085811444709813 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00390803595920178\n",
      "SNR: 10/30, LS+LI, Epoch 28/50, Loss: 0.010631929433276488 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003820260584523732\n",
      "SNR: 10/30, LS+LI, Epoch 29/50, Loss: 0.010445684687299438 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004047768836078996\n",
      "SNR: 10/30, LS+LI, Epoch 30/50, Loss: 0.010306717508450844 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00448945923496715\n",
      "SNR: 10/30, LS+LI, Epoch 31/50, Loss: 0.010190902965489862 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037888794269582086\n",
      "SNR: 10/30, LS+LI, Epoch 32/50, Loss: 0.009937666519003551 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003737722385928712\n",
      "SNR: 10/30, LS+LI, Epoch 33/50, Loss: 0.009870735381534972 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037558092418211427\n",
      "SNR: 10/30, LS+LI, Epoch 34/50, Loss: 0.00967397878141424 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004211171064525843\n",
      "SNR: 10/30, LS+LI, Epoch 35/50, Loss: 0.00975072429634544 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003908405059271238\n",
      "SNR: 10/30, LS+LI, Epoch 36/50, Loss: 0.009523721103188257 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004294709164903245\n",
      "SNR: 10/30, LS+LI, Epoch 37/50, Loss: 0.009355327574709473 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037025804208083587\n",
      "SNR: 10/30, LS+LI, Epoch 38/50, Loss: 0.009316893849456899 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003751120212572542\n",
      "SNR: 10/30, LS+LI, Epoch 39/50, Loss: 0.009129537921940345 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004734073088250377\n",
      "SNR: 10/30, LS+LI, Epoch 40/50, Loss: 0.009161196039924614 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037050858266990294\n",
      "SNR: 10/30, LS+LI, Epoch 41/50, Loss: 0.009149024788246946 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004419291889379648\n",
      "SNR: 10/30, LS+LI, Epoch 42/50, Loss: 0.009005774483951024 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005030118352310224\n",
      "SNR: 10/30, LS+LI, Epoch 43/50, Loss: 0.009032046606460975 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004290524764325131\n",
      "SNR: 10/30, LS+LI, Epoch 44/50, Loss: 0.00878664334088044 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003656783268194307\n",
      "SNR: 10/30, LS+LI, Epoch 45/50, Loss: 0.00872890392675736 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003809747741218995\n",
      "SNR: 10/30, LS+LI, Epoch 46/50, Loss: 0.00856587572597227 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0036988407373428345\n",
      "SNR: 10/30, LS+LI, Epoch 47/50, Loss: 0.008589958541939944 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003972594054754485\n",
      "SNR: 10/30, LS+LI, Epoch 48/50, Loss: 0.008565269556806185 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0038442849181592464\n",
      "SNR: 10/30, LS+LI, Epoch 49/50, Loss: 0.008536399975635631 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037627357735552573\n",
      "SNR: 10/30, LS+LI, Epoch 50/50, Loss: 0.00859709553756253 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037395546890117907\n",
      "LI+NN NMSE: 0.010630225762724876\n",
      "LS+LI NMSE: 0.00819182489067316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS\n",
      "SNR: 10/30, LS, Epoch 1/50, Loss: 0.25051818495659633 \n",
      "SNR: 10/30, LS, Val Loss: 0.06362521546808156\n",
      "SNR: 10/30, LS, Epoch 2/50, Loss: 0.015457231026186152 \n",
      "SNR: 10/30, LS, Val Loss: 0.006752024764533748\n",
      "SNR: 10/30, LS, Epoch 3/50, Loss: 0.006835626638602725 \n",
      "SNR: 10/30, LS, Val Loss: 0.005127164598723704\n",
      "SNR: 10/30, LS, Epoch 4/50, Loss: 0.005757104801717972 \n",
      "SNR: 10/30, LS, Val Loss: 0.004248585932972756\n",
      "SNR: 10/30, LS, Epoch 5/50, Loss: 0.005055790857769289 \n",
      "SNR: 10/30, LS, Val Loss: 0.003849132600325075\n",
      "SNR: 10/30, LS, Epoch 6/50, Loss: 0.004702042039689543 \n",
      "SNR: 10/30, LS, Val Loss: 0.003440303151199425\n",
      "SNR: 10/30, LS, Epoch 7/50, Loss: 0.004785685403391632 \n",
      "SNR: 10/30, LS, Val Loss: 0.003155489801429212\n",
      "SNR: 10/30, LS, Epoch 8/50, Loss: 0.0043163430108147305 \n",
      "SNR: 10/30, LS, Val Loss: 0.0039031847316602416\n",
      "SNR: 10/30, LS, Epoch 9/50, Loss: 0.0040386815225099066 \n",
      "SNR: 10/30, LS, Val Loss: 0.002858915757811205\n",
      "SNR: 10/30, LS, Epoch 10/50, Loss: 0.0038361798952940072 \n",
      "SNR: 10/30, LS, Val Loss: 0.0030304708740335295\n",
      "SNR: 10/30, LS, Epoch 11/50, Loss: 0.003953434445700327 \n",
      "SNR: 10/30, LS, Val Loss: 0.0028246079984290354\n",
      "SNR: 10/30, LS, Epoch 12/50, Loss: 0.003671831444588078 \n",
      "SNR: 10/30, LS, Val Loss: 0.0023170857298695905\n",
      "SNR: 10/30, LS, Epoch 13/50, Loss: 0.003960406250688572 \n",
      "SNR: 10/30, LS, Val Loss: 0.0025003769710151987\n",
      "SNR: 10/30, LS, Epoch 14/50, Loss: 0.0036670712823167356 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022919700184667654\n",
      "SNR: 10/30, LS, Epoch 15/50, Loss: 0.003559369157301262 \n",
      "SNR: 10/30, LS, Val Loss: 0.002237768536856906\n",
      "SNR: 10/30, LS, Epoch 16/50, Loss: 0.0036916976982760137 \n",
      "SNR: 10/30, LS, Val Loss: 0.00221744735873389\n",
      "SNR: 10/30, LS, Epoch 17/50, Loss: 0.003584880709409887 \n",
      "SNR: 10/30, LS, Val Loss: 0.0021984702166677876\n",
      "SNR: 10/30, LS, Epoch 18/50, Loss: 0.0035354185025045256 \n",
      "SNR: 10/30, LS, Val Loss: 0.0024183333311653273\n",
      "SNR: 10/30, LS, Epoch 19/50, Loss: 0.0032364841446356285 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018902725688266482\n",
      "SNR: 10/30, LS, Epoch 20/50, Loss: 0.0032265870270135185 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020369479792531242\n",
      "SNR: 10/30, LS, Epoch 21/50, Loss: 0.0033591163722354227 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020573045264675534\n",
      "SNR: 10/30, LS, Epoch 22/50, Loss: 0.0032549207484577026 \n",
      "SNR: 10/30, LS, Val Loss: 0.001930652969432148\n",
      "SNR: 10/30, LS, Epoch 23/50, Loss: 0.003036841965377937 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018982810645618222\n",
      "SNR: 10/30, LS, Epoch 24/50, Loss: 0.0033866091005958963 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022184799890965223\n",
      "SNR: 10/30, LS, Epoch 25/50, Loss: 0.003107711050773126 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019722270557064226\n",
      "SNR: 10/30, LS, Epoch 26/50, Loss: 0.0032893556446313512 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019500360305590386\n",
      "SNR: 10/30, LS, Epoch 27/50, Loss: 0.003075954905673212 \n",
      "SNR: 10/30, LS, Val Loss: 0.001891114241020246\n",
      "SNR: 10/30, LS, Epoch 28/50, Loss: 0.0031782146759851033 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017962860028174791\n",
      "SNR: 10/30, LS, Epoch 29/50, Loss: 0.0032878020232770767 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018580515435050156\n",
      "SNR: 10/30, LS, Epoch 30/50, Loss: 0.0030304757278510046 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020681882001967592\n",
      "SNR: 10/30, LS, Epoch 31/50, Loss: 0.0029053103603790837 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017022662690248\n",
      "SNR: 10/30, LS, Epoch 32/50, Loss: 0.002952138313260146 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015980798687616532\n",
      "SNR: 10/30, LS, Epoch 33/50, Loss: 0.0034672897376748194 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017091398000378501\n",
      "SNR: 10/30, LS, Epoch 34/50, Loss: 0.003314789919978614 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015793659787794406\n",
      "SNR: 10/30, LS, Epoch 35/50, Loss: 0.003192378457115833 \n",
      "SNR: 10/30, LS, Val Loss: 0.001591953475409272\n",
      "SNR: 10/30, LS, Epoch 36/50, Loss: 0.003005169127623789 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015867190827107565\n",
      "SNR: 10/30, LS, Epoch 37/50, Loss: 0.0030448800501099594 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016890258306044746\n",
      "SNR: 10/30, LS, Epoch 38/50, Loss: 0.00310351119409207 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015926904426040974\n",
      "SNR: 10/30, LS, Epoch 39/50, Loss: 0.0027724801208065864 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017208062980154698\n",
      "SNR: 10/30, LS, Epoch 40/50, Loss: 0.0030833409069008517 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015159104897809977\n",
      "SNR: 10/30, LS, Epoch 41/50, Loss: 0.0027084841317129 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015724025910127568\n",
      "SNR: 10/30, LS, Epoch 42/50, Loss: 0.003085762621742825 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016904771063392136\n",
      "SNR: 10/30, LS, Epoch 43/50, Loss: 0.003042501911147346 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016809323463927615\n",
      "SNR: 10/30, LS, Epoch 44/50, Loss: 0.0027322113083480576 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015042125490832734\n",
      "SNR: 10/30, LS, Epoch 45/50, Loss: 0.0028384603555909856 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017606168403290212\n",
      "SNR: 10/30, LS, Epoch 46/50, Loss: 0.002821883950842718 \n",
      "SNR: 10/30, LS, Val Loss: 0.0013418078676543453\n",
      "SNR: 10/30, LS, Epoch 47/50, Loss: 0.0027761424676417696 \n",
      "SNR: 10/30, LS, Val Loss: 0.001814028052401475\n",
      "SNR: 10/30, LS, Epoch 48/50, Loss: 0.0028238539194125074 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022992803873917596\n",
      "SNR: 10/30, LS, Epoch 49/50, Loss: 0.0027994934014629485 \n",
      "SNR: 10/30, LS, Val Loss: 0.0013197965718890455\n",
      "SNR: 10/30, LS, Epoch 50/50, Loss: 0.002775282896161729 \n",
      "SNR: 10/30, LS, Val Loss: 0.001403770269296894\n",
      "LS+LI NMSE: 0.004100498743355274\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/50, Loss: 0.10720857360595187 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.016920921477404507\n",
      "SNR: 15/30, LS+LI, Epoch 2/50, Loss: 0.04287857962988837 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00541017071174627\n",
      "SNR: 15/30, LS+LI, Epoch 3/50, Loss: 0.030443436856013396 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0043269037798216396\n",
      "SNR: 15/30, LS+LI, Epoch 4/50, Loss: 0.02543959034563497 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0037977146090600977\n",
      "SNR: 15/30, LS+LI, Epoch 5/50, Loss: 0.022414929201003422 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.004543753351423551\n",
      "SNR: 15/30, LS+LI, Epoch 6/50, Loss: 0.020288251816879873 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0028354431587186727\n",
      "SNR: 15/30, LS+LI, Epoch 7/50, Loss: 0.018647339422429025 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002277331320907582\n",
      "SNR: 15/30, LS+LI, Epoch 8/50, Loss: 0.017164555491966216 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0023967359553683887\n",
      "SNR: 15/30, LS+LI, Epoch 9/50, Loss: 0.016176206731172496 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0025246127413331783\n",
      "SNR: 15/30, LS+LI, Epoch 10/50, Loss: 0.01514774311312236 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0021417610061524265\n",
      "SNR: 15/30, LS+LI, Epoch 11/50, Loss: 0.014346824097988565 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002166881670498035\n",
      "SNR: 15/30, LS+LI, Epoch 12/50, Loss: 0.013913301003793644 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0030647690767760982\n",
      "SNR: 15/30, LS+LI, Epoch 13/50, Loss: 0.013066670960248557 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0030721753983843055\n",
      "SNR: 15/30, LS+LI, Epoch 14/50, Loss: 0.01237978170582548 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002833544361320409\n",
      "SNR: 15/30, LS+LI, Epoch 15/50, Loss: 0.012144011640271474 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0024140846005386925\n",
      "SNR: 15/30, LS+LI, Epoch 16/50, Loss: 0.01146083117765916 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001758270320186222\n",
      "SNR: 15/30, LS+LI, Epoch 17/50, Loss: 0.01115317294525719 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001840158185752278\n",
      "SNR: 15/30, LS+LI, Epoch 18/50, Loss: 0.01088990657698623 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017833135365931826\n",
      "SNR: 15/30, LS+LI, Epoch 19/50, Loss: 0.010334201693144996 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017065640263767405\n",
      "SNR: 15/30, LS+LI, Epoch 20/50, Loss: 0.010109730795848855 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017846121865494008\n",
      "SNR: 15/30, LS+LI, Epoch 21/50, Loss: 0.009781031365787913 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0023381392397409813\n",
      "SNR: 15/30, LS+LI, Epoch 22/50, Loss: 0.009713434348922483 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002182180686345832\n",
      "SNR: 15/30, LS+LI, Epoch 23/50, Loss: 0.009332253289040785 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002093099380462346\n",
      "SNR: 15/30, LS+LI, Epoch 24/50, Loss: 0.00908797079978814 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017796968776648018\n",
      "SNR: 15/30, LS+LI, Epoch 25/50, Loss: 0.008997064744403888 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019133578911847012\n",
      "SNR: 15/30, LS+LI, Epoch 26/50, Loss: 0.008679643422256895 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001884270877450366\n",
      "SNR: 15/30, LS+LI, Epoch 27/50, Loss: 0.008681947097377202 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0028101701225916095\n",
      "SNR: 15/30, LS+LI, Epoch 28/50, Loss: 0.008362131160792223 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018784696268002417\n",
      "SNR: 15/30, LS+LI, Epoch 29/50, Loss: 0.00808514462145002 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018550443346612155\n",
      "SNR: 15/30, LS+LI, Epoch 30/50, Loss: 0.008016849738047567 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015589744328859854\n",
      "SNR: 15/30, LS+LI, Epoch 31/50, Loss: 0.007921870567749232 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019253736510026183\n",
      "SNR: 15/30, LS+LI, Epoch 32/50, Loss: 0.0077447129933293475 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016623568901030178\n",
      "SNR: 15/30, LS+LI, Epoch 33/50, Loss: 0.007695182876358199 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016775766853243113\n",
      "SNR: 15/30, LS+LI, Epoch 34/50, Loss: 0.007658176262169903 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016008588347838006\n",
      "SNR: 15/30, LS+LI, Epoch 35/50, Loss: 0.007397201353532457 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0021154356919313696\n",
      "SNR: 15/30, LS+LI, Epoch 36/50, Loss: 0.007586201999423115 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001547253060958941\n",
      "SNR: 15/30, LS+LI, Epoch 37/50, Loss: 0.007266549953952605 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017027125312862072\n",
      "SNR: 15/30, LS+LI, Epoch 38/50, Loss: 0.007227661301988328 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016748131972483613\n",
      "SNR: 15/30, LS+LI, Epoch 39/50, Loss: 0.006954543127375114 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015892154346643524\n",
      "SNR: 15/30, LS+LI, Epoch 40/50, Loss: 0.006940980590771624 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016405197939920154\n",
      "SNR: 15/30, LS+LI, Epoch 41/50, Loss: 0.006808617626056942 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015201830326325514\n",
      "SNR: 15/30, LS+LI, Epoch 42/50, Loss: 0.006790657782234078 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015111794504760342\n",
      "SNR: 15/30, LS+LI, Epoch 43/50, Loss: 0.006661328671196866 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001566419616045261\n",
      "SNR: 15/30, LS+LI, Epoch 44/50, Loss: 0.006661116316113188 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017461941408162768\n",
      "SNR: 15/30, LS+LI, Epoch 45/50, Loss: 0.006658438030023908 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002268139325844293\n",
      "SNR: 15/30, LS+LI, Epoch 46/50, Loss: 0.006610532210013548 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016613084537146444\n",
      "SNR: 15/30, LS+LI, Epoch 47/50, Loss: 0.006401394344974569 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015422774542292411\n",
      "SNR: 15/30, LS+LI, Epoch 48/50, Loss: 0.006367285031998573 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001486331240316345\n",
      "SNR: 15/30, LS+LI, Epoch 49/50, Loss: 0.006317677628790396 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001612714280120351\n",
      "SNR: 15/30, LS+LI, Epoch 50/50, Loss: 0.006371985186909347 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001849755792963234\n",
      "LI+NN NMSE: 0.004782072268426418\n",
      "LS+LI NMSE: 0.0026099637616425753\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/50, Loss: 0.24073111798700897 \n",
      "SNR: 15/30, LS, Val Loss: 0.06673792935907841\n",
      "SNR: 15/30, LS, Epoch 2/50, Loss: 0.015631440436727432 \n",
      "SNR: 15/30, LS, Val Loss: 0.005658334375105121\n",
      "SNR: 15/30, LS, Epoch 3/50, Loss: 0.005873601473488866 \n",
      "SNR: 15/30, LS, Val Loss: 0.004301430996168743\n",
      "SNR: 15/30, LS, Epoch 4/50, Loss: 0.0052856071242997635 \n",
      "SNR: 15/30, LS, Val Loss: 0.003815433571369133\n",
      "SNR: 15/30, LS, Epoch 5/50, Loss: 0.004638223583961642 \n",
      "SNR: 15/30, LS, Val Loss: 0.0033972788580947304\n",
      "SNR: 15/30, LS, Epoch 6/50, Loss: 0.004269014669008293 \n",
      "SNR: 15/30, LS, Val Loss: 0.002885244426910173\n",
      "SNR: 15/30, LS, Epoch 7/50, Loss: 0.004358281623734551 \n",
      "SNR: 15/30, LS, Val Loss: 0.002636627495204183\n",
      "SNR: 15/30, LS, Epoch 8/50, Loss: 0.004099289262613152 \n",
      "SNR: 15/30, LS, Val Loss: 0.0037330178628590975\n",
      "SNR: 15/30, LS, Epoch 9/50, Loss: 0.0038298882170428716 \n",
      "SNR: 15/30, LS, Val Loss: 0.0024120995235121386\n",
      "SNR: 15/30, LS, Epoch 10/50, Loss: 0.003871191361361335 \n",
      "SNR: 15/30, LS, Val Loss: 0.0023661452419632537\n",
      "SNR: 15/30, LS, Epoch 11/50, Loss: 0.0034620005699675964 \n",
      "SNR: 15/30, LS, Val Loss: 0.0021382745895111425\n",
      "SNR: 15/30, LS, Epoch 12/50, Loss: 0.0034905801822301434 \n",
      "SNR: 15/30, LS, Val Loss: 0.0023532725066285243\n",
      "SNR: 15/30, LS, Epoch 13/50, Loss: 0.003508004193399968 \n",
      "SNR: 15/30, LS, Val Loss: 0.002628398418892175\n",
      "SNR: 15/30, LS, Epoch 14/50, Loss: 0.00362074128176129 \n",
      "SNR: 15/30, LS, Val Loss: 0.0023524720454588532\n",
      "SNR: 15/30, LS, Epoch 15/50, Loss: 0.0032129171507454717 \n",
      "SNR: 15/30, LS, Val Loss: 0.0019357398797927256\n",
      "SNR: 15/30, LS, Epoch 16/50, Loss: 0.003016699161678336 \n",
      "SNR: 15/30, LS, Val Loss: 0.002251158717130734\n",
      "SNR: 15/30, LS, Epoch 17/50, Loss: 0.003051216276173025 \n",
      "SNR: 15/30, LS, Val Loss: 0.0017811535878784277\n",
      "SNR: 15/30, LS, Epoch 18/50, Loss: 0.0028851472185166594 \n",
      "SNR: 15/30, LS, Val Loss: 0.0017256443547508256\n",
      "SNR: 15/30, LS, Epoch 19/50, Loss: 0.0032604781986582416 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016435082705522125\n",
      "SNR: 15/30, LS, Epoch 20/50, Loss: 0.0030652955790364377 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016921896656805818\n",
      "SNR: 15/30, LS, Epoch 21/50, Loss: 0.0029174017105359842 \n",
      "SNR: 15/30, LS, Val Loss: 0.0017184564388695765\n",
      "SNR: 15/30, LS, Epoch 22/50, Loss: 0.0030040955299587358 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016406019250015643\n",
      "SNR: 15/30, LS, Epoch 23/50, Loss: 0.0029392990609901676 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014334530040452426\n",
      "SNR: 15/30, LS, Epoch 24/50, Loss: 0.0032942988645816005 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015707143624736505\n",
      "SNR: 15/30, LS, Epoch 25/50, Loss: 0.003099819504504287 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015740755215202544\n",
      "SNR: 15/30, LS, Epoch 26/50, Loss: 0.002707705393753036 \n",
      "SNR: 15/30, LS, Val Loss: 0.00138771209590645\n",
      "SNR: 15/30, LS, Epoch 27/50, Loss: 0.003009610268595997 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014539369942874393\n",
      "SNR: 15/30, LS, Epoch 28/50, Loss: 0.002775422718408409 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013620507935146716\n",
      "SNR: 15/30, LS, Epoch 29/50, Loss: 0.002798935051920802 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013147005388005214\n",
      "SNR: 15/30, LS, Epoch 30/50, Loss: 0.0028174668056403047 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013004107115028257\n",
      "SNR: 15/30, LS, Epoch 31/50, Loss: 0.0029718403028984835 \n",
      "SNR: 15/30, LS, Val Loss: 0.001344438795719973\n",
      "SNR: 15/30, LS, Epoch 32/50, Loss: 0.0030327853563967225 \n",
      "SNR: 15/30, LS, Val Loss: 0.0031105715527453208\n",
      "SNR: 15/30, LS, Epoch 33/50, Loss: 0.0029021308454143446 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013465475534427571\n",
      "SNR: 15/30, LS, Epoch 34/50, Loss: 0.002687903874429203 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016391420398246157\n",
      "SNR: 15/30, LS, Epoch 35/50, Loss: 0.002622623071697172 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013770455896685069\n",
      "SNR: 15/30, LS, Epoch 36/50, Loss: 0.0026310440518373494 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012841979200443761\n",
      "SNR: 15/30, LS, Epoch 37/50, Loss: 0.0027426296742199814 \n",
      "SNR: 15/30, LS, Val Loss: 0.0011471207676963372\n",
      "SNR: 15/30, LS, Epoch 38/50, Loss: 0.002684736963453551 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016310956826518204\n",
      "SNR: 15/30, LS, Epoch 39/50, Loss: 0.0026690682462622347 \n",
      "SNR: 15/30, LS, Val Loss: 0.001210350582947616\n",
      "SNR: 15/30, LS, Epoch 40/50, Loss: 0.0027556681093830224 \n",
      "SNR: 15/30, LS, Val Loss: 0.0019115463523617523\n",
      "SNR: 15/30, LS, Epoch 41/50, Loss: 0.0027263894180366553 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012056673400696707\n",
      "SNR: 15/30, LS, Epoch 42/50, Loss: 0.0028794670861950794 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012473223561590369\n",
      "SNR: 15/30, LS, Epoch 43/50, Loss: 0.0026217583901259702 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012488692935386841\n",
      "SNR: 15/30, LS, Epoch 44/50, Loss: 0.0026580342961350714 \n",
      "SNR: 15/30, LS, Val Loss: 0.0011719862073236568\n",
      "SNR: 15/30, LS, Epoch 45/50, Loss: 0.0027870798556588936 \n",
      "SNR: 15/30, LS, Val Loss: 0.0011644520802127029\n",
      "SNR: 15/30, LS, Epoch 46/50, Loss: 0.0029655475342689557 \n",
      "SNR: 15/30, LS, Val Loss: 0.001585528026969934\n",
      "SNR: 15/30, LS, Epoch 47/50, Loss: 0.0023388627955153976 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010642714888407763\n",
      "SNR: 15/30, LS, Epoch 48/50, Loss: 0.002570102092143971 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010343561589252204\n",
      "SNR: 15/30, LS, Epoch 49/50, Loss: 0.002488616530764523 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010194182078438726\n",
      "SNR: 15/30, LS, Epoch 50/50, Loss: 0.0026534527220741606 \n",
      "SNR: 15/30, LS, Val Loss: 0.001390635813798078\n",
      "LS+LI NMSE: 0.0040097907185554504\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/50, Loss: 0.11510772723704576 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.017351628027179024\n",
      "SNR: 20/30, LS+LI, Epoch 2/50, Loss: 0.0457584232655029 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.005509808045727285\n",
      "SNR: 20/30, LS+LI, Epoch 3/50, Loss: 0.03223215064120501 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.005699507278305563\n",
      "SNR: 20/30, LS+LI, Epoch 4/50, Loss: 0.0265821986615138 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0023975026613863356\n",
      "SNR: 20/30, LS+LI, Epoch 5/50, Loss: 0.022897625601915425 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0022475067420269956\n",
      "SNR: 20/30, LS+LI, Epoch 6/50, Loss: 0.02033211652536032 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.002652786719739776\n",
      "SNR: 20/30, LS+LI, Epoch 7/50, Loss: 0.018393921655017968 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0024617048911750317\n",
      "SNR: 20/30, LS+LI, Epoch 8/50, Loss: 0.017044184875652887 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0017129449618302963\n",
      "SNR: 20/30, LS+LI, Epoch 9/50, Loss: 0.015868272047576515 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001520712563598698\n",
      "SNR: 20/30, LS+LI, Epoch 10/50, Loss: 0.014803044075622808 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014844944261395458\n",
      "SNR: 20/30, LS+LI, Epoch 11/50, Loss: 0.013969388812087303 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0013353594351263548\n",
      "SNR: 20/30, LS+LI, Epoch 12/50, Loss: 0.013227484762928513 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0013074071109506556\n",
      "SNR: 20/30, LS+LI, Epoch 13/50, Loss: 0.01253232802805859 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00139030527101237\n",
      "SNR: 20/30, LS+LI, Epoch 14/50, Loss: 0.012100567131541496 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.002327815629541874\n",
      "SNR: 20/30, LS+LI, Epoch 15/50, Loss: 0.011573607042475148 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00274145193609663\n",
      "SNR: 20/30, LS+LI, Epoch 16/50, Loss: 0.011240697065151708 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014770356197418137\n",
      "SNR: 20/30, LS+LI, Epoch 17/50, Loss: 0.01068804090366114 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001258012984180823\n",
      "SNR: 20/30, LS+LI, Epoch 18/50, Loss: 0.010252305127810253 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0020827937458472497\n",
      "SNR: 20/30, LS+LI, Epoch 19/50, Loss: 0.009902813038680442 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.002210793175353584\n",
      "SNR: 20/30, LS+LI, Epoch 20/50, Loss: 0.009593583697583093 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014331360183529216\n",
      "SNR: 20/30, LS+LI, Epoch 21/50, Loss: 0.009230635583747265 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0011144081310538406\n",
      "SNR: 20/30, LS+LI, Epoch 22/50, Loss: 0.009005434946481919 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010181804854338143\n",
      "SNR: 20/30, LS+LI, Epoch 23/50, Loss: 0.008950495242336116 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.003165695900944146\n",
      "SNR: 20/30, LS+LI, Epoch 24/50, Loss: 0.008513432437402392 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010445198012431238\n",
      "SNR: 20/30, LS+LI, Epoch 25/50, Loss: 0.008322034553668006 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0026000488485971637\n",
      "SNR: 20/30, LS+LI, Epoch 26/50, Loss: 0.008153863762895208 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018523982091044838\n",
      "SNR: 20/30, LS+LI, Epoch 27/50, Loss: 0.008191105601009588 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0011067856817548586\n",
      "SNR: 20/30, LS+LI, Epoch 28/50, Loss: 0.007774554704705817 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001256500085053796\n",
      "SNR: 20/30, LS+LI, Epoch 29/50, Loss: 0.0076545819688891605 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009126619406742975\n",
      "SNR: 20/30, LS+LI, Epoch 30/50, Loss: 0.007410208494294175 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0017307562785307791\n",
      "SNR: 20/30, LS+LI, Epoch 31/50, Loss: 0.007268542892212958 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014911430930210786\n",
      "SNR: 20/30, LS+LI, Epoch 32/50, Loss: 0.007225644106023707 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008807041700823571\n",
      "SNR: 20/30, LS+LI, Epoch 33/50, Loss: 0.006960518352232527 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014156209310220386\n",
      "SNR: 20/30, LS+LI, Epoch 34/50, Loss: 0.007032147646600077 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0011840040440967475\n",
      "SNR: 20/30, LS+LI, Epoch 35/50, Loss: 0.006702521339405415 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000992879652502862\n",
      "SNR: 20/30, LS+LI, Epoch 36/50, Loss: 0.006567015946127994 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000973236485151574\n",
      "SNR: 20/30, LS+LI, Epoch 37/50, Loss: 0.006942313955013835 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008826126815454865\n",
      "SNR: 20/30, LS+LI, Epoch 38/50, Loss: 0.006741582665072624 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014858335886277598\n",
      "SNR: 20/30, LS+LI, Epoch 39/50, Loss: 0.006397796949090133 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000845721361904659\n",
      "SNR: 20/30, LS+LI, Epoch 40/50, Loss: 0.00621781591055265 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009025548947234215\n",
      "SNR: 20/30, LS+LI, Epoch 41/50, Loss: 0.0061217189447001314 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0017815856474705718\n",
      "SNR: 20/30, LS+LI, Epoch 42/50, Loss: 0.006223013827598892 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008681217520709404\n",
      "SNR: 20/30, LS+LI, Epoch 43/50, Loss: 0.0059982868057654 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001679312173192474\n",
      "SNR: 20/30, LS+LI, Epoch 44/50, Loss: 0.006157566931336945 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018498302723111754\n",
      "SNR: 20/30, LS+LI, Epoch 45/50, Loss: 0.005990505789753136 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008760477490299804\n",
      "SNR: 20/30, LS+LI, Epoch 46/50, Loss: 0.005718254397601583 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000893836811883375\n",
      "SNR: 20/30, LS+LI, Epoch 47/50, Loss: 0.005832497038618597 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000987945322942158\n",
      "SNR: 20/30, LS+LI, Epoch 48/50, Loss: 0.005737040302889465 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008663750698112628\n",
      "SNR: 20/30, LS+LI, Epoch 49/50, Loss: 0.005753212971179638 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014547359076624905\n",
      "SNR: 20/30, LS+LI, Epoch 50/50, Loss: 0.005596626774667827 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008232615179043602\n",
      "LI+NN NMSE: 0.0023921621032059193\n",
      "LS+LI NMSE: 0.000826778297778219\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/50, Loss: 0.2541892139977494 \n",
      "SNR: 20/30, LS, Val Loss: 0.10158064114776524\n",
      "SNR: 20/30, LS, Epoch 2/50, Loss: 0.022139125437269983 \n",
      "SNR: 20/30, LS, Val Loss: 0.006185405834747309\n",
      "SNR: 20/30, LS, Epoch 3/50, Loss: 0.00552546089856214 \n",
      "SNR: 20/30, LS, Val Loss: 0.004816983561878177\n",
      "SNR: 20/30, LS, Epoch 4/50, Loss: 0.0051756895114776005 \n",
      "SNR: 20/30, LS, Val Loss: 0.003849545906467194\n",
      "SNR: 20/30, LS, Epoch 5/50, Loss: 0.004653292300645262 \n",
      "SNR: 20/30, LS, Val Loss: 0.003330305335111916\n",
      "SNR: 20/30, LS, Epoch 6/50, Loss: 0.004337301396569887 \n",
      "SNR: 20/30, LS, Val Loss: 0.003918396002105014\n",
      "SNR: 20/30, LS, Epoch 7/50, Loss: 0.004232912895616231 \n",
      "SNR: 20/30, LS, Val Loss: 0.002850981259887869\n",
      "SNR: 20/30, LS, Epoch 8/50, Loss: 0.0038308692090267445 \n",
      "SNR: 20/30, LS, Val Loss: 0.0027111498374407265\n",
      "SNR: 20/30, LS, Epoch 9/50, Loss: 0.0037362719858931594 \n",
      "SNR: 20/30, LS, Val Loss: 0.002520342526788061\n",
      "SNR: 20/30, LS, Epoch 10/50, Loss: 0.0036707810298160673 \n",
      "SNR: 20/30, LS, Val Loss: 0.002365494051694193\n",
      "SNR: 20/30, LS, Epoch 11/50, Loss: 0.0034729943483483134 \n",
      "SNR: 20/30, LS, Val Loss: 0.0023120126358910716\n",
      "SNR: 20/30, LS, Epoch 12/50, Loss: 0.003249612953622154 \n",
      "SNR: 20/30, LS, Val Loss: 0.0020918957095339215\n",
      "SNR: 20/30, LS, Epoch 13/50, Loss: 0.0032388397700933 \n",
      "SNR: 20/30, LS, Val Loss: 0.0019081609048457308\n",
      "SNR: 20/30, LS, Epoch 14/50, Loss: 0.0032558188770984322 \n",
      "SNR: 20/30, LS, Val Loss: 0.0018055880368179219\n",
      "SNR: 20/30, LS, Epoch 15/50, Loss: 0.003213619497918719 \n",
      "SNR: 20/30, LS, Val Loss: 0.001848452676891942\n",
      "SNR: 20/30, LS, Epoch 16/50, Loss: 0.003445817914325744 \n",
      "SNR: 20/30, LS, Val Loss: 0.004275669110938907\n",
      "SNR: 20/30, LS, Epoch 17/50, Loss: 0.00316474779216616 \n",
      "SNR: 20/30, LS, Val Loss: 0.002835808226584711\n",
      "SNR: 20/30, LS, Epoch 18/50, Loss: 0.0030528639150826735 \n",
      "SNR: 20/30, LS, Val Loss: 0.0020939070540903645\n",
      "SNR: 20/30, LS, Epoch 19/50, Loss: 0.002728543576627407 \n",
      "SNR: 20/30, LS, Val Loss: 0.001544398996471004\n",
      "SNR: 20/30, LS, Epoch 20/50, Loss: 0.002868300826332077 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015608361837538805\n",
      "SNR: 20/30, LS, Epoch 21/50, Loss: 0.002740080724199584 \n",
      "SNR: 20/30, LS, Val Loss: 0.0017448231599039652\n",
      "SNR: 20/30, LS, Epoch 22/50, Loss: 0.0027530710964171257 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015354591781612146\n",
      "SNR: 20/30, LS, Epoch 23/50, Loss: 0.0028830855180574364 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015278829536824064\n",
      "SNR: 20/30, LS, Epoch 24/50, Loss: 0.00295506268306527 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014250486485914073\n",
      "SNR: 20/30, LS, Epoch 25/50, Loss: 0.0030060186014283273 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012383419274225491\n",
      "SNR: 20/30, LS, Epoch 26/50, Loss: 0.003100083950029816 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014017631024630232\n",
      "SNR: 20/30, LS, Epoch 27/50, Loss: 0.002797082405629416 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015659396938810294\n",
      "SNR: 20/30, LS, Epoch 28/50, Loss: 0.0029359606621234655 \n",
      "SNR: 20/30, LS, Val Loss: 0.0013881003462963483\n",
      "SNR: 20/30, LS, Epoch 29/50, Loss: 0.0026074893394252285 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011970353053501722\n",
      "SNR: 20/30, LS, Epoch 30/50, Loss: 0.0025923527048922384 \n",
      "SNR: 20/30, LS, Val Loss: 0.001166523246369748\n",
      "SNR: 20/30, LS, Epoch 31/50, Loss: 0.002596357197035104 \n",
      "SNR: 20/30, LS, Val Loss: 0.001392899769019674\n",
      "SNR: 20/30, LS, Epoch 32/50, Loss: 0.0023697851710346375 \n",
      "SNR: 20/30, LS, Val Loss: 0.001788299504286525\n",
      "SNR: 20/30, LS, Epoch 33/50, Loss: 0.0025415583791178757 \n",
      "SNR: 20/30, LS, Val Loss: 0.0010717341051944954\n",
      "SNR: 20/30, LS, Epoch 34/50, Loss: 0.0027714720098058108 \n",
      "SNR: 20/30, LS, Val Loss: 0.0017768042744137347\n",
      "SNR: 20/30, LS, Epoch 35/50, Loss: 0.0023307790103243922 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011620060276155445\n",
      "SNR: 20/30, LS, Epoch 36/50, Loss: 0.0026502962976147227 \n",
      "SNR: 20/30, LS, Val Loss: 0.0013343852584842932\n",
      "SNR: 20/30, LS, Epoch 37/50, Loss: 0.0022927444251552007 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011958437495526266\n",
      "SNR: 20/30, LS, Epoch 38/50, Loss: 0.0025666883749329637 \n",
      "SNR: 20/30, LS, Val Loss: 0.001040430525211956\n",
      "SNR: 20/30, LS, Epoch 39/50, Loss: 0.0022110420618975143 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015077102156779306\n",
      "SNR: 20/30, LS, Epoch 40/50, Loss: 0.002237162505395624 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011955064520324495\n",
      "SNR: 20/30, LS, Epoch 41/50, Loss: 0.0025842450988928377 \n",
      "SNR: 20/30, LS, Val Loss: 0.0010395158685489812\n",
      "SNR: 20/30, LS, Epoch 42/50, Loss: 0.0021759067847512575 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009071560237895359\n",
      "SNR: 20/30, LS, Epoch 43/50, Loss: 0.0023244763470693427 \n",
      "SNR: 20/30, LS, Val Loss: 0.00158899295440113\n",
      "SNR: 20/30, LS, Epoch 44/50, Loss: 0.0025330607252747775 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012273122450675476\n",
      "SNR: 20/30, LS, Epoch 45/50, Loss: 0.00266136986177772 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009078360136217353\n",
      "SNR: 20/30, LS, Epoch 46/50, Loss: 0.00221166507473627 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011684152467006986\n",
      "SNR: 20/30, LS, Epoch 47/50, Loss: 0.002367675868891786 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009732677506028929\n",
      "SNR: 20/30, LS, Epoch 48/50, Loss: 0.002080526095977443 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009119713133920661\n",
      "SNR: 20/30, LS, Epoch 49/50, Loss: 0.002393642527411345 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014323109538633037\n",
      "SNR: 20/30, LS, Epoch 50/50, Loss: 0.0024346642011402954 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008691928868012673\n",
      "LS+LI NMSE: 0.0024452924262732267\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/50, Loss: 0.10375979233013335 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.011820969595150515\n",
      "SNR: 25/30, LS+LI, Epoch 2/50, Loss: 0.04066560371930516 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0046508587600493975\n",
      "SNR: 25/30, LS+LI, Epoch 3/50, Loss: 0.028813206839786713 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001995157857891172\n",
      "SNR: 25/30, LS+LI, Epoch 4/50, Loss: 0.024105597038341815 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0029403451851315117\n",
      "SNR: 25/30, LS+LI, Epoch 5/50, Loss: 0.020987487170672 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0016066166254776445\n",
      "SNR: 25/30, LS+LI, Epoch 6/50, Loss: 0.01898193804460556 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0025947618785060263\n",
      "SNR: 25/30, LS+LI, Epoch 7/50, Loss: 0.01730172665313233 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0022480926180089063\n",
      "SNR: 25/30, LS+LI, Epoch 8/50, Loss: 0.016010822912374902 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0013849176836877384\n",
      "SNR: 25/30, LS+LI, Epoch 9/50, Loss: 0.014760314275748854 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001636606265409765\n",
      "SNR: 25/30, LS+LI, Epoch 10/50, Loss: 0.013748140393777988 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0009543367539828813\n",
      "SNR: 25/30, LS+LI, Epoch 11/50, Loss: 0.013033070617766922 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0014304418106224728\n",
      "SNR: 25/30, LS+LI, Epoch 12/50, Loss: 0.012341868121523497 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008186403508509763\n",
      "SNR: 25/30, LS+LI, Epoch 13/50, Loss: 0.011602733322137664 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008799563696480949\n",
      "SNR: 25/30, LS+LI, Epoch 14/50, Loss: 0.01126185278299936 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007796762273011899\n",
      "SNR: 25/30, LS+LI, Epoch 15/50, Loss: 0.010695250824007184 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.000768998423485424\n",
      "SNR: 25/30, LS+LI, Epoch 16/50, Loss: 0.010257604136673171 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0014984993189996617\n",
      "SNR: 25/30, LS+LI, Epoch 17/50, Loss: 0.009846889668382531 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006474316072523255\n",
      "SNR: 25/30, LS+LI, Epoch 18/50, Loss: 0.009474896701312688 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008647367225917565\n",
      "SNR: 25/30, LS+LI, Epoch 19/50, Loss: 0.009138501070569767 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007177354550962759\n",
      "SNR: 25/30, LS+LI, Epoch 20/50, Loss: 0.008960923039202774 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005719370542051779\n",
      "SNR: 25/30, LS+LI, Epoch 21/50, Loss: 0.008579296254834463 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006441025761887431\n",
      "SNR: 25/30, LS+LI, Epoch 22/50, Loss: 0.008373150561373074 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0010881103040777486\n",
      "SNR: 25/30, LS+LI, Epoch 23/50, Loss: 0.008190103021428682 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005245917643399232\n",
      "SNR: 25/30, LS+LI, Epoch 24/50, Loss: 0.007942205211039373 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005284342756071551\n",
      "SNR: 25/30, LS+LI, Epoch 25/50, Loss: 0.0077155614163466665 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005635964520148594\n",
      "SNR: 25/30, LS+LI, Epoch 26/50, Loss: 0.007527987870690954 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001193106439049271\n",
      "SNR: 25/30, LS+LI, Epoch 27/50, Loss: 0.007356549735007764 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006147602398414165\n",
      "SNR: 25/30, LS+LI, Epoch 28/50, Loss: 0.00737547455355525 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0014181445797228\n",
      "SNR: 25/30, LS+LI, Epoch 29/50, Loss: 0.007035647857349453 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004694826480276375\n",
      "SNR: 25/30, LS+LI, Epoch 30/50, Loss: 0.0067421582522044 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008853069554210048\n",
      "SNR: 25/30, LS+LI, Epoch 31/50, Loss: 0.006714034116242168 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005775517717913979\n",
      "SNR: 25/30, LS+LI, Epoch 32/50, Loss: 0.006512337656648353 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.000863805902719667\n",
      "SNR: 25/30, LS+LI, Epoch 33/50, Loss: 0.006458535173171481 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005308810055298222\n",
      "SNR: 25/30, LS+LI, Epoch 34/50, Loss: 0.006519211223348975 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005405404385369779\n",
      "SNR: 25/30, LS+LI, Epoch 35/50, Loss: 0.006323848271655829 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007080882311459969\n",
      "SNR: 25/30, LS+LI, Epoch 36/50, Loss: 0.006132270910690517 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.000449059762600386\n",
      "SNR: 25/30, LS+LI, Epoch 37/50, Loss: 0.006130736905994804 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006767584206748077\n",
      "SNR: 25/30, LS+LI, Epoch 38/50, Loss: 0.005935641298027232 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0009161905830048702\n",
      "SNR: 25/30, LS+LI, Epoch 39/50, Loss: 0.00592339382409443 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004794369292953475\n",
      "SNR: 25/30, LS+LI, Epoch 40/50, Loss: 0.005793041013571066 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00056780791121789\n",
      "SNR: 25/30, LS+LI, Epoch 41/50, Loss: 0.005817230184410893 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007616498994387009\n",
      "SNR: 25/30, LS+LI, Epoch 42/50, Loss: 0.005788181272205399 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005006866651290858\n",
      "SNR: 25/30, LS+LI, Epoch 43/50, Loss: 0.0055083268414099894 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00043759768331338734\n",
      "SNR: 25/30, LS+LI, Epoch 44/50, Loss: 0.005465273639772001 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007333499167791822\n",
      "SNR: 25/30, LS+LI, Epoch 45/50, Loss: 0.005463863779834017 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006002572970993987\n",
      "SNR: 25/30, LS+LI, Epoch 46/50, Loss: 0.005381119155953097 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001239216383758255\n",
      "SNR: 25/30, LS+LI, Epoch 47/50, Loss: 0.005318138491210722 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.000526441709635864\n",
      "SNR: 25/30, LS+LI, Epoch 48/50, Loss: 0.00535025195554332 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00040051324652846563\n",
      "SNR: 25/30, LS+LI, Epoch 49/50, Loss: 0.005173871006686674 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005214116880035198\n",
      "SNR: 25/30, LS+LI, Epoch 50/50, Loss: 0.0052877872435072824 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001025024378164248\n",
      "LI+NN NMSE: 0.00285220704972744\n",
      "LS+LI NMSE: 0.0002621324092615396\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/50, Loss: 0.2347380915050243 \n",
      "SNR: 25/30, LS, Val Loss: 0.05873835069889372\n",
      "SNR: 25/30, LS, Epoch 2/50, Loss: 0.014059864241781449 \n",
      "SNR: 25/30, LS, Val Loss: 0.004977192158218135\n",
      "SNR: 25/30, LS, Epoch 3/50, Loss: 0.005110429143695551 \n",
      "SNR: 25/30, LS, Val Loss: 0.003597674425691366\n",
      "SNR: 25/30, LS, Epoch 4/50, Loss: 0.0046574918209401845 \n",
      "SNR: 25/30, LS, Val Loss: 0.00325687807476656\n",
      "SNR: 25/30, LS, Epoch 5/50, Loss: 0.004269012806363144 \n",
      "SNR: 25/30, LS, Val Loss: 0.0030076665782623672\n",
      "SNR: 25/30, LS, Epoch 6/50, Loss: 0.0039006240062177356 \n",
      "SNR: 25/30, LS, Val Loss: 0.002403954435563223\n",
      "SNR: 25/30, LS, Epoch 7/50, Loss: 0.0038368925567294015 \n",
      "SNR: 25/30, LS, Val Loss: 0.0023916347153400156\n",
      "SNR: 25/30, LS, Epoch 8/50, Loss: 0.0039014448459141044 \n",
      "SNR: 25/30, LS, Val Loss: 0.002470908469562842\n",
      "SNR: 25/30, LS, Epoch 9/50, Loss: 0.00344338986703173 \n",
      "SNR: 25/30, LS, Val Loss: 0.002572971978224814\n",
      "SNR: 25/30, LS, Epoch 10/50, Loss: 0.0031594895692758783 \n",
      "SNR: 25/30, LS, Val Loss: 0.0018093804352578115\n",
      "SNR: 25/30, LS, Epoch 11/50, Loss: 0.0032266746911350204 \n",
      "SNR: 25/30, LS, Val Loss: 0.001778774736025794\n",
      "SNR: 25/30, LS, Epoch 12/50, Loss: 0.0031838294647926423 \n",
      "SNR: 25/30, LS, Val Loss: 0.0026576940012587743\n",
      "SNR: 25/30, LS, Epoch 13/50, Loss: 0.0032186524395636 \n",
      "SNR: 25/30, LS, Val Loss: 0.0016190282344310121\n",
      "SNR: 25/30, LS, Epoch 14/50, Loss: 0.0033675236925266162 \n",
      "SNR: 25/30, LS, Val Loss: 0.001977767170914872\n",
      "SNR: 25/30, LS, Epoch 15/50, Loss: 0.0029479161495082947 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014498959644697607\n",
      "SNR: 25/30, LS, Epoch 16/50, Loss: 0.0029494645768440826 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015255773905664682\n",
      "SNR: 25/30, LS, Epoch 17/50, Loss: 0.0031930688723954266 \n",
      "SNR: 25/30, LS, Val Loss: 0.001725885519673201\n",
      "SNR: 25/30, LS, Epoch 18/50, Loss: 0.002797693299768536 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012564096171197227\n",
      "SNR: 25/30, LS, Epoch 19/50, Loss: 0.0029611389171657 \n",
      "SNR: 25/30, LS, Val Loss: 0.003109220828099007\n",
      "SNR: 25/30, LS, Epoch 20/50, Loss: 0.0029690986787521303 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015809935443526642\n",
      "SNR: 25/30, LS, Epoch 21/50, Loss: 0.0024891851901694007 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012985537601211531\n",
      "SNR: 25/30, LS, Epoch 22/50, Loss: 0.002876775515899279 \n",
      "SNR: 25/30, LS, Val Loss: 0.0017171848978085275\n",
      "SNR: 25/30, LS, Epoch 23/50, Loss: 0.002714860631385818 \n",
      "SNR: 25/30, LS, Val Loss: 0.001443935642865571\n",
      "SNR: 25/30, LS, Epoch 24/50, Loss: 0.002516214377084357 \n",
      "SNR: 25/30, LS, Val Loss: 0.001199565108188174\n",
      "SNR: 25/30, LS, Epoch 25/50, Loss: 0.002614684645248967 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012604574334215033\n",
      "SNR: 25/30, LS, Epoch 26/50, Loss: 0.0029424022261167033 \n",
      "SNR: 25/30, LS, Val Loss: 0.001521252466111698\n",
      "SNR: 25/30, LS, Epoch 27/50, Loss: 0.0026114258605873125 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011243119740604677\n",
      "SNR: 25/30, LS, Epoch 28/50, Loss: 0.00271950937742584 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011730177158659155\n",
      "SNR: 25/30, LS, Epoch 29/50, Loss: 0.0026006037826232916 \n",
      "SNR: 25/30, LS, Val Loss: 0.0017386518831534142\n",
      "SNR: 25/30, LS, Epoch 30/50, Loss: 0.0026565434977677545 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012575038497082212\n",
      "SNR: 25/30, LS, Epoch 31/50, Loss: 0.002522624997275903 \n",
      "SNR: 25/30, LS, Val Loss: 0.001044132664736191\n",
      "SNR: 25/30, LS, Epoch 32/50, Loss: 0.0023859390555095836 \n",
      "SNR: 25/30, LS, Val Loss: 0.0023727511606094513\n",
      "SNR: 25/30, LS, Epoch 33/50, Loss: 0.002727933826336507 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015704481947151098\n",
      "SNR: 25/30, LS, Epoch 34/50, Loss: 0.002746858625594245 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009201864727815105\n",
      "SNR: 25/30, LS, Epoch 35/50, Loss: 0.002407018805591411 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011340724912853066\n",
      "SNR: 25/30, LS, Epoch 36/50, Loss: 0.0026353375091444876 \n",
      "SNR: 25/30, LS, Val Loss: 0.001496011983941902\n",
      "SNR: 25/30, LS, Epoch 37/50, Loss: 0.002493073762770807 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011786361838775601\n",
      "SNR: 25/30, LS, Epoch 38/50, Loss: 0.002461804691593834 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015928751513869925\n",
      "SNR: 25/30, LS, Epoch 39/50, Loss: 0.0023607648127349527 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008547761932608079\n",
      "SNR: 25/30, LS, Epoch 40/50, Loss: 0.002449013330015289 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009406259632669389\n",
      "SNR: 25/30, LS, Epoch 41/50, Loss: 0.002342558870982747 \n",
      "SNR: 25/30, LS, Val Loss: 0.0016325251252221112\n",
      "SNR: 25/30, LS, Epoch 42/50, Loss: 0.0023959668273333635 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012125831510109658\n",
      "SNR: 25/30, LS, Epoch 43/50, Loss: 0.0022820459511591297 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008444714344064282\n",
      "SNR: 25/30, LS, Epoch 44/50, Loss: 0.002249259318273818 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008213446576105939\n",
      "SNR: 25/30, LS, Epoch 45/50, Loss: 0.002388268323049361 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008576398302631623\n",
      "SNR: 25/30, LS, Epoch 46/50, Loss: 0.0025555716315149007 \n",
      "SNR: 25/30, LS, Val Loss: 0.0007960923460566185\n",
      "SNR: 25/30, LS, Epoch 47/50, Loss: 0.00246652138221814 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008286069152580404\n",
      "SNR: 25/30, LS, Epoch 48/50, Loss: 0.0022604806672884585 \n",
      "SNR: 25/30, LS, Val Loss: 0.0017945104045793414\n",
      "SNR: 25/30, LS, Epoch 49/50, Loss: 0.0025397734144610505 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015739054599014873\n",
      "SNR: 25/30, LS, Epoch 50/50, Loss: 0.002196339621319609 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008568283784287897\n",
      "LS+LI NMSE: 0.00232556089758873\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/50, Loss: 0.12441555449609147 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.02025279106402939\n",
      "SNR: 30/30, LS+LI, Epoch 2/50, Loss: 0.05064035518917927 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.005261178107254885\n",
      "SNR: 30/30, LS+LI, Epoch 3/50, Loss: 0.03437240322142146 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.002689384823580357\n",
      "SNR: 30/30, LS+LI, Epoch 4/50, Loss: 0.027892866334336443 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0023624967275695367\n",
      "SNR: 30/30, LS+LI, Epoch 5/50, Loss: 0.023782944209267232 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.001592159128366885\n",
      "SNR: 30/30, LS+LI, Epoch 6/50, Loss: 0.02105533264490754 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0021939769662408667\n",
      "SNR: 30/30, LS+LI, Epoch 7/50, Loss: 0.018998177353899148 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0020858217612840235\n",
      "SNR: 30/30, LS+LI, Epoch 8/50, Loss: 0.01738030433676444 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.001016385371754454\n",
      "SNR: 30/30, LS+LI, Epoch 9/50, Loss: 0.01612621053057008 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0025007401021536102\n",
      "SNR: 30/30, LS+LI, Epoch 10/50, Loss: 0.015019373832876945 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008678221334279938\n",
      "SNR: 30/30, LS+LI, Epoch 11/50, Loss: 0.014015925831572955 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008174713293556124\n",
      "SNR: 30/30, LS+LI, Epoch 12/50, Loss: 0.013234325029432427 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0011118880541868168\n",
      "SNR: 30/30, LS+LI, Epoch 13/50, Loss: 0.012556509331388528 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008577555444472554\n",
      "SNR: 30/30, LS+LI, Epoch 14/50, Loss: 0.011828401624116787 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007483652390708977\n",
      "SNR: 30/30, LS+LI, Epoch 15/50, Loss: 0.011449919298811014 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.001054324564227665\n",
      "SNR: 30/30, LS+LI, Epoch 16/50, Loss: 0.010725136548497303 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006493950958511876\n",
      "SNR: 30/30, LS+LI, Epoch 17/50, Loss: 0.010299025027644496 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005922657662515783\n",
      "SNR: 30/30, LS+LI, Epoch 18/50, Loss: 0.009939312924046156 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007533076542048631\n",
      "SNR: 30/30, LS+LI, Epoch 19/50, Loss: 0.009440989731702694 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0010923291503621097\n",
      "SNR: 30/30, LS+LI, Epoch 20/50, Loss: 0.009333649839729417 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.001688744444188408\n",
      "SNR: 30/30, LS+LI, Epoch 21/50, Loss: 0.008929457710406114 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004980023487322879\n",
      "SNR: 30/30, LS+LI, Epoch 22/50, Loss: 0.00857402159572514 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005982680291212587\n",
      "SNR: 30/30, LS+LI, Epoch 23/50, Loss: 0.008586076537666971 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0022132297639142384\n",
      "SNR: 30/30, LS+LI, Epoch 24/50, Loss: 0.008156294222422984 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000824177502760325\n",
      "SNR: 30/30, LS+LI, Epoch 25/50, Loss: 0.007976216107043762 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005330931043400514\n",
      "SNR: 30/30, LS+LI, Epoch 26/50, Loss: 0.007655528734091583 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007529986773575233\n",
      "SNR: 30/30, LS+LI, Epoch 27/50, Loss: 0.007562924493212513 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006427555053960532\n",
      "SNR: 30/30, LS+LI, Epoch 28/50, Loss: 0.007239221993205679 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00042457373505881566\n",
      "SNR: 30/30, LS+LI, Epoch 29/50, Loss: 0.007243090785693291 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004480033504395661\n",
      "SNR: 30/30, LS+LI, Epoch 30/50, Loss: 0.007031734204352941 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005179092430890622\n",
      "SNR: 30/30, LS+LI, Epoch 31/50, Loss: 0.006899793578181849 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000960128088164228\n",
      "SNR: 30/30, LS+LI, Epoch 32/50, Loss: 0.006718548047248014 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007346298212227835\n",
      "SNR: 30/30, LS+LI, Epoch 33/50, Loss: 0.006543261007145914 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004633403110677715\n",
      "SNR: 30/30, LS+LI, Epoch 34/50, Loss: 0.006378966278050008 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00043915020069107413\n",
      "SNR: 30/30, LS+LI, Epoch 35/50, Loss: 0.006271834084547536 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00044038972224701536\n",
      "SNR: 30/30, LS+LI, Epoch 36/50, Loss: 0.0063073742907321035 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00043915948216718704\n",
      "SNR: 30/30, LS+LI, Epoch 37/50, Loss: 0.006141670232335496 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00052868744189089\n",
      "SNR: 30/30, LS+LI, Epoch 38/50, Loss: 0.0061218855675136625 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004895027761284092\n",
      "SNR: 30/30, LS+LI, Epoch 39/50, Loss: 0.005869006464626033 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003400398153727028\n",
      "SNR: 30/30, LS+LI, Epoch 40/50, Loss: 0.005788828665932077 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0011749370764432983\n",
      "SNR: 30/30, LS+LI, Epoch 41/50, Loss: 0.005731399081712372 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000354043463382616\n",
      "SNR: 30/30, LS+LI, Epoch 42/50, Loss: 0.005666245695550081 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000630759427704933\n",
      "SNR: 30/30, LS+LI, Epoch 43/50, Loss: 0.005645879982905679 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0009646163195032965\n",
      "SNR: 30/30, LS+LI, Epoch 44/50, Loss: 0.005573803442530334 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004560364825672216\n",
      "SNR: 30/30, LS+LI, Epoch 45/50, Loss: 0.005396066542151709 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00031147650522391564\n",
      "SNR: 30/30, LS+LI, Epoch 46/50, Loss: 0.005389061916164707 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00029772161691322583\n",
      "SNR: 30/30, LS+LI, Epoch 47/50, Loss: 0.005331901595169722 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00034526372407774693\n",
      "SNR: 30/30, LS+LI, Epoch 48/50, Loss: 0.005163694442206517 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00029244506334758955\n",
      "SNR: 30/30, LS+LI, Epoch 49/50, Loss: 0.005269625838737675 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006943145338234237\n",
      "SNR: 30/30, LS+LI, Epoch 50/50, Loss: 0.005119393801663158 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007190152113749223\n",
      "LI+NN NMSE: 0.0019768686033785343\n",
      "LS+LI NMSE: 8.330419950652868e-05\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/50, Loss: 0.26212627245763015 \n",
      "SNR: 30/30, LS, Val Loss: 0.08836490559307011\n",
      "SNR: 30/30, LS, Epoch 2/50, Loss: 0.019416116316109722 \n",
      "SNR: 30/30, LS, Val Loss: 0.004851811300878498\n",
      "SNR: 30/30, LS, Epoch 3/50, Loss: 0.005356043027605601 \n",
      "SNR: 30/30, LS, Val Loss: 0.0037155549560504205\n",
      "SNR: 30/30, LS, Epoch 4/50, Loss: 0.004875731072388589 \n",
      "SNR: 30/30, LS, Val Loss: 0.0029220368490893056\n",
      "SNR: 30/30, LS, Epoch 5/50, Loss: 0.004477247147723426 \n",
      "SNR: 30/30, LS, Val Loss: 0.0025192816022106194\n",
      "SNR: 30/30, LS, Epoch 6/50, Loss: 0.0038463672430817646 \n",
      "SNR: 30/30, LS, Val Loss: 0.0022761821376413786\n",
      "SNR: 30/30, LS, Epoch 7/50, Loss: 0.0038797235208411895 \n",
      "SNR: 30/30, LS, Val Loss: 0.0023515503271482885\n",
      "SNR: 30/30, LS, Epoch 8/50, Loss: 0.0038485128559756937 \n",
      "SNR: 30/30, LS, Val Loss: 0.002239735786464404\n",
      "SNR: 30/30, LS, Epoch 9/50, Loss: 0.0036580397369784063 \n",
      "SNR: 30/30, LS, Val Loss: 0.0017849233170801942\n",
      "SNR: 30/30, LS, Epoch 10/50, Loss: 0.003315021757707866 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016905517259147018\n",
      "SNR: 30/30, LS, Epoch 11/50, Loss: 0.0032081340025395676 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016449125779961998\n",
      "SNR: 30/30, LS, Epoch 12/50, Loss: 0.003220472442186546 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014997023893308572\n",
      "SNR: 30/30, LS, Epoch 13/50, Loss: 0.003219455344532075 \n",
      "SNR: 30/30, LS, Val Loss: 0.0020754747330846094\n",
      "SNR: 30/30, LS, Epoch 14/50, Loss: 0.003130540397251025 \n",
      "SNR: 30/30, LS, Val Loss: 0.0019414463366212492\n",
      "SNR: 30/30, LS, Epoch 15/50, Loss: 0.0028655116722464216 \n",
      "SNR: 30/30, LS, Val Loss: 0.0020604460203850813\n",
      "SNR: 30/30, LS, Epoch 16/50, Loss: 0.0029048380437902673 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014367401097181507\n",
      "SNR: 30/30, LS, Epoch 17/50, Loss: 0.002889688211346998 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016380944527389313\n",
      "SNR: 30/30, LS, Epoch 18/50, Loss: 0.0031593312295478617 \n",
      "SNR: 30/30, LS, Val Loss: 0.001308581619840962\n",
      "SNR: 30/30, LS, Epoch 19/50, Loss: 0.002816575751937709 \n",
      "SNR: 30/30, LS, Val Loss: 0.001399149067848074\n",
      "SNR: 30/30, LS, Epoch 20/50, Loss: 0.002651150553584705 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012521167015868493\n",
      "SNR: 30/30, LS, Epoch 21/50, Loss: 0.0028278137425902885 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010997437136459419\n",
      "SNR: 30/30, LS, Epoch 22/50, Loss: 0.002697184559385574 \n",
      "SNR: 30/30, LS, Val Loss: 0.001670822800158269\n",
      "SNR: 30/30, LS, Epoch 23/50, Loss: 0.0026991769006789856 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010337372791995717\n",
      "SNR: 30/30, LS, Epoch 24/50, Loss: 0.0028349719772407743 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014892412053251808\n",
      "SNR: 30/30, LS, Epoch 25/50, Loss: 0.002587381924968213 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011794653255492449\n",
      "SNR: 30/30, LS, Epoch 26/50, Loss: 0.0028434263381208187 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012895963075359098\n",
      "SNR: 30/30, LS, Epoch 27/50, Loss: 0.002758576298473663 \n",
      "SNR: 30/30, LS, Val Loss: 0.001257225214927034\n",
      "SNR: 30/30, LS, Epoch 28/50, Loss: 0.002412562852801192 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011604001999578693\n",
      "SNR: 30/30, LS, Epoch 29/50, Loss: 0.0027389075768824538 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009763799872334031\n",
      "SNR: 30/30, LS, Epoch 30/50, Loss: 0.0026631616015355426 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010680806405037981\n",
      "SNR: 30/30, LS, Epoch 31/50, Loss: 0.0026295540988347816 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010431501749818299\n",
      "SNR: 30/30, LS, Epoch 32/50, Loss: 0.0026108446767212565 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009154539796079255\n",
      "SNR: 30/30, LS, Epoch 33/50, Loss: 0.0028054474431312058 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009266571909062226\n",
      "SNR: 30/30, LS, Epoch 34/50, Loss: 0.0022349227263814184 \n",
      "SNR: 30/30, LS, Val Loss: 0.000969905583505434\n",
      "SNR: 30/30, LS, Epoch 35/50, Loss: 0.0027828208718389314 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008251172191442245\n",
      "SNR: 30/30, LS, Epoch 36/50, Loss: 0.0026238205619995634 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009037698129594156\n",
      "SNR: 30/30, LS, Epoch 37/50, Loss: 0.002466855478286202 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011186237785626542\n",
      "SNR: 30/30, LS, Epoch 38/50, Loss: 0.002580450467364646 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008392047166125849\n",
      "SNR: 30/30, LS, Epoch 39/50, Loss: 0.00223875627988343 \n",
      "SNR: 30/30, LS, Val Loss: 0.0007968967666701329\n",
      "SNR: 30/30, LS, Epoch 40/50, Loss: 0.0022647218050456846 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010404981598681347\n",
      "SNR: 30/30, LS, Epoch 41/50, Loss: 0.0021689300216209185 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008072182536125183\n",
      "SNR: 30/30, LS, Epoch 42/50, Loss: 0.0024842356174621123 \n",
      "SNR: 30/30, LS, Val Loss: 0.001250469919548116\n",
      "SNR: 30/30, LS, Epoch 43/50, Loss: 0.002722766827372293 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009501827404495667\n",
      "SNR: 30/30, LS, Epoch 44/50, Loss: 0.0023355020384769887 \n",
      "SNR: 30/30, LS, Val Loss: 0.0007936014100612903\n",
      "SNR: 30/30, LS, Epoch 45/50, Loss: 0.002792951775454851 \n",
      "SNR: 30/30, LS, Val Loss: 0.0007908050425943326\n",
      "SNR: 30/30, LS, Epoch 46/50, Loss: 0.0025350236409035143 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008121701142623682\n",
      "SNR: 30/30, LS, Epoch 47/50, Loss: 0.002569566813478961 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009292289085516876\n",
      "SNR: 30/30, LS, Epoch 48/50, Loss: 0.0023887793159215213 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008601419050881469\n",
      "SNR: 30/30, LS, Epoch 49/50, Loss: 0.002213715505921607 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010029623650056733\n",
      "SNR: 30/30, LS, Epoch 50/50, Loss: 0.002181748519814032 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008273082309063863\n",
      "LS+LI NMSE: 0.0023686536587774754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                    # of valLabels\n",
    "        # train_loader, val_loader are already normalized by their own min, max\n",
    "        # scale to range [0 1]\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    \n",
    "    nmse_LI_NN = utils.calNMSE(H_val_NN_denormd_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu().mean()\n",
    "    nmse_LI_NN_val.append(variables['NMSE_LI_NN'].item())\n",
    "    print(f\"LI+NN NMSE: {variables['NMSE_LI_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN[-1], index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "#####\n",
    "##### above is LS+LI+NN \n",
    "\n",
    "##### following is Linear interpolated channel (only LS+LI)\n",
    "    H_val_linInterp = H_linear_val.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI'] = nmse_LI.cpu().mean()\n",
    "    nmse_LS_LI_val.append(variables['NMSE_LI'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LI'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI[-1], index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    H_LS_train = H_equal_train.cpu()\n",
    "    plotfig.figTrueChan(H_LS_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est(dropOut=0, act =CNN_activation).to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = utils.calNMSE(H_val_LS_NN_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu().mean()\n",
    "    nmse_LS_NN_val.append(variables['NMSE_LS_NN'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LS_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN[-1], index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver18_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+NN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+NN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(save_folder_fig, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n",
    "\n",
    "nmse_compare ={\n",
    "    'nmse_LS_LI_val': nmse_LS_LI_val, \n",
    "    'nmse_LS_NN_val':nmse_LS_NN_val, \n",
    "    'nmse_LI_NN_val':nmse_LI_NN_val\n",
    "}\n",
    "torch.save( nmse_compare, os.path.join(save_folder_fig, 'NMSE.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver18_/NMSE2.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+NN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE2.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE2.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
