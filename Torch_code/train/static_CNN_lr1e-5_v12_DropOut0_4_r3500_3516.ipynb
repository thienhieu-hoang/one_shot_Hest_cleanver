{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 1e-5 \n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                        '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "lower_range = -1 \n",
    "    # if norm_approach = 'minmax': \n",
    "        # =  0 for scaling to  [0 1]\n",
    "        # = -1 for scaling to [-1 1]\n",
    "    # if norm_approach = 'std': can be any value, but need to be defined\n",
    "    \n",
    "if norm_approach == 'minmax':\n",
    "    if lower_range == 0:\n",
    "        norm_txt = 'Using min-max [0 1]'\n",
    "    elif lower_range ==-1:\n",
    "        norm_txt = 'Using min-max [-1 1]'\n",
    "elif norm_approach == 'no':\n",
    "    norm_txt = 'No'\n",
    "    \n",
    "CNN_activation = 'Tanh'\n",
    "CNN_DropOut = 0.4\n",
    "if CNN_DropOut != 0:\n",
    "    dropOut_txt = f'Add p={CNN_DropOut} DropOut'\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'train/static_CNN_lr1e-5_v11_(...).ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows {rowss},\n",
    "Data got from {outer_file_path},\n",
    "Learning rate {learning_rate}, {NUM_EPOCHS} epochs\n",
    "{norm_txt} scaler for each sample\n",
    "Using {CNN_activation} as activation function of CNN\n",
    "{dropOut_txt}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver16_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver16_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/50, Loss: 0.08097572369111139 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.031997851519422096\n",
      "SNR: 0/30, LS+LI, Epoch 2/50, Loss: 0.03706886020467379 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026510606265880844\n",
      "SNR: 0/30, LS+LI, Epoch 3/50, Loss: 0.03313157308933347 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025613505477932366\n",
      "SNR: 0/30, LS+LI, Epoch 4/50, Loss: 0.03114411608467615 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025505983101373367\n",
      "SNR: 0/30, LS+LI, Epoch 5/50, Loss: 0.03035849873193128 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025324617808854036\n",
      "SNR: 0/30, LS+LI, Epoch 6/50, Loss: 0.029660622426850157 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025234838100996883\n",
      "SNR: 0/30, LS+LI, Epoch 7/50, Loss: 0.029092321897921866 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024878537578677588\n",
      "SNR: 0/30, LS+LI, Epoch 8/50, Loss: 0.028586805657332025 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024758781560442665\n",
      "SNR: 0/30, LS+LI, Epoch 9/50, Loss: 0.028203839663589417 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024688547434793276\n",
      "SNR: 0/30, LS+LI, Epoch 10/50, Loss: 0.027935203641306524 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024775320156054062\n",
      "SNR: 0/30, LS+LI, Epoch 11/50, Loss: 0.02765368169909993 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024448867971924217\n",
      "SNR: 0/30, LS+LI, Epoch 12/50, Loss: 0.027412367822212534 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024511352816427297\n",
      "SNR: 0/30, LS+LI, Epoch 13/50, Loss: 0.027030890720874765 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024562831798737698\n",
      "SNR: 0/30, LS+LI, Epoch 14/50, Loss: 0.026935882525258633 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024898344693197447\n",
      "SNR: 0/30, LS+LI, Epoch 15/50, Loss: 0.02673669762606191 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024395228236575018\n",
      "SNR: 0/30, LS+LI, Epoch 16/50, Loss: 0.026547077290583834 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024852438787506384\n",
      "SNR: 0/30, LS+LI, Epoch 17/50, Loss: 0.026381627082564803 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024132152257317848\n",
      "SNR: 0/30, LS+LI, Epoch 18/50, Loss: 0.02637302745025345 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02417374292219227\n",
      "SNR: 0/30, LS+LI, Epoch 19/50, Loss: 0.026184307606241037 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024093681523068386\n",
      "SNR: 0/30, LS+LI, Epoch 20/50, Loss: 0.026012219672719408 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024225514255125414\n",
      "SNR: 0/30, LS+LI, Epoch 21/50, Loss: 0.025970236972234276 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02406607318500226\n",
      "SNR: 0/30, LS+LI, Epoch 22/50, Loss: 0.0259530549533232 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0240234369835393\n",
      "SNR: 0/30, LS+LI, Epoch 23/50, Loss: 0.025776046084586616 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024400527589023113\n",
      "SNR: 0/30, LS+LI, Epoch 24/50, Loss: 0.025642723657277433 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02454886060546745\n",
      "SNR: 0/30, LS+LI, Epoch 25/50, Loss: 0.025665588687758808 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023994457865641874\n",
      "SNR: 0/30, LS+LI, Epoch 26/50, Loss: 0.025617238220780394 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024065975311466238\n",
      "SNR: 0/30, LS+LI, Epoch 27/50, Loss: 0.025505430871880678 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024018549106337807\n",
      "SNR: 0/30, LS+LI, Epoch 28/50, Loss: 0.02542538325800452 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023948207624595274\n",
      "SNR: 0/30, LS+LI, Epoch 29/50, Loss: 0.025399259031685287 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023883390917696735\n",
      "SNR: 0/30, LS+LI, Epoch 30/50, Loss: 0.025412740240003482 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023948563262820244\n",
      "SNR: 0/30, LS+LI, Epoch 31/50, Loss: 0.025279428013925288 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024136759764091534\n",
      "SNR: 0/30, LS+LI, Epoch 32/50, Loss: 0.025221366446118717 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024590825958346777\n",
      "SNR: 0/30, LS+LI, Epoch 33/50, Loss: 0.025232613162505767 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02423548097298904\n",
      "SNR: 0/30, LS+LI, Epoch 34/50, Loss: 0.025086027727094153 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024051339365541935\n",
      "SNR: 0/30, LS+LI, Epoch 35/50, Loss: 0.02512778571352016 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02392441580410708\n",
      "SNR: 0/30, LS+LI, Epoch 36/50, Loss: 0.025111341854384125 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023858446289192547\n",
      "SNR: 0/30, LS+LI, Epoch 37/50, Loss: 0.0250853948934047 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024181509390473366\n",
      "SNR: 0/30, LS+LI, Epoch 38/50, Loss: 0.02513630249061037 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024138770108534532\n",
      "SNR: 0/30, LS+LI, Epoch 39/50, Loss: 0.02502944206190837 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023932202719151974\n",
      "SNR: 0/30, LS+LI, Epoch 40/50, Loss: 0.02492764985816943 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023867071690884503\n",
      "SNR: 0/30, LS+LI, Epoch 41/50, Loss: 0.024859584007022338 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023817500734532423\n",
      "SNR: 0/30, LS+LI, Epoch 42/50, Loss: 0.02488754890036098 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02382981480861252\n",
      "SNR: 0/30, LS+LI, Epoch 43/50, Loss: 0.024885711817850553 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023895536210726608\n",
      "SNR: 0/30, LS+LI, Epoch 44/50, Loss: 0.02472539514649746 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023921540726653555\n",
      "SNR: 0/30, LS+LI, Epoch 45/50, Loss: 0.024746215821048894 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02385785938663916\n",
      "SNR: 0/30, LS+LI, Epoch 46/50, Loss: 0.0248178519893351 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02436849529939619\n",
      "SNR: 0/30, LS+LI, Epoch 47/50, Loss: 0.02476045988001969 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024079677648842335\n",
      "SNR: 0/30, LS+LI, Epoch 48/50, Loss: 0.024691296865903708 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023748810530047525\n",
      "SNR: 0/30, LS+LI, Epoch 49/50, Loss: 0.024714258093343572 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.023793188262392174\n",
      "SNR: 0/30, LS+LI, Epoch 50/50, Loss: 0.024689468300663108 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.024059551683339207\n",
      "LI+NN NMSE: 0.06777302920818329\n",
      "LS+LI NMSE: 0.08220602571964264\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/50, Loss: 0.24210032816369867 \n",
      "SNR: 0/30, LS, Val Loss: 0.04760017737068913\n",
      "SNR: 0/30, LS, Epoch 2/50, Loss: 0.0144500644731357 \n",
      "SNR: 0/30, LS, Val Loss: 0.008405121593651447\n",
      "SNR: 0/30, LS, Epoch 3/50, Loss: 0.009391176184032892 \n",
      "SNR: 0/30, LS, Val Loss: 0.0075298492712053385\n",
      "SNR: 0/30, LS, Epoch 4/50, Loss: 0.00890133219370402 \n",
      "SNR: 0/30, LS, Val Loss: 0.007275935791602189\n",
      "SNR: 0/30, LS, Epoch 5/50, Loss: 0.008215877533413816 \n",
      "SNR: 0/30, LS, Val Loss: 0.0069420543202961035\n",
      "SNR: 0/30, LS, Epoch 6/50, Loss: 0.008254424224845892 \n",
      "SNR: 0/30, LS, Val Loss: 0.006875908298587257\n",
      "SNR: 0/30, LS, Epoch 7/50, Loss: 0.007887086841862562 \n",
      "SNR: 0/30, LS, Val Loss: 0.0066548609598116445\n",
      "SNR: 0/30, LS, Epoch 8/50, Loss: 0.008142279628880842 \n",
      "SNR: 0/30, LS, Val Loss: 0.007805982054295865\n",
      "SNR: 0/30, LS, Epoch 9/50, Loss: 0.007759405735901795 \n",
      "SNR: 0/30, LS, Val Loss: 0.006422454893419688\n",
      "SNR: 0/30, LS, Epoch 10/50, Loss: 0.007818065001629293 \n",
      "SNR: 0/30, LS, Val Loss: 0.006402450021017681\n",
      "SNR: 0/30, LS, Epoch 11/50, Loss: 0.007801011656844165 \n",
      "SNR: 0/30, LS, Val Loss: 0.006179306846620007\n",
      "SNR: 0/30, LS, Epoch 12/50, Loss: 0.007474986606190891 \n",
      "SNR: 0/30, LS, Val Loss: 0.006124311105602167\n",
      "SNR: 0/30, LS, Epoch 13/50, Loss: 0.007403580988973899 \n",
      "SNR: 0/30, LS, Val Loss: 0.0062498761002313\n",
      "SNR: 0/30, LS, Epoch 14/50, Loss: 0.007724549927272249 \n",
      "SNR: 0/30, LS, Val Loss: 0.006036189448257739\n",
      "SNR: 0/30, LS, Epoch 15/50, Loss: 0.00734920403920114 \n",
      "SNR: 0/30, LS, Val Loss: 0.0062330755066465245\n",
      "SNR: 0/30, LS, Epoch 16/50, Loss: 0.007386205853287911 \n",
      "SNR: 0/30, LS, Val Loss: 0.007246888877654617\n",
      "SNR: 0/30, LS, Epoch 17/50, Loss: 0.00717465854033308 \n",
      "SNR: 0/30, LS, Val Loss: 0.006188346221196381\n",
      "SNR: 0/30, LS, Epoch 18/50, Loss: 0.00723747945888791 \n",
      "SNR: 0/30, LS, Val Loss: 0.005999870111488483\n",
      "SNR: 0/30, LS, Epoch 19/50, Loss: 0.007037614959530359 \n",
      "SNR: 0/30, LS, Val Loss: 0.0058330385522408915\n",
      "SNR: 0/30, LS, Epoch 20/50, Loss: 0.00691580168935362 \n",
      "SNR: 0/30, LS, Val Loss: 0.005731618836183439\n",
      "SNR: 0/30, LS, Epoch 21/50, Loss: 0.006993906123043839 \n",
      "SNR: 0/30, LS, Val Loss: 0.006316447567025369\n",
      "SNR: 0/30, LS, Epoch 22/50, Loss: 0.006706425665639514 \n",
      "SNR: 0/30, LS, Val Loss: 0.0060244879092682495\n",
      "SNR: 0/30, LS, Epoch 23/50, Loss: 0.006694490014207225 \n",
      "SNR: 0/30, LS, Val Loss: 0.006748931376602162\n",
      "SNR: 0/30, LS, Epoch 24/50, Loss: 0.0068885977975590975 \n",
      "SNR: 0/30, LS, Val Loss: 0.005639087535779585\n",
      "SNR: 0/30, LS, Epoch 25/50, Loss: 0.006916200490343536 \n",
      "SNR: 0/30, LS, Val Loss: 0.006023060064762831\n",
      "SNR: 0/30, LS, Epoch 26/50, Loss: 0.006730389383318293 \n",
      "SNR: 0/30, LS, Val Loss: 0.0077545844992114735\n",
      "SNR: 0/30, LS, Epoch 27/50, Loss: 0.007025212807537511 \n",
      "SNR: 0/30, LS, Val Loss: 0.005947795230895281\n",
      "SNR: 0/30, LS, Epoch 28/50, Loss: 0.006914642100698899 \n",
      "SNR: 0/30, LS, Val Loss: 0.005477923603559082\n",
      "SNR: 0/30, LS, Epoch 29/50, Loss: 0.006726023722115124 \n",
      "SNR: 0/30, LS, Val Loss: 0.005901791642165997\n",
      "SNR: 0/30, LS, Epoch 30/50, Loss: 0.00627852012782336 \n",
      "SNR: 0/30, LS, Val Loss: 0.006217105525799773\n",
      "SNR: 0/30, LS, Epoch 31/50, Loss: 0.006576795152626758 \n",
      "SNR: 0/30, LS, Val Loss: 0.006128955590115352\n",
      "SNR: 0/30, LS, Epoch 32/50, Loss: 0.0065542995106688765 \n",
      "SNR: 0/30, LS, Val Loss: 0.005296243079514666\n",
      "SNR: 0/30, LS, Epoch 33/50, Loss: 0.006527717092594262 \n",
      "SNR: 0/30, LS, Val Loss: 0.005339583466676148\n",
      "SNR: 0/30, LS, Epoch 34/50, Loss: 0.006518580049254694 \n",
      "SNR: 0/30, LS, Val Loss: 0.0054640000135722485\n",
      "SNR: 0/30, LS, Epoch 35/50, Loss: 0.006391995664967527 \n",
      "SNR: 0/30, LS, Val Loss: 0.0056440993635491895\n",
      "SNR: 0/30, LS, Epoch 36/50, Loss: 0.006453158076700949 \n",
      "SNR: 0/30, LS, Val Loss: 0.00545931592668322\n",
      "SNR: 0/30, LS, Epoch 37/50, Loss: 0.006250790628972788 \n",
      "SNR: 0/30, LS, Val Loss: 0.0050441100135106935\n",
      "SNR: 0/30, LS, Epoch 38/50, Loss: 0.006376917455020512 \n",
      "SNR: 0/30, LS, Val Loss: 0.005128710276701234\n",
      "SNR: 0/30, LS, Epoch 39/50, Loss: 0.006433407605495737 \n",
      "SNR: 0/30, LS, Val Loss: 0.005243003664707596\n",
      "SNR: 0/30, LS, Epoch 40/50, Loss: 0.006287646358074664 \n",
      "SNR: 0/30, LS, Val Loss: 0.005218779837543314\n",
      "SNR: 0/30, LS, Epoch 41/50, Loss: 0.006476474331616056 \n",
      "SNR: 0/30, LS, Val Loss: 0.005512346132573756\n",
      "SNR: 0/30, LS, Epoch 42/50, Loss: 0.006343204778521646 \n",
      "SNR: 0/30, LS, Val Loss: 0.004934620048681443\n",
      "SNR: 0/30, LS, Epoch 43/50, Loss: 0.006107670801886639 \n",
      "SNR: 0/30, LS, Val Loss: 0.0051247564102099704\n",
      "SNR: 0/30, LS, Epoch 44/50, Loss: 0.0061742126708850265 \n",
      "SNR: 0/30, LS, Val Loss: 0.005139955975623293\n",
      "SNR: 0/30, LS, Epoch 45/50, Loss: 0.006077256446249436 \n",
      "SNR: 0/30, LS, Val Loss: 0.004824948391284455\n",
      "SNR: 0/30, LS, Epoch 46/50, Loss: 0.006271116524869793 \n",
      "SNR: 0/30, LS, Val Loss: 0.0049488538114184685\n",
      "SNR: 0/30, LS, Epoch 47/50, Loss: 0.00595282310170533 \n",
      "SNR: 0/30, LS, Val Loss: 0.005124127068980174\n",
      "SNR: 0/30, LS, Epoch 48/50, Loss: 0.00613640873898687 \n",
      "SNR: 0/30, LS, Val Loss: 0.0053109132938764314\n",
      "SNR: 0/30, LS, Epoch 49/50, Loss: 0.006107788833486306 \n",
      "SNR: 0/30, LS, Val Loss: 0.00523458084684204\n",
      "SNR: 0/30, LS, Epoch 50/50, Loss: 0.006250152974876813 \n",
      "SNR: 0/30, LS, Val Loss: 0.004773673220452937\n",
      "LS+LI NMSE: 0.013432797975838184\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/50, Loss: 0.06714202457129262 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.020132217302241108\n",
      "SNR: 5/30, LS+LI, Epoch 2/50, Loss: 0.023819407090804604 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.012669559271836823\n",
      "SNR: 5/30, LS+LI, Epoch 3/50, Loss: 0.018313351395908138 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011011215455999429\n",
      "SNR: 5/30, LS+LI, Epoch 4/50, Loss: 0.016487736861373104 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010771692825735292\n",
      "SNR: 5/30, LS+LI, Epoch 5/50, Loss: 0.015619892426658162 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010555116121064533\n",
      "SNR: 5/30, LS+LI, Epoch 6/50, Loss: 0.01495863630999486 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010884186295284466\n",
      "SNR: 5/30, LS+LI, Epoch 7/50, Loss: 0.014492971676423452 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010311865501783112\n",
      "SNR: 5/30, LS+LI, Epoch 8/50, Loss: 0.01393879191993281 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01022243742111393\n",
      "SNR: 5/30, LS+LI, Epoch 9/50, Loss: 0.013672410710823051 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009968797528100285\n",
      "SNR: 5/30, LS+LI, Epoch 10/50, Loss: 0.013238873798400164 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010012901324609464\n",
      "SNR: 5/30, LS+LI, Epoch 11/50, Loss: 0.01305738593949828 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009948895715007728\n",
      "SNR: 5/30, LS+LI, Epoch 12/50, Loss: 0.012716307383312215 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009594801982695406\n",
      "SNR: 5/30, LS+LI, Epoch 13/50, Loss: 0.012496583805376188 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009681739780882543\n",
      "SNR: 5/30, LS+LI, Epoch 14/50, Loss: 0.012368788176519407 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009506049121476033\n",
      "SNR: 5/30, LS+LI, Epoch 15/50, Loss: 0.01216510305354415 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009564424102956598\n",
      "SNR: 5/30, LS+LI, Epoch 16/50, Loss: 0.011999746175417892 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00943433039356023\n",
      "SNR: 5/30, LS+LI, Epoch 17/50, Loss: 0.01193137910910124 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009511649344031784\n",
      "SNR: 5/30, LS+LI, Epoch 18/50, Loss: 0.01178075192052178 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009576375458643517\n",
      "SNR: 5/30, LS+LI, Epoch 19/50, Loss: 0.011673862063109355 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009390923205170442\n",
      "SNR: 5/30, LS+LI, Epoch 20/50, Loss: 0.011646322643405996 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009816388313827867\n",
      "SNR: 5/30, LS+LI, Epoch 21/50, Loss: 0.011554305498531564 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009331256881440904\n",
      "SNR: 5/30, LS+LI, Epoch 22/50, Loss: 0.011423322967751774 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009334202157333493\n",
      "SNR: 5/30, LS+LI, Epoch 23/50, Loss: 0.011359332684362523 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009311252390034497\n",
      "SNR: 5/30, LS+LI, Epoch 24/50, Loss: 0.011292795184999704 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009368665368211541\n",
      "SNR: 5/30, LS+LI, Epoch 25/50, Loss: 0.011317083587718392 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009994308284314518\n",
      "SNR: 5/30, LS+LI, Epoch 26/50, Loss: 0.011229059902604583 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009597213303839619\n",
      "SNR: 5/30, LS+LI, Epoch 27/50, Loss: 0.011192273827767822 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009662102241153743\n",
      "SNR: 5/30, LS+LI, Epoch 28/50, Loss: 0.011089209989687904 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009297547269273888\n",
      "SNR: 5/30, LS+LI, Epoch 29/50, Loss: 0.011125068212751039 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009519160894507711\n",
      "SNR: 5/30, LS+LI, Epoch 30/50, Loss: 0.010994389534083217 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009333004148422995\n",
      "SNR: 5/30, LS+LI, Epoch 31/50, Loss: 0.010892304253417912 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009474418009631336\n",
      "SNR: 5/30, LS+LI, Epoch 32/50, Loss: 0.011077290463131355 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009458133241754364\n",
      "SNR: 5/30, LS+LI, Epoch 33/50, Loss: 0.010960594675135474 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009379104457118294\n",
      "SNR: 5/30, LS+LI, Epoch 34/50, Loss: 0.010809312482516086 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0093839919639074\n",
      "SNR: 5/30, LS+LI, Epoch 35/50, Loss: 0.010836245410880723 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009517207858152688\n",
      "SNR: 5/30, LS+LI, Epoch 36/50, Loss: 0.010792919997732306 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009351067467253994\n",
      "SNR: 5/30, LS+LI, Epoch 37/50, Loss: 0.010877038392801444 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009228622403249821\n",
      "SNR: 5/30, LS+LI, Epoch 38/50, Loss: 0.010760669658761905 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010030993726104498\n",
      "SNR: 5/30, LS+LI, Epoch 39/50, Loss: 0.010804889618072572 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009223620968193492\n",
      "SNR: 5/30, LS+LI, Epoch 40/50, Loss: 0.010650260874806621 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009293976694938134\n",
      "SNR: 5/30, LS+LI, Epoch 41/50, Loss: 0.010713378127209496 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00934793236030435\n",
      "SNR: 5/30, LS+LI, Epoch 42/50, Loss: 0.010613277920001989 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009337615348737349\n",
      "SNR: 5/30, LS+LI, Epoch 43/50, Loss: 0.010573113377769153 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009215817776169966\n",
      "SNR: 5/30, LS+LI, Epoch 44/50, Loss: 0.010674585588276386 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00941620425278829\n",
      "SNR: 5/30, LS+LI, Epoch 45/50, Loss: 0.01057491386796586 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009273187902925367\n",
      "SNR: 5/30, LS+LI, Epoch 46/50, Loss: 0.010545760647632008 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009433316786519506\n",
      "SNR: 5/30, LS+LI, Epoch 47/50, Loss: 0.010412742012873465 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00929733802860772\n",
      "SNR: 5/30, LS+LI, Epoch 48/50, Loss: 0.010543639901592287 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009211509403857317\n",
      "SNR: 5/30, LS+LI, Epoch 49/50, Loss: 0.010475962915522762 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009322309549051251\n",
      "SNR: 5/30, LS+LI, Epoch 50/50, Loss: 0.010411981089842008 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.009254232197153297\n",
      "LI+NN NMSE: 0.027265630662441254\n",
      "LS+LI NMSE: 0.025872929021716118\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/50, Loss: 0.23927406650469746 \n",
      "SNR: 5/30, LS, Val Loss: 0.049720957705920395\n",
      "SNR: 5/30, LS, Epoch 2/50, Loss: 0.015780336464495334 \n",
      "SNR: 5/30, LS, Val Loss: 0.007239944767206907\n",
      "SNR: 5/30, LS, Epoch 3/50, Loss: 0.007798084312356835 \n",
      "SNR: 5/30, LS, Val Loss: 0.00576891328885474\n",
      "SNR: 5/30, LS, Epoch 4/50, Loss: 0.006695989752188325 \n",
      "SNR: 5/30, LS, Val Loss: 0.005580985770476135\n",
      "SNR: 5/30, LS, Epoch 5/50, Loss: 0.006328674386591153 \n",
      "SNR: 5/30, LS, Val Loss: 0.005302055103873665\n",
      "SNR: 5/30, LS, Epoch 6/50, Loss: 0.0060064613881390975 \n",
      "SNR: 5/30, LS, Val Loss: 0.005498989030126144\n",
      "SNR: 5/30, LS, Epoch 7/50, Loss: 0.005385061207519801 \n",
      "SNR: 5/30, LS, Val Loss: 0.004123096692968498\n",
      "SNR: 5/30, LS, Epoch 8/50, Loss: 0.0053995817109162726 \n",
      "SNR: 5/30, LS, Val Loss: 0.00391844349955632\n",
      "SNR: 5/30, LS, Epoch 9/50, Loss: 0.005166676952666062 \n",
      "SNR: 5/30, LS, Val Loss: 0.0038080104330385275\n",
      "SNR: 5/30, LS, Epoch 10/50, Loss: 0.004945154473737835 \n",
      "SNR: 5/30, LS, Val Loss: 0.003608808672817593\n",
      "SNR: 5/30, LS, Epoch 11/50, Loss: 0.004858860686464712 \n",
      "SNR: 5/30, LS, Val Loss: 0.00372115718412467\n",
      "SNR: 5/30, LS, Epoch 12/50, Loss: 0.005074408251878827 \n",
      "SNR: 5/30, LS, Val Loss: 0.0036903707395223055\n",
      "SNR: 5/30, LS, Epoch 13/50, Loss: 0.004655111475501123 \n",
      "SNR: 5/30, LS, Val Loss: 0.003352356989952651\n",
      "SNR: 5/30, LS, Epoch 14/50, Loss: 0.004498293102166594 \n",
      "SNR: 5/30, LS, Val Loss: 0.003278724902140146\n",
      "SNR: 5/30, LS, Epoch 15/50, Loss: 0.004608283963238517 \n",
      "SNR: 5/30, LS, Val Loss: 0.0037677499825473537\n",
      "SNR: 5/30, LS, Epoch 16/50, Loss: 0.004700808049461176 \n",
      "SNR: 5/30, LS, Val Loss: 0.00320031972263347\n",
      "SNR: 5/30, LS, Epoch 17/50, Loss: 0.0049819240162452295 \n",
      "SNR: 5/30, LS, Val Loss: 0.0033307871252129025\n",
      "SNR: 5/30, LS, Epoch 18/50, Loss: 0.004668587641411482 \n",
      "SNR: 5/30, LS, Val Loss: 0.003378767107444053\n",
      "SNR: 5/30, LS, Epoch 19/50, Loss: 0.004319115368606046 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031681850616058164\n",
      "SNR: 5/30, LS, Epoch 20/50, Loss: 0.004292220340196996 \n",
      "SNR: 5/30, LS, Val Loss: 0.003134196761741557\n",
      "SNR: 5/30, LS, Epoch 21/50, Loss: 0.004516513021879418 \n",
      "SNR: 5/30, LS, Val Loss: 0.0036963227374309845\n",
      "SNR: 5/30, LS, Epoch 22/50, Loss: 0.0043150057480129045 \n",
      "SNR: 5/30, LS, Val Loss: 0.002996350241697986\n",
      "SNR: 5/30, LS, Epoch 23/50, Loss: 0.004170666263319639 \n",
      "SNR: 5/30, LS, Val Loss: 0.003316749490543523\n",
      "SNR: 5/30, LS, Epoch 24/50, Loss: 0.004646276837203998 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029933258510110054\n",
      "SNR: 5/30, LS, Epoch 25/50, Loss: 0.0042876588075075215 \n",
      "SNR: 5/30, LS, Val Loss: 0.0034045686162161555\n",
      "SNR: 5/30, LS, Epoch 26/50, Loss: 0.004504483974224693 \n",
      "SNR: 5/30, LS, Val Loss: 0.003494809455746277\n",
      "SNR: 5/30, LS, Epoch 27/50, Loss: 0.0042157302161158865 \n",
      "SNR: 5/30, LS, Val Loss: 0.003022397328591482\n",
      "SNR: 5/30, LS, Epoch 28/50, Loss: 0.004366558803202108 \n",
      "SNR: 5/30, LS, Val Loss: 0.0027973078381778164\n",
      "SNR: 5/30, LS, Epoch 29/50, Loss: 0.003984840835856144 \n",
      "SNR: 5/30, LS, Val Loss: 0.002916551168627021\n",
      "SNR: 5/30, LS, Epoch 30/50, Loss: 0.004004601803391652 \n",
      "SNR: 5/30, LS, Val Loss: 0.0028206628313372758\n",
      "SNR: 5/30, LS, Epoch 31/50, Loss: 0.004159842475674786 \n",
      "SNR: 5/30, LS, Val Loss: 0.0033149335491047664\n",
      "SNR: 5/30, LS, Epoch 32/50, Loss: 0.00425137942359068 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031690109648149123\n",
      "SNR: 5/30, LS, Epoch 33/50, Loss: 0.00394565433664464 \n",
      "SNR: 5/30, LS, Val Loss: 0.0029277222506193953\n",
      "SNR: 5/30, LS, Epoch 34/50, Loss: 0.004110489973289415 \n",
      "SNR: 5/30, LS, Val Loss: 0.002741765342017805\n",
      "SNR: 5/30, LS, Epoch 35/50, Loss: 0.003984633665315287 \n",
      "SNR: 5/30, LS, Val Loss: 0.0027425769420171327\n",
      "SNR: 5/30, LS, Epoch 36/50, Loss: 0.0041398073432880435 \n",
      "SNR: 5/30, LS, Val Loss: 0.003107544733211398\n",
      "SNR: 5/30, LS, Epoch 37/50, Loss: 0.003884877168930807 \n",
      "SNR: 5/30, LS, Val Loss: 0.002659368148835545\n",
      "SNR: 5/30, LS, Epoch 38/50, Loss: 0.003931559707568742 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026468153280968017\n",
      "SNR: 5/30, LS, Epoch 39/50, Loss: 0.003913583614332818 \n",
      "SNR: 5/30, LS, Val Loss: 0.002879605279304087\n",
      "SNR: 5/30, LS, Epoch 40/50, Loss: 0.00403610551540285 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026541983348910103\n",
      "SNR: 5/30, LS, Epoch 41/50, Loss: 0.0038550966568182896 \n",
      "SNR: 5/30, LS, Val Loss: 0.002808170689439232\n",
      "SNR: 5/30, LS, Epoch 42/50, Loss: 0.004074167902852127 \n",
      "SNR: 5/30, LS, Val Loss: 0.0026598982301286674\n",
      "SNR: 5/30, LS, Epoch 43/50, Loss: 0.0037838734069102725 \n",
      "SNR: 5/30, LS, Val Loss: 0.0025342464478771117\n",
      "SNR: 5/30, LS, Epoch 44/50, Loss: 0.0036481775798250077 \n",
      "SNR: 5/30, LS, Val Loss: 0.002482820693826811\n",
      "SNR: 5/30, LS, Epoch 45/50, Loss: 0.0038307493005684296 \n",
      "SNR: 5/30, LS, Val Loss: 0.0028898149136115203\n",
      "SNR: 5/30, LS, Epoch 46/50, Loss: 0.004171051413936237 \n",
      "SNR: 5/30, LS, Val Loss: 0.0024437816517258234\n",
      "SNR: 5/30, LS, Epoch 47/50, Loss: 0.004029188742373832 \n",
      "SNR: 5/30, LS, Val Loss: 0.002582144727718762\n",
      "SNR: 5/30, LS, Epoch 48/50, Loss: 0.0038703358163623964 \n",
      "SNR: 5/30, LS, Val Loss: 0.002450897697020661\n",
      "SNR: 5/30, LS, Epoch 49/50, Loss: 0.00380020409952416 \n",
      "SNR: 5/30, LS, Val Loss: 0.002667137945536524\n",
      "SNR: 5/30, LS, Epoch 50/50, Loss: 0.0036768622515008374 \n",
      "SNR: 5/30, LS, Val Loss: 0.0028786755018782887\n",
      "LS+LI NMSE: 0.007948249578475952\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/50, Loss: 0.06854739352021107 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.01845419652421366\n",
      "SNR: 10/30, LS+LI, Epoch 2/50, Loss: 0.019914932104997164 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.007181332234970548\n",
      "SNR: 10/30, LS+LI, Epoch 3/50, Loss: 0.013383660108110932 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00492376666939394\n",
      "SNR: 10/30, LS+LI, Epoch 4/50, Loss: 0.010992550773026293 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005192670600742779\n",
      "SNR: 10/30, LS+LI, Epoch 5/50, Loss: 0.010116406981724986 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00445959288415245\n",
      "SNR: 10/30, LS+LI, Epoch 6/50, Loss: 0.009446258204555961 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004330162699757652\n",
      "SNR: 10/30, LS+LI, Epoch 7/50, Loss: 0.008872595296219685 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004281217560426078\n",
      "SNR: 10/30, LS+LI, Epoch 8/50, Loss: 0.00848203918322661 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004695524387484925\n",
      "SNR: 10/30, LS+LI, Epoch 9/50, Loss: 0.008199518717024042 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00413470483512025\n",
      "SNR: 10/30, LS+LI, Epoch 10/50, Loss: 0.007777203757012653 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004057040385139937\n",
      "SNR: 10/30, LS+LI, Epoch 11/50, Loss: 0.0075533429815888755 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003842464584687894\n",
      "SNR: 10/30, LS+LI, Epoch 12/50, Loss: 0.007319016742173496 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0038753040875731544\n",
      "SNR: 10/30, LS+LI, Epoch 13/50, Loss: 0.007381433815976908 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005006992670876736\n",
      "SNR: 10/30, LS+LI, Epoch 14/50, Loss: 0.007012194463831567 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0036686278604479\n",
      "SNR: 10/30, LS+LI, Epoch 15/50, Loss: 0.006794749875552952 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003958622575737536\n",
      "SNR: 10/30, LS+LI, Epoch 16/50, Loss: 0.006689609938062901 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037860567681491375\n",
      "SNR: 10/30, LS+LI, Epoch 17/50, Loss: 0.006552912581841959 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0036896788303486324\n",
      "SNR: 10/30, LS+LI, Epoch 18/50, Loss: 0.006559566072145 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003523305323059586\n",
      "SNR: 10/30, LS+LI, Epoch 19/50, Loss: 0.006437298925701789 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0037220862577669322\n",
      "SNR: 10/30, LS+LI, Epoch 20/50, Loss: 0.0062431404285869276 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004020477983761917\n",
      "SNR: 10/30, LS+LI, Epoch 21/50, Loss: 0.006183098573887417 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0035504678380675614\n",
      "SNR: 10/30, LS+LI, Epoch 22/50, Loss: 0.006143472403786037 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0035301029459911992\n",
      "SNR: 10/30, LS+LI, Epoch 23/50, Loss: 0.006032138618878847 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003548318758310581\n",
      "SNR: 10/30, LS+LI, Epoch 24/50, Loss: 0.006018816975356881 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034548637340776622\n",
      "SNR: 10/30, LS+LI, Epoch 25/50, Loss: 0.005869487749932464 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0035004855969666755\n",
      "SNR: 10/30, LS+LI, Epoch 26/50, Loss: 0.0059275898329783664 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004159147237342867\n",
      "SNR: 10/30, LS+LI, Epoch 27/50, Loss: 0.005847320802574761 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00385835743509233\n",
      "SNR: 10/30, LS+LI, Epoch 28/50, Loss: 0.00575588796515191 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004552414683117108\n",
      "SNR: 10/30, LS+LI, Epoch 29/50, Loss: 0.005815127523356053 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0035086396806450052\n",
      "SNR: 10/30, LS+LI, Epoch 30/50, Loss: 0.005776167738922807 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003521087505346672\n",
      "SNR: 10/30, LS+LI, Epoch 31/50, Loss: 0.0056270191657118674 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003423395540184257\n",
      "SNR: 10/30, LS+LI, Epoch 32/50, Loss: 0.00557288738119221 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003646845918741416\n",
      "SNR: 10/30, LS+LI, Epoch 33/50, Loss: 0.005571762769927033 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034292413884858515\n",
      "SNR: 10/30, LS+LI, Epoch 34/50, Loss: 0.00551374337560129 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003493685989682986\n",
      "SNR: 10/30, LS+LI, Epoch 35/50, Loss: 0.005526736736037704 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00341587282971225\n",
      "SNR: 10/30, LS+LI, Epoch 36/50, Loss: 0.00548502006757528 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034603230411779473\n",
      "SNR: 10/30, LS+LI, Epoch 37/50, Loss: 0.00541599876610129 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034056351498954677\n",
      "SNR: 10/30, LS+LI, Epoch 38/50, Loss: 0.005386015799622116 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00358719736951488\n",
      "SNR: 10/30, LS+LI, Epoch 39/50, Loss: 0.005372181713451133 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0036103285489265213\n",
      "SNR: 10/30, LS+LI, Epoch 40/50, Loss: 0.005317750778103377 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034088021916845305\n",
      "SNR: 10/30, LS+LI, Epoch 41/50, Loss: 0.005276873585941313 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003598068470389328\n",
      "SNR: 10/30, LS+LI, Epoch 42/50, Loss: 0.005302656397255961 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0036902346182614565\n",
      "SNR: 10/30, LS+LI, Epoch 43/50, Loss: 0.0053010204533483225 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.003562223483723673\n",
      "SNR: 10/30, LS+LI, Epoch 44/50, Loss: 0.005249882263109781 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0033937371283007615\n",
      "SNR: 10/30, LS+LI, Epoch 45/50, Loss: 0.005232595787167029 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0033617855832827363\n",
      "SNR: 10/30, LS+LI, Epoch 46/50, Loss: 0.00523035857978082 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0034395823181098835\n",
      "SNR: 10/30, LS+LI, Epoch 47/50, Loss: 0.005159749763173072 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0033526549020528114\n",
      "SNR: 10/30, LS+LI, Epoch 48/50, Loss: 0.005214157786361093 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004671118709004738\n",
      "SNR: 10/30, LS+LI, Epoch 49/50, Loss: 0.0051800798080580005 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0033550582804971123\n",
      "SNR: 10/30, LS+LI, Epoch 50/50, Loss: 0.005123799420395043 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0033638009177097542\n",
      "LI+NN NMSE: 0.009531146846711636\n",
      "LS+LI NMSE: 0.008206961676478386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS\n",
      "SNR: 10/30, LS, Epoch 1/50, Loss: 0.2522527458102897 \n",
      "SNR: 10/30, LS, Val Loss: 0.0680330576883121\n",
      "SNR: 10/30, LS, Epoch 2/50, Loss: 0.015336614914325088 \n",
      "SNR: 10/30, LS, Val Loss: 0.004538977719758722\n",
      "SNR: 10/30, LS, Epoch 3/50, Loss: 0.006369089566950881 \n",
      "SNR: 10/30, LS, Val Loss: 0.0036269936879927463\n",
      "SNR: 10/30, LS, Epoch 4/50, Loss: 0.005468633307447267 \n",
      "SNR: 10/30, LS, Val Loss: 0.0036296015076169915\n",
      "SNR: 10/30, LS, Epoch 5/50, Loss: 0.0047518924517600345 \n",
      "SNR: 10/30, LS, Val Loss: 0.0033045541918413205\n",
      "SNR: 10/30, LS, Epoch 6/50, Loss: 0.004658316053601719 \n",
      "SNR: 10/30, LS, Val Loss: 0.0028834483607418156\n",
      "SNR: 10/30, LS, Epoch 7/50, Loss: 0.004228896816087843 \n",
      "SNR: 10/30, LS, Val Loss: 0.0029073691270737486\n",
      "SNR: 10/30, LS, Epoch 8/50, Loss: 0.004358668668130629 \n",
      "SNR: 10/30, LS, Val Loss: 0.002549885878000747\n",
      "SNR: 10/30, LS, Epoch 9/50, Loss: 0.004054052866237281 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022777528449131005\n",
      "SNR: 10/30, LS, Epoch 10/50, Loss: 0.003784824782700906 \n",
      "SNR: 10/30, LS, Val Loss: 0.0023858440955254164\n",
      "SNR: 10/30, LS, Epoch 11/50, Loss: 0.003918131051292686 \n",
      "SNR: 10/30, LS, Val Loss: 0.0024422146909108215\n",
      "SNR: 10/30, LS, Epoch 12/50, Loss: 0.004106267002075477 \n",
      "SNR: 10/30, LS, Val Loss: 0.002262086962053383\n",
      "SNR: 10/30, LS, Epoch 13/50, Loss: 0.003568603026377427 \n",
      "SNR: 10/30, LS, Val Loss: 0.00214641915359111\n",
      "SNR: 10/30, LS, Epoch 14/50, Loss: 0.0037190592834227825 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022426284955475817\n",
      "SNR: 10/30, LS, Epoch 15/50, Loss: 0.00354117879422035 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020067497918551617\n",
      "SNR: 10/30, LS, Epoch 16/50, Loss: 0.0034634492767509073 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019384799525141716\n",
      "SNR: 10/30, LS, Epoch 17/50, Loss: 0.0036344566913105027 \n",
      "SNR: 10/30, LS, Val Loss: 0.0021227598560720003\n",
      "SNR: 10/30, LS, Epoch 18/50, Loss: 0.0033358540595779845 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018902392687530003\n",
      "SNR: 10/30, LS, Epoch 19/50, Loss: 0.003356392272656004 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019138061430897903\n",
      "SNR: 10/30, LS, Epoch 20/50, Loss: 0.0038123562475828846 \n",
      "SNR: 10/30, LS, Val Loss: 0.00227141743843359\n",
      "SNR: 10/30, LS, Epoch 21/50, Loss: 0.003425913884542709 \n",
      "SNR: 10/30, LS, Val Loss: 0.0023272269384258175\n",
      "SNR: 10/30, LS, Epoch 22/50, Loss: 0.003370489420228486 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020040776263075795\n",
      "SNR: 10/30, LS, Epoch 23/50, Loss: 0.0035148598037140315 \n",
      "SNR: 10/30, LS, Val Loss: 0.002296423401937566\n",
      "SNR: 10/30, LS, Epoch 24/50, Loss: 0.0033573447692825265 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018038236620751295\n",
      "SNR: 10/30, LS, Epoch 25/50, Loss: 0.0031831381398491386 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018767154066484761\n",
      "SNR: 10/30, LS, Epoch 26/50, Loss: 0.0035709200601559132 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017449356435628777\n",
      "SNR: 10/30, LS, Epoch 27/50, Loss: 0.003207822620657511 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020190966633063826\n",
      "SNR: 10/30, LS, Epoch 28/50, Loss: 0.003292730126833153 \n",
      "SNR: 10/30, LS, Val Loss: 0.002033352470872077\n",
      "SNR: 10/30, LS, Epoch 29/50, Loss: 0.0031808481191631494 \n",
      "SNR: 10/30, LS, Val Loss: 0.0019064974568953569\n",
      "SNR: 10/30, LS, Epoch 30/50, Loss: 0.0034646973999347104 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018050291162746196\n",
      "SNR: 10/30, LS, Epoch 31/50, Loss: 0.003355529817189415 \n",
      "SNR: 10/30, LS, Val Loss: 0.002027526365550743\n",
      "SNR: 10/30, LS, Epoch 32/50, Loss: 0.0031485867423958385 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016853755858557468\n",
      "SNR: 10/30, LS, Epoch 33/50, Loss: 0.003271762588261735 \n",
      "SNR: 10/30, LS, Val Loss: 0.0026007005627351728\n",
      "SNR: 10/30, LS, Epoch 34/50, Loss: 0.003257035001635898 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016878244985656982\n",
      "SNR: 10/30, LS, Epoch 35/50, Loss: 0.003353578220581809 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015483571015383031\n",
      "SNR: 10/30, LS, Epoch 36/50, Loss: 0.003185271624567767 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020948801750571215\n",
      "SNR: 10/30, LS, Epoch 37/50, Loss: 0.0029184565396145595 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015085909505036068\n",
      "SNR: 10/30, LS, Epoch 38/50, Loss: 0.003171457379087156 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017804016401483254\n",
      "SNR: 10/30, LS, Epoch 39/50, Loss: 0.0029808230478814697 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015012632304040546\n",
      "SNR: 10/30, LS, Epoch 40/50, Loss: 0.0030792093900747076 \n",
      "SNR: 10/30, LS, Val Loss: 0.0014852041336284442\n",
      "SNR: 10/30, LS, Epoch 41/50, Loss: 0.0031804337774046024 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020330161099660804\n",
      "SNR: 10/30, LS, Epoch 42/50, Loss: 0.003097334838077036 \n",
      "SNR: 10/30, LS, Val Loss: 0.0016228868149813604\n",
      "SNR: 10/30, LS, Epoch 43/50, Loss: 0.0028480185124059314 \n",
      "SNR: 10/30, LS, Val Loss: 0.001716597005724907\n",
      "SNR: 10/30, LS, Epoch 44/50, Loss: 0.0027274328160781934 \n",
      "SNR: 10/30, LS, Val Loss: 0.0013980243873613124\n",
      "SNR: 10/30, LS, Epoch 45/50, Loss: 0.0030782219729126366 \n",
      "SNR: 10/30, LS, Val Loss: 0.0015062698459422047\n",
      "SNR: 10/30, LS, Epoch 46/50, Loss: 0.0029876475414629417 \n",
      "SNR: 10/30, LS, Val Loss: 0.001483839534392411\n",
      "SNR: 10/30, LS, Epoch 47/50, Loss: 0.0029226547779872755 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017118189928375862\n",
      "SNR: 10/30, LS, Epoch 48/50, Loss: 0.0027636238434731006 \n",
      "SNR: 10/30, LS, Val Loss: 0.0012720053623938425\n",
      "SNR: 10/30, LS, Epoch 49/50, Loss: 0.0029589667575173947 \n",
      "SNR: 10/30, LS, Val Loss: 0.0014507947701283476\n",
      "SNR: 10/30, LS, Epoch 50/50, Loss: 0.002708759664444166 \n",
      "SNR: 10/30, LS, Val Loss: 0.0013613720233975487\n",
      "LS+LI NMSE: 0.00375541253015399\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/50, Loss: 0.0822790376192262 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.021864506500688465\n",
      "SNR: 15/30, LS+LI, Epoch 2/50, Loss: 0.024580225586717904 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00647626285949214\n",
      "SNR: 15/30, LS+LI, Epoch 3/50, Loss: 0.013833797737133018 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0034789891638369722\n",
      "SNR: 15/30, LS+LI, Epoch 4/50, Loss: 0.010870991691643761 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002922704866663976\n",
      "SNR: 15/30, LS+LI, Epoch 5/50, Loss: 0.009493684737271694 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.003027777557938614\n",
      "SNR: 15/30, LS+LI, Epoch 6/50, Loss: 0.00859872184065712 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0029730476301417434\n",
      "SNR: 15/30, LS+LI, Epoch 7/50, Loss: 0.007933680967124568 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0029572085847824133\n",
      "SNR: 15/30, LS+LI, Epoch 8/50, Loss: 0.007342657967752149 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00229908992134204\n",
      "SNR: 15/30, LS+LI, Epoch 9/50, Loss: 0.006813312366301584 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0020786020851863377\n",
      "SNR: 15/30, LS+LI, Epoch 10/50, Loss: 0.00647645010775345 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0020665721332823687\n",
      "SNR: 15/30, LS+LI, Epoch 11/50, Loss: 0.006136032720204703 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002238172582689334\n",
      "SNR: 15/30, LS+LI, Epoch 12/50, Loss: 0.005807807265650914 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002089825919194316\n",
      "SNR: 15/30, LS+LI, Epoch 13/50, Loss: 0.005532458725082147 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017728883540257812\n",
      "SNR: 15/30, LS+LI, Epoch 14/50, Loss: 0.005437734666778598 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019956448178907685\n",
      "SNR: 15/30, LS+LI, Epoch 15/50, Loss: 0.005157396792932306 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018070521288212728\n",
      "SNR: 15/30, LS+LI, Epoch 16/50, Loss: 0.00493803164694285 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001691355330298062\n",
      "SNR: 15/30, LS+LI, Epoch 17/50, Loss: 0.004790917607457485 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016406056106048213\n",
      "SNR: 15/30, LS+LI, Epoch 18/50, Loss: 0.004872451739407382 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015925399387593973\n",
      "SNR: 15/30, LS+LI, Epoch 19/50, Loss: 0.004563211244097803 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016106616610407152\n",
      "SNR: 15/30, LS+LI, Epoch 20/50, Loss: 0.004404034064866082 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0020843388946642253\n",
      "SNR: 15/30, LS+LI, Epoch 21/50, Loss: 0.0043115162447658045 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018330242072062736\n",
      "SNR: 15/30, LS+LI, Epoch 22/50, Loss: 0.0045032896978650675 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016449812842024999\n",
      "SNR: 15/30, LS+LI, Epoch 23/50, Loss: 0.004202101835818571 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015883530167312447\n",
      "SNR: 15/30, LS+LI, Epoch 24/50, Loss: 0.004140624371736289 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001558692228916863\n",
      "SNR: 15/30, LS+LI, Epoch 25/50, Loss: 0.00399372624883125 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017199488277335397\n",
      "SNR: 15/30, LS+LI, Epoch 26/50, Loss: 0.0038931069375817166 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019429698877502233\n",
      "SNR: 15/30, LS+LI, Epoch 27/50, Loss: 0.003934740675017671 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015594951321624897\n",
      "SNR: 15/30, LS+LI, Epoch 28/50, Loss: 0.0038360498702088588 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016875906387047673\n",
      "SNR: 15/30, LS+LI, Epoch 29/50, Loss: 0.0037938628500045904 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015334879228083248\n",
      "SNR: 15/30, LS+LI, Epoch 30/50, Loss: 0.0036967049114579376 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015850967293689873\n",
      "SNR: 15/30, LS+LI, Epoch 31/50, Loss: 0.0036959809895474897 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001523000664416362\n",
      "SNR: 15/30, LS+LI, Epoch 32/50, Loss: 0.003628778841270697 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016814405442511832\n",
      "SNR: 15/30, LS+LI, Epoch 33/50, Loss: 0.0035960134010502073 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016532483119094236\n",
      "SNR: 15/30, LS+LI, Epoch 34/50, Loss: 0.003539317208992014 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015934208799576895\n",
      "SNR: 15/30, LS+LI, Epoch 35/50, Loss: 0.0034767574208333742 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018974936789494347\n",
      "SNR: 15/30, LS+LI, Epoch 36/50, Loss: 0.0034907575287899477 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001784197734774683\n",
      "SNR: 15/30, LS+LI, Epoch 37/50, Loss: 0.0033977002982959843 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001462042601567439\n",
      "SNR: 15/30, LS+LI, Epoch 38/50, Loss: 0.003285404615548201 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015084380627906119\n",
      "SNR: 15/30, LS+LI, Epoch 39/50, Loss: 0.0033994367451753555 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001749356957258318\n",
      "SNR: 15/30, LS+LI, Epoch 40/50, Loss: 0.0033786283091230447 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014903093714648012\n",
      "SNR: 15/30, LS+LI, Epoch 41/50, Loss: 0.0033196956189999053 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017447055936579338\n",
      "SNR: 15/30, LS+LI, Epoch 42/50, Loss: 0.0032709544892747734 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015546503445048902\n",
      "SNR: 15/30, LS+LI, Epoch 43/50, Loss: 0.0033305373102383213 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016679893173700707\n",
      "SNR: 15/30, LS+LI, Epoch 44/50, Loss: 0.00323513901364708 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015727440689013085\n",
      "SNR: 15/30, LS+LI, Epoch 45/50, Loss: 0.0031591114225299204 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014529075627003542\n",
      "SNR: 15/30, LS+LI, Epoch 46/50, Loss: 0.0031388036671181232 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015596292505506426\n",
      "SNR: 15/30, LS+LI, Epoch 47/50, Loss: 0.0030841649574942366 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014390025806443934\n",
      "SNR: 15/30, LS+LI, Epoch 48/50, Loss: 0.0031162789064394527 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001742034568451345\n",
      "SNR: 15/30, LS+LI, Epoch 49/50, Loss: 0.003102828679487196 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014679694405375894\n",
      "SNR: 15/30, LS+LI, Epoch 50/50, Loss: 0.0030183569612089803 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014434165919241918\n",
      "LI+NN NMSE: 0.0042523290030658245\n",
      "LS+LI NMSE: 0.002597494749352336\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/50, Loss: 0.2096007710625959 \n",
      "SNR: 15/30, LS, Val Loss: 0.027791289443319492\n",
      "SNR: 15/30, LS, Epoch 2/50, Loss: 0.009549174104481502 \n",
      "SNR: 15/30, LS, Val Loss: 0.0037137716479430146\n",
      "SNR: 15/30, LS, Epoch 3/50, Loss: 0.005087939842311709 \n",
      "SNR: 15/30, LS, Val Loss: 0.002941924739967693\n",
      "SNR: 15/30, LS, Epoch 4/50, Loss: 0.004546498365397024 \n",
      "SNR: 15/30, LS, Val Loss: 0.0027611746442165563\n",
      "SNR: 15/30, LS, Epoch 5/50, Loss: 0.004318759064623263 \n",
      "SNR: 15/30, LS, Val Loss: 0.0026430000064217233\n",
      "SNR: 15/30, LS, Epoch 6/50, Loss: 0.004233021022437877 \n",
      "SNR: 15/30, LS, Val Loss: 0.0023397632758133113\n",
      "SNR: 15/30, LS, Epoch 7/50, Loss: 0.0038576449543714177 \n",
      "SNR: 15/30, LS, Val Loss: 0.002090171513951976\n",
      "SNR: 15/30, LS, Epoch 8/50, Loss: 0.0040041724217210915 \n",
      "SNR: 15/30, LS, Val Loss: 0.0023754385553977704\n",
      "SNR: 15/30, LS, Epoch 9/50, Loss: 0.003908206951712409 \n",
      "SNR: 15/30, LS, Val Loss: 0.001947701188989661\n",
      "SNR: 15/30, LS, Epoch 10/50, Loss: 0.00338028492148814 \n",
      "SNR: 15/30, LS, Val Loss: 0.0021763059035451574\n",
      "SNR: 15/30, LS, Epoch 11/50, Loss: 0.0036898558535667265 \n",
      "SNR: 15/30, LS, Val Loss: 0.002322056055576964\n",
      "SNR: 15/30, LS, Epoch 12/50, Loss: 0.003120246412351641 \n",
      "SNR: 15/30, LS, Val Loss: 0.0017789023960093882\n",
      "SNR: 15/30, LS, Epoch 13/50, Loss: 0.0033161046198666704 \n",
      "SNR: 15/30, LS, Val Loss: 0.0018722369145093994\n",
      "SNR: 15/30, LS, Epoch 14/50, Loss: 0.003028571655768035 \n",
      "SNR: 15/30, LS, Val Loss: 0.0021399147861467845\n",
      "SNR: 15/30, LS, Epoch 15/50, Loss: 0.0034398970561004567 \n",
      "SNR: 15/30, LS, Val Loss: 0.00176301124421033\n",
      "SNR: 15/30, LS, Epoch 16/50, Loss: 0.0033719287488100575 \n",
      "SNR: 15/30, LS, Val Loss: 0.001572074072266167\n",
      "SNR: 15/30, LS, Epoch 17/50, Loss: 0.0030897133976903334 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015327762177383358\n",
      "SNR: 15/30, LS, Epoch 18/50, Loss: 0.00297886461052004 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015027738620781086\n",
      "SNR: 15/30, LS, Epoch 19/50, Loss: 0.003377013740286794 \n",
      "SNR: 15/30, LS, Val Loss: 0.001465282365891405\n",
      "SNR: 15/30, LS, Epoch 20/50, Loss: 0.0031416069683727135 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015274523916146295\n",
      "SNR: 15/30, LS, Epoch 21/50, Loss: 0.0030779017630942858 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015953234079378572\n",
      "SNR: 15/30, LS, Epoch 22/50, Loss: 0.002861297990569065 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013610777360471811\n",
      "SNR: 15/30, LS, Epoch 23/50, Loss: 0.002842181359504371 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016776319773105736\n",
      "SNR: 15/30, LS, Epoch 24/50, Loss: 0.0032046187633843442 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016540159333751283\n",
      "SNR: 15/30, LS, Epoch 25/50, Loss: 0.0030820039100944996 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013963818253779953\n",
      "SNR: 15/30, LS, Epoch 26/50, Loss: 0.0029388570191533586 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015113005435771563\n",
      "SNR: 15/30, LS, Epoch 27/50, Loss: 0.002603870536319825 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014104477066377347\n",
      "SNR: 15/30, LS, Epoch 28/50, Loss: 0.002819171651851299 \n",
      "SNR: 15/30, LS, Val Loss: 0.001358583289071579\n",
      "SNR: 15/30, LS, Epoch 29/50, Loss: 0.0026106330062544278 \n",
      "SNR: 15/30, LS, Val Loss: 0.001484776000407609\n",
      "SNR: 15/30, LS, Epoch 30/50, Loss: 0.0029351913470363374 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012314531274817207\n",
      "SNR: 15/30, LS, Epoch 31/50, Loss: 0.00277597245930824 \n",
      "SNR: 15/30, LS, Val Loss: 0.0020426092034375124\n",
      "SNR: 15/30, LS, Epoch 32/50, Loss: 0.00296168259296263 \n",
      "SNR: 15/30, LS, Val Loss: 0.001589582042387602\n",
      "SNR: 15/30, LS, Epoch 33/50, Loss: 0.0028010470025122253 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014813662115061147\n",
      "SNR: 15/30, LS, Epoch 34/50, Loss: 0.002725785581238005 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012531328459524295\n",
      "SNR: 15/30, LS, Epoch 35/50, Loss: 0.0027340926770743545 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013064951953393493\n",
      "SNR: 15/30, LS, Epoch 36/50, Loss: 0.002804214271532675 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012914184375073421\n",
      "SNR: 15/30, LS, Epoch 37/50, Loss: 0.0027666379816743522 \n",
      "SNR: 15/30, LS, Val Loss: 0.00123082618070343\n",
      "SNR: 15/30, LS, Epoch 38/50, Loss: 0.0025998727698691277 \n",
      "SNR: 15/30, LS, Val Loss: 0.002125663735734468\n",
      "SNR: 15/30, LS, Epoch 39/50, Loss: 0.0027178560808669167 \n",
      "SNR: 15/30, LS, Val Loss: 0.001084847896973687\n",
      "SNR: 15/30, LS, Epoch 40/50, Loss: 0.0029475835367203367 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012574832494878633\n",
      "SNR: 15/30, LS, Epoch 41/50, Loss: 0.00261417071288993 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014497739770873027\n",
      "SNR: 15/30, LS, Epoch 42/50, Loss: 0.002719167939747337 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010961089600724254\n",
      "SNR: 15/30, LS, Epoch 43/50, Loss: 0.00280787035698331 \n",
      "SNR: 15/30, LS, Val Loss: 0.001446749538775872\n",
      "SNR: 15/30, LS, Epoch 44/50, Loss: 0.002852845486242671 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012968767233277586\n",
      "SNR: 15/30, LS, Epoch 45/50, Loss: 0.0028586184858414884 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010543578616555103\n",
      "SNR: 15/30, LS, Epoch 46/50, Loss: 0.0026257094713252817 \n",
      "SNR: 15/30, LS, Val Loss: 0.0009835049806332047\n",
      "SNR: 15/30, LS, Epoch 47/50, Loss: 0.00266434132394944 \n",
      "SNR: 15/30, LS, Val Loss: 0.002273790136148984\n",
      "SNR: 15/30, LS, Epoch 48/50, Loss: 0.0026224466869174397 \n",
      "SNR: 15/30, LS, Val Loss: 0.0011406595083165237\n",
      "SNR: 15/30, LS, Epoch 49/50, Loss: 0.002617456535686912 \n",
      "SNR: 15/30, LS, Val Loss: 0.0010433122833174739\n",
      "SNR: 15/30, LS, Epoch 50/50, Loss: 0.002505969024008833 \n",
      "SNR: 15/30, LS, Val Loss: 0.001059720406456935\n",
      "LS+LI NMSE: 0.0030015981756150723\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/50, Loss: 0.07979053581609975 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.020401138134978035\n",
      "SNR: 20/30, LS+LI, Epoch 2/50, Loss: 0.02341248163260346 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.006429173539138653\n",
      "SNR: 20/30, LS+LI, Epoch 3/50, Loss: 0.01345883515598469 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.003034586954692548\n",
      "SNR: 20/30, LS+LI, Epoch 4/50, Loss: 0.010028807733337893 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00242075592872094\n",
      "SNR: 20/30, LS+LI, Epoch 5/50, Loss: 0.008566480067688538 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.002070379872086712\n",
      "SNR: 20/30, LS+LI, Epoch 6/50, Loss: 0.007591624251501851 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018435366430573843\n",
      "SNR: 20/30, LS+LI, Epoch 7/50, Loss: 0.006835522644525004 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0017417453927919269\n",
      "SNR: 20/30, LS+LI, Epoch 8/50, Loss: 0.006249706777960582 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018789438710717316\n",
      "SNR: 20/30, LS+LI, Epoch 9/50, Loss: 0.005862755007868589 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0013771115759895606\n",
      "SNR: 20/30, LS+LI, Epoch 10/50, Loss: 0.005458692530018472 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012105995768003843\n",
      "SNR: 20/30, LS+LI, Epoch 11/50, Loss: 0.005130247716510365 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0024244409922341056\n",
      "SNR: 20/30, LS+LI, Epoch 12/50, Loss: 0.004914720020213619 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010586591987785969\n",
      "SNR: 20/30, LS+LI, Epoch 13/50, Loss: 0.004734887773994096 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012048201355024833\n",
      "SNR: 20/30, LS+LI, Epoch 14/50, Loss: 0.0044995160370003865 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009799713946201584\n",
      "SNR: 20/30, LS+LI, Epoch 15/50, Loss: 0.004356240807642597 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009714107357219539\n",
      "SNR: 20/30, LS+LI, Epoch 16/50, Loss: 0.004145613404499844 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010289792632895776\n",
      "SNR: 20/30, LS+LI, Epoch 17/50, Loss: 0.004136226833039938 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009038353111298585\n",
      "SNR: 20/30, LS+LI, Epoch 18/50, Loss: 0.003877938788676591 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010282219419340518\n",
      "SNR: 20/30, LS+LI, Epoch 19/50, Loss: 0.0037545675606748393 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008114517258945853\n",
      "SNR: 20/30, LS+LI, Epoch 20/50, Loss: 0.0037168222520132226 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010170393242416058\n",
      "SNR: 20/30, LS+LI, Epoch 21/50, Loss: 0.0036378814067236733 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012237347942903978\n",
      "SNR: 20/30, LS+LI, Epoch 22/50, Loss: 0.003567283185263879 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009975766191597688\n",
      "SNR: 20/30, LS+LI, Epoch 23/50, Loss: 0.003423811069169883 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007288972661957483\n",
      "SNR: 20/30, LS+LI, Epoch 24/50, Loss: 0.0033110908238043967 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018536906043829565\n",
      "SNR: 20/30, LS+LI, Epoch 25/50, Loss: 0.0033495020849608577 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007881700452840464\n",
      "SNR: 20/30, LS+LI, Epoch 26/50, Loss: 0.003241380338210526 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006835160655265844\n",
      "SNR: 20/30, LS+LI, Epoch 27/50, Loss: 0.0030881109861332144 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007025593129748648\n",
      "SNR: 20/30, LS+LI, Epoch 28/50, Loss: 0.0030541159402102578 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008662425045093352\n",
      "SNR: 20/30, LS+LI, Epoch 29/50, Loss: 0.003050196528716316 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008396425162738359\n",
      "SNR: 20/30, LS+LI, Epoch 30/50, Loss: 0.0030147025326461812 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0014374419591728258\n",
      "SNR: 20/30, LS+LI, Epoch 31/50, Loss: 0.0029663905937246287 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006620105361269617\n",
      "SNR: 20/30, LS+LI, Epoch 32/50, Loss: 0.002820309612975824 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008325566754634069\n",
      "SNR: 20/30, LS+LI, Epoch 33/50, Loss: 0.00288187394996152 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009746468065052547\n",
      "SNR: 20/30, LS+LI, Epoch 34/50, Loss: 0.0027860465546160245 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006368268249471756\n",
      "SNR: 20/30, LS+LI, Epoch 35/50, Loss: 0.0027262110244157876 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006298082510263405\n",
      "SNR: 20/30, LS+LI, Epoch 36/50, Loss: 0.0026690328688642314 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007179234182165766\n",
      "SNR: 20/30, LS+LI, Epoch 37/50, Loss: 0.0026293737830074375 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007511059256185862\n",
      "SNR: 20/30, LS+LI, Epoch 38/50, Loss: 0.0027138599015902294 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008261017448438162\n",
      "SNR: 20/30, LS+LI, Epoch 39/50, Loss: 0.00260478388761755 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009329090455800972\n",
      "SNR: 20/30, LS+LI, Epoch 40/50, Loss: 0.002592514388176591 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006830642814747989\n",
      "SNR: 20/30, LS+LI, Epoch 41/50, Loss: 0.0025583457994967874 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0017146641727198255\n",
      "SNR: 20/30, LS+LI, Epoch 42/50, Loss: 0.0025719511674630433 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000590642042383975\n",
      "SNR: 20/30, LS+LI, Epoch 43/50, Loss: 0.0024529847947252523 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009293282690288669\n",
      "SNR: 20/30, LS+LI, Epoch 44/50, Loss: 0.0024517803367628 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006120768627046015\n",
      "SNR: 20/30, LS+LI, Epoch 45/50, Loss: 0.002376967309405594 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0005733457219321281\n",
      "SNR: 20/30, LS+LI, Epoch 46/50, Loss: 0.002424948597678828 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0005772899696074256\n",
      "SNR: 20/30, LS+LI, Epoch 47/50, Loss: 0.002365357939662888 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006369669956091622\n",
      "SNR: 20/30, LS+LI, Epoch 48/50, Loss: 0.0023184002906376454 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007036513230890374\n",
      "SNR: 20/30, LS+LI, Epoch 49/50, Loss: 0.002307172501216058 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000593039651655338\n",
      "SNR: 20/30, LS+LI, Epoch 50/50, Loss: 0.002362738810154761 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0007439909135097299\n",
      "LI+NN NMSE: 0.002102547325193882\n",
      "LS+LI NMSE: 0.000820028712041676\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/50, Loss: 0.22463449958148737 \n",
      "SNR: 20/30, LS, Val Loss: 0.039535580880262634\n",
      "SNR: 20/30, LS, Epoch 2/50, Loss: 0.012294244229641938 \n",
      "SNR: 20/30, LS, Val Loss: 0.003978340632536195\n",
      "SNR: 20/30, LS, Epoch 3/50, Loss: 0.005153686491783362 \n",
      "SNR: 20/30, LS, Val Loss: 0.0035643742567944255\n",
      "SNR: 20/30, LS, Epoch 4/50, Loss: 0.00467021317291615 \n",
      "SNR: 20/30, LS, Val Loss: 0.0028779433712109244\n",
      "SNR: 20/30, LS, Epoch 5/50, Loss: 0.004384358765470774 \n",
      "SNR: 20/30, LS, Val Loss: 0.002811266283970326\n",
      "SNR: 20/30, LS, Epoch 6/50, Loss: 0.003978314284955389 \n",
      "SNR: 20/30, LS, Val Loss: 0.002439405276990411\n",
      "SNR: 20/30, LS, Epoch 7/50, Loss: 0.0038392783973777538 \n",
      "SNR: 20/30, LS, Val Loss: 0.0023097556550055742\n",
      "SNR: 20/30, LS, Epoch 8/50, Loss: 0.0035771425389738883 \n",
      "SNR: 20/30, LS, Val Loss: 0.0026229663000611417\n",
      "SNR: 20/30, LS, Epoch 9/50, Loss: 0.0035992424466733844 \n",
      "SNR: 20/30, LS, Val Loss: 0.0020851336779411545\n",
      "SNR: 20/30, LS, Epoch 10/50, Loss: 0.0031635278672099026 \n",
      "SNR: 20/30, LS, Val Loss: 0.0017325758817605674\n",
      "SNR: 20/30, LS, Epoch 11/50, Loss: 0.003203403123459497 \n",
      "SNR: 20/30, LS, Val Loss: 0.0017088611917146905\n",
      "SNR: 20/30, LS, Epoch 12/50, Loss: 0.003077126802540882 \n",
      "SNR: 20/30, LS, Val Loss: 0.001986197153614326\n",
      "SNR: 20/30, LS, Epoch 13/50, Loss: 0.0029872532793169104 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015612296992912889\n",
      "SNR: 20/30, LS, Epoch 14/50, Loss: 0.0031590073093295443 \n",
      "SNR: 20/30, LS, Val Loss: 0.0016826618335802448\n",
      "SNR: 20/30, LS, Epoch 15/50, Loss: 0.002934959370556266 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015685830995525148\n",
      "SNR: 20/30, LS, Epoch 16/50, Loss: 0.002753041346887733 \n",
      "SNR: 20/30, LS, Val Loss: 0.002159550426189195\n",
      "SNR: 20/30, LS, Epoch 17/50, Loss: 0.0029975485583214998 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014018058427609503\n",
      "SNR: 20/30, LS, Epoch 18/50, Loss: 0.0026877065531660392 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015464637862433765\n",
      "SNR: 20/30, LS, Epoch 19/50, Loss: 0.002688256515390348 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014826702694831924\n",
      "SNR: 20/30, LS, Epoch 20/50, Loss: 0.002901360862969616 \n",
      "SNR: 20/30, LS, Val Loss: 0.001245057334678925\n",
      "SNR: 20/30, LS, Epoch 21/50, Loss: 0.002753651240667285 \n",
      "SNR: 20/30, LS, Val Loss: 0.001202671968547458\n",
      "SNR: 20/30, LS, Epoch 22/50, Loss: 0.0026402447371321274 \n",
      "SNR: 20/30, LS, Val Loss: 0.0014064909191802144\n",
      "SNR: 20/30, LS, Epoch 23/50, Loss: 0.002915949534982183 \n",
      "SNR: 20/30, LS, Val Loss: 0.0018668462183665145\n",
      "SNR: 20/30, LS, Epoch 24/50, Loss: 0.002592003818325222 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012172230053693056\n",
      "SNR: 20/30, LS, Epoch 25/50, Loss: 0.0027497128412928866 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012260232734578576\n",
      "SNR: 20/30, LS, Epoch 26/50, Loss: 0.0024973258337542023 \n",
      "SNR: 20/30, LS, Val Loss: 0.001288899797311222\n",
      "SNR: 20/30, LS, Epoch 27/50, Loss: 0.0025896540945152167 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011855488463135605\n",
      "SNR: 20/30, LS, Epoch 28/50, Loss: 0.0022795983379690497 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011126580939162523\n",
      "SNR: 20/30, LS, Epoch 29/50, Loss: 0.00271386094188296 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011929145336828449\n",
      "SNR: 20/30, LS, Epoch 30/50, Loss: 0.0023577531087645436 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011162990757094865\n",
      "SNR: 20/30, LS, Epoch 31/50, Loss: 0.002607564097690006 \n",
      "SNR: 20/30, LS, Val Loss: 0.0013222357586280189\n",
      "SNR: 20/30, LS, Epoch 32/50, Loss: 0.0023564924441987303 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012681850375057284\n",
      "SNR: 20/30, LS, Epoch 33/50, Loss: 0.0025504173326500973 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009408309759402817\n",
      "SNR: 20/30, LS, Epoch 34/50, Loss: 0.002565801080023913 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009382890897210349\n",
      "SNR: 20/30, LS, Epoch 35/50, Loss: 0.002586101588581927 \n",
      "SNR: 20/30, LS, Val Loss: 0.000899196517738429\n",
      "SNR: 20/30, LS, Epoch 36/50, Loss: 0.002404504210273952 \n",
      "SNR: 20/30, LS, Val Loss: 0.000926312268182466\n",
      "SNR: 20/30, LS, Epoch 37/50, Loss: 0.0025013343107529243 \n",
      "SNR: 20/30, LS, Val Loss: 0.000950804038438946\n",
      "SNR: 20/30, LS, Epoch 38/50, Loss: 0.0024214228550865596 \n",
      "SNR: 20/30, LS, Val Loss: 0.001542855533030392\n",
      "SNR: 20/30, LS, Epoch 39/50, Loss: 0.0023838035189709087 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009708575406958433\n",
      "SNR: 20/30, LS, Epoch 40/50, Loss: 0.002476135528372969 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008603547996079379\n",
      "SNR: 20/30, LS, Epoch 41/50, Loss: 0.0022667723651677587 \n",
      "SNR: 20/30, LS, Val Loss: 0.0016229590692091733\n",
      "SNR: 20/30, LS, Epoch 42/50, Loss: 0.0022795849268562917 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008178491499909961\n",
      "SNR: 20/30, LS, Epoch 43/50, Loss: 0.002390878548815868 \n",
      "SNR: 20/30, LS, Val Loss: 0.0007933798240794039\n",
      "SNR: 20/30, LS, Epoch 44/50, Loss: 0.002253974249131631 \n",
      "SNR: 20/30, LS, Val Loss: 0.000873252648902549\n",
      "SNR: 20/30, LS, Epoch 45/50, Loss: 0.0021441103162942454 \n",
      "SNR: 20/30, LS, Val Loss: 0.0007933745576089925\n",
      "SNR: 20/30, LS, Epoch 46/50, Loss: 0.002240072635982489 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008855105261318386\n",
      "SNR: 20/30, LS, Epoch 47/50, Loss: 0.0023259602755790055 \n",
      "SNR: 20/30, LS, Val Loss: 0.000864858908409422\n",
      "SNR: 20/30, LS, Epoch 48/50, Loss: 0.0021413847452793054 \n",
      "SNR: 20/30, LS, Val Loss: 0.0008670329248574985\n",
      "SNR: 20/30, LS, Epoch 49/50, Loss: 0.002200178961746048 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009183156018314713\n",
      "SNR: 20/30, LS, Epoch 50/50, Loss: 0.0022379256301656974 \n",
      "SNR: 20/30, LS, Val Loss: 0.0009303050253286281\n",
      "LS+LI NMSE: 0.0025654034689068794\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/50, Loss: 0.0529831284765414 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.01050343703139912\n",
      "SNR: 25/30, LS+LI, Epoch 2/50, Loss: 0.012684309795542165 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0032289058964868837\n",
      "SNR: 25/30, LS+LI, Epoch 3/50, Loss: 0.008127912518914876 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0020326376702128487\n",
      "SNR: 25/30, LS+LI, Epoch 4/50, Loss: 0.006835468665718339 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.001801111984108998\n",
      "SNR: 25/30, LS+LI, Epoch 5/50, Loss: 0.006047756684575837 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0015202641476538372\n",
      "SNR: 25/30, LS+LI, Epoch 6/50, Loss: 0.005469722881761574 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0012648961591449652\n",
      "SNR: 25/30, LS+LI, Epoch 7/50, Loss: 0.00505423009514722 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0012459062272682786\n",
      "SNR: 25/30, LS+LI, Epoch 8/50, Loss: 0.004684502372604816 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0010909125214146281\n",
      "SNR: 25/30, LS+LI, Epoch 9/50, Loss: 0.0043667683629643956 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0010368973254861141\n",
      "SNR: 25/30, LS+LI, Epoch 10/50, Loss: 0.0041695380418258175 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008736135443376207\n",
      "SNR: 25/30, LS+LI, Epoch 11/50, Loss: 0.0039658978551647866 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0011003129739864644\n",
      "SNR: 25/30, LS+LI, Epoch 12/50, Loss: 0.0037313372053769094 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008405323235572062\n",
      "SNR: 25/30, LS+LI, Epoch 13/50, Loss: 0.003541922111464881 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008091634001836858\n",
      "SNR: 25/30, LS+LI, Epoch 14/50, Loss: 0.0034966295866598915 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00071981234412471\n",
      "SNR: 25/30, LS+LI, Epoch 15/50, Loss: 0.0032757894368842244 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008561801197091964\n",
      "SNR: 25/30, LS+LI, Epoch 16/50, Loss: 0.0032047803708633712 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006017550635574894\n",
      "SNR: 25/30, LS+LI, Epoch 17/50, Loss: 0.003039640064492042 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0010069091328081083\n",
      "SNR: 25/30, LS+LI, Epoch 18/50, Loss: 0.0030400115958696535 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007407264254817909\n",
      "SNR: 25/30, LS+LI, Epoch 19/50, Loss: 0.00288834098758999 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005820963521149348\n",
      "SNR: 25/30, LS+LI, Epoch 20/50, Loss: 0.0028741345348291445 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006316858528986235\n",
      "SNR: 25/30, LS+LI, Epoch 21/50, Loss: 0.0027386315835661494 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006299852631689811\n",
      "SNR: 25/30, LS+LI, Epoch 22/50, Loss: 0.0028024243020322607 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.000482747335230339\n",
      "SNR: 25/30, LS+LI, Epoch 23/50, Loss: 0.002646227376697975 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00044490229497155684\n",
      "SNR: 25/30, LS+LI, Epoch 24/50, Loss: 0.002543335982197679 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004588243040912361\n",
      "SNR: 25/30, LS+LI, Epoch 25/50, Loss: 0.0024793437183942904 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004170683400430293\n",
      "SNR: 25/30, LS+LI, Epoch 26/50, Loss: 0.0024559426603318994 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00041441209032200277\n",
      "SNR: 25/30, LS+LI, Epoch 27/50, Loss: 0.0025158717329505573 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00040909697285810995\n",
      "SNR: 25/30, LS+LI, Epoch 28/50, Loss: 0.0023586887969137276 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003869743509726091\n",
      "SNR: 25/30, LS+LI, Epoch 29/50, Loss: 0.002283217097757124 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003887844174063172\n",
      "SNR: 25/30, LS+LI, Epoch 30/50, Loss: 0.0023088668747859205 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00043831849391360515\n",
      "SNR: 25/30, LS+LI, Epoch 31/50, Loss: 0.002409581044217745 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00044508197540628976\n",
      "SNR: 25/30, LS+LI, Epoch 32/50, Loss: 0.0023220679952849657 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004120123432420025\n",
      "SNR: 25/30, LS+LI, Epoch 33/50, Loss: 0.0021470135110322128 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007816155927933075\n",
      "SNR: 25/30, LS+LI, Epoch 34/50, Loss: 0.002145630122043279 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00035603185824584216\n",
      "SNR: 25/30, LS+LI, Epoch 35/50, Loss: 0.0021984520947647304 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00036908269447105175\n",
      "SNR: 25/30, LS+LI, Epoch 36/50, Loss: 0.002240751899757184 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00036039958517490464\n",
      "SNR: 25/30, LS+LI, Epoch 37/50, Loss: 0.0021536666074182926 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003505244398680092\n",
      "SNR: 25/30, LS+LI, Epoch 38/50, Loss: 0.0021462690688907925 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00037686246320266616\n",
      "SNR: 25/30, LS+LI, Epoch 39/50, Loss: 0.001968596940778932 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00043710953402544624\n",
      "SNR: 25/30, LS+LI, Epoch 40/50, Loss: 0.0020129155993006778 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003693258688806302\n",
      "SNR: 25/30, LS+LI, Epoch 41/50, Loss: 0.001965477613889244 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003760968803279948\n",
      "SNR: 25/30, LS+LI, Epoch 42/50, Loss: 0.0019580627721192878 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00047896501200739294\n",
      "SNR: 25/30, LS+LI, Epoch 43/50, Loss: 0.0019568331982279846 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00031883250498636204\n",
      "SNR: 25/30, LS+LI, Epoch 44/50, Loss: 0.0019187144765922756 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003278319782111794\n",
      "SNR: 25/30, LS+LI, Epoch 45/50, Loss: 0.002001084355491235 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005749278035099534\n",
      "SNR: 25/30, LS+LI, Epoch 46/50, Loss: 0.0019153128716509877 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003164568810131062\n",
      "SNR: 25/30, LS+LI, Epoch 47/50, Loss: 0.001948881935636881 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003087893485578454\n",
      "SNR: 25/30, LS+LI, Epoch 48/50, Loss: 0.0018605103189677952 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00032318535059775144\n",
      "SNR: 25/30, LS+LI, Epoch 49/50, Loss: 0.0018714204522629464 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00032186850810169494\n",
      "SNR: 25/30, LS+LI, Epoch 50/50, Loss: 0.0018265770374645675 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003196388715878129\n",
      "LI+NN NMSE: 0.0008823683601804078\n",
      "LS+LI NMSE: 0.0002619863662403077\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/50, Loss: 0.23834800291373287 \n",
      "SNR: 25/30, LS, Val Loss: 0.05404296297241341\n",
      "SNR: 25/30, LS, Epoch 2/50, Loss: 0.013542175467591733 \n",
      "SNR: 25/30, LS, Val Loss: 0.004423243543979796\n",
      "SNR: 25/30, LS, Epoch 3/50, Loss: 0.005515526584891039 \n",
      "SNR: 25/30, LS, Val Loss: 0.0037513377928090367\n",
      "SNR: 25/30, LS, Epoch 4/50, Loss: 0.004942701406625294 \n",
      "SNR: 25/30, LS, Val Loss: 0.004218814143149013\n",
      "SNR: 25/30, LS, Epoch 5/50, Loss: 0.004487025356569955 \n",
      "SNR: 25/30, LS, Val Loss: 0.0031513820656321264\n",
      "SNR: 25/30, LS, Epoch 6/50, Loss: 0.004246818792443116 \n",
      "SNR: 25/30, LS, Val Loss: 0.0024158333491703324\n",
      "SNR: 25/30, LS, Epoch 7/50, Loss: 0.00382335368289374 \n",
      "SNR: 25/30, LS, Val Loss: 0.002178283159578727\n",
      "SNR: 25/30, LS, Epoch 8/50, Loss: 0.0037190066190263215 \n",
      "SNR: 25/30, LS, Val Loss: 0.002002683431121775\n",
      "SNR: 25/30, LS, Epoch 9/50, Loss: 0.0035474510094540756 \n",
      "SNR: 25/30, LS, Val Loss: 0.0019664562000385063\n",
      "SNR: 25/30, LS, Epoch 10/50, Loss: 0.0036765581543752274 \n",
      "SNR: 25/30, LS, Val Loss: 0.001981806999538094\n",
      "SNR: 25/30, LS, Epoch 11/50, Loss: 0.003235520071452917 \n",
      "SNR: 25/30, LS, Val Loss: 0.002531823781530627\n",
      "SNR: 25/30, LS, Epoch 12/50, Loss: 0.003171602579450971 \n",
      "SNR: 25/30, LS, Val Loss: 0.0016678760029290888\n",
      "SNR: 25/30, LS, Epoch 13/50, Loss: 0.00307389979892367 \n",
      "SNR: 25/30, LS, Val Loss: 0.001583896863104945\n",
      "SNR: 25/30, LS, Epoch 14/50, Loss: 0.002952711854324958 \n",
      "SNR: 25/30, LS, Val Loss: 0.0017701909739778123\n",
      "SNR: 25/30, LS, Epoch 15/50, Loss: 0.0029198180831329855 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014825848418033936\n",
      "SNR: 25/30, LS, Epoch 16/50, Loss: 0.0030546153105015673 \n",
      "SNR: 25/30, LS, Val Loss: 0.001446104253938591\n",
      "SNR: 25/30, LS, Epoch 17/50, Loss: 0.002834344752468602 \n",
      "SNR: 25/30, LS, Val Loss: 0.00144929763734002\n",
      "SNR: 25/30, LS, Epoch 18/50, Loss: 0.002912978398705681 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014657958527095616\n",
      "SNR: 25/30, LS, Epoch 19/50, Loss: 0.003038665635760354 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012239505674436011\n",
      "SNR: 25/30, LS, Epoch 20/50, Loss: 0.0025689254966997648 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012993361663327298\n",
      "SNR: 25/30, LS, Epoch 21/50, Loss: 0.0028781057815987963 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012427683422257278\n",
      "SNR: 25/30, LS, Epoch 22/50, Loss: 0.003009178487551507 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012465621323578737\n",
      "SNR: 25/30, LS, Epoch 23/50, Loss: 0.002684137534869965 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012079308137551627\n",
      "SNR: 25/30, LS, Epoch 24/50, Loss: 0.0025784547791307317 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011394907619846476\n",
      "SNR: 25/30, LS, Epoch 25/50, Loss: 0.0026886511335506777 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012335037463344634\n",
      "SNR: 25/30, LS, Epoch 26/50, Loss: 0.002515460790587091 \n",
      "SNR: 25/30, LS, Val Loss: 0.0019323855151676319\n",
      "SNR: 25/30, LS, Epoch 27/50, Loss: 0.0025721363679960716 \n",
      "SNR: 25/30, LS, Val Loss: 0.00184580595867539\n",
      "SNR: 25/30, LS, Epoch 28/50, Loss: 0.0026915477711279595 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011329092297025702\n",
      "SNR: 25/30, LS, Epoch 29/50, Loss: 0.002493303473889936 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012827250810170715\n",
      "SNR: 25/30, LS, Epoch 30/50, Loss: 0.002543747429478762 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010745938449293715\n",
      "SNR: 25/30, LS, Epoch 31/50, Loss: 0.0024809914584905126 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011591091249349781\n",
      "SNR: 25/30, LS, Epoch 32/50, Loss: 0.0027437405603217653 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010971872305328195\n",
      "SNR: 25/30, LS, Epoch 33/50, Loss: 0.0025308033340437296 \n",
      "SNR: 25/30, LS, Val Loss: 0.000983993178868497\n",
      "SNR: 25/30, LS, Epoch 34/50, Loss: 0.002752365548499362 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010041962324810977\n",
      "SNR: 25/30, LS, Epoch 35/50, Loss: 0.0030122746457616517 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010480718258556656\n",
      "SNR: 25/30, LS, Epoch 36/50, Loss: 0.0025849857206488853 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010073194439014928\n",
      "SNR: 25/30, LS, Epoch 37/50, Loss: 0.002580398943093822 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014859563353556123\n",
      "SNR: 25/30, LS, Epoch 38/50, Loss: 0.0026238117902404306 \n",
      "SNR: 25/30, LS, Val Loss: 0.0013319811021739786\n",
      "SNR: 25/30, LS, Epoch 39/50, Loss: 0.002458826029946659 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010049567658411847\n",
      "SNR: 25/30, LS, Epoch 40/50, Loss: 0.0025492677919236335 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011830150562507863\n",
      "SNR: 25/30, LS, Epoch 41/50, Loss: 0.0025886635534292045 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010704938401679763\n",
      "SNR: 25/30, LS, Epoch 42/50, Loss: 0.002569640089478885 \n",
      "SNR: 25/30, LS, Val Loss: 0.001074172992957756\n",
      "SNR: 25/30, LS, Epoch 43/50, Loss: 0.0023051955450196253 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010438691454262218\n",
      "SNR: 25/30, LS, Epoch 44/50, Loss: 0.0023225782229971182 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009550911384973336\n",
      "SNR: 25/30, LS, Epoch 45/50, Loss: 0.0023296148215723764 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008107208149422976\n",
      "SNR: 25/30, LS, Epoch 46/50, Loss: 0.0025590366114006747 \n",
      "SNR: 25/30, LS, Val Loss: 0.000992977184730328\n",
      "SNR: 25/30, LS, Epoch 47/50, Loss: 0.0023230049521581076 \n",
      "SNR: 25/30, LS, Val Loss: 0.0008695448473603888\n",
      "SNR: 25/30, LS, Epoch 48/50, Loss: 0.002137517522706455 \n",
      "SNR: 25/30, LS, Val Loss: 0.0007708332453727384\n",
      "SNR: 25/30, LS, Epoch 49/50, Loss: 0.0024507844409104003 \n",
      "SNR: 25/30, LS, Val Loss: 0.001536553492769599\n",
      "SNR: 25/30, LS, Epoch 50/50, Loss: 0.0023060334243318933 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010596783937547696\n",
      "LS+LI NMSE: 0.002879577223211527\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/50, Loss: 0.06863995248365194 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.014877407261255112\n",
      "SNR: 30/30, LS+LI, Epoch 2/50, Loss: 0.018095683766702234 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0036920072955333376\n",
      "SNR: 30/30, LS+LI, Epoch 3/50, Loss: 0.010816084632520066 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0021667038355107334\n",
      "SNR: 30/30, LS+LI, Epoch 4/50, Loss: 0.008783831797150332 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0018781087340109727\n",
      "SNR: 30/30, LS+LI, Epoch 5/50, Loss: 0.007514858190620015 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0014381026214157994\n",
      "SNR: 30/30, LS+LI, Epoch 6/50, Loss: 0.006575577854460409 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0011750624954319474\n",
      "SNR: 30/30, LS+LI, Epoch 7/50, Loss: 0.00585789791427466 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0009742666205221957\n",
      "SNR: 30/30, LS+LI, Epoch 8/50, Loss: 0.005416249442130847 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008132864075543529\n",
      "SNR: 30/30, LS+LI, Epoch 9/50, Loss: 0.004872276834862003 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008325385279022157\n",
      "SNR: 30/30, LS+LI, Epoch 10/50, Loss: 0.004609382808814908 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007900224141353233\n",
      "SNR: 30/30, LS+LI, Epoch 11/50, Loss: 0.004318110175095065 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005676927050279284\n",
      "SNR: 30/30, LS+LI, Epoch 12/50, Loss: 0.004115640495763009 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006050490417030894\n",
      "SNR: 30/30, LS+LI, Epoch 13/50, Loss: 0.003933667719667387 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005298395633210682\n",
      "SNR: 30/30, LS+LI, Epoch 14/50, Loss: 0.0037163801242185886 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00044406495660289443\n",
      "SNR: 30/30, LS+LI, Epoch 15/50, Loss: 0.003553916602720355 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006459605620792983\n",
      "SNR: 30/30, LS+LI, Epoch 16/50, Loss: 0.0034562299829409564 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00046550033254210246\n",
      "SNR: 30/30, LS+LI, Epoch 17/50, Loss: 0.00328628494685819 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000930566475620832\n",
      "SNR: 30/30, LS+LI, Epoch 18/50, Loss: 0.0033467064183855125 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00040302665332670915\n",
      "SNR: 30/30, LS+LI, Epoch 19/50, Loss: 0.0030734126813449832 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003327973522986709\n",
      "SNR: 30/30, LS+LI, Epoch 20/50, Loss: 0.0031197256026897838 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002966435779605738\n",
      "SNR: 30/30, LS+LI, Epoch 21/50, Loss: 0.002960052445455086 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00043360493013592946\n",
      "SNR: 30/30, LS+LI, Epoch 22/50, Loss: 0.00283056856972317 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005324863886926323\n",
      "SNR: 30/30, LS+LI, Epoch 23/50, Loss: 0.0027897096046809716 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002665249670495872\n",
      "SNR: 30/30, LS+LI, Epoch 24/50, Loss: 0.002747902420598494 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0013791681531901386\n",
      "SNR: 30/30, LS+LI, Epoch 25/50, Loss: 0.002835248961102564 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00033071775661400437\n",
      "SNR: 30/30, LS+LI, Epoch 26/50, Loss: 0.0026990562598870763 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003431890707526525\n",
      "SNR: 30/30, LS+LI, Epoch 27/50, Loss: 0.0025219727851732007 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00030906591762852094\n",
      "SNR: 30/30, LS+LI, Epoch 28/50, Loss: 0.0024653669693074083 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00022283339388774368\n",
      "SNR: 30/30, LS+LI, Epoch 29/50, Loss: 0.0024946803879534263 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003219896322909997\n",
      "SNR: 30/30, LS+LI, Epoch 30/50, Loss: 0.0023387493376165283 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007385141374966638\n",
      "SNR: 30/30, LS+LI, Epoch 31/50, Loss: 0.0024675729421920383 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004039006228347055\n",
      "SNR: 30/30, LS+LI, Epoch 32/50, Loss: 0.0023438993802153353 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004064566323491321\n",
      "SNR: 30/30, LS+LI, Epoch 33/50, Loss: 0.002222498066636712 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004303213235371831\n",
      "SNR: 30/30, LS+LI, Epoch 34/50, Loss: 0.002282368059833209 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002896547984247181\n",
      "SNR: 30/30, LS+LI, Epoch 35/50, Loss: 0.0022278463103819293 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00030294879583049226\n",
      "SNR: 30/30, LS+LI, Epoch 36/50, Loss: 0.002163412597647673 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005136762814469297\n",
      "SNR: 30/30, LS+LI, Epoch 37/50, Loss: 0.0021546514221564544 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0001882722082717175\n",
      "SNR: 30/30, LS+LI, Epoch 38/50, Loss: 0.0020849955299338543 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0003297408283370632\n",
      "SNR: 30/30, LS+LI, Epoch 39/50, Loss: 0.0021916546311965862 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006479466656773267\n",
      "SNR: 30/30, LS+LI, Epoch 40/50, Loss: 0.002038876522673554 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00022978165427709675\n",
      "SNR: 30/30, LS+LI, Epoch 41/50, Loss: 0.002011038762311516 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00017964045202296057\n",
      "SNR: 30/30, LS+LI, Epoch 42/50, Loss: 0.0019943916156270735 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004511327649445527\n",
      "SNR: 30/30, LS+LI, Epoch 43/50, Loss: 0.0019903656299669987 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00019721348508028314\n",
      "SNR: 30/30, LS+LI, Epoch 44/50, Loss: 0.0019535526293492336 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002299628441423093\n",
      "SNR: 30/30, LS+LI, Epoch 45/50, Loss: 0.0019377124242668667 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008626611696937206\n",
      "SNR: 30/30, LS+LI, Epoch 46/50, Loss: 0.001881829888673586 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00020057119995313272\n",
      "SNR: 30/30, LS+LI, Epoch 47/50, Loss: 0.0019131406375510228 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002468146320263093\n",
      "SNR: 30/30, LS+LI, Epoch 48/50, Loss: 0.0019629489932328375 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0010809949652122502\n",
      "SNR: 30/30, LS+LI, Epoch 49/50, Loss: 0.0018740058077910786 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000298825677336109\n",
      "SNR: 30/30, LS+LI, Epoch 50/50, Loss: 0.0018158386147386113 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00018064104832857\n",
      "LI+NN NMSE: 0.0005085369339212775\n",
      "LS+LI NMSE: 8.368714043172076e-05\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/50, Loss: 0.27305415060457794 \n",
      "SNR: 30/30, LS, Val Loss: 0.13425091992725025\n",
      "SNR: 30/30, LS, Epoch 2/50, Loss: 0.02785103703405015 \n",
      "SNR: 30/30, LS, Val Loss: 0.006165686941874976\n",
      "SNR: 30/30, LS, Epoch 3/50, Loss: 0.006113379106716102 \n",
      "SNR: 30/30, LS, Val Loss: 0.004175125536593524\n",
      "SNR: 30/30, LS, Epoch 4/50, Loss: 0.005122963998325949 \n",
      "SNR: 30/30, LS, Val Loss: 0.0040069208162921395\n",
      "SNR: 30/30, LS, Epoch 5/50, Loss: 0.004519517613347446 \n",
      "SNR: 30/30, LS, Val Loss: 0.0031855155142362823\n",
      "SNR: 30/30, LS, Epoch 6/50, Loss: 0.00428321705670854 \n",
      "SNR: 30/30, LS, Val Loss: 0.002830704293129119\n",
      "SNR: 30/30, LS, Epoch 7/50, Loss: 0.004071896386787642 \n",
      "SNR: 30/30, LS, Val Loss: 0.0027724833132445133\n",
      "SNR: 30/30, LS, Epoch 8/50, Loss: 0.003781267621169993 \n",
      "SNR: 30/30, LS, Val Loss: 0.003246505014513704\n",
      "SNR: 30/30, LS, Epoch 9/50, Loss: 0.003574653819669038 \n",
      "SNR: 30/30, LS, Val Loss: 0.0023396564012562685\n",
      "SNR: 30/30, LS, Epoch 10/50, Loss: 0.00350763883338808 \n",
      "SNR: 30/30, LS, Val Loss: 0.0019796843831004067\n",
      "SNR: 30/30, LS, Epoch 11/50, Loss: 0.00322860156234657 \n",
      "SNR: 30/30, LS, Val Loss: 0.001826849538536573\n",
      "SNR: 30/30, LS, Epoch 12/50, Loss: 0.0032444375521113534 \n",
      "SNR: 30/30, LS, Val Loss: 0.0020531116116961293\n",
      "SNR: 30/30, LS, Epoch 13/50, Loss: 0.0034558216785351465 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016756973822008479\n",
      "SNR: 30/30, LS, Epoch 14/50, Loss: 0.003106590033492593 \n",
      "SNR: 30/30, LS, Val Loss: 0.0017943908301690085\n",
      "SNR: 30/30, LS, Epoch 15/50, Loss: 0.0029204418222138354 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016477164780636403\n",
      "SNR: 30/30, LS, Epoch 16/50, Loss: 0.003139083123451835 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014672876356846907\n",
      "SNR: 30/30, LS, Epoch 17/50, Loss: 0.0030400115782719885 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013480336823373693\n",
      "SNR: 30/30, LS, Epoch 18/50, Loss: 0.002705649275137761 \n",
      "SNR: 30/30, LS, Val Loss: 0.001422992063453421\n",
      "SNR: 30/30, LS, Epoch 19/50, Loss: 0.002921185053500542 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016034384448589249\n",
      "SNR: 30/30, LS, Epoch 20/50, Loss: 0.0025620282482799834 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012765415462622927\n",
      "SNR: 30/30, LS, Epoch 21/50, Loss: 0.002906014084231195 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011745686828031796\n",
      "SNR: 30/30, LS, Epoch 22/50, Loss: 0.002776847911327211 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012152287394697355\n",
      "SNR: 30/30, LS, Epoch 23/50, Loss: 0.002707988246436079 \n",
      "SNR: 30/30, LS, Val Loss: 0.0017586891930973666\n",
      "SNR: 30/30, LS, Epoch 24/50, Loss: 0.002821800519636464 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011994825459127737\n",
      "SNR: 30/30, LS, Epoch 25/50, Loss: 0.0026854551549551488 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011080682955004952\n",
      "SNR: 30/30, LS, Epoch 26/50, Loss: 0.0025530057890898396 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013210804476826029\n",
      "SNR: 30/30, LS, Epoch 27/50, Loss: 0.002842730298695198 \n",
      "SNR: 30/30, LS, Val Loss: 0.0017579966595142403\n",
      "SNR: 30/30, LS, Epoch 28/50, Loss: 0.002660584412339187 \n",
      "SNR: 30/30, LS, Val Loss: 0.00135178489621136\n",
      "SNR: 30/30, LS, Epoch 29/50, Loss: 0.002563664735346318 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013186774766919289\n",
      "SNR: 30/30, LS, Epoch 30/50, Loss: 0.0024368230962102454 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010781629085117443\n",
      "SNR: 30/30, LS, Epoch 31/50, Loss: 0.0023551080995212244 \n",
      "SNR: 30/30, LS, Val Loss: 0.0013509606625038114\n",
      "SNR: 30/30, LS, Epoch 32/50, Loss: 0.002699973643418986 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010545288360762324\n",
      "SNR: 30/30, LS, Epoch 33/50, Loss: 0.0027081809720013636 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011015369223473085\n",
      "SNR: 30/30, LS, Epoch 34/50, Loss: 0.002850428758985038 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012433834331618114\n",
      "SNR: 30/30, LS, Epoch 35/50, Loss: 0.002459377408444578 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009432537137234414\n",
      "SNR: 30/30, LS, Epoch 36/50, Loss: 0.002685378973310012 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012693705979141998\n",
      "SNR: 30/30, LS, Epoch 37/50, Loss: 0.0025795180994210506 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008310174426614222\n",
      "SNR: 30/30, LS, Epoch 38/50, Loss: 0.0025850134508462277 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008994760282803327\n",
      "SNR: 30/30, LS, Epoch 39/50, Loss: 0.0024469463780067515 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008396506335967305\n",
      "SNR: 30/30, LS, Epoch 40/50, Loss: 0.0022449467306128205 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008031228525479409\n",
      "SNR: 30/30, LS, Epoch 41/50, Loss: 0.0023662390720050478 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008113971932537177\n",
      "SNR: 30/30, LS, Epoch 42/50, Loss: 0.002409799538179149 \n",
      "SNR: 30/30, LS, Val Loss: 0.0007803060712335123\n",
      "SNR: 30/30, LS, Epoch 43/50, Loss: 0.0025230673118765185 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008592632683840665\n",
      "SNR: 30/30, LS, Epoch 44/50, Loss: 0.002435831461700091 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010285093210933899\n",
      "SNR: 30/30, LS, Epoch 45/50, Loss: 0.0021887295300731177 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010075086214452642\n",
      "SNR: 30/30, LS, Epoch 46/50, Loss: 0.002436475356537199 \n",
      "SNR: 30/30, LS, Val Loss: 0.000910733725917949\n",
      "SNR: 30/30, LS, Epoch 47/50, Loss: 0.0021939636573606973 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008370603159578009\n",
      "SNR: 30/30, LS, Epoch 48/50, Loss: 0.0023861139587012963 \n",
      "SNR: 30/30, LS, Val Loss: 0.001233423279534856\n",
      "SNR: 30/30, LS, Epoch 49/50, Loss: 0.00229831938130976 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008628346311690456\n",
      "SNR: 30/30, LS, Epoch 50/50, Loss: 0.0022228861976885993 \n",
      "SNR: 30/30, LS, Val Loss: 0.0008671873550735075\n",
      "LS+LI NMSE: 0.0024109836667776108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                    # of valLabels\n",
    "        # train_loader, val_loader are already normalized by their own min, max\n",
    "        # scale to range [0 1]\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    \n",
    "    nmse_LI_NN = utils.calNMSE(H_val_NN_denormd_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu().mean()\n",
    "    nmse_LI_NN_val.append(variables['NMSE_LI_NN'].item())\n",
    "    print(f\"LI+NN NMSE: {variables['NMSE_LI_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN[-1], index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "#####\n",
    "##### above is LS+LI+NN \n",
    "\n",
    "##### following is Linear interpolated channel (only LS+LI)\n",
    "    H_val_linInterp = H_linear_val.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI'] = nmse_LI.cpu().mean()\n",
    "    nmse_LS_LI_val.append(variables['NMSE_LI'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LI'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI[-1], index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    H_LS_train = H_equal_train.cpu()\n",
    "    plotfig.figTrueChan(H_LS_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est(dropOut=0, act =CNN_activation).to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = utils.calNMSE(H_val_LS_NN_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu().mean()\n",
    "    nmse_LS_NN_val.append(variables['NMSE_LS_NN'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LS_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN[-1], index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver16_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+NN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+NN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(save_folder_fig, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n",
    "\n",
    "nmse_compare ={\n",
    "    'nmse_LS_LI_val': nmse_LS_LI_val, \n",
    "    'nmse_LS_NN_val':nmse_LS_NN_val, \n",
    "    'nmse_LI_NN_val':nmse_LI_NN_val\n",
    "}\n",
    "torch.save( nmse_compare, os.path.join(save_folder_fig, 'NMSE.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver16_/NMSE2.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+NN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE2.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE2.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
