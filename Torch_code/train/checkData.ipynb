{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 0\n",
    "BATCH_SIZE = 32\n",
    "rows = [['3500', '3516']] \n",
    "H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_'+ fc +'_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "    file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "    file_path = os.path.normpath(file_path)\n",
    "    file = h5py.File(file_path, 'r')\n",
    "\n",
    "    H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "    H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "    H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "    H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min data -2.763166048680432e-05\n",
      "max data 2.7671640054904856e-05\n",
      "mean data  6.890068043088681e-09\n",
      "min abs data  3.865352482534945e-12\n",
      "max abs data  2.7671640054904856e-05\n"
     ]
    }
   ],
   "source": [
    "print('min data' , np.min(H_true))\n",
    "print('max data' , np.max(H_true))\n",
    "print('mean data ', np.mean(H_true))\n",
    "print('min abs data ', np.min(np.abs(H_true)))\n",
    "print('max abs data ', np.max(np.abs(H_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS+LI\n"
     ]
    }
   ],
   "source": [
    "train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "train_size = int(train_size)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. When input is H_linear (after LS+LI)\n",
    "print(f\" Training for LS+LI\")\n",
    "# [samples, 2, 612, 14]\n",
    "# 1.1 Split into training and validation sets for H_NN training\n",
    "trainData   = H_linear[0:train_size,:,:,:]\n",
    "trainLabels = H_true[0:train_size,:,:,:]\n",
    "\n",
    "valData   = H_linear[train_size:,:,:,:]\n",
    "valLabels = H_true[train_size:,:,:,:]\n",
    "\n",
    "# Split H_equal, H_linear, H_practical for validation later\n",
    "H_equal_val = H_equal[train_size:,:,:,:]\n",
    "H_linear_val = H_linear[train_size:,:,:,:]\n",
    "H_practical_val = H_practical[train_size:,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: (min-max scaling) range [0 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating data also gets normalized by max_min of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training normalization\n",
    "trainData_min = trainData.min()\n",
    "trainData_max = trainData.max()\n",
    "trainLabels_min = trainLabels.min()\n",
    "trainLabels_max = trainLabels.max()\n",
    "\n",
    "trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  0.0\n",
      "max nomrd train  1.0\n",
      "mean nomrd train  0.4997292828098262\n",
      "min abs nomrd train  0.0\n",
      "max abs nomrd train  1.0\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train ' , np.min(trainLabels_normd))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation  0.0023010980613262814\n",
      "max nomrd validation  0.9989782691760117\n",
      "mean nomrd validation  0.5000497336187739\n",
      "min abs nomrd validation  0.0023010980613262814\n",
      "max abs nomrd validation  0.9989782691760117\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd validation ' , np.min(valLabels_normd))\n",
    "print('max nomrd validation ' , np.max(valLabels_normd))\n",
    "print('mean nomrd validation ', np.mean(valLabels_normd))\n",
    "print('min abs nomrd validation ', np.min(np.abs(valLabels_normd)))\n",
    "print('max abs nomrd validation ', np.max(np.abs(valLabels_normd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: (min-max scaling) range [-1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_normd2   = (trainData - trainData_min)/ (trainData_max - trainData_min) *2 - 1\n",
    "trainLabels_normd2 = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min) *2 - 1\n",
    "valData_normd2     = (valData - trainData_min)/ (trainData_max - trainData_min) *2 - 1\n",
    "valLabels_normd2   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min) *2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  -1.0\n",
      "max nomrd train  1.0\n",
      "mean nomrd train  -0.0005414343803454471\n",
      "min abs nomrd train  4.316964030692816e-08\n",
      "max abs nomrd train  1.0\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train ' , np.min(trainLabels_normd2))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd2))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd2))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd2)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation  -0.9953978038773474\n",
      "max nomrd validation  0.9979565383520235\n",
      "mean nomrd validation  9.946723754790591e-05\n",
      "min abs nomrd validation  8.901168692121431e-07\n",
      "max abs nomrd validation  0.9979565383520235\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd validation ' , np.min(valLabels_normd2))\n",
    "print('max nomrd validation ' , np.max(valLabels_normd2))\n",
    "print('mean nomrd validation ', np.mean(valLabels_normd2))\n",
    "print('min abs nomrd validation ', np.min(np.abs(valLabels_normd2)))\n",
    "print('max abs nomrd validation ', np.max(np.abs(valLabels_normd2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation 1  -0.37007745636651224\n",
      "max nomrd validation 1  0.3666743730641706\n",
      "mean nomrd validation 1  0.01144091171114728\n",
      "min abs nomrd validation 1  0.00017454205069966644\n",
      "max abs nomrd validation 1  0.37007745636651224\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train 1 ' , np.min(trainLabels_normd2[1,:,:,:]))\n",
    "print('max nomrd train 1 ' , np.max(trainLabels_normd2[1,:,:,:]))\n",
    "print('mean nomrd train 1 ', np.mean(trainLabels_normd2[1,:,:,:]))\n",
    "print('min abs nomrd train 1 ', np.min(np.abs(trainLabels_normd2[1,:,:,:])))\n",
    "print('max abs nomrd train 1 ', np.max(np.abs(trainLabels_normd2[1,:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation 100  -0.39982342712607843\n",
      "max nomrd validation 100  0.39510213213291134\n",
      "mean nomrd validation 100  -0.006273588457452051\n",
      "min abs nomrd validation 100  0.0004005721202535728\n",
      "max abs nomrd validation 100  0.39982342712607843\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train 100 ' , np.min(trainLabels_normd2[100,:,:,:]))\n",
    "print('max nomrd train 100 ' , np.max(trainLabels_normd2[100,:,:,:]))\n",
    "print('mean nomrd train 100 ', np.mean(trainLabels_normd2[100,:,:,:]))\n",
    "print('min abs nomrd train 100 ', np.min(np.abs(trainLabels_normd2[100,:,:,:])))\n",
    "print('max abs nomrd train 100 ', np.max(np.abs(trainLabels_normd2[100,:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation 500  -0.2806238110053211\n",
      "max nomrd validation 500  0.27837550324699833\n",
      "mean nomrd validation 500  0.00254815752903729\n",
      "min abs nomrd validation 500  0.0004748537091898708\n",
      "max abs nomrd validation 500  0.2806238110053211\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train 500 ' , np.min(trainLabels_normd2[500,:,:,:]))\n",
    "print('max nomrd train 500 ' , np.max(trainLabels_normd2[500,:,:,:]))\n",
    "print('mean nomrd train 500 ', np.mean(trainLabels_normd2[500,:,:,:]))\n",
    "print('min abs nomrd train 500 ', np.min(np.abs(trainLabels_normd2[500,:,:,:])))\n",
    "print('max abs nomrd train 500 ', np.max(np.abs(trainLabels_normd2[500,:,:,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Instance normalization, Range [-1 1] (min-max scaling) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instance norm for H_LI \n",
    "* Instance norm for H_true\n",
    "* Train H_LI_normed to get H_true_normed, then denorm to get H_true, then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min = []\n",
    "train_max = []\n",
    "trainLabels_normd3 = np.empty((trainLabels.shape[0], 2, 612, 14))\n",
    "\n",
    "for i in range(trainLabels.shape[0]):\n",
    "    sample = trainLabels[i]\n",
    "    \n",
    "    # Compute mean and variance for the current sample\n",
    "    min = sample.min()\n",
    "    max = sample.max()\n",
    "    \n",
    "    trainLabels_normd3[i,:,:,:] = (sample - min) / (max - min) *2 -1\n",
    "\n",
    "    # Append to lists\n",
    "    train_min.append(min.item())\n",
    "    train_max.append(max.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  -1.0\n",
      "max nomrd train  1.0\n",
      "mean nomrd train  -0.0005734639920682292\n",
      "min abs nomrd train  4.4367372198372834e-07\n",
      "max abs nomrd train  1.0\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train ' , np.min(trainLabels_normd3))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd3))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd3))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd3)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproach 4: Instance normalization, (standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = []\n",
    "train_var = []\n",
    "trainLabels_normd4 = np.empty((trainLabels.shape[0], 2, 612, 14))\n",
    "\n",
    "for i in range(trainLabels.shape[0]):\n",
    "    sample = trainLabels[i]\n",
    "    \n",
    "    # Compute mean and variance for the current sample\n",
    "    mean = sample.mean()\n",
    "    variance = sample.var()\n",
    "    \n",
    "    trainLabels_normd4[i,:,:,:] = (sample - mean) / np.sqrt(variance)\n",
    "    \n",
    "    # Append to lists\n",
    "    train_mean.append(mean.item())\n",
    "    train_var.append(variance.item())\n",
    "\n",
    "# # Convert lists to tensors or numpy arrays if needed\n",
    "# means = torch.tensor(means)\n",
    "# variances = torch.tensor(variances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  -2.7031298970480138\n",
      "max nomrd train  2.6884923172900796\n",
      "mean nomrd train  5.568834140846658e-19\n",
      "min abs nomrd train  3.720750786702688e-07\n",
      "max abs nomrd train  2.7031298970480138\n"
     ]
    }
   ],
   "source": [
    "trainLabels_normd4.shape\n",
    "\n",
    "print('min nomrd train ' , np.min(trainLabels_normd4))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd4))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd4))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd4)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd4)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
