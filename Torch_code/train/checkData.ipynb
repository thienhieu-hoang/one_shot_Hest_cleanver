{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 0\n",
    "BATCH_SIZE = 32\n",
    "rows = [['3500', '3516']] \n",
    "H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_'+ fc +'_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "    file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "    file_path = os.path.normpath(file_path)\n",
    "    file = h5py.File(file_path, 'r')\n",
    "\n",
    "    H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "    H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "    H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "    H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min data -2.763166048680432e-05\n",
      "max data 2.7671640054904856e-05\n",
      "mean data  6.890068043088681e-09\n",
      "min abs data  3.865352482534945e-12\n",
      "max abs data  2.7671640054904856e-05\n"
     ]
    }
   ],
   "source": [
    "print('min data' , np.min(H_true))\n",
    "print('max data' , np.max(H_true))\n",
    "print('mean data ', np.mean(H_true))\n",
    "print('min abs data ', np.min(np.abs(H_true)))\n",
    "print('max abs data ', np.max(np.abs(H_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS+LI\n"
     ]
    }
   ],
   "source": [
    "train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "train_size = int(train_size)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. When input is H_linear (after LS+LI)\n",
    "print(f\" Training for LS+LI\")\n",
    "# [samples, 2, 612, 14]\n",
    "# 1.1 Split into training and validation sets for H_NN training\n",
    "trainData   = H_linear[0:train_size,:,:,:]\n",
    "trainLabels = H_true[0:train_size,:,:,:]\n",
    "\n",
    "valData   = H_linear[train_size:,:,:,:]\n",
    "valLabels = H_true[train_size:,:,:,:]\n",
    "\n",
    "# Split H_equal, H_linear, H_practical for validation later\n",
    "H_equal_val = H_equal[train_size:,:,:,:]\n",
    "H_linear_val = H_linear[train_size:,:,:,:]\n",
    "H_practical_val = H_practical[train_size:,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: range [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training normalization\n",
    "trainData_min = trainData.min()\n",
    "trainData_max = trainData.max()\n",
    "trainLabels_min = trainLabels.min()\n",
    "trainLabels_max = trainLabels.max()\n",
    "\n",
    "trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  0.0\n",
      "max nomrd train  1.0\n",
      "mean nomrd train  0.4997292828098262\n",
      "min abs nomrd train  0.0\n",
      "max abs nomrd train  1.0\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train ' , np.min(trainLabels_normd))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation  0.0023010980613262814\n",
      "max nomrd validation  0.9989782691760117\n",
      "mean nomrd validation  0.5000497336187739\n",
      "min abs nomrd validation  0.0023010980613262814\n",
      "max abs nomrd validation  0.9989782691760117\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd validation ' , np.min(valLabels_normd))\n",
    "print('max nomrd validation ' , np.max(valLabels_normd))\n",
    "print('mean nomrd validation ', np.mean(valLabels_normd))\n",
    "print('min abs nomrd validation ', np.min(np.abs(valLabels_normd)))\n",
    "print('max abs nomrd validation ', np.max(np.abs(valLabels_normd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: range [-1 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_normd2   = (trainData - trainData_min)/ (trainData_max - trainData_min) *2 - 1\n",
    "trainLabels_normd2 = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min) *2 - 1\n",
    "valData_normd2     = (valData - trainData_min)/ (trainData_max - trainData_min) *2 - 1\n",
    "valLabels_normd2   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min) *2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd train  -1.0\n",
      "max nomrd train  1.0\n",
      "mean nomrd train  -0.0005414343803454471\n",
      "min abs nomrd train  4.316964030692816e-08\n",
      "max abs nomrd train  1.0\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd train ' , np.min(trainLabels_normd2))\n",
    "print('max nomrd train ' , np.max(trainLabels_normd2))\n",
    "print('mean nomrd train ', np.mean(trainLabels_normd2))\n",
    "print('min abs nomrd train ', np.min(np.abs(trainLabels_normd2)))\n",
    "print('max abs nomrd train ', np.max(np.abs(trainLabels_normd2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min nomrd validation  -0.9953978038773474\n",
      "max nomrd validation  0.9979565383520235\n",
      "mean nomrd validation  9.946723754790591e-05\n",
      "min abs nomrd validation  8.901168692121431e-07\n",
      "max abs nomrd validation  0.9979565383520235\n"
     ]
    }
   ],
   "source": [
    "print('min nomrd validation ' , np.min(valLabels_normd2))\n",
    "print('max nomrd validation ' , np.max(valLabels_normd2))\n",
    "print('mean nomrd validation ', np.mean(valLabels_normd2))\n",
    "print('min abs nomrd validation ', np.min(np.abs(valLabels_normd2)))\n",
    "print('max abs nomrd validation ', np.max(np.abs(valLabels_normd2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
