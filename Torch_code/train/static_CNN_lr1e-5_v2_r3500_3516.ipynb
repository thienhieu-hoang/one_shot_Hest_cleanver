{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/20, Loss: 0.11895821045347771 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.028824803165414116\n",
      "SNR: 0/30, LS+LI, Epoch 2/20, Loss: 0.01611607915689346 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.008368831805207512\n",
      "SNR: 0/30, LS+LI, Epoch 3/20, Loss: 0.0047312814919657055 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0018101574810729785\n",
      "SNR: 0/30, LS+LI, Epoch 4/20, Loss: 0.001225174238518162 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0008832931926008314\n",
      "SNR: 0/30, LS+LI, Epoch 5/20, Loss: 0.0006718975334458031 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.0005078371839110994\n",
      "SNR: 0/30, LS+LI, Epoch 6/20, Loss: 0.00042746389328047286 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00036026216614779764\n",
      "SNR: 0/30, LS+LI, Epoch 7/20, Loss: 0.0003186922365065859 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00027929320904976606\n",
      "SNR: 0/30, LS+LI, Epoch 8/20, Loss: 0.0002558394665166541 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00023486330345886844\n",
      "SNR: 0/30, LS+LI, Epoch 9/20, Loss: 0.0002242134275526718 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00021224705878094855\n",
      "SNR: 0/30, LS+LI, Epoch 10/20, Loss: 0.00020677640697063315 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00019733791520014745\n",
      "SNR: 0/30, LS+LI, Epoch 11/20, Loss: 0.00019165164790032322 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00018545301877152681\n",
      "SNR: 0/30, LS+LI, Epoch 12/20, Loss: 0.00018426021288601183 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00017866004517682913\n",
      "SNR: 0/30, LS+LI, Epoch 13/20, Loss: 0.00017700178038868998 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.000178506715614772\n",
      "SNR: 0/30, LS+LI, Epoch 14/20, Loss: 0.00017308930783169776 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016819780847237615\n",
      "SNR: 0/30, LS+LI, Epoch 15/20, Loss: 0.00016718031081329045 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016528857436655514\n",
      "SNR: 0/30, LS+LI, Epoch 16/20, Loss: 0.00016255044106084062 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016222292436974715\n",
      "SNR: 0/30, LS+LI, Epoch 17/20, Loss: 0.0001595292686160551 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00015669747484604488\n",
      "SNR: 0/30, LS+LI, Epoch 18/20, Loss: 0.00015671186025259843 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00016127985740736634\n",
      "SNR: 0/30, LS+LI, Epoch 19/20, Loss: 0.00015366650163635968 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00015055972868470815\n",
      "SNR: 0/30, LS+LI, Epoch 20/20, Loss: 0.0001500873271187058 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.00014990016345770775\n",
      "LS+LI NMSE: 0.08189645409584045\n",
      "LS+LI+CNN NMSE: 0.005609797779470682\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/20, Loss: 0.1284288362231712 \n",
      "SNR: 0/30, LS, Val Loss: 0.040068609809333626\n",
      "SNR: 0/30, LS, Epoch 2/20, Loss: 0.030123136829324933 \n",
      "SNR: 0/30, LS, Val Loss: 0.02463560966266827\n",
      "SNR: 0/30, LS, Epoch 3/20, Loss: 0.02327197660193887 \n",
      "SNR: 0/30, LS, Val Loss: 0.021902506324377926\n",
      "SNR: 0/30, LS, Epoch 4/20, Loss: 0.019218994304537773 \n",
      "SNR: 0/30, LS, Val Loss: 0.015313944779336452\n",
      "SNR: 0/30, LS, Epoch 5/20, Loss: 0.009128783867412876 \n",
      "SNR: 0/30, LS, Val Loss: 0.003353158054365353\n",
      "SNR: 0/30, LS, Epoch 6/20, Loss: 0.0019013213689525633 \n",
      "SNR: 0/30, LS, Val Loss: 0.001285263448318636\n",
      "SNR: 0/30, LS, Epoch 7/20, Loss: 0.001054991724654534 \n",
      "SNR: 0/30, LS, Val Loss: 0.0008747392196462235\n",
      "SNR: 0/30, LS, Epoch 8/20, Loss: 0.000764558958783096 \n",
      "SNR: 0/30, LS, Val Loss: 0.0006671526630684225\n",
      "SNR: 0/30, LS, Epoch 9/20, Loss: 0.0005988247002553476 \n",
      "SNR: 0/30, LS, Val Loss: 0.000544203686083413\n",
      "SNR: 0/30, LS, Epoch 10/20, Loss: 0.0004971466041752137 \n",
      "SNR: 0/30, LS, Val Loss: 0.00046153039412191987\n",
      "SNR: 0/30, LS, Epoch 11/20, Loss: 0.0004388693636174985 \n",
      "SNR: 0/30, LS, Val Loss: 0.00041615614662243223\n",
      "SNR: 0/30, LS, Epoch 12/20, Loss: 0.0004060284025103482 \n",
      "SNR: 0/30, LS, Val Loss: 0.00037858883892609316\n",
      "SNR: 0/30, LS, Epoch 13/20, Loss: 0.0003719845756910048 \n",
      "SNR: 0/30, LS, Val Loss: 0.00037573272658681327\n",
      "SNR: 0/30, LS, Epoch 14/20, Loss: 0.0003470081940386715 \n",
      "SNR: 0/30, LS, Val Loss: 0.00034056881320959127\n",
      "SNR: 0/30, LS, Epoch 15/20, Loss: 0.00033136106461359644 \n",
      "SNR: 0/30, LS, Val Loss: 0.000321380440172189\n",
      "SNR: 0/30, LS, Epoch 16/20, Loss: 0.00032140728259502454 \n",
      "SNR: 0/30, LS, Val Loss: 0.00031188274442683905\n",
      "SNR: 0/30, LS, Epoch 17/20, Loss: 0.0003083849990426368 \n",
      "SNR: 0/30, LS, Val Loss: 0.00029798940853321585\n",
      "SNR: 0/30, LS, Epoch 18/20, Loss: 0.00030049049035919465 \n",
      "SNR: 0/30, LS, Val Loss: 0.0002904411362992092\n",
      "SNR: 0/30, LS, Epoch 19/20, Loss: 0.0002947537187685876 \n",
      "SNR: 0/30, LS, Val Loss: 0.000283742176014295\n",
      "SNR: 0/30, LS, Epoch 20/20, Loss: 0.0002877057721529719 \n",
      "SNR: 0/30, LS, Val Loss: 0.00027661003299396145\n",
      "LS+CNN NMSE: 0.010445776395499706\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/20, Loss: 0.10964159447656469 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.025917127813127907\n",
      "SNR: 5/30, LS+LI, Epoch 2/20, Loss: 0.013058680892098955 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0028099664381112566\n",
      "SNR: 5/30, LS+LI, Epoch 3/20, Loss: 0.0012707992211162915 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.000705633362734013\n",
      "SNR: 5/30, LS+LI, Epoch 4/20, Loss: 0.0006003221779517548 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00046024140399161047\n",
      "SNR: 5/30, LS+LI, Epoch 5/20, Loss: 0.0003917851183444348 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0003033690379445695\n",
      "SNR: 5/30, LS+LI, Epoch 6/20, Loss: 0.0002509857719793894 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.00018574648460013452\n",
      "SNR: 5/30, LS+LI, Epoch 7/20, Loss: 0.0001620507920411318 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.000130712796156083\n",
      "SNR: 5/30, LS+LI, Epoch 8/20, Loss: 0.00012400919352563336 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.0001075512138248252\n",
      "SNR: 5/30, LS+LI, Epoch 9/20, Loss: 0.00010680511196517538 \n",
      "SNR: 5/30, LS+LI, Val Loss: 9.455819831187414e-05\n",
      "SNR: 5/30, LS+LI, Epoch 10/20, Loss: 9.583415568306729e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 8.810224575096403e-05\n",
      "SNR: 5/30, LS+LI, Epoch 11/20, Loss: 8.77450977494063e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 7.92016805710525e-05\n",
      "SNR: 5/30, LS+LI, Epoch 12/20, Loss: 8.160744115695368e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 7.365630501061042e-05\n",
      "SNR: 5/30, LS+LI, Epoch 13/20, Loss: 7.602176296935542e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 7.146027316842016e-05\n",
      "SNR: 5/30, LS+LI, Epoch 14/20, Loss: 7.203635708043125e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 6.520752537074837e-05\n",
      "SNR: 5/30, LS+LI, Epoch 15/20, Loss: 6.759479854440014e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 6.140418141016694e-05\n",
      "SNR: 5/30, LS+LI, Epoch 16/20, Loss: 6.453617985497722e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.8864753803143024e-05\n",
      "SNR: 5/30, LS+LI, Epoch 17/20, Loss: 6.197707684910964e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.550052446778864e-05\n",
      "SNR: 5/30, LS+LI, Epoch 18/20, Loss: 5.875610470464507e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.490620887113354e-05\n",
      "SNR: 5/30, LS+LI, Epoch 19/20, Loss: 5.6577290896986895e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 5.119828810248609e-05\n",
      "SNR: 5/30, LS+LI, Epoch 20/20, Loss: 5.450667123473385e-05 \n",
      "SNR: 5/30, LS+LI, Val Loss: 4.974631470262962e-05\n",
      "LS+LI NMSE: 0.025822140276432037\n",
      "LS+LI+CNN NMSE: 0.0020194079261273146\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/20, Loss: 0.0917211077717501 \n",
      "SNR: 5/30, LS, Val Loss: 0.030019776218316772\n",
      "SNR: 5/30, LS, Epoch 2/20, Loss: 0.025839542894255975 \n",
      "SNR: 5/30, LS, Val Loss: 0.02180793856016614\n",
      "SNR: 5/30, LS, Epoch 3/20, Loss: 0.021397464193923528 \n",
      "SNR: 5/30, LS, Val Loss: 0.01667149652811614\n",
      "SNR: 5/30, LS, Epoch 4/20, Loss: 0.011909417401955918 \n",
      "SNR: 5/30, LS, Val Loss: 0.004628067232922397\n",
      "SNR: 5/30, LS, Epoch 5/20, Loss: 0.0020601662477548774 \n",
      "SNR: 5/30, LS, Val Loss: 0.0009270450311966918\n",
      "SNR: 5/30, LS, Epoch 6/20, Loss: 0.0008642719547551256 \n",
      "SNR: 5/30, LS, Val Loss: 0.0007031771198274906\n",
      "SNR: 5/30, LS, Epoch 7/20, Loss: 0.0006628526874877469 \n",
      "SNR: 5/30, LS, Val Loss: 0.0005462034221802077\n",
      "SNR: 5/30, LS, Epoch 8/20, Loss: 0.0005064250855316776 \n",
      "SNR: 5/30, LS, Val Loss: 0.0004085587517527694\n",
      "SNR: 5/30, LS, Epoch 9/20, Loss: 0.000397168944568135 \n",
      "SNR: 5/30, LS, Val Loss: 0.0003360385956263847\n",
      "SNR: 5/30, LS, Epoch 10/20, Loss: 0.00032537550764255834 \n",
      "SNR: 5/30, LS, Val Loss: 0.00029768980510363525\n",
      "SNR: 5/30, LS, Epoch 11/20, Loss: 0.0002797741004161613 \n",
      "SNR: 5/30, LS, Val Loss: 0.0002463311307523823\n",
      "SNR: 5/30, LS, Epoch 12/20, Loss: 0.0002515633660910088 \n",
      "SNR: 5/30, LS, Val Loss: 0.0002213277555049651\n",
      "SNR: 5/30, LS, Epoch 13/20, Loss: 0.00023515098663940377 \n",
      "SNR: 5/30, LS, Val Loss: 0.00020991029305150732\n",
      "SNR: 5/30, LS, Epoch 14/20, Loss: 0.0002213360887761282 \n",
      "SNR: 5/30, LS, Val Loss: 0.0001959872391704597\n",
      "SNR: 5/30, LS, Epoch 15/20, Loss: 0.00021100751668157945 \n",
      "SNR: 5/30, LS, Val Loss: 0.000217587192971471\n",
      "SNR: 5/30, LS, Epoch 16/20, Loss: 0.00019948646318922793 \n",
      "SNR: 5/30, LS, Val Loss: 0.00019251448512394828\n",
      "SNR: 5/30, LS, Epoch 17/20, Loss: 0.00019159593428539243 \n",
      "SNR: 5/30, LS, Val Loss: 0.0001824825297014534\n",
      "SNR: 5/30, LS, Epoch 18/20, Loss: 0.0001846597928264135 \n",
      "SNR: 5/30, LS, Val Loss: 0.00016568626365783118\n",
      "SNR: 5/30, LS, Epoch 19/20, Loss: 0.0001788724011719243 \n",
      "SNR: 5/30, LS, Val Loss: 0.00016750969900220463\n",
      "SNR: 5/30, LS, Epoch 20/20, Loss: 0.0001746584373397 \n",
      "SNR: 5/30, LS, Val Loss: 0.00015740754249484533\n",
      "LS+CNN NMSE: 0.006412005051970482\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/20, Loss: 0.14374367895990955 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.023084568367763\n",
      "SNR: 10/30, LS+LI, Epoch 2/20, Loss: 0.009851778451986827 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.001644259175836024\n",
      "SNR: 10/30, LS+LI, Epoch 3/20, Loss: 0.0008152790202117569 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.000549057302784852\n",
      "SNR: 10/30, LS+LI, Epoch 4/20, Loss: 0.0003984626612712651 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00033297198586462235\n",
      "SNR: 10/30, LS+LI, Epoch 5/20, Loss: 0.00024369780649701782 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00019123978100568903\n",
      "SNR: 10/30, LS+LI, Epoch 6/20, Loss: 0.00014321039867185348 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00012163779452252625\n",
      "SNR: 10/30, LS+LI, Epoch 7/20, Loss: 9.819133684200203e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 9.017951709789817e-05\n",
      "SNR: 10/30, LS+LI, Epoch 8/20, Loss: 7.584268528156573e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 7.246278718494895e-05\n",
      "SNR: 10/30, LS+LI, Epoch 9/20, Loss: 6.233036687220637e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 6.121067500234031e-05\n",
      "SNR: 10/30, LS+LI, Epoch 10/20, Loss: 5.3395382269098814e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 5.3412831799836234e-05\n",
      "SNR: 10/30, LS+LI, Epoch 11/20, Loss: 4.7239680476872475e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 4.773832948888991e-05\n",
      "SNR: 10/30, LS+LI, Epoch 12/20, Loss: 4.2464413592486294e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 4.339410886380144e-05\n",
      "SNR: 10/30, LS+LI, Epoch 13/20, Loss: 3.8666672649966596e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 4.015576517055954e-05\n",
      "SNR: 10/30, LS+LI, Epoch 14/20, Loss: 3.5428981571089404e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.659014510049019e-05\n",
      "SNR: 10/30, LS+LI, Epoch 15/20, Loss: 3.251053396186678e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.371668853188484e-05\n",
      "SNR: 10/30, LS+LI, Epoch 16/20, Loss: 2.9973741030242013e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 3.139016429155493e-05\n",
      "SNR: 10/30, LS+LI, Epoch 17/20, Loss: 2.7826168333863173e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.922515117957532e-05\n",
      "SNR: 10/30, LS+LI, Epoch 18/20, Loss: 2.590969443401771e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.785607069778383e-05\n",
      "SNR: 10/30, LS+LI, Epoch 19/20, Loss: 2.4487670966769908e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.6007713792999063e-05\n",
      "SNR: 10/30, LS+LI, Epoch 20/20, Loss: 2.3161223865361874e-05 \n",
      "SNR: 10/30, LS+LI, Val Loss: 2.4884706363081932e-05\n",
      "LS+LI NMSE: 0.008184215985238552\n",
      "LS+LI+CNN NMSE: 0.0008457059157080948\n",
      " Training for LS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5125/3903695496.py:257: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 10/30, LS, Epoch 1/20, Loss: 0.08870073418717744 \n",
      "SNR: 10/30, LS, Val Loss: 0.03713824523782188\n",
      "SNR: 10/30, LS, Epoch 2/20, Loss: 0.026212537639536137 \n",
      "SNR: 10/30, LS, Val Loss: 0.025147668763317844\n",
      "SNR: 10/30, LS, Epoch 3/20, Loss: 0.017816438009355996 \n",
      "SNR: 10/30, LS, Val Loss: 0.012766973115503788\n",
      "SNR: 10/30, LS, Epoch 4/20, Loss: 0.005080556277683828 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017316052795980465\n",
      "SNR: 10/30, LS, Epoch 5/20, Loss: 0.001071015641913576 \n",
      "SNR: 10/30, LS, Val Loss: 0.0009813189522405578\n",
      "SNR: 10/30, LS, Epoch 6/20, Loss: 0.0007273369180417598 \n",
      "SNR: 10/30, LS, Val Loss: 0.0006943588721862233\n",
      "SNR: 10/30, LS, Epoch 7/20, Loss: 0.0005453782798086163 \n",
      "SNR: 10/30, LS, Val Loss: 0.0005334418290823868\n",
      "SNR: 10/30, LS, Epoch 8/20, Loss: 0.0004240730721544106 \n",
      "SNR: 10/30, LS, Val Loss: 0.0004146795492322946\n",
      "SNR: 10/30, LS, Epoch 9/20, Loss: 0.0003302516252429192 \n",
      "SNR: 10/30, LS, Val Loss: 0.0003321465972641652\n",
      "SNR: 10/30, LS, Epoch 10/20, Loss: 0.00027333731393513897 \n",
      "SNR: 10/30, LS, Val Loss: 0.00027934235086749226\n",
      "SNR: 10/30, LS, Epoch 11/20, Loss: 0.00023472944109058982 \n",
      "SNR: 10/30, LS, Val Loss: 0.000244467250674709\n",
      "SNR: 10/30, LS, Epoch 12/20, Loss: 0.0002111026867147979 \n",
      "SNR: 10/30, LS, Val Loss: 0.00021996558577732438\n",
      "SNR: 10/30, LS, Epoch 13/20, Loss: 0.00019375840878807182 \n",
      "SNR: 10/30, LS, Val Loss: 0.0002267711123832586\n",
      "SNR: 10/30, LS, Epoch 14/20, Loss: 0.0001792223129298289 \n",
      "SNR: 10/30, LS, Val Loss: 0.00019191686376209626\n",
      "SNR: 10/30, LS, Epoch 15/20, Loss: 0.000166366057762156 \n",
      "SNR: 10/30, LS, Val Loss: 0.00017691749830687925\n",
      "SNR: 10/30, LS, Epoch 16/20, Loss: 0.00015776655003042663 \n",
      "SNR: 10/30, LS, Val Loss: 0.0001666287763245319\n",
      "SNR: 10/30, LS, Epoch 17/20, Loss: 0.00014713167086504887 \n",
      "SNR: 10/30, LS, Val Loss: 0.0001571951629144182\n",
      "SNR: 10/30, LS, Epoch 18/20, Loss: 0.00013997247473060607 \n",
      "SNR: 10/30, LS, Val Loss: 0.00014703871883367273\n",
      "SNR: 10/30, LS, Epoch 19/20, Loss: 0.00013445934526443612 \n",
      "SNR: 10/30, LS, Val Loss: 0.00013710732342918743\n",
      "SNR: 10/30, LS, Epoch 20/20, Loss: 0.00012226055615999855 \n",
      "SNR: 10/30, LS, Val Loss: 0.00013878866758948953\n",
      "LS+CNN NMSE: 0.004738396033644676\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/20, Loss: 0.08038163871699294 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0137215327386829\n",
      "SNR: 15/30, LS+LI, Epoch 2/20, Loss: 0.00451622172130196 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0007127374913331798\n",
      "SNR: 15/30, LS+LI, Epoch 3/20, Loss: 0.0005227137943472561 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00037844049537935376\n",
      "SNR: 15/30, LS+LI, Epoch 4/20, Loss: 0.00032211578345172606 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00024982806710547516\n",
      "SNR: 15/30, LS+LI, Epoch 5/20, Loss: 0.00020330435849203685 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0001400556185134602\n",
      "SNR: 15/30, LS+LI, Epoch 6/20, Loss: 0.00011201183287782844 \n",
      "SNR: 15/30, LS+LI, Val Loss: 8.261169039707801e-05\n",
      "SNR: 15/30, LS+LI, Epoch 7/20, Loss: 7.277557988557017e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 5.796449146476913e-05\n",
      "SNR: 15/30, LS+LI, Epoch 8/20, Loss: 5.1765391554211014e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 4.209343089976094e-05\n",
      "SNR: 15/30, LS+LI, Epoch 9/20, Loss: 3.8917715406823e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 3.246114887257466e-05\n",
      "SNR: 15/30, LS+LI, Epoch 10/20, Loss: 3.0767738566240486e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 2.6243168659592893e-05\n",
      "SNR: 15/30, LS+LI, Epoch 11/20, Loss: 2.530988242438599e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 2.18125865516909e-05\n",
      "SNR: 15/30, LS+LI, Epoch 12/20, Loss: 2.132612818841576e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.8546550770472756e-05\n",
      "SNR: 15/30, LS+LI, Epoch 13/20, Loss: 1.8030653643299322e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.5283239297952438e-05\n",
      "SNR: 15/30, LS+LI, Epoch 14/20, Loss: 1.5022607586552323e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.3127758599942105e-05\n",
      "SNR: 15/30, LS+LI, Epoch 15/20, Loss: 1.2909545915156973e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.1397167451253733e-05\n",
      "SNR: 15/30, LS+LI, Epoch 16/20, Loss: 1.1516716112118746e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 1.0350705617218575e-05\n",
      "SNR: 15/30, LS+LI, Epoch 17/20, Loss: 1.0545442105573128e-05 \n",
      "SNR: 15/30, LS+LI, Val Loss: 9.28062548733909e-06\n",
      "SNR: 15/30, LS+LI, Epoch 18/20, Loss: 9.7529971801419e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 8.713199866344274e-06\n",
      "SNR: 15/30, LS+LI, Epoch 19/20, Loss: 9.290006602874877e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 8.284782325063134e-06\n",
      "SNR: 15/30, LS+LI, Epoch 20/20, Loss: 8.76032153385939e-06 \n",
      "SNR: 15/30, LS+LI, Val Loss: 7.855698289528267e-06\n",
      "LS+LI NMSE: 0.0025866026990115643\n",
      "LS+LI+CNN NMSE: 0.00031707686139270663\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/20, Loss: 0.09628089968938121 \n",
      "SNR: 15/30, LS, Val Loss: 0.03257280164821581\n",
      "SNR: 15/30, LS, Epoch 2/20, Loss: 0.027028923886719833 \n",
      "SNR: 15/30, LS, Val Loss: 0.02242748320780017\n",
      "SNR: 15/30, LS, Epoch 3/20, Loss: 0.02219802607933796 \n",
      "SNR: 15/30, LS, Val Loss: 0.0181412510573864\n",
      "SNR: 15/30, LS, Epoch 4/20, Loss: 0.013050013072897009 \n",
      "SNR: 15/30, LS, Val Loss: 0.0048008689826185055\n",
      "SNR: 15/30, LS, Epoch 5/20, Loss: 0.001836469943491677 \n",
      "SNR: 15/30, LS, Val Loss: 0.0008289404028222303\n",
      "SNR: 15/30, LS, Epoch 6/20, Loss: 0.0007080835114953347 \n",
      "SNR: 15/30, LS, Val Loss: 0.0005394891843686557\n",
      "SNR: 15/30, LS, Epoch 7/20, Loss: 0.0004904960971840029 \n",
      "SNR: 15/30, LS, Val Loss: 0.00039074388570787215\n",
      "SNR: 15/30, LS, Epoch 8/20, Loss: 0.00036262481495044955 \n",
      "SNR: 15/30, LS, Val Loss: 0.0002958374746164984\n",
      "SNR: 15/30, LS, Epoch 9/20, Loss: 0.000280374536127648 \n",
      "SNR: 15/30, LS, Val Loss: 0.00023571073093493894\n",
      "SNR: 15/30, LS, Epoch 10/20, Loss: 0.00021868902170586637 \n",
      "SNR: 15/30, LS, Val Loss: 0.00018860540082889864\n",
      "SNR: 15/30, LS, Epoch 11/20, Loss: 0.00017055514378393297 \n",
      "SNR: 15/30, LS, Val Loss: 0.000143593392501564\n",
      "SNR: 15/30, LS, Epoch 12/20, Loss: 0.00014253955258788855 \n",
      "SNR: 15/30, LS, Val Loss: 0.00013795540276491508\n",
      "SNR: 15/30, LS, Epoch 13/20, Loss: 0.00012793033479389378 \n",
      "SNR: 15/30, LS, Val Loss: 0.00011349377878518267\n",
      "SNR: 15/30, LS, Epoch 14/20, Loss: 0.0001151315544882172 \n",
      "SNR: 15/30, LS, Val Loss: 0.00010473632408485918\n",
      "SNR: 15/30, LS, Epoch 15/20, Loss: 0.00010599135076031522 \n",
      "SNR: 15/30, LS, Val Loss: 0.00010088762329277498\n",
      "SNR: 15/30, LS, Epoch 16/20, Loss: 9.497874363956345e-05 \n",
      "SNR: 15/30, LS, Val Loss: 8.211747444875073e-05\n",
      "SNR: 15/30, LS, Epoch 17/20, Loss: 8.324744297613845e-05 \n",
      "SNR: 15/30, LS, Val Loss: 8.100376709824724e-05\n",
      "SNR: 15/30, LS, Epoch 18/20, Loss: 7.647498968740259e-05 \n",
      "SNR: 15/30, LS, Val Loss: 6.444743667088915e-05\n",
      "SNR: 15/30, LS, Epoch 19/20, Loss: 6.717842806274137e-05 \n",
      "SNR: 15/30, LS, Val Loss: 6.786633837856988e-05\n",
      "SNR: 15/30, LS, Epoch 20/20, Loss: 6.032368881194067e-05 \n",
      "SNR: 15/30, LS, Val Loss: 5.29878479111093e-05\n",
      "LS+CNN NMSE: 0.0021056034602224827\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/20, Loss: 0.11149132027572324 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.016581874594769695\n",
      "SNR: 20/30, LS+LI, Epoch 2/20, Loss: 0.006828560973084424 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0013455532978034832\n",
      "SNR: 20/30, LS+LI, Epoch 3/20, Loss: 0.0006697846801280109 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00037307675467507744\n",
      "SNR: 20/30, LS+LI, Epoch 4/20, Loss: 0.0003022646970050626 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00022126850407485935\n",
      "SNR: 20/30, LS+LI, Epoch 5/20, Loss: 0.00016657746248732342 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00010929562102484687\n",
      "SNR: 20/30, LS+LI, Epoch 6/20, Loss: 8.161744921550095e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 5.8305146839385e-05\n",
      "SNR: 20/30, LS+LI, Epoch 7/20, Loss: 5.12433632117558e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.2443739320416086e-05\n",
      "SNR: 20/30, LS+LI, Epoch 8/20, Loss: 3.777668926400216e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 3.131436956623061e-05\n",
      "SNR: 20/30, LS+LI, Epoch 9/20, Loss: 2.8141823698861963e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 2.370894112986703e-05\n",
      "SNR: 20/30, LS+LI, Epoch 10/20, Loss: 2.1638765987475826e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.8475873441109964e-05\n",
      "SNR: 20/30, LS+LI, Epoch 11/20, Loss: 1.7033564692483618e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.470532044384692e-05\n",
      "SNR: 20/30, LS+LI, Epoch 12/20, Loss: 1.361019050903472e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 1.1882974459612425e-05\n",
      "SNR: 20/30, LS+LI, Epoch 13/20, Loss: 1.0983940762534351e-05 \n",
      "SNR: 20/30, LS+LI, Val Loss: 9.627068865566715e-06\n",
      "SNR: 20/30, LS+LI, Epoch 14/20, Loss: 9.024559615280067e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 8.022578557839468e-06\n",
      "SNR: 20/30, LS+LI, Epoch 15/20, Loss: 7.596046398354046e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 6.8386599319968475e-06\n",
      "SNR: 20/30, LS+LI, Epoch 16/20, Loss: 6.529436005663694e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 5.979931343476479e-06\n",
      "SNR: 20/30, LS+LI, Epoch 17/20, Loss: 5.733447144235089e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 5.440806303754058e-06\n",
      "SNR: 20/30, LS+LI, Epoch 18/20, Loss: 5.115420060255294e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.869321752597568e-06\n",
      "SNR: 20/30, LS+LI, Epoch 19/20, Loss: 4.592191290548938e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.3073257943020016e-06\n",
      "SNR: 20/30, LS+LI, Epoch 20/20, Loss: 4.201596159736107e-06 \n",
      "SNR: 20/30, LS+LI, Val Loss: 4.000651177772273e-06\n",
      "LS+LI NMSE: 0.0008178051793947816\n",
      "LS+LI+CNN NMSE: 0.00015275669284164906\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/20, Loss: 0.13397935775736736 \n",
      "SNR: 20/30, LS, Val Loss: 0.04034663178026676\n",
      "SNR: 20/30, LS, Epoch 2/20, Loss: 0.03055625739182497 \n",
      "SNR: 20/30, LS, Val Loss: 0.024009581316601147\n",
      "SNR: 20/30, LS, Epoch 3/20, Loss: 0.021669559608495165 \n",
      "SNR: 20/30, LS, Val Loss: 0.019395153461532158\n",
      "SNR: 20/30, LS, Epoch 4/20, Loss: 0.015145965868087356 \n",
      "SNR: 20/30, LS, Val Loss: 0.00969054393300956\n",
      "SNR: 20/30, LS, Epoch 5/20, Loss: 0.003958578088502183 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011198114847171712\n",
      "SNR: 20/30, LS, Epoch 6/20, Loss: 0.0008051973714447191 \n",
      "SNR: 20/30, LS, Val Loss: 0.000599782850423997\n",
      "SNR: 20/30, LS, Epoch 7/20, Loss: 0.0005319206943250868 \n",
      "SNR: 20/30, LS, Val Loss: 0.00044846502053339714\n",
      "SNR: 20/30, LS, Epoch 8/20, Loss: 0.00041276852594861803 \n",
      "SNR: 20/30, LS, Val Loss: 0.00035674849641509354\n",
      "SNR: 20/30, LS, Epoch 9/20, Loss: 0.0003280686910858454 \n",
      "SNR: 20/30, LS, Val Loss: 0.0002852781849056059\n",
      "SNR: 20/30, LS, Epoch 10/20, Loss: 0.00026136349942832966 \n",
      "SNR: 20/30, LS, Val Loss: 0.0002268000766476193\n",
      "SNR: 20/30, LS, Epoch 11/20, Loss: 0.0002112551978931405 \n",
      "SNR: 20/30, LS, Val Loss: 0.00018353529065445235\n",
      "SNR: 20/30, LS, Epoch 12/20, Loss: 0.00017281096243518837 \n",
      "SNR: 20/30, LS, Val Loss: 0.00015392584464279935\n",
      "SNR: 20/30, LS, Epoch 13/20, Loss: 0.00014757599794477775 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001349580621039918\n",
      "SNR: 20/30, LS, Epoch 14/20, Loss: 0.0001291072516492974 \n",
      "SNR: 20/30, LS, Val Loss: 0.00011870356386432171\n",
      "SNR: 20/30, LS, Epoch 15/20, Loss: 0.00011397283903301455 \n",
      "SNR: 20/30, LS, Val Loss: 0.0001045300946729681\n",
      "SNR: 20/30, LS, Epoch 16/20, Loss: 0.0001014086872516579 \n",
      "SNR: 20/30, LS, Val Loss: 9.35064875772117e-05\n",
      "SNR: 20/30, LS, Epoch 17/20, Loss: 9.1219477664793e-05 \n",
      "SNR: 20/30, LS, Val Loss: 8.333541766412303e-05\n",
      "SNR: 20/30, LS, Epoch 18/20, Loss: 8.173341425284635e-05 \n",
      "SNR: 20/30, LS, Val Loss: 7.537109575588892e-05\n",
      "SNR: 20/30, LS, Epoch 19/20, Loss: 7.36591711629867e-05 \n",
      "SNR: 20/30, LS, Val Loss: 7.191482721034184e-05\n",
      "SNR: 20/30, LS, Epoch 20/20, Loss: 6.633760444116021e-05 \n",
      "SNR: 20/30, LS, Val Loss: 6.197799203536388e-05\n",
      "LS+CNN NMSE: 0.002372625283896923\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/20, Loss: 0.09874545497993051 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.014573174317113378\n",
      "SNR: 25/30, LS+LI, Epoch 2/20, Loss: 0.004584545190080589 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005995881907768886\n",
      "SNR: 25/30, LS+LI, Epoch 3/20, Loss: 0.00039603901119377507 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003130827562100339\n",
      "SNR: 25/30, LS+LI, Epoch 4/20, Loss: 0.0002579429219199377 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00021791607750029388\n",
      "SNR: 25/30, LS+LI, Epoch 5/20, Loss: 0.00017445564332965025 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00014114551959210075\n",
      "SNR: 25/30, LS+LI, Epoch 6/20, Loss: 0.00010921281559709568 \n",
      "SNR: 25/30, LS+LI, Val Loss: 8.523253133964978e-05\n",
      "SNR: 25/30, LS+LI, Epoch 7/20, Loss: 6.79539758747587e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 5.67890046196143e-05\n",
      "SNR: 25/30, LS+LI, Epoch 8/20, Loss: 4.822107092517991e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 4.347760014669885e-05\n",
      "SNR: 25/30, LS+LI, Epoch 9/20, Loss: 3.851979375022618e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 3.569706429764417e-05\n",
      "SNR: 25/30, LS+LI, Epoch 10/20, Loss: 3.154969836878293e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 2.9277789177616466e-05\n",
      "SNR: 25/30, LS+LI, Epoch 11/20, Loss: 2.5454182377870893e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 2.347280315007083e-05\n",
      "SNR: 25/30, LS+LI, Epoch 12/20, Loss: 2.079900365103196e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.9470772630566817e-05\n",
      "SNR: 25/30, LS+LI, Epoch 13/20, Loss: 1.7273230220547872e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.634569137174615e-05\n",
      "SNR: 25/30, LS+LI, Epoch 14/20, Loss: 1.4500800383503639e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.3912450289023003e-05\n",
      "SNR: 25/30, LS+LI, Epoch 15/20, Loss: 1.2229985893713472e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 1.1722441162088547e-05\n",
      "SNR: 25/30, LS+LI, Epoch 16/20, Loss: 1.0332152664146675e-05 \n",
      "SNR: 25/30, LS+LI, Val Loss: 9.814265757251468e-06\n",
      "SNR: 25/30, LS+LI, Epoch 17/20, Loss: 8.822384986985504e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 8.442541167658584e-06\n",
      "SNR: 25/30, LS+LI, Epoch 18/20, Loss: 7.5716226742875985e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 7.254782241778395e-06\n",
      "SNR: 25/30, LS+LI, Epoch 19/20, Loss: 6.572486992893594e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 6.339686664928608e-06\n",
      "SNR: 25/30, LS+LI, Epoch 20/20, Loss: 5.742603484789068e-06 \n",
      "SNR: 25/30, LS+LI, Val Loss: 5.605419966576102e-06\n",
      "LS+LI NMSE: 0.00026133988285437226\n",
      "LS+LI+CNN NMSE: 0.0001928100100485608\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/20, Loss: 0.09896981816868795 \n",
      "SNR: 25/30, LS, Val Loss: 0.036138137463818894\n",
      "SNR: 25/30, LS, Epoch 2/20, Loss: 0.026817473160579454 \n",
      "SNR: 25/30, LS, Val Loss: 0.02614721486514265\n",
      "SNR: 25/30, LS, Epoch 3/20, Loss: 0.02165498693343685 \n",
      "SNR: 25/30, LS, Val Loss: 0.021158383397216148\n",
      "SNR: 25/30, LS, Epoch 4/20, Loss: 0.01274456081337967 \n",
      "SNR: 25/30, LS, Val Loss: 0.005441243654455651\n",
      "SNR: 25/30, LS, Epoch 5/20, Loss: 0.0017995769645325667 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009698943785307082\n",
      "SNR: 25/30, LS, Epoch 6/20, Loss: 0.0007348011100940882 \n",
      "SNR: 25/30, LS, Val Loss: 0.0006809058461592279\n",
      "SNR: 25/30, LS, Epoch 7/20, Loss: 0.000543360786544982 \n",
      "SNR: 25/30, LS, Val Loss: 0.0005177699548022991\n",
      "SNR: 25/30, LS, Epoch 8/20, Loss: 0.000415469765484463 \n",
      "SNR: 25/30, LS, Val Loss: 0.0003920748303326863\n",
      "SNR: 25/30, LS, Epoch 9/20, Loss: 0.00031611657856089106 \n",
      "SNR: 25/30, LS, Val Loss: 0.00031609426382188263\n",
      "SNR: 25/30, LS, Epoch 10/20, Loss: 0.00025353694142067135 \n",
      "SNR: 25/30, LS, Val Loss: 0.0002615576489585113\n",
      "SNR: 25/30, LS, Epoch 11/20, Loss: 0.00021854857034266515 \n",
      "SNR: 25/30, LS, Val Loss: 0.0002265658219006251\n",
      "SNR: 25/30, LS, Epoch 12/20, Loss: 0.00019422692829996165 \n",
      "SNR: 25/30, LS, Val Loss: 0.00022801876184530556\n",
      "SNR: 25/30, LS, Epoch 13/20, Loss: 0.00017766481594366649 \n",
      "SNR: 25/30, LS, Val Loss: 0.0001900939129303548\n",
      "SNR: 25/30, LS, Epoch 14/20, Loss: 0.00016776774218881253 \n",
      "SNR: 25/30, LS, Val Loss: 0.00017292523857163772\n",
      "SNR: 25/30, LS, Epoch 15/20, Loss: 0.0001566900761624078 \n",
      "SNR: 25/30, LS, Val Loss: 0.00016172715450838123\n",
      "SNR: 25/30, LS, Epoch 16/20, Loss: 0.00014932776266082223 \n",
      "SNR: 25/30, LS, Val Loss: 0.00015285373195762406\n",
      "SNR: 25/30, LS, Epoch 17/20, Loss: 0.0001376883639834908 \n",
      "SNR: 25/30, LS, Val Loss: 0.00014063344265609473\n",
      "SNR: 25/30, LS, Epoch 18/20, Loss: 0.00012937609912918305 \n",
      "SNR: 25/30, LS, Val Loss: 0.00013767732261013325\n",
      "SNR: 25/30, LS, Epoch 19/20, Loss: 0.00011966811972913917 \n",
      "SNR: 25/30, LS, Val Loss: 0.00012970162193100393\n",
      "SNR: 25/30, LS, Epoch 20/20, Loss: 0.00011606974383243522 \n",
      "SNR: 25/30, LS, Val Loss: 0.00011632163758887063\n",
      "LS+CNN NMSE: 0.0039844149723649025\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/20, Loss: 0.08864774813247454 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.008434317117048935\n",
      "SNR: 30/30, LS+LI, Epoch 2/20, Loss: 0.0022964696036069654 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0004869751124219461\n",
      "SNR: 30/30, LS+LI, Epoch 3/20, Loss: 0.0003658311027318759 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00028147625959139657\n",
      "SNR: 30/30, LS+LI, Epoch 4/20, Loss: 0.00021755122936663738 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00015866627522469074\n",
      "SNR: 30/30, LS+LI, Epoch 5/20, Loss: 0.00011867529695358149 \n",
      "SNR: 30/30, LS+LI, Val Loss: 9.131589302507399e-05\n",
      "SNR: 30/30, LS+LI, Epoch 6/20, Loss: 7.677306957491457e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 6.515210820494262e-05\n",
      "SNR: 30/30, LS+LI, Epoch 7/20, Loss: 5.688193813998518e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 4.950776879426981e-05\n",
      "SNR: 30/30, LS+LI, Epoch 8/20, Loss: 4.3598413804131773e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 3.795877339805222e-05\n",
      "SNR: 30/30, LS+LI, Epoch 9/20, Loss: 3.3527078315717856e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 2.9666712510912806e-05\n",
      "SNR: 30/30, LS+LI, Epoch 10/20, Loss: 2.6402424515084888e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 2.3500787805956364e-05\n",
      "SNR: 30/30, LS+LI, Epoch 11/20, Loss: 2.1177595129323213e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.8921051212766376e-05\n",
      "SNR: 30/30, LS+LI, Epoch 12/20, Loss: 1.6900132455110757e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.4859547553152714e-05\n",
      "SNR: 30/30, LS+LI, Epoch 13/20, Loss: 1.2852095678258486e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 1.1297216794694329e-05\n",
      "SNR: 30/30, LS+LI, Epoch 14/20, Loss: 1.0161362773265695e-05 \n",
      "SNR: 30/30, LS+LI, Val Loss: 9.248421809554037e-06\n",
      "SNR: 30/30, LS+LI, Epoch 15/20, Loss: 8.287509029837248e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 7.511496691718507e-06\n",
      "SNR: 30/30, LS+LI, Epoch 16/20, Loss: 6.882706207592449e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 6.24784725418563e-06\n",
      "SNR: 30/30, LS+LI, Epoch 17/20, Loss: 5.7300694712720605e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 5.205048162017854e-06\n",
      "SNR: 30/30, LS+LI, Epoch 18/20, Loss: 4.776369622917162e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 4.417939056689978e-06\n",
      "SNR: 30/30, LS+LI, Epoch 19/20, Loss: 4.054683328440449e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 3.736826990709894e-06\n",
      "SNR: 30/30, LS+LI, Epoch 20/20, Loss: 3.428755389957714e-06 \n",
      "SNR: 30/30, LS+LI, Val Loss: 3.21788016580368e-06\n",
      "LS+LI NMSE: 8.329083357239142e-05\n",
      "LS+LI+CNN NMSE: 0.00011716008884832263\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/20, Loss: 0.11178896506858427 \n",
      "SNR: 30/30, LS, Val Loss: 0.03588377633555369\n",
      "SNR: 30/30, LS, Epoch 2/20, Loss: 0.027738154974094657 \n",
      "SNR: 30/30, LS, Val Loss: 0.02344193851405924\n",
      "SNR: 30/30, LS, Epoch 3/20, Loss: 0.018584631415907035 \n",
      "SNR: 30/30, LS, Val Loss: 0.01299198077652942\n",
      "SNR: 30/30, LS, Epoch 4/20, Loss: 0.005638140010739525 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014976845017041671\n",
      "SNR: 30/30, LS, Epoch 5/20, Loss: 0.0008356680187970659 \n",
      "SNR: 30/30, LS, Val Loss: 0.0005614254081261937\n",
      "SNR: 30/30, LS, Epoch 6/20, Loss: 0.0004399453227538182 \n",
      "SNR: 30/30, LS, Val Loss: 0.0003563952830683609\n",
      "SNR: 30/30, LS, Epoch 7/20, Loss: 0.00028773763780157234 \n",
      "SNR: 30/30, LS, Val Loss: 0.00023370409061581913\n",
      "SNR: 30/30, LS, Epoch 8/20, Loss: 0.00018979330838361463 \n",
      "SNR: 30/30, LS, Val Loss: 0.00015465411243812096\n",
      "SNR: 30/30, LS, Epoch 9/20, Loss: 0.0001324495637544355 \n",
      "SNR: 30/30, LS, Val Loss: 0.00011478897530733693\n",
      "SNR: 30/30, LS, Epoch 10/20, Loss: 0.00010047471318272116 \n",
      "SNR: 30/30, LS, Val Loss: 8.929627768917602e-05\n",
      "SNR: 30/30, LS, Epoch 11/20, Loss: 7.858792346374938e-05 \n",
      "SNR: 30/30, LS, Val Loss: 7.187792322259735e-05\n",
      "SNR: 30/30, LS, Epoch 12/20, Loss: 6.369267220877593e-05 \n",
      "SNR: 30/30, LS, Val Loss: 6.276685863585126e-05\n",
      "SNR: 30/30, LS, Epoch 13/20, Loss: 5.239713913778e-05 \n",
      "SNR: 30/30, LS, Val Loss: 4.8510519925250925e-05\n",
      "SNR: 30/30, LS, Epoch 14/20, Loss: 4.507430719249262e-05 \n",
      "SNR: 30/30, LS, Val Loss: 4.367052679299377e-05\n",
      "SNR: 30/30, LS, Epoch 15/20, Loss: 3.9627854527870385e-05 \n",
      "SNR: 30/30, LS, Val Loss: 3.7493487980100326e-05\n",
      "SNR: 30/30, LS, Epoch 16/20, Loss: 3.4857195111916825e-05 \n",
      "SNR: 30/30, LS, Val Loss: 3.274423653982178e-05\n",
      "SNR: 30/30, LS, Epoch 17/20, Loss: 3.1752482850289344e-05 \n",
      "SNR: 30/30, LS, Val Loss: 2.9154617963782087e-05\n",
      "SNR: 30/30, LS, Epoch 18/20, Loss: 2.9286087526490393e-05 \n",
      "SNR: 30/30, LS, Val Loss: 2.6613809082350187e-05\n",
      "SNR: 30/30, LS, Epoch 19/20, Loss: 2.6171492864641763e-05 \n",
      "SNR: 30/30, LS, Val Loss: 2.4354851451459002e-05\n",
      "SNR: 30/30, LS, Epoch 20/20, Loss: 2.667499627001911e-05 \n",
      "SNR: 30/30, LS, Val Loss: 2.288572357594438e-05\n",
      "LS+CNN NMSE: 0.0008399543585255742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "rowss = \"3500_3516\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver3'))\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "\n",
    "    H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "    H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "    H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "    # read data from ifferent .mat file, then concatenate them\n",
    "    for i in range(len(rows)):\n",
    "        file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_60_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "        file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "        file_path = os.path.normpath(file_path)\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        \n",
    "        H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "        H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "        H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "        H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)\n",
    "\n",
    "    shuffle_order = np.random.permutation(H_true.shape[0]);\n",
    "    H_true = torch.tensor(H_true[shuffle_order])\n",
    "    H_equal = torch.tensor(H_equal[shuffle_order])\n",
    "    H_linear = torch.tensor(H_linear[shuffle_order])\n",
    "    H_practical = torch.tensor(H_practical[shuffle_order])\n",
    "\n",
    "    train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "    train_size = int(train_size)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # 1.1 Split into training and validation sets for H_NN training\n",
    "    trainData   = H_linear[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Split H_equal, H_linear, H_practical for validation later\n",
    "    H_equal_val = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_linear_val = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_practical_val = H_practical[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # 1.2 Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    # for evaluation, output of model(valData) will be de-normalized and compared with valLabels\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    # 1.3 Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 1.4 model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    learning_rate = 0.00001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver1', str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                'train_min_LI': trainData_min.cpu(),\n",
    "                'train_max_LI': trainData_max.cpu(),\n",
    "                'train_label_min': trainLabels_min.cpu(),\n",
    "                'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver1', str(snr) + 'dB') \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_true[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('True Channel')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_trueChannel.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = valData.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_linInterp[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS + Interpolate Estimated Channel, NMSE: {nmse_LI:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_estimatedChan.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('LI+CNN Estimated Channel (before de-normlized)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan_before_denorm.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # De-normalized\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LI+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LI_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # Split into training and validation sets for H_NN training\n",
    "    trainData   = H_equal[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    H_temp = trainData.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_temp[0,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS Channel')\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Chan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    learning_rate = 0.00001\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "    variables['train_min_LS']= trainData_min.cpu()\n",
    "    variables['train_max_LS']= trainData_max.cpu()\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LS_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
