{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/home/thien/Hprediction/one_shot_Hest_cleanver/DeepMIMOv2/DeepMIMO_Data/Static_BS16_ver3/freq_symb_1ant_612sub/Gan_0_dBOutdoor1_60_1ant_612subcs_Row_3500_3516.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outer_file_path, file_path_partial)\n\u001b[1;32m     22\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(file_path)\n\u001b[0;32m---> 23\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m H_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((H_true, np\u001b[38;5;241m.\u001b[39marray(file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_data\u001b[39m\u001b[38;5;124m'\u001b[39m])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# N_samples x channel(2) x height(614) x width(14)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m H_equal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((H_equal, np\u001b[38;5;241m.\u001b[39marray(file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_equalized_data\u001b[39m\u001b[38;5;124m'\u001b[39m])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_GPU/lib/python3.8/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_GPU/lib/python3.8/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/thien/Hprediction/one_shot_Hest_cleanver/DeepMIMOv2/DeepMIMO_Data/Static_BS16_ver3/freq_symb_1ant_612sub/Gan_0_dBOutdoor1_60_1ant_612subcs_Row_3500_3516.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "rowss = \"3500_3516\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver3'))\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "\n",
    "    H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "    H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "    H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "    # read data from ifferent .mat file, then concatenate them\n",
    "    for i in range(len(rows)):\n",
    "        file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_60_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "        file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "        file_path = os.path.normpath(file_path)\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        \n",
    "        H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "        H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "        H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "        H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)\n",
    "\n",
    "    shuffle_order = np.random.permutation(H_true.shape[0]);\n",
    "    H_true = torch.tensor(H_true[shuffle_order])\n",
    "    H_equal = torch.tensor(H_equal[shuffle_order])\n",
    "    H_linear = torch.tensor(H_linear[shuffle_order])\n",
    "    H_practical = torch.tensor(H_practical[shuffle_order])\n",
    "\n",
    "    train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "    train_size = int(train_size)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # 1.1 Split into training and validation sets for H_NN training\n",
    "    trainData   = H_linear[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Split H_equal, H_linear, H_practical for validation later\n",
    "    H_equal_val = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_linear_val = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_practical_val = H_practical[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # 1.2 Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    # for evaluation, output of model(valData) will be de-normalized and compared with valLabels\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    # 1.3 Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 1.4 model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    learning_rate = 0.00001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver1', str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                'train_min_LI': trainData_min.cpu(),\n",
    "                'train_max_LI': trainData_max.cpu(),\n",
    "                'train_label_min': trainLabels_min.cpu(),\n",
    "                'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver1', str(snr) + 'dB') \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_true[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('True Channel')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_trueChannel.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = valData.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_linInterp[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS + Interpolate Estimated Channel, NMSE: {nmse_LI:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_estimatedChan.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('LI+CNN Estimated Channel (before de-normlized)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan_before_denorm.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # De-normalized\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LI+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LI_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # Split into training and validation sets for H_NN training\n",
    "    trainData   = H_equal[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    H_temp = trainData.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_temp[0,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS Channel')\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Chan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    learning_rate = 0.00001\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "    variables['train_min_LS']= trainData_min.cpu()\n",
    "    variables['train_max_LS']= trainData_max.cpu()\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LS_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
