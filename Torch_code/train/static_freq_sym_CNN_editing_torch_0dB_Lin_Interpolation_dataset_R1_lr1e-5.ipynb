{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/train\n"
     ]
    }
   ],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/35\n",
      " Training for LS+LI\n",
      "SNR: 0/35, LS+LI, Epoch 1/20, Loss: 0.10639935431282709 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.02729308162815869\n",
      "SNR: 0/35, LS+LI, Epoch 2/20, Loss: 0.01655197358404351 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.008318237805118164\n",
      "SNR: 0/35, LS+LI, Epoch 3/20, Loss: 0.004165001447533838 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0017632471572142094\n",
      "SNR: 0/35, LS+LI, Epoch 4/20, Loss: 0.001401608068977787 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0009348632762945878\n",
      "SNR: 0/35, LS+LI, Epoch 5/20, Loss: 0.0008296137726070396 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0006133642915907936\n",
      "SNR: 0/35, LS+LI, Epoch 6/20, Loss: 0.0005624144416449979 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00043759166267894517\n",
      "SNR: 0/35, LS+LI, Epoch 7/20, Loss: 0.0004264022809185899 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0003680683330458123\n",
      "SNR: 0/35, LS+LI, Epoch 8/20, Loss: 0.0003631900678853283 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0003173308268742403\n",
      "SNR: 0/35, LS+LI, Epoch 9/20, Loss: 0.00032944626748010903 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00029237234108829097\n",
      "SNR: 0/35, LS+LI, Epoch 10/20, Loss: 0.0003091435738128038 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002775605341109137\n",
      "SNR: 0/35, LS+LI, Epoch 11/20, Loss: 0.000291738940240345 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00026299248687185656\n",
      "SNR: 0/35, LS+LI, Epoch 12/20, Loss: 0.00027883958927583924 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002511749504871356\n",
      "SNR: 0/35, LS+LI, Epoch 13/20, Loss: 0.00026619470513156054 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00024083120903621116\n",
      "SNR: 0/35, LS+LI, Epoch 14/20, Loss: 0.00025855936837615445 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00023309941328382897\n",
      "SNR: 0/35, LS+LI, Epoch 15/20, Loss: 0.00025010023566912675 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00022602436426192676\n",
      "SNR: 0/35, LS+LI, Epoch 16/20, Loss: 0.00024464951959521613 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00022188218160105558\n",
      "SNR: 0/35, LS+LI, Epoch 17/20, Loss: 0.00023558328775654427 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021407870311425844\n",
      "SNR: 0/35, LS+LI, Epoch 18/20, Loss: 0.00023204919838607033 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021164076497370843\n",
      "SNR: 0/35, LS+LI, Epoch 19/20, Loss: 0.00022744567752735098 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00020653186341708837\n",
      "SNR: 0/35, LS+LI, Epoch 20/20, Loss: 0.00022316651705809232 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00020320326863535834\n",
      "LS+LI NMSE: 0.0825415700674057\n",
      "LS+LI+CNN NMSE: 0.007002431433647871\n",
      " Training for LS\n",
      "SNR: 0/35, LS, Epoch 1/20, Loss: 0.09391692780548393 \n",
      "SNR: 0/35, LS, Val Loss: 0.03716663791177174\n",
      "SNR: 0/35, LS, Epoch 2/20, Loss: 0.03177504590020912 \n",
      "SNR: 0/35, LS, Val Loss: 0.026159869274124503\n",
      "SNR: 0/35, LS, Epoch 3/20, Loss: 0.025403587313571778 \n",
      "SNR: 0/35, LS, Val Loss: 0.018550549789021414\n",
      "SNR: 0/35, LS, Epoch 4/20, Loss: 0.00951739041351409 \n",
      "SNR: 0/35, LS, Val Loss: 0.002042515169402274\n",
      "SNR: 0/35, LS, Epoch 5/20, Loss: 0.0016728230866737259 \n",
      "SNR: 0/35, LS, Val Loss: 0.0011913313525534857\n",
      "SNR: 0/35, LS, Epoch 6/20, Loss: 0.0010800955167021788 \n",
      "SNR: 0/35, LS, Val Loss: 0.0008015477748510117\n",
      "SNR: 0/35, LS, Epoch 7/20, Loss: 0.0007624852810790393 \n",
      "SNR: 0/35, LS, Val Loss: 0.0006122044530153895\n",
      "SNR: 0/35, LS, Epoch 8/20, Loss: 0.0006160545600854819 \n",
      "SNR: 0/35, LS, Val Loss: 0.0005433306275032616\n",
      "SNR: 0/35, LS, Epoch 9/20, Loss: 0.0005395403396946812 \n",
      "SNR: 0/35, LS, Val Loss: 0.00046332947628494975\n",
      "SNR: 0/35, LS, Epoch 10/20, Loss: 0.0004824047532430527 \n",
      "SNR: 0/35, LS, Val Loss: 0.0004217152357644712\n",
      "SNR: 0/35, LS, Epoch 11/20, Loss: 0.0004464171208455089 \n",
      "SNR: 0/35, LS, Val Loss: 0.00039901037113547017\n",
      "SNR: 0/35, LS, Epoch 12/20, Loss: 0.00042534818758123026 \n",
      "SNR: 0/35, LS, Val Loss: 0.0004233233606404004\n",
      "SNR: 0/35, LS, Epoch 13/20, Loss: 0.00042040499980736633 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003764293857481486\n",
      "SNR: 0/35, LS, Epoch 14/20, Loss: 0.00040892413539274846 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003740092470252421\n",
      "SNR: 0/35, LS, Epoch 15/20, Loss: 0.00040556078991105796 \n",
      "SNR: 0/35, LS, Val Loss: 0.00037227486973279156\n",
      "SNR: 0/35, LS, Epoch 16/20, Loss: 0.00039235107159232813 \n",
      "SNR: 0/35, LS, Val Loss: 0.000351164835592499\n",
      "SNR: 0/35, LS, Epoch 17/20, Loss: 0.0003829375432405418 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003559954602678772\n",
      "SNR: 0/35, LS, Epoch 18/20, Loss: 0.0003737725371075333 \n",
      "SNR: 0/35, LS, Val Loss: 0.00033791399861608323\n",
      "SNR: 0/35, LS, Epoch 19/20, Loss: 0.00037286630563673073 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003442854273695654\n",
      "SNR: 0/35, LS, Epoch 20/20, Loss: 0.0003615375980648378 \n",
      "SNR: 0/35, LS, Val Loss: 0.00034272848279215395\n",
      "LS+CNN NMSE: 0.011810120195150375\n",
      " SNR: 5/35\n",
      " Training for LS+LI\n",
      "SNR: 5/35, LS+LI, Epoch 1/20, Loss: 0.07669370707198239 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.018451524743189413\n",
      "SNR: 5/35, LS+LI, Epoch 2/20, Loss: 0.006762689207150315 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0013373826465491827\n",
      "SNR: 5/35, LS+LI, Epoch 3/20, Loss: 0.0010222619740029631 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.000763275243419533\n",
      "SNR: 5/35, LS+LI, Epoch 4/20, Loss: 0.0005677345956302257 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0004279788639299416\n",
      "SNR: 5/35, LS+LI, Epoch 5/20, Loss: 0.0003411696477744747 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00028895639115944505\n",
      "SNR: 5/35, LS+LI, Epoch 6/20, Loss: 0.0002441484098424121 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00021281735401620003\n",
      "SNR: 5/35, LS+LI, Epoch 7/20, Loss: 0.0001852794734491404 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00016672221499902662\n",
      "SNR: 5/35, LS+LI, Epoch 8/20, Loss: 0.0001528309779915968 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00014831902929775728\n",
      "SNR: 5/35, LS+LI, Epoch 9/20, Loss: 0.00013621966711142893 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00013171516487394305\n",
      "SNR: 5/35, LS+LI, Epoch 10/20, Loss: 0.00012560363425694564 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0001223854924319312\n",
      "SNR: 5/35, LS+LI, Epoch 11/20, Loss: 0.00011791133474976995 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0001157164679170819\n",
      "SNR: 5/35, LS+LI, Epoch 12/20, Loss: 0.0001118574340094116 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00011025918714343182\n",
      "SNR: 5/35, LS+LI, Epoch 13/20, Loss: 0.0001071250571299916 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00010739686543577893\n",
      "SNR: 5/35, LS+LI, Epoch 14/20, Loss: 0.00010230781063541198 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00010482601798382045\n",
      "SNR: 5/35, LS+LI, Epoch 15/20, Loss: 9.882097061329272e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00010273339042517667\n",
      "SNR: 5/35, LS+LI, Epoch 16/20, Loss: 9.57652775450877e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 9.572953361688026e-05\n",
      "SNR: 5/35, LS+LI, Epoch 17/20, Loss: 9.243088949222168e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 9.146903842823424e-05\n",
      "SNR: 5/35, LS+LI, Epoch 18/20, Loss: 9.064079008882377e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 9.206016056850785e-05\n",
      "SNR: 5/35, LS+LI, Epoch 19/20, Loss: 8.803807959158785e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 8.70450391327419e-05\n",
      "SNR: 5/35, LS+LI, Epoch 20/20, Loss: 8.603443097629202e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 8.521203168735762e-05\n",
      "LS+LI NMSE: 0.02583254687488079\n",
      "LS+LI+CNN NMSE: 0.0027218370232731104\n",
      " Training for LS\n",
      "SNR: 5/35, LS, Epoch 1/20, Loss: 0.10741351416684908 \n",
      "SNR: 5/35, LS, Val Loss: 0.037222602404654026\n",
      "SNR: 5/35, LS, Epoch 2/20, Loss: 0.030874810255326256 \n",
      "SNR: 5/35, LS, Val Loss: 0.027799564336116116\n",
      "SNR: 5/35, LS, Epoch 3/20, Loss: 0.021948675440605914 \n",
      "SNR: 5/35, LS, Val Loss: 0.01201091210047404\n",
      "SNR: 5/35, LS, Epoch 4/20, Loss: 0.0036725674434288378 \n",
      "SNR: 5/35, LS, Val Loss: 0.0011289705895857576\n",
      "SNR: 5/35, LS, Epoch 5/20, Loss: 0.0008968437118755451 \n",
      "SNR: 5/35, LS, Val Loss: 0.0007736876844622506\n",
      "SNR: 5/35, LS, Epoch 6/20, Loss: 0.0006588546262124996 \n",
      "SNR: 5/35, LS, Val Loss: 0.0005722169832248861\n",
      "SNR: 5/35, LS, Epoch 7/20, Loss: 0.00048249589390522517 \n",
      "SNR: 5/35, LS, Val Loss: 0.00041171143675455824\n",
      "SNR: 5/35, LS, Epoch 8/20, Loss: 0.000366944836113731 \n",
      "SNR: 5/35, LS, Val Loss: 0.00034487969969632104\n",
      "SNR: 5/35, LS, Epoch 9/20, Loss: 0.0003080911674890621 \n",
      "SNR: 5/35, LS, Val Loss: 0.00030762130093838397\n",
      "SNR: 5/35, LS, Epoch 10/20, Loss: 0.00028222013137529207 \n",
      "SNR: 5/35, LS, Val Loss: 0.00027220843791534816\n",
      "SNR: 5/35, LS, Epoch 11/20, Loss: 0.00026020186134593305 \n",
      "SNR: 5/35, LS, Val Loss: 0.00025118154007941484\n",
      "SNR: 5/35, LS, Epoch 12/20, Loss: 0.0002495779228393256 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002455959674989572\n",
      "SNR: 5/35, LS, Epoch 13/20, Loss: 0.00023923597811769675 \n",
      "SNR: 5/35, LS, Val Loss: 0.00022981156386473836\n",
      "SNR: 5/35, LS, Epoch 14/20, Loss: 0.00023722422806578364 \n",
      "SNR: 5/35, LS, Val Loss: 0.00022469426767202094\n",
      "SNR: 5/35, LS, Epoch 15/20, Loss: 0.00022298335599122882 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002163296455061451\n",
      "SNR: 5/35, LS, Epoch 16/20, Loss: 0.00021866517290438406 \n",
      "SNR: 5/35, LS, Val Loss: 0.00021121687495906372\n",
      "SNR: 5/35, LS, Epoch 17/20, Loss: 0.0002130887870668747 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002043582802192153\n",
      "SNR: 5/35, LS, Epoch 18/20, Loss: 0.00020361092491398132 \n",
      "SNR: 5/35, LS, Val Loss: 0.00020682866367375632\n",
      "SNR: 5/35, LS, Epoch 19/20, Loss: 0.00019969332269923116 \n",
      "SNR: 5/35, LS, Val Loss: 0.0001975280417051787\n",
      "SNR: 5/35, LS, Epoch 20/20, Loss: 0.00019603811067847148 \n",
      "SNR: 5/35, LS, Val Loss: 0.00019362347908706093\n",
      "LS+CNN NMSE: 0.006184612866491079\n",
      " SNR: 10/35\n",
      " Training for LS+LI\n",
      "SNR: 10/35, LS+LI, Epoch 1/20, Loss: 0.08006482913924179 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.01243426693448176\n",
      "SNR: 10/35, LS+LI, Epoch 2/20, Loss: 0.003981598691224111 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.0008871279278537259\n",
      "SNR: 10/35, LS+LI, Epoch 3/20, Loss: 0.0005564602102858411 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.0004143017140449956\n",
      "SNR: 10/35, LS+LI, Epoch 4/20, Loss: 0.00029779260699743274 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.00022259131765167695\n",
      "SNR: 10/35, LS+LI, Epoch 5/20, Loss: 0.00016476703517537766 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.00013326998699388545\n",
      "SNR: 10/35, LS+LI, Epoch 6/20, Loss: 0.00010854181996229713 \n",
      "SNR: 10/35, LS+LI, Val Loss: 9.469016276852926e-05\n",
      "SNR: 10/35, LS+LI, Epoch 7/20, Loss: 7.99500533386242e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 7.271925339106626e-05\n",
      "SNR: 10/35, LS+LI, Epoch 8/20, Loss: 6.375971951465455e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 6.177187151479302e-05\n",
      "SNR: 10/35, LS+LI, Epoch 9/20, Loss: 5.526740084077222e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 5.4035684570408193e-05\n",
      "SNR: 10/35, LS+LI, Epoch 10/20, Loss: 5.008581642373834e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.9480388952360954e-05\n",
      "SNR: 10/35, LS+LI, Epoch 11/20, Loss: 4.649506099487535e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.6385073195172786e-05\n",
      "SNR: 10/35, LS+LI, Epoch 12/20, Loss: 4.375583980933274e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.3739373874511024e-05\n",
      "SNR: 10/35, LS+LI, Epoch 13/20, Loss: 4.1566889554851155e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.189668622226842e-05\n",
      "SNR: 10/35, LS+LI, Epoch 14/20, Loss: 3.9556845597934906e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.9837410743833367e-05\n",
      "SNR: 10/35, LS+LI, Epoch 15/20, Loss: 3.801551864142149e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.826190474380079e-05\n",
      "SNR: 10/35, LS+LI, Epoch 16/20, Loss: 3.681593306741843e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.743262868738384e-05\n",
      "SNR: 10/35, LS+LI, Epoch 17/20, Loss: 3.549152106553256e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.601978437473008e-05\n",
      "SNR: 10/35, LS+LI, Epoch 18/20, Loss: 3.4312646189706845e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.574401299980915e-05\n",
      "SNR: 10/35, LS+LI, Epoch 19/20, Loss: 3.367691529137578e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.4317257359361975e-05\n",
      "SNR: 10/35, LS+LI, Epoch 20/20, Loss: 3.310194315057707e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.366767972086867e-05\n",
      "LS+LI NMSE: 0.008327984251081944\n",
      "LS+LI+CNN NMSE: 0.0010567804565653205\n",
      " Training for LS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7427/3518025190.py:257: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 10/35, LS, Epoch 1/20, Loss: 0.11869965146968861 \n",
      "SNR: 10/35, LS, Val Loss: 0.038832329058398805\n",
      "SNR: 10/35, LS, Epoch 2/20, Loss: 0.0309980522177302 \n",
      "SNR: 10/35, LS, Val Loss: 0.027712496385599177\n",
      "SNR: 10/35, LS, Epoch 3/20, Loss: 0.02241960539952806 \n",
      "SNR: 10/35, LS, Val Loss: 0.01493601310842981\n",
      "SNR: 10/35, LS, Epoch 4/20, Loss: 0.00519238810382304 \n",
      "SNR: 10/35, LS, Val Loss: 0.0014560722629539669\n",
      "SNR: 10/35, LS, Epoch 5/20, Loss: 0.0010139532802202324 \n",
      "SNR: 10/35, LS, Val Loss: 0.000784931432766219\n",
      "SNR: 10/35, LS, Epoch 6/20, Loss: 0.0006130130697585789 \n",
      "SNR: 10/35, LS, Val Loss: 0.0005209779374126811\n",
      "SNR: 10/35, LS, Epoch 7/20, Loss: 0.0004226520214066149 \n",
      "SNR: 10/35, LS, Val Loss: 0.00037598372728098184\n",
      "SNR: 10/35, LS, Epoch 8/20, Loss: 0.00031563143852733925 \n",
      "SNR: 10/35, LS, Val Loss: 0.00028942188146174885\n",
      "SNR: 10/35, LS, Epoch 9/20, Loss: 0.0002560982097973033 \n",
      "SNR: 10/35, LS, Val Loss: 0.00024262186404181799\n",
      "SNR: 10/35, LS, Epoch 10/20, Loss: 0.00022100323935368992 \n",
      "SNR: 10/35, LS, Val Loss: 0.00021436612041725311\n",
      "SNR: 10/35, LS, Epoch 11/20, Loss: 0.00019494548134821568 \n",
      "SNR: 10/35, LS, Val Loss: 0.00018927303790405858\n",
      "SNR: 10/35, LS, Epoch 12/20, Loss: 0.0001745795001408966 \n",
      "SNR: 10/35, LS, Val Loss: 0.00017231239871762227\n",
      "SNR: 10/35, LS, Epoch 13/20, Loss: 0.00015915268522803672 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001740913024453524\n",
      "SNR: 10/35, LS, Epoch 14/20, Loss: 0.00014704537166871528 \n",
      "SNR: 10/35, LS, Val Loss: 0.00014362078066672743\n",
      "SNR: 10/35, LS, Epoch 15/20, Loss: 0.00013658433799899303 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001331309510230009\n",
      "SNR: 10/35, LS, Epoch 16/20, Loss: 0.00012650208668449044 \n",
      "SNR: 10/35, LS, Val Loss: 0.00012466308695972353\n",
      "SNR: 10/35, LS, Epoch 17/20, Loss: 0.00011904488532633364 \n",
      "SNR: 10/35, LS, Val Loss: 0.00011683626689773519\n",
      "SNR: 10/35, LS, Epoch 18/20, Loss: 0.00011291485037026457 \n",
      "SNR: 10/35, LS, Val Loss: 0.00011495273793116212\n",
      "SNR: 10/35, LS, Epoch 19/20, Loss: 0.0001072281633205781 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001165284850988731\n",
      "SNR: 10/35, LS, Epoch 20/20, Loss: 0.00010218962228518109 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001010682902536549\n",
      "LS+CNN NMSE: 0.0031732735224068165\n",
      " SNR: 15/35\n",
      " Training for LS+LI\n",
      "SNR: 15/35, LS+LI, Epoch 1/20, Loss: 0.10434518479234954 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.015413498738780618\n",
      "SNR: 15/35, LS+LI, Epoch 2/20, Loss: 0.004235976842741509 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0007380024520292258\n",
      "SNR: 15/35, LS+LI, Epoch 3/20, Loss: 0.0005344549874892679 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0004061473579592227\n",
      "SNR: 15/35, LS+LI, Epoch 4/20, Loss: 0.000315101554667425 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.00023309515442330545\n",
      "SNR: 15/35, LS+LI, Epoch 5/20, Loss: 0.00017615286866779265 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.00013237507391750114\n",
      "SNR: 15/35, LS+LI, Epoch 6/20, Loss: 0.00010930798867271319 \n",
      "SNR: 15/35, LS+LI, Val Loss: 9.298228997067781e-05\n",
      "SNR: 15/35, LS+LI, Epoch 7/20, Loss: 8.159558054481606e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 7.299945006404111e-05\n",
      "SNR: 15/35, LS+LI, Epoch 8/20, Loss: 6.579883336256683e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 6.079063556777934e-05\n",
      "SNR: 15/35, LS+LI, Epoch 9/20, Loss: 5.5340855685091524e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 5.17908686864151e-05\n",
      "SNR: 15/35, LS+LI, Epoch 10/20, Loss: 4.784233275887967e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 4.5136596024046106e-05\n",
      "SNR: 15/35, LS+LI, Epoch 11/20, Loss: 4.225192998713436e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 4.041990329521165e-05\n",
      "SNR: 15/35, LS+LI, Epoch 12/20, Loss: 3.786733778535635e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 3.623036915693471e-05\n",
      "SNR: 15/35, LS+LI, Epoch 13/20, Loss: 3.418507057545813e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 3.2993343817603694e-05\n",
      "SNR: 15/35, LS+LI, Epoch 14/20, Loss: 3.116549440633072e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.9916978595186567e-05\n",
      "SNR: 15/35, LS+LI, Epoch 15/20, Loss: 2.847829982963976e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.7447051024864777e-05\n",
      "SNR: 15/35, LS+LI, Epoch 16/20, Loss: 2.616786929534686e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.5126955430702463e-05\n",
      "SNR: 15/35, LS+LI, Epoch 17/20, Loss: 2.386425681960294e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.2858538386572036e-05\n",
      "SNR: 15/35, LS+LI, Epoch 18/20, Loss: 2.1806170777138207e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.108808356145649e-05\n",
      "SNR: 15/35, LS+LI, Epoch 19/20, Loss: 2.0512516206652814e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.0235713388198445e-05\n",
      "SNR: 15/35, LS+LI, Epoch 20/20, Loss: 1.9168960813595454e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 1.8921224220018e-05\n",
      "LS+LI NMSE: 0.0026925019919872284\n",
      "LS+LI+CNN NMSE: 0.0005940240807831287\n",
      " Training for LS\n",
      "SNR: 15/35, LS, Epoch 1/20, Loss: 0.08814233404095514 \n",
      "SNR: 15/35, LS, Val Loss: 0.03640756895765662\n",
      "SNR: 15/35, LS, Epoch 2/20, Loss: 0.028371645017794454 \n",
      "SNR: 15/35, LS, Val Loss: 0.024186015594750643\n",
      "SNR: 15/35, LS, Epoch 3/20, Loss: 0.0146261746822257 \n",
      "SNR: 15/35, LS, Val Loss: 0.003613554591235394\n",
      "SNR: 15/35, LS, Epoch 4/20, Loss: 0.0017619955129829226 \n",
      "SNR: 15/35, LS, Val Loss: 0.0011012118993676268\n",
      "SNR: 15/35, LS, Epoch 5/20, Loss: 0.0008669530083586711 \n",
      "SNR: 15/35, LS, Val Loss: 0.0007049478614741626\n",
      "SNR: 15/35, LS, Epoch 6/20, Loss: 0.0005891460894796039 \n",
      "SNR: 15/35, LS, Val Loss: 0.000512248038527711\n",
      "SNR: 15/35, LS, Epoch 7/20, Loss: 0.000428490214352957 \n",
      "SNR: 15/35, LS, Val Loss: 0.00038507299177581444\n",
      "SNR: 15/35, LS, Epoch 8/20, Loss: 0.00032663170188045276 \n",
      "SNR: 15/35, LS, Val Loss: 0.00029114002488010254\n",
      "SNR: 15/35, LS, Epoch 9/20, Loss: 0.00025373051103808465 \n",
      "SNR: 15/35, LS, Val Loss: 0.00023293253191999005\n",
      "SNR: 15/35, LS, Epoch 10/20, Loss: 0.00020865309510338534 \n",
      "SNR: 15/35, LS, Val Loss: 0.00019679724452241013\n",
      "SNR: 15/35, LS, Epoch 11/20, Loss: 0.00017925466245557827 \n",
      "SNR: 15/35, LS, Val Loss: 0.00016970870092336554\n",
      "SNR: 15/35, LS, Epoch 12/20, Loss: 0.00015911071552344053 \n",
      "SNR: 15/35, LS, Val Loss: 0.00016442211866281772\n",
      "SNR: 15/35, LS, Epoch 13/20, Loss: 0.00013937825223374513 \n",
      "SNR: 15/35, LS, Val Loss: 0.00013343480380475134\n",
      "SNR: 15/35, LS, Epoch 14/20, Loss: 0.00012823590113479404 \n",
      "SNR: 15/35, LS, Val Loss: 0.00012155759971695564\n",
      "SNR: 15/35, LS, Epoch 15/20, Loss: 0.00011472273759900057 \n",
      "SNR: 15/35, LS, Val Loss: 0.00012257845355634345\n",
      "SNR: 15/35, LS, Epoch 16/20, Loss: 0.00010424752600547525 \n",
      "SNR: 15/35, LS, Val Loss: 0.0001123354513765662\n",
      "SNR: 15/35, LS, Epoch 17/20, Loss: 9.583521156432337e-05 \n",
      "SNR: 15/35, LS, Val Loss: 9.362330517130128e-05\n",
      "SNR: 15/35, LS, Epoch 18/20, Loss: 9.206916763672564e-05 \n",
      "SNR: 15/35, LS, Val Loss: 9.319675154983997e-05\n",
      "SNR: 15/35, LS, Epoch 19/20, Loss: 8.601088664381498e-05 \n",
      "SNR: 15/35, LS, Val Loss: 8.792808148427866e-05\n",
      "SNR: 15/35, LS, Epoch 20/20, Loss: 8.352587906076656e-05 \n",
      "SNR: 15/35, LS, Val Loss: 7.775753268409365e-05\n",
      "LS+CNN NMSE: 0.0024411261547356844\n",
      " SNR: 20/35\n",
      " Training for LS+LI\n",
      "SNR: 20/35, LS+LI, Epoch 1/20, Loss: 0.07329362091875755 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.007917219869947681\n",
      "SNR: 20/35, LS+LI, Epoch 2/20, Loss: 0.002183261668334927 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.0005577959915778289\n",
      "SNR: 20/35, LS+LI, Epoch 3/20, Loss: 0.00045978378156997666 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.00033769014407880604\n",
      "SNR: 20/35, LS+LI, Epoch 4/20, Loss: 0.00029709941261196694 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.00021891578883999804\n",
      "SNR: 20/35, LS+LI, Epoch 5/20, Loss: 0.0001917151721049732 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.00013697757670646146\n",
      "SNR: 20/35, LS+LI, Epoch 6/20, Loss: 0.0001246187343039679 \n",
      "SNR: 20/35, LS+LI, Val Loss: 9.190119696237768e-05\n",
      "SNR: 20/35, LS+LI, Epoch 7/20, Loss: 8.747678961893567e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 6.571314073274455e-05\n",
      "SNR: 20/35, LS+LI, Epoch 8/20, Loss: 6.641142220423087e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 5.085619811021994e-05\n",
      "SNR: 20/35, LS+LI, Epoch 9/20, Loss: 5.2592411881086814e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 4.049512335768668e-05\n",
      "SNR: 20/35, LS+LI, Epoch 10/20, Loss: 4.2384689640139096e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 3.233220612249473e-05\n",
      "SNR: 20/35, LS+LI, Epoch 11/20, Loss: 3.3971350729747305e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 2.6249208303852356e-05\n",
      "SNR: 20/35, LS+LI, Epoch 12/20, Loss: 2.8239497272680988e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 2.1840550895528093e-05\n",
      "SNR: 20/35, LS+LI, Epoch 13/20, Loss: 2.4137203424045468e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.878889471148189e-05\n",
      "SNR: 20/35, LS+LI, Epoch 14/20, Loss: 2.0968277702663592e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.6463308687283035e-05\n",
      "SNR: 20/35, LS+LI, Epoch 15/20, Loss: 1.8468703481378517e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.4516250947356943e-05\n",
      "SNR: 20/35, LS+LI, Epoch 16/20, Loss: 1.64083985329835e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.2911460430586885e-05\n",
      "SNR: 20/35, LS+LI, Epoch 17/20, Loss: 1.4665933865064002e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.1577503111463253e-05\n",
      "SNR: 20/35, LS+LI, Epoch 18/20, Loss: 1.3219003383908623e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.0881432482771439e-05\n",
      "SNR: 20/35, LS+LI, Epoch 19/20, Loss: 1.2021256049529887e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 9.969203953611819e-06\n",
      "SNR: 20/35, LS+LI, Epoch 20/20, Loss: 1.0933623309821348e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 8.665392632186316e-06\n",
      "LS+LI NMSE: 0.000901186722330749\n",
      "LS+LI+CNN NMSE: 0.0002799514913931489\n",
      " Training for LS\n",
      "SNR: 20/35, LS, Epoch 1/20, Loss: 0.10661203375473471 \n",
      "SNR: 20/35, LS, Val Loss: 0.038706502954786025\n",
      "SNR: 20/35, LS, Epoch 2/20, Loss: 0.030186339410593604 \n",
      "SNR: 20/35, LS, Val Loss: 0.025190617345894378\n",
      "SNR: 20/35, LS, Epoch 3/20, Loss: 0.017380365306548407 \n",
      "SNR: 20/35, LS, Val Loss: 0.005311976157827303\n",
      "SNR: 20/35, LS, Epoch 4/20, Loss: 0.002255948802161187 \n",
      "SNR: 20/35, LS, Val Loss: 0.0012087597084852557\n",
      "SNR: 20/35, LS, Epoch 5/20, Loss: 0.000955419720664602 \n",
      "SNR: 20/35, LS, Val Loss: 0.0006775777510483749\n",
      "SNR: 20/35, LS, Epoch 6/20, Loss: 0.000576049710265453 \n",
      "SNR: 20/35, LS, Val Loss: 0.0004358063063894709\n",
      "SNR: 20/35, LS, Epoch 7/20, Loss: 0.00036807021121540575 \n",
      "SNR: 20/35, LS, Val Loss: 0.0002732437787926756\n",
      "SNR: 20/35, LS, Epoch 8/20, Loss: 0.0002529168553940841 \n",
      "SNR: 20/35, LS, Val Loss: 0.00019854294259857852\n",
      "SNR: 20/35, LS, Epoch 9/20, Loss: 0.00018974899775106552 \n",
      "SNR: 20/35, LS, Val Loss: 0.00016085599539413428\n",
      "SNR: 20/35, LS, Epoch 10/20, Loss: 0.0001550866893894906 \n",
      "SNR: 20/35, LS, Val Loss: 0.0001324309775251701\n",
      "SNR: 20/35, LS, Epoch 11/20, Loss: 0.00013195379535030195 \n",
      "SNR: 20/35, LS, Val Loss: 0.00011226600660544743\n",
      "SNR: 20/35, LS, Epoch 12/20, Loss: 0.00011458498700827333 \n",
      "SNR: 20/35, LS, Val Loss: 0.00011898684169864282\n",
      "SNR: 20/35, LS, Epoch 13/20, Loss: 0.00010443498482201525 \n",
      "SNR: 20/35, LS, Val Loss: 9.90041265443627e-05\n",
      "SNR: 20/35, LS, Epoch 14/20, Loss: 9.451241248375437e-05 \n",
      "SNR: 20/35, LS, Val Loss: 8.669691851537209e-05\n",
      "SNR: 20/35, LS, Epoch 15/20, Loss: 8.824876506581193e-05 \n",
      "SNR: 20/35, LS, Val Loss: 7.647616772980352e-05\n",
      "SNR: 20/35, LS, Epoch 16/20, Loss: 8.061859397016498e-05 \n",
      "SNR: 20/35, LS, Val Loss: 7.64338371178989e-05\n",
      "SNR: 20/35, LS, Epoch 17/20, Loss: 7.663629505691685e-05 \n",
      "SNR: 20/35, LS, Val Loss: 6.750695016914203e-05\n",
      "SNR: 20/35, LS, Epoch 18/20, Loss: 7.296980760710909e-05 \n",
      "SNR: 20/35, LS, Val Loss: 7.494742233878544e-05\n",
      "SNR: 20/35, LS, Epoch 19/20, Loss: 7.036744732836764e-05 \n",
      "SNR: 20/35, LS, Val Loss: 6.151939214760205e-05\n",
      "SNR: 20/35, LS, Epoch 20/20, Loss: 6.527113767486587e-05 \n",
      "SNR: 20/35, LS, Val Loss: 6.194965650744659e-05\n",
      "LS+CNN NMSE: 0.0020017961505800486\n",
      " SNR: 25/35\n",
      " Training for LS+LI\n",
      "SNR: 25/35, LS+LI, Epoch 1/20, Loss: 0.1029575808840518 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.013892344625977179\n",
      "SNR: 25/35, LS+LI, Epoch 2/20, Loss: 0.003993150774656915 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.0007535741630514773\n",
      "SNR: 25/35, LS+LI, Epoch 3/20, Loss: 0.0005211124221430077 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.0003408243792364374\n",
      "SNR: 25/35, LS+LI, Epoch 4/20, Loss: 0.00025517779669267964 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.00018279439548981222\n",
      "SNR: 25/35, LS+LI, Epoch 5/20, Loss: 0.00014703567141245147 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.00011594750170236996\n",
      "SNR: 25/35, LS+LI, Epoch 6/20, Loss: 0.00010091391559759395 \n",
      "SNR: 25/35, LS+LI, Val Loss: 8.365124752648019e-05\n",
      "SNR: 25/35, LS+LI, Epoch 7/20, Loss: 7.023080985109658e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 5.59223146107494e-05\n",
      "SNR: 25/35, LS+LI, Epoch 8/20, Loss: 4.865636244833488e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 4.001846665839063e-05\n",
      "SNR: 25/35, LS+LI, Epoch 9/20, Loss: 3.5410953252253556e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 2.9456045922415797e-05\n",
      "SNR: 25/35, LS+LI, Epoch 10/20, Loss: 2.6814338458045835e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 2.249964101489847e-05\n",
      "SNR: 25/35, LS+LI, Epoch 11/20, Loss: 2.0582105991148764e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.7532946041380153e-05\n",
      "SNR: 25/35, LS+LI, Epoch 12/20, Loss: 1.6304225000837533e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.4025389873495442e-05\n",
      "SNR: 25/35, LS+LI, Epoch 13/20, Loss: 1.3251931371690594e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.1554385537237977e-05\n",
      "SNR: 25/35, LS+LI, Epoch 14/20, Loss: 1.1004695435607718e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 9.691701923960258e-06\n",
      "SNR: 25/35, LS+LI, Epoch 15/20, Loss: 9.261170533244523e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 8.202808790732282e-06\n",
      "SNR: 25/35, LS+LI, Epoch 16/20, Loss: 7.93180915349181e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 7.117558614784987e-06\n",
      "SNR: 25/35, LS+LI, Epoch 17/20, Loss: 6.89695638140962e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 6.279005750305562e-06\n",
      "SNR: 25/35, LS+LI, Epoch 18/20, Loss: 6.052793984360172e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 5.462096548095967e-06\n",
      "SNR: 25/35, LS+LI, Epoch 19/20, Loss: 5.432655008448954e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 4.913072833308736e-06\n",
      "SNR: 25/35, LS+LI, Epoch 20/20, Loss: 4.883038443067292e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 4.476123592667136e-06\n",
      "LS+LI NMSE: 0.00033961236476898193\n",
      "LS+LI+CNN NMSE: 0.000146256570587866\n",
      " Training for LS\n",
      "SNR: 25/35, LS, Epoch 1/20, Loss: 0.11459718762647987 \n",
      "SNR: 25/35, LS, Val Loss: 0.04098648841803273\n",
      "SNR: 25/35, LS, Epoch 2/20, Loss: 0.032028591804353905 \n",
      "SNR: 25/35, LS, Val Loss: 0.0249033117822061\n",
      "SNR: 25/35, LS, Epoch 3/20, Loss: 0.01928913809064001 \n",
      "SNR: 25/35, LS, Val Loss: 0.009540089367267987\n",
      "SNR: 25/35, LS, Epoch 4/20, Loss: 0.0027420154371008386 \n",
      "SNR: 25/35, LS, Val Loss: 0.0008222809556173161\n",
      "SNR: 25/35, LS, Epoch 5/20, Loss: 0.0006807677590145296 \n",
      "SNR: 25/35, LS, Val Loss: 0.000530723487221015\n",
      "SNR: 25/35, LS, Epoch 6/20, Loss: 0.00043856033102706037 \n",
      "SNR: 25/35, LS, Val Loss: 0.0003497539061451486\n",
      "SNR: 25/35, LS, Epoch 7/20, Loss: 0.0003013401027160263 \n",
      "SNR: 25/35, LS, Val Loss: 0.0002479359512411368\n",
      "SNR: 25/35, LS, Epoch 8/20, Loss: 0.00022155964501561725 \n",
      "SNR: 25/35, LS, Val Loss: 0.00018981108466202082\n",
      "SNR: 25/35, LS, Epoch 9/20, Loss: 0.0001771864708193744 \n",
      "SNR: 25/35, LS, Val Loss: 0.0001644134432960224\n",
      "SNR: 25/35, LS, Epoch 10/20, Loss: 0.00014859552736945064 \n",
      "SNR: 25/35, LS, Val Loss: 0.00013461899834510405\n",
      "SNR: 25/35, LS, Epoch 11/20, Loss: 0.0001294252294905848 \n",
      "SNR: 25/35, LS, Val Loss: 0.00011797153092629742\n",
      "SNR: 25/35, LS, Epoch 12/20, Loss: 0.0001155909688683402 \n",
      "SNR: 25/35, LS, Val Loss: 0.0001063378822436789\n",
      "SNR: 25/35, LS, Epoch 13/20, Loss: 0.00010398231205555823 \n",
      "SNR: 25/35, LS, Val Loss: 9.759500486931454e-05\n",
      "SNR: 25/35, LS, Epoch 14/20, Loss: 9.574080102556584e-05 \n",
      "SNR: 25/35, LS, Val Loss: 9.026937580832357e-05\n",
      "SNR: 25/35, LS, Epoch 15/20, Loss: 8.684275752163405e-05 \n",
      "SNR: 25/35, LS, Val Loss: 8.171958749395951e-05\n",
      "SNR: 25/35, LS, Epoch 16/20, Loss: 8.013686311813325e-05 \n",
      "SNR: 25/35, LS, Val Loss: 7.501865896604916e-05\n",
      "SNR: 25/35, LS, Epoch 17/20, Loss: 7.396059499844323e-05 \n",
      "SNR: 25/35, LS, Val Loss: 6.956846770359941e-05\n",
      "SNR: 25/35, LS, Epoch 18/20, Loss: 6.900574705225765e-05 \n",
      "SNR: 25/35, LS, Val Loss: 6.296851825027261e-05\n",
      "SNR: 25/35, LS, Epoch 19/20, Loss: 6.341699428399932e-05 \n",
      "SNR: 25/35, LS, Val Loss: 5.7977502365247346e-05\n",
      "SNR: 25/35, LS, Epoch 20/20, Loss: 5.943762122421171e-05 \n",
      "SNR: 25/35, LS, Val Loss: 5.381759759378232e-05\n",
      "LS+CNN NMSE: 0.0017579775303602219\n",
      " SNR: 30/35\n",
      " Training for LS+LI\n",
      "SNR: 30/35, LS+LI, Epoch 1/20, Loss: 0.08684403778948259 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.011338979781915745\n",
      "SNR: 30/35, LS+LI, Epoch 2/20, Loss: 0.00346680946122523 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.0008021995430074943\n",
      "SNR: 30/35, LS+LI, Epoch 3/20, Loss: 0.0005364297378559293 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.0003952331656667714\n",
      "SNR: 30/35, LS+LI, Epoch 4/20, Loss: 0.0003009783086052284 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.00023067184641452818\n",
      "SNR: 30/35, LS+LI, Epoch 5/20, Loss: 0.00017040366835524513 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.0001354963924313779\n",
      "SNR: 30/35, LS+LI, Epoch 6/20, Loss: 0.00010719082994982461 \n",
      "SNR: 30/35, LS+LI, Val Loss: 9.125358580301206e-05\n",
      "SNR: 30/35, LS+LI, Epoch 7/20, Loss: 7.658971457437861e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 6.906915920505223e-05\n",
      "SNR: 30/35, LS+LI, Epoch 8/20, Loss: 5.994201455905568e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 5.530602690366019e-05\n",
      "SNR: 30/35, LS+LI, Epoch 9/20, Loss: 4.8045774134818814e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 4.4457195751116764e-05\n",
      "SNR: 30/35, LS+LI, Epoch 10/20, Loss: 3.915748615921498e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 3.6436743812373606e-05\n",
      "SNR: 30/35, LS+LI, Epoch 11/20, Loss: 3.217902517147618e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 2.994171344046966e-05\n",
      "SNR: 30/35, LS+LI, Epoch 12/20, Loss: 2.6423592704070483e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 2.3957183429956785e-05\n",
      "SNR: 30/35, LS+LI, Epoch 13/20, Loss: 2.0268316816192495e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 1.8033267110695306e-05\n",
      "SNR: 30/35, LS+LI, Epoch 14/20, Loss: 1.5419539639617933e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 1.388093721743644e-05\n",
      "SNR: 30/35, LS+LI, Epoch 15/20, Loss: 1.2033668603594784e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 1.1000154358953296e-05\n",
      "SNR: 30/35, LS+LI, Epoch 16/20, Loss: 9.621618130382774e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 8.789362690701333e-06\n",
      "SNR: 30/35, LS+LI, Epoch 17/20, Loss: 7.852912957706294e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 7.366070974512695e-06\n",
      "SNR: 30/35, LS+LI, Epoch 18/20, Loss: 6.671163740939297e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 6.356344821748887e-06\n",
      "SNR: 30/35, LS+LI, Epoch 19/20, Loss: 5.7973049708812365e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 5.474126188194835e-06\n",
      "SNR: 30/35, LS+LI, Epoch 20/20, Loss: 5.057011968923383e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 4.913581250320931e-06\n",
      "LS+LI NMSE: 0.00016702823631931096\n",
      "LS+LI+CNN NMSE: 0.00014582174480892718\n",
      " Training for LS\n",
      "SNR: 30/35, LS, Epoch 1/20, Loss: 0.128930545421225 \n",
      "SNR: 30/35, LS, Val Loss: 0.043946373431632914\n",
      "SNR: 30/35, LS, Epoch 2/20, Loss: 0.03271697970605133 \n",
      "SNR: 30/35, LS, Val Loss: 0.027551240830992658\n",
      "SNR: 30/35, LS, Epoch 3/20, Loss: 0.01871243646681899 \n",
      "SNR: 30/35, LS, Val Loss: 0.00780404588052382\n",
      "SNR: 30/35, LS, Epoch 4/20, Loss: 0.0025952176604705796 \n",
      "SNR: 30/35, LS, Val Loss: 0.001290246097293372\n",
      "SNR: 30/35, LS, Epoch 5/20, Loss: 0.0009313377209980557 \n",
      "SNR: 30/35, LS, Val Loss: 0.0007221167519067725\n",
      "SNR: 30/35, LS, Epoch 6/20, Loss: 0.0005854751343036642 \n",
      "SNR: 30/35, LS, Val Loss: 0.000522266237870402\n",
      "SNR: 30/35, LS, Epoch 7/20, Loss: 0.00043077243732329975 \n",
      "SNR: 30/35, LS, Val Loss: 0.0003906522385174564\n",
      "SNR: 30/35, LS, Epoch 8/20, Loss: 0.000336022044997086 \n",
      "SNR: 30/35, LS, Val Loss: 0.0003094742878602119\n",
      "SNR: 30/35, LS, Epoch 9/20, Loss: 0.0002734982098814672 \n",
      "SNR: 30/35, LS, Val Loss: 0.00025563215725317906\n",
      "SNR: 30/35, LS, Epoch 10/20, Loss: 0.00023085585244099084 \n",
      "SNR: 30/35, LS, Val Loss: 0.00022179797512459723\n",
      "SNR: 30/35, LS, Epoch 11/20, Loss: 0.000199957634610502 \n",
      "SNR: 30/35, LS, Val Loss: 0.00019281762191288485\n",
      "SNR: 30/35, LS, Epoch 12/20, Loss: 0.00017576201294150002 \n",
      "SNR: 30/35, LS, Val Loss: 0.0001689386720803062\n",
      "SNR: 30/35, LS, Epoch 13/20, Loss: 0.00015611579636801127 \n",
      "SNR: 30/35, LS, Val Loss: 0.00016240195297238338\n",
      "SNR: 30/35, LS, Epoch 14/20, Loss: 0.00013985173539160566 \n",
      "SNR: 30/35, LS, Val Loss: 0.00013387601696498072\n",
      "SNR: 30/35, LS, Epoch 15/20, Loss: 0.00012562879473449303 \n",
      "SNR: 30/35, LS, Val Loss: 0.00012106711740974181\n",
      "SNR: 30/35, LS, Epoch 16/20, Loss: 0.00011369861403911255 \n",
      "SNR: 30/35, LS, Val Loss: 0.00010841985931620002\n",
      "SNR: 30/35, LS, Epoch 17/20, Loss: 0.00010320368074635643 \n",
      "SNR: 30/35, LS, Val Loss: 9.788270290300716e-05\n",
      "SNR: 30/35, LS, Epoch 18/20, Loss: 9.314169709805266e-05 \n",
      "SNR: 30/35, LS, Val Loss: 9.133712956099771e-05\n",
      "SNR: 30/35, LS, Epoch 19/20, Loss: 8.510531159405975e-05 \n",
      "SNR: 30/35, LS, Val Loss: 8.578843547487243e-05\n",
      "SNR: 30/35, LS, Epoch 20/20, Loss: 7.819331810901306e-05 \n",
      "SNR: 30/35, LS, Val Loss: 8.064515410903066e-05\n",
      "LS+CNN NMSE: 0.0023928144946694374\n",
      " SNR: 35/35\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/home/thien/Hprediction/one_shot_Hest_cleanver/DeepMIMOv2/DeepMIMO_Data/Static_BS16/freq_symb_1ant_612sub/Gan_35_dBOutdoor1_60_1ant_612subcs_Row_1500_1509.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outer_file_path, file_path_partial)\n\u001b[1;32m     22\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(file_path)\n\u001b[0;32m---> 23\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m H_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((H_true, np\u001b[38;5;241m.\u001b[39marray(file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_data\u001b[39m\u001b[38;5;124m'\u001b[39m])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# N_samples x channel(2) x height(614) x width(14)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m H_equal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((H_equal, np\u001b[38;5;241m.\u001b[39marray(file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_equalized_data\u001b[39m\u001b[38;5;124m'\u001b[39m])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_GPU/lib/python3.8/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/Torch_GPU/lib/python3.8/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/thien/Hprediction/one_shot_Hest_cleanver/DeepMIMOv2/DeepMIMO_Data/Static_BS16/freq_symb_1ant_612sub/Gan_35_dBOutdoor1_60_1ant_612subcs_Row_1500_1509.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['1500', '1509'], ['3916', '3920']] \n",
    "rowss = \"1500_1509_3916_3920\"\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub'))\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "\n",
    "    H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "    H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "    H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "    # read data from ifferent .mat file, then concatenate them\n",
    "    for i in range(len(rows)):\n",
    "        file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_60_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "        file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "        file_path = os.path.normpath(file_path)\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        \n",
    "        H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "        H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "        H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "        H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)\n",
    "\n",
    "    shuffle_order = np.random.permutation(H_true.shape[0]);\n",
    "    H_true = torch.tensor(H_true[shuffle_order])\n",
    "    H_equal = torch.tensor(H_equal[shuffle_order])\n",
    "    H_linear = torch.tensor(H_linear[shuffle_order])\n",
    "    H_practical = torch.tensor(H_practical[shuffle_order])\n",
    "\n",
    "    train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "    train_size = int(train_size)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # 1.1 Split into training and validation sets for H_NN training\n",
    "    trainData   = H_linear[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Split H_equal, H_linear, H_practical for validation later\n",
    "    H_equal_val = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_linear_val = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_practical_val = H_practical[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # 1.2 Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    # for evaluation, output of model(valData) will be de-normalized and compared with valLabels\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    # 1.3 Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 1.4 model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    learning_rate = 0.00001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver2', str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                'train_min_LI': trainData_min.cpu(),\n",
    "                'train_max_LI': trainData_max.cpu(),\n",
    "                'train_label_min': trainLabels_min.cpu(),\n",
    "                'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, str(snr) + 'dB') \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_true[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('True Channel')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_trueChannel.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = valData.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_linInterp[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS + Interpolate Estimated Channel, NMSE: {nmse_LI:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_estimatedChan.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('LI+CNN Estimated Channel (before de-normlized)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan_before_denorm.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # De-normalized\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LI+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LI_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_LI_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # Split into training and validation sets for H_NN training\n",
    "    trainData   = H_equal[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    H_temp = trainData.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_temp[0,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS Channel')\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Chan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    learning_rate = 0.00001\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    x = range(1, len(val_loss) + 1)\n",
    "    plt.plot(x,train_loss, label='Training Loss')\n",
    "    plt.plot(x,val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(range(0, len(val_loss) + 1, int(len(val_loss)/5)))\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "    variables['train_min_LS']= trainData_min.cpu()\n",
    "    variables['train_max_LS']= trainData_max.cpu()\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LS_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(figure_save_path,  str(index_save) + '_LS_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
