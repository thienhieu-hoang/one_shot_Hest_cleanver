{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tempfile import TemporaryFile\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AT30890\\Hoctap\\Hprediction\\H_est_cGAN\\Channel_Estimation_cGAN_new\\Channel_Estimation_cGAN\\Torch_code\\train\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AT30890\\Hoctap\\Hprediction\\H_est_cGAN\\Channel_Estimation_cGAN_new\\Channel_Estimation_cGAN\\Torch_code\n"
     ]
    }
   ],
   "source": [
    "print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/35\n",
      " Training for LS+LI\n",
      "SNR: 0/35, LS+LI, Epoch 1/20, Loss: 0.09429796080803499 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.028029144353543717\n",
      "SNR: 0/35, LS+LI, Epoch 2/20, Loss: 0.01724621262110304 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.01219334825873375\n",
      "SNR: 0/35, LS+LI, Epoch 3/20, Loss: 0.007287797718163347 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.002619391850506266\n",
      "SNR: 0/35, LS+LI, Epoch 4/20, Loss: 0.001714134645832625 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0013193897563420858\n",
      "SNR: 0/35, LS+LI, Epoch 5/20, Loss: 0.0010574158350209473 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.000882947351783514\n",
      "SNR: 0/35, LS+LI, Epoch 6/20, Loss: 0.0007446678804020243 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0006414688056490073\n",
      "SNR: 0/35, LS+LI, Epoch 7/20, Loss: 0.0005508470918963818 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0005020009254318817\n",
      "SNR: 0/35, LS+LI, Epoch 8/20, Loss: 0.00043238663389881066 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0003962052602825376\n",
      "SNR: 0/35, LS+LI, Epoch 9/20, Loss: 0.00036057899327109527 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00033969005016842857\n",
      "SNR: 0/35, LS+LI, Epoch 10/20, Loss: 0.00031333472202277335 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002996212315338198\n",
      "SNR: 0/35, LS+LI, Epoch 11/20, Loss: 0.00028387601666205836 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002814974389669563\n",
      "SNR: 0/35, LS+LI, Epoch 12/20, Loss: 0.00026447220473831595 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002609972919647892\n",
      "SNR: 0/35, LS+LI, Epoch 13/20, Loss: 0.0002489257022565046 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002485009742182835\n",
      "SNR: 0/35, LS+LI, Epoch 14/20, Loss: 0.0002368844813342245 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.0002355421383981593\n",
      "SNR: 0/35, LS+LI, Epoch 15/20, Loss: 0.00023011174835119164 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00022867208220607912\n",
      "SNR: 0/35, LS+LI, Epoch 16/20, Loss: 0.00022179506208885869 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00022148706072281735\n",
      "SNR: 0/35, LS+LI, Epoch 17/20, Loss: 0.00021802132512978764 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021902373130918326\n",
      "SNR: 0/35, LS+LI, Epoch 18/20, Loss: 0.00021117500887157803 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021110408912742665\n",
      "SNR: 0/35, LS+LI, Epoch 19/20, Loss: 0.00020675769330106655 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021237895089143422\n",
      "SNR: 0/35, LS+LI, Epoch 20/20, Loss: 0.0002030451234228773 \n",
      "SNR: 0/35, LS+LI, Val Loss: 0.00021437178778190477\n",
      "LS+LI NMSE: 0.08212301135063171\n",
      "LS+LI+CNN NMSE: 0.008113346062600613\n",
      " Training for LS\n",
      "SNR: 0/35, LS, Epoch 1/20, Loss: 0.11867819052228394 \n",
      "SNR: 0/35, LS, Val Loss: 0.03475515839333335\n",
      "SNR: 0/35, LS, Epoch 2/20, Loss: 0.02652342170282888 \n",
      "SNR: 0/35, LS, Val Loss: 0.02381906860197584\n",
      "SNR: 0/35, LS, Epoch 3/20, Loss: 0.02047871887528648 \n",
      "SNR: 0/35, LS, Val Loss: 0.016177643633758027\n",
      "SNR: 0/35, LS, Epoch 4/20, Loss: 0.008792486230959184 \n",
      "SNR: 0/35, LS, Val Loss: 0.003599344490794465\n",
      "SNR: 0/35, LS, Epoch 5/20, Loss: 0.002440927777570323 \n",
      "SNR: 0/35, LS, Val Loss: 0.0018399220571154729\n",
      "SNR: 0/35, LS, Epoch 6/20, Loss: 0.0014644973756124575 \n",
      "SNR: 0/35, LS, Val Loss: 0.0012428476935989845\n",
      "SNR: 0/35, LS, Epoch 7/20, Loss: 0.0009883096348251759 \n",
      "SNR: 0/35, LS, Val Loss: 0.0008773977945869168\n",
      "SNR: 0/35, LS, Epoch 8/20, Loss: 0.0007525545352109475 \n",
      "SNR: 0/35, LS, Val Loss: 0.0006860007464032\n",
      "SNR: 0/35, LS, Epoch 9/20, Loss: 0.0006225202171966279 \n",
      "SNR: 0/35, LS, Val Loss: 0.0005825729203934316\n",
      "SNR: 0/35, LS, Epoch 10/20, Loss: 0.0005279077116332095 \n",
      "SNR: 0/35, LS, Val Loss: 0.0004998396325390786\n",
      "SNR: 0/35, LS, Epoch 11/20, Loss: 0.0004641825950481386 \n",
      "SNR: 0/35, LS, Val Loss: 0.0005221305048811095\n",
      "SNR: 0/35, LS, Epoch 12/20, Loss: 0.00043238282417708734 \n",
      "SNR: 0/35, LS, Val Loss: 0.00041335876449011266\n",
      "SNR: 0/35, LS, Epoch 13/20, Loss: 0.00039786904714371 \n",
      "SNR: 0/35, LS, Val Loss: 0.00039160789068167407\n",
      "SNR: 0/35, LS, Epoch 14/20, Loss: 0.00037263941476339824 \n",
      "SNR: 0/35, LS, Val Loss: 0.00036553617489213747\n",
      "SNR: 0/35, LS, Epoch 15/20, Loss: 0.0003537510451678827 \n",
      "SNR: 0/35, LS, Val Loss: 0.00034811563697682385\n",
      "SNR: 0/35, LS, Epoch 16/20, Loss: 0.00034118089683943253 \n",
      "SNR: 0/35, LS, Val Loss: 0.00033159203606677085\n",
      "SNR: 0/35, LS, Epoch 17/20, Loss: 0.00032960232586750254 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003756605171171638\n",
      "SNR: 0/35, LS, Epoch 18/20, Loss: 0.00032074599607767595 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003489836684214727\n",
      "SNR: 0/35, LS, Epoch 19/20, Loss: 0.00031541004083616525 \n",
      "SNR: 0/35, LS, Val Loss: 0.0003470907286100555\n",
      "SNR: 0/35, LS, Epoch 20/20, Loss: 0.0003017484317903533 \n",
      "SNR: 0/35, LS, Val Loss: 0.00031629759663095075\n",
      "LS+CNN NMSE: 0.011955869384109974\n",
      " SNR: 5/35\n",
      " Training for LS+LI\n",
      "SNR: 5/35, LS+LI, Epoch 1/20, Loss: 0.10986365160594384 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.024189877168585856\n",
      "SNR: 5/35, LS+LI, Epoch 2/20, Loss: 0.01308595976054979 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.006795800543234994\n",
      "SNR: 5/35, LS+LI, Epoch 3/20, Loss: 0.0028980325372079583 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0011085379495246646\n",
      "SNR: 5/35, LS+LI, Epoch 4/20, Loss: 0.0007589519270065163 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.000539464087826976\n",
      "SNR: 5/35, LS+LI, Epoch 5/20, Loss: 0.000405230325213779 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0003074591058975784\n",
      "SNR: 5/35, LS+LI, Epoch 6/20, Loss: 0.0002463816097133531 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.0002067513942165533\n",
      "SNR: 5/35, LS+LI, Epoch 7/20, Loss: 0.00017997037578728245 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00016643310967386546\n",
      "SNR: 5/35, LS+LI, Epoch 8/20, Loss: 0.000150616966607231 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00014473823102889583\n",
      "SNR: 5/35, LS+LI, Epoch 9/20, Loss: 0.0001346034097574981 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00013141071788898748\n",
      "SNR: 5/35, LS+LI, Epoch 10/20, Loss: 0.00012319740604501325 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00012160494103833723\n",
      "SNR: 5/35, LS+LI, Epoch 11/20, Loss: 0.00011385747351747948 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00011213055374052298\n",
      "SNR: 5/35, LS+LI, Epoch 12/20, Loss: 0.00010679098280282535 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00010553403778127783\n",
      "SNR: 5/35, LS+LI, Epoch 13/20, Loss: 0.00010074656529468484 \n",
      "SNR: 5/35, LS+LI, Val Loss: 0.00010065132391900988\n",
      "SNR: 5/35, LS+LI, Epoch 14/20, Loss: 9.548328171149478e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 9.537603121619516e-05\n",
      "SNR: 5/35, LS+LI, Epoch 15/20, Loss: 9.049686205268397e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 8.930598354102888e-05\n",
      "SNR: 5/35, LS+LI, Epoch 16/20, Loss: 8.635139268638643e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 8.599612222800108e-05\n",
      "SNR: 5/35, LS+LI, Epoch 17/20, Loss: 8.270546247028203e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 8.190937235970826e-05\n",
      "SNR: 5/35, LS+LI, Epoch 18/20, Loss: 7.971822380644274e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 7.886481322808929e-05\n",
      "SNR: 5/35, LS+LI, Epoch 19/20, Loss: 7.695357836231172e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 7.898987541921088e-05\n",
      "SNR: 5/35, LS+LI, Epoch 20/20, Loss: 7.493328162884912e-05 \n",
      "SNR: 5/35, LS+LI, Val Loss: 7.460042221888823e-05\n",
      "LS+LI NMSE: 0.026123691350221634\n",
      "LS+LI+CNN NMSE: 0.0028195446357131004\n",
      " Training for LS\n",
      "SNR: 5/35, LS, Epoch 1/20, Loss: 0.08909422727689768 \n",
      "SNR: 5/35, LS, Val Loss: 0.030027471482753754\n",
      "SNR: 5/35, LS, Epoch 2/20, Loss: 0.02484685101080686 \n",
      "SNR: 5/35, LS, Val Loss: 0.02292041728893916\n",
      "SNR: 5/35, LS, Epoch 3/20, Loss: 0.018582898842093225 \n",
      "SNR: 5/35, LS, Val Loss: 0.011925653593304256\n",
      "SNR: 5/35, LS, Epoch 4/20, Loss: 0.004153932001524178 \n",
      "SNR: 5/35, LS, Val Loss: 0.0011022288672393188\n",
      "SNR: 5/35, LS, Epoch 5/20, Loss: 0.0008810298692575694 \n",
      "SNR: 5/35, LS, Val Loss: 0.0007638234407446968\n",
      "SNR: 5/35, LS, Epoch 6/20, Loss: 0.00068372370878933 \n",
      "SNR: 5/35, LS, Val Loss: 0.0006347962153085973\n",
      "SNR: 5/35, LS, Epoch 7/20, Loss: 0.0005705758217118273 \n",
      "SNR: 5/35, LS, Val Loss: 0.0005420289950658722\n",
      "SNR: 5/35, LS, Epoch 8/20, Loss: 0.0004844626281131544 \n",
      "SNR: 5/35, LS, Val Loss: 0.0004775996955383259\n",
      "SNR: 5/35, LS, Epoch 9/20, Loss: 0.00041605561955293524 \n",
      "SNR: 5/35, LS, Val Loss: 0.0004044321431138087\n",
      "SNR: 5/35, LS, Epoch 10/20, Loss: 0.0003595408400087763 \n",
      "SNR: 5/35, LS, Val Loss: 0.0003367180561326677\n",
      "SNR: 5/35, LS, Epoch 11/20, Loss: 0.00031350328299595276 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002966946152203794\n",
      "SNR: 5/35, LS, Epoch 12/20, Loss: 0.00028165014547691197 \n",
      "SNR: 5/35, LS, Val Loss: 0.000274456397164613\n",
      "SNR: 5/35, LS, Epoch 13/20, Loss: 0.00025479395996323245 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002461170946238174\n",
      "SNR: 5/35, LS, Epoch 14/20, Loss: 0.00023668722845589704 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002270432214572793\n",
      "SNR: 5/35, LS, Epoch 15/20, Loss: 0.0002182807739548783 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002117658071559466\n",
      "SNR: 5/35, LS, Epoch 16/20, Loss: 0.00021108231294419966 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002021200028442157\n",
      "SNR: 5/35, LS, Epoch 17/20, Loss: 0.00019617242662661738 \n",
      "SNR: 5/35, LS, Val Loss: 0.00019156818962073885\n",
      "SNR: 5/35, LS, Epoch 18/20, Loss: 0.00019031595900287357 \n",
      "SNR: 5/35, LS, Val Loss: 0.0002459473247048057\n",
      "SNR: 5/35, LS, Epoch 19/20, Loss: 0.00018238613987856903 \n",
      "SNR: 5/35, LS, Val Loss: 0.00017578459483047482\n",
      "SNR: 5/35, LS, Epoch 20/20, Loss: 0.00017202183149341485 \n",
      "SNR: 5/35, LS, Val Loss: 0.00016613947385242986\n",
      "LS+CNN NMSE: 0.00629715109243989\n",
      " SNR: 10/35\n",
      " Training for LS+LI\n",
      "SNR: 10/35, LS+LI, Epoch 1/20, Loss: 0.1408331374890016 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.020214235332484048\n",
      "SNR: 10/35, LS+LI, Epoch 2/20, Loss: 0.008706783612675887 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.0030554377493293336\n",
      "SNR: 10/35, LS+LI, Epoch 3/20, Loss: 0.0013513016444145858 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.0006513150171182739\n",
      "SNR: 10/35, LS+LI, Epoch 4/20, Loss: 0.0004815431154080822 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.00032905314583331347\n",
      "SNR: 10/35, LS+LI, Epoch 5/20, Loss: 0.000254586376968291 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.00018862941578845493\n",
      "SNR: 10/35, LS+LI, Epoch 6/20, Loss: 0.0001542040741545255 \n",
      "SNR: 10/35, LS+LI, Val Loss: 0.00012148318122247777\n",
      "SNR: 10/35, LS+LI, Epoch 7/20, Loss: 0.00010763464793702345 \n",
      "SNR: 10/35, LS+LI, Val Loss: 9.214488636644091e-05\n",
      "SNR: 10/35, LS+LI, Epoch 8/20, Loss: 8.59184632039008e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 7.716189217414164e-05\n",
      "SNR: 10/35, LS+LI, Epoch 9/20, Loss: 7.271588911332098e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 6.597572413132487e-05\n",
      "SNR: 10/35, LS+LI, Epoch 10/20, Loss: 6.364191979931395e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 5.827625060798406e-05\n",
      "SNR: 10/35, LS+LI, Epoch 11/20, Loss: 5.66469322507146e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 5.263569725381482e-05\n",
      "SNR: 10/35, LS+LI, Epoch 12/20, Loss: 5.1628752335849036e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.891781100013759e-05\n",
      "SNR: 10/35, LS+LI, Epoch 13/20, Loss: 4.7812899045614664e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.550120956992032e-05\n",
      "SNR: 10/35, LS+LI, Epoch 14/20, Loss: 4.4204048426384666e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 4.179863162789843e-05\n",
      "SNR: 10/35, LS+LI, Epoch 15/20, Loss: 4.164892054821697e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.915579585130521e-05\n",
      "SNR: 10/35, LS+LI, Epoch 16/20, Loss: 3.9013087606084205e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.6876813813554086e-05\n",
      "SNR: 10/35, LS+LI, Epoch 17/20, Loss: 3.681022982959803e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.51543307412309e-05\n",
      "SNR: 10/35, LS+LI, Epoch 18/20, Loss: 3.5089479969959335e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.330656924542078e-05\n",
      "SNR: 10/35, LS+LI, Epoch 19/20, Loss: 3.350895348338175e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.225889478623382e-05\n",
      "SNR: 10/35, LS+LI, Epoch 20/20, Loss: 3.244483348415391e-05 \n",
      "SNR: 10/35, LS+LI, Val Loss: 3.0844673347019125e-05\n",
      "LS+LI NMSE: 0.008314792066812515\n",
      "LS+LI+CNN NMSE: 0.0012069711228832603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AT30890\\AppData\\Local\\Temp\\ipykernel_23068\\1234052587.py:251: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS\n",
      "SNR: 10/35, LS, Epoch 1/20, Loss: 0.1214221907236303 \n",
      "SNR: 10/35, LS, Val Loss: 0.03825410036370158\n",
      "SNR: 10/35, LS, Epoch 2/20, Loss: 0.029097594403234932 \n",
      "SNR: 10/35, LS, Val Loss: 0.02281663039078315\n",
      "SNR: 10/35, LS, Epoch 3/20, Loss: 0.020556683302856982 \n",
      "SNR: 10/35, LS, Val Loss: 0.016445850487798452\n",
      "SNR: 10/35, LS, Epoch 4/20, Loss: 0.00963937026729885 \n",
      "SNR: 10/35, LS, Val Loss: 0.0026196724987433604\n",
      "SNR: 10/35, LS, Epoch 5/20, Loss: 0.0014330238755064784 \n",
      "SNR: 10/35, LS, Val Loss: 0.0009085535032985111\n",
      "SNR: 10/35, LS, Epoch 6/20, Loss: 0.0007254838421128321 \n",
      "SNR: 10/35, LS, Val Loss: 0.000544130826407733\n",
      "SNR: 10/35, LS, Epoch 7/20, Loss: 0.0004540430786619254 \n",
      "SNR: 10/35, LS, Val Loss: 0.00036060816880005103\n",
      "SNR: 10/35, LS, Epoch 8/20, Loss: 0.0002947949856206833 \n",
      "SNR: 10/35, LS, Val Loss: 0.000237406199327476\n",
      "SNR: 10/35, LS, Epoch 9/20, Loss: 0.0002221192296474328 \n",
      "SNR: 10/35, LS, Val Loss: 0.00019967994315569135\n",
      "SNR: 10/35, LS, Epoch 10/20, Loss: 0.00019225418433658584 \n",
      "SNR: 10/35, LS, Val Loss: 0.00017958760872716084\n",
      "SNR: 10/35, LS, Epoch 11/20, Loss: 0.00017496110524461983 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001745190365909366\n",
      "SNR: 10/35, LS, Epoch 12/20, Loss: 0.00016283854696060493 \n",
      "SNR: 10/35, LS, Val Loss: 0.00015942675175513918\n",
      "SNR: 10/35, LS, Epoch 13/20, Loss: 0.0001543488912526906 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001477035563463384\n",
      "SNR: 10/35, LS, Epoch 14/20, Loss: 0.00014566354555730263 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001409251093112592\n",
      "SNR: 10/35, LS, Epoch 15/20, Loss: 0.00013833659238571272 \n",
      "SNR: 10/35, LS, Val Loss: 0.00013257279442768777\n",
      "SNR: 10/35, LS, Epoch 16/20, Loss: 0.00013326164560112375 \n",
      "SNR: 10/35, LS, Val Loss: 0.0001289564373413062\n",
      "SNR: 10/35, LS, Epoch 17/20, Loss: 0.00012832372703996953 \n",
      "SNR: 10/35, LS, Val Loss: 0.00012254930576697612\n",
      "SNR: 10/35, LS, Epoch 18/20, Loss: 0.00012252877915367813 \n",
      "SNR: 10/35, LS, Val Loss: 0.00011815849029517267\n",
      "SNR: 10/35, LS, Epoch 19/20, Loss: 0.00011762051068823591 \n",
      "SNR: 10/35, LS, Val Loss: 0.00011200389963050839\n",
      "SNR: 10/35, LS, Epoch 20/20, Loss: 0.00011214138498871762 \n",
      "SNR: 10/35, LS, Val Loss: 0.000107344984220011\n",
      "LS+CNN NMSE: 0.004191394429653883\n",
      " SNR: 15/35\n",
      " Training for LS+LI\n",
      "SNR: 15/35, LS+LI, Epoch 1/20, Loss: 0.09672655436831216 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.01418567068564395\n",
      "SNR: 15/35, LS+LI, Epoch 2/20, Loss: 0.004536525036201056 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0009843196651975934\n",
      "SNR: 15/35, LS+LI, Epoch 3/20, Loss: 0.0005829123153186325 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0004072725605510641\n",
      "SNR: 15/35, LS+LI, Epoch 4/20, Loss: 0.0003186111302208398 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0002512166174710728\n",
      "SNR: 15/35, LS+LI, Epoch 5/20, Loss: 0.00017751229374122582 \n",
      "SNR: 15/35, LS+LI, Val Loss: 0.0001323140562211241\n",
      "SNR: 15/35, LS+LI, Epoch 6/20, Loss: 0.00010987519957931606 \n",
      "SNR: 15/35, LS+LI, Val Loss: 9.378260680629562e-05\n",
      "SNR: 15/35, LS+LI, Epoch 7/20, Loss: 8.271290031795313e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 7.438099813346828e-05\n",
      "SNR: 15/35, LS+LI, Epoch 8/20, Loss: 6.709758146901852e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 6.108719223144969e-05\n",
      "SNR: 15/35, LS+LI, Epoch 9/20, Loss: 5.559784699471493e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 5.120484168704328e-05\n",
      "SNR: 15/35, LS+LI, Epoch 10/20, Loss: 4.753414473649779e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 4.4465537181774074e-05\n",
      "SNR: 15/35, LS+LI, Epoch 11/20, Loss: 4.153548439944643e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 3.91417124774307e-05\n",
      "SNR: 15/35, LS+LI, Epoch 12/20, Loss: 3.6491630282853293e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 3.425580174128603e-05\n",
      "SNR: 15/35, LS+LI, Epoch 13/20, Loss: 3.202086055390888e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 3.003727700464272e-05\n",
      "SNR: 15/35, LS+LI, Epoch 14/20, Loss: 2.812492409513349e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.6378996759982936e-05\n",
      "SNR: 15/35, LS+LI, Epoch 15/20, Loss: 2.482599763690511e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.3304855782650218e-05\n",
      "SNR: 15/35, LS+LI, Epoch 16/20, Loss: 2.20302970319608e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 2.0825026467719e-05\n",
      "SNR: 15/35, LS+LI, Epoch 17/20, Loss: 1.982261215971448e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 1.872860896886171e-05\n",
      "SNR: 15/35, LS+LI, Epoch 18/20, Loss: 1.7858306558575048e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 1.7003435611210687e-05\n",
      "SNR: 15/35, LS+LI, Epoch 19/20, Loss: 1.641058347464271e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 1.6543579931749264e-05\n",
      "SNR: 15/35, LS+LI, Epoch 20/20, Loss: 1.5158171133104284e-05 \n",
      "SNR: 15/35, LS+LI, Val Loss: 1.4792220175271117e-05\n",
      "LS+LI NMSE: 0.002655960386618972\n",
      "LS+LI+CNN NMSE: 0.0005611475207842886\n",
      " Training for LS\n",
      "SNR: 15/35, LS, Epoch 1/20, Loss: 0.12127892232577626 \n",
      "SNR: 15/35, LS, Val Loss: 0.03851350008820494\n",
      "SNR: 15/35, LS, Epoch 2/20, Loss: 0.02714280117652379 \n",
      "SNR: 15/35, LS, Val Loss: 0.022211292758584023\n",
      "SNR: 15/35, LS, Epoch 3/20, Loss: 0.018158549374978367 \n",
      "SNR: 15/35, LS, Val Loss: 0.013255485294697186\n",
      "SNR: 15/35, LS, Epoch 4/20, Loss: 0.006142309800755659 \n",
      "SNR: 15/35, LS, Val Loss: 0.001506809494458139\n",
      "SNR: 15/35, LS, Epoch 5/20, Loss: 0.0009656379982819393 \n",
      "SNR: 15/35, LS, Val Loss: 0.0007548861758550629\n",
      "SNR: 15/35, LS, Epoch 6/20, Loss: 0.000627111102555015 \n",
      "SNR: 15/35, LS, Val Loss: 0.0005422321106986298\n",
      "SNR: 15/35, LS, Epoch 7/20, Loss: 0.0004558074686732046 \n",
      "SNR: 15/35, LS, Val Loss: 0.0003936123260549114\n",
      "SNR: 15/35, LS, Epoch 8/20, Loss: 0.0003456981216913846 \n",
      "SNR: 15/35, LS, Val Loss: 0.00029781322094398394\n",
      "SNR: 15/35, LS, Epoch 9/20, Loss: 0.000258405210388446 \n",
      "SNR: 15/35, LS, Val Loss: 0.00024036136043529646\n",
      "SNR: 15/35, LS, Epoch 10/20, Loss: 0.00020054546863927195 \n",
      "SNR: 15/35, LS, Val Loss: 0.00017685326686963285\n",
      "SNR: 15/35, LS, Epoch 11/20, Loss: 0.00016691725382618947 \n",
      "SNR: 15/35, LS, Val Loss: 0.00015148580981379686\n",
      "SNR: 15/35, LS, Epoch 12/20, Loss: 0.0001482151415454306 \n",
      "SNR: 15/35, LS, Val Loss: 0.00013580677659774665\n",
      "SNR: 15/35, LS, Epoch 13/20, Loss: 0.00013094217263187602 \n",
      "SNR: 15/35, LS, Val Loss: 0.0001232320831453156\n",
      "SNR: 15/35, LS, Epoch 14/20, Loss: 0.0001222926864556939 \n",
      "SNR: 15/35, LS, Val Loss: 0.00011379880015738308\n",
      "SNR: 15/35, LS, Epoch 15/20, Loss: 0.00011383473160246164 \n",
      "SNR: 15/35, LS, Val Loss: 0.00011016980897693429\n",
      "SNR: 15/35, LS, Epoch 16/20, Loss: 0.0001043856503126032 \n",
      "SNR: 15/35, LS, Val Loss: 0.00011467221884231549\n",
      "SNR: 15/35, LS, Epoch 17/20, Loss: 9.776642169375312e-05 \n",
      "SNR: 15/35, LS, Val Loss: 9.149826473731082e-05\n",
      "SNR: 15/35, LS, Epoch 18/20, Loss: 9.022767335409299e-05 \n",
      "SNR: 15/35, LS, Val Loss: 8.6784441312678e-05\n",
      "SNR: 15/35, LS, Epoch 19/20, Loss: 8.682338809270125e-05 \n",
      "SNR: 15/35, LS, Val Loss: 8.295918905787403e-05\n",
      "SNR: 15/35, LS, Epoch 20/20, Loss: 8.10059995425642e-05 \n",
      "SNR: 15/35, LS, Val Loss: 9.5406622979984e-05\n",
      "LS+CNN NMSE: 0.003620132338255644\n",
      " SNR: 20/35\n",
      " Training for LS+LI\n",
      "SNR: 20/35, LS+LI, Epoch 1/20, Loss: 0.07915250918692134 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.008581222888703147\n",
      "SNR: 20/35, LS+LI, Epoch 2/20, Loss: 0.002158563850874392 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.0006255416519707069\n",
      "SNR: 20/35, LS+LI, Epoch 3/20, Loss: 0.0004891039135751877 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.0003723491281562019\n",
      "SNR: 20/35, LS+LI, Epoch 4/20, Loss: 0.0003055582545433329 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.00023742094466191097\n",
      "SNR: 20/35, LS+LI, Epoch 5/20, Loss: 0.00019558503277039563 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.0001528672140314787\n",
      "SNR: 20/35, LS+LI, Epoch 6/20, Loss: 0.0001283544012646113 \n",
      "SNR: 20/35, LS+LI, Val Loss: 0.00010379249943071045\n",
      "SNR: 20/35, LS+LI, Epoch 7/20, Loss: 9.053969108663296e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 7.64732858442585e-05\n",
      "SNR: 20/35, LS+LI, Epoch 8/20, Loss: 6.908830747912968e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 5.990886681198996e-05\n",
      "SNR: 20/35, LS+LI, Epoch 9/20, Loss: 5.451852623158023e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 4.7423012953610545e-05\n",
      "SNR: 20/35, LS+LI, Epoch 10/20, Loss: 4.373337568116161e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 3.8800550100859255e-05\n",
      "SNR: 20/35, LS+LI, Epoch 11/20, Loss: 3.5259037834597016e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 3.0408707592262847e-05\n",
      "SNR: 20/35, LS+LI, Epoch 12/20, Loss: 2.7589894045831898e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 2.4131098825819208e-05\n",
      "SNR: 20/35, LS+LI, Epoch 13/20, Loss: 2.2362770418264215e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.9912198619446524e-05\n",
      "SNR: 20/35, LS+LI, Epoch 14/20, Loss: 1.8690183457200266e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.6764166768249805e-05\n",
      "SNR: 20/35, LS+LI, Epoch 15/20, Loss: 1.5882296930650835e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.4406843888536969e-05\n",
      "SNR: 20/35, LS+LI, Epoch 16/20, Loss: 1.3704391553422587e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.2445180497403877e-05\n",
      "SNR: 20/35, LS+LI, Epoch 17/20, Loss: 1.1941375371786004e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 1.091669632084328e-05\n",
      "SNR: 20/35, LS+LI, Epoch 18/20, Loss: 1.0516552469160464e-05 \n",
      "SNR: 20/35, LS+LI, Val Loss: 9.715253118732411e-06\n",
      "SNR: 20/35, LS+LI, Epoch 19/20, Loss: 9.350999950659874e-06 \n",
      "SNR: 20/35, LS+LI, Val Loss: 8.646596522036512e-06\n",
      "SNR: 20/35, LS+LI, Epoch 20/20, Loss: 8.391835220796414e-06 \n",
      "SNR: 20/35, LS+LI, Val Loss: 7.750182987820153e-06\n",
      "LS+LI NMSE: 0.0008820203947834671\n",
      "LS+LI+CNN NMSE: 0.000308426795527339\n",
      " Training for LS\n",
      "SNR: 20/35, LS, Epoch 1/20, Loss: 0.12167870852863416 \n",
      "SNR: 20/35, LS, Val Loss: 0.0355141810917606\n",
      "SNR: 20/35, LS, Epoch 2/20, Loss: 0.026846482961749036 \n",
      "SNR: 20/35, LS, Val Loss: 0.021005914352523785\n",
      "SNR: 20/35, LS, Epoch 3/20, Loss: 0.018032641969815206 \n",
      "SNR: 20/35, LS, Val Loss: 0.012070070370100439\n",
      "SNR: 20/35, LS, Epoch 4/20, Loss: 0.005603266808369274 \n",
      "SNR: 20/35, LS, Val Loss: 0.001308448280421241\n",
      "SNR: 20/35, LS, Epoch 5/20, Loss: 0.0009531209140429079 \n",
      "SNR: 20/35, LS, Val Loss: 0.0006899693641268337\n",
      "SNR: 20/35, LS, Epoch 6/20, Loss: 0.0005804275130382545 \n",
      "SNR: 20/35, LS, Val Loss: 0.0004439347346002857\n",
      "SNR: 20/35, LS, Epoch 7/20, Loss: 0.0003755886473300052 \n",
      "SNR: 20/35, LS, Val Loss: 0.0003020745625690324\n",
      "SNR: 20/35, LS, Epoch 8/20, Loss: 0.0002691052191797401 \n",
      "SNR: 20/35, LS, Val Loss: 0.000232510115893092\n",
      "SNR: 20/35, LS, Epoch 9/20, Loss: 0.00021607464509543206 \n",
      "SNR: 20/35, LS, Val Loss: 0.0001919764587607157\n",
      "SNR: 20/35, LS, Epoch 10/20, Loss: 0.00018342781459068647 \n",
      "SNR: 20/35, LS, Val Loss: 0.00016393832902394934\n",
      "SNR: 20/35, LS, Epoch 11/20, Loss: 0.00016324302782777522 \n",
      "SNR: 20/35, LS, Val Loss: 0.00014678996376460418\n",
      "SNR: 20/35, LS, Epoch 12/20, Loss: 0.00014481850318285675 \n",
      "SNR: 20/35, LS, Val Loss: 0.00013177991513657616\n",
      "SNR: 20/35, LS, Epoch 13/20, Loss: 0.0001311760472617607 \n",
      "SNR: 20/35, LS, Val Loss: 0.00012067470379406586\n",
      "SNR: 20/35, LS, Epoch 14/20, Loss: 0.00011850330217081743 \n",
      "SNR: 20/35, LS, Val Loss: 0.00010862942963285604\n",
      "SNR: 20/35, LS, Epoch 15/20, Loss: 0.00011043204790439631 \n",
      "SNR: 20/35, LS, Val Loss: 0.00010138508908615525\n",
      "SNR: 20/35, LS, Epoch 16/20, Loss: 0.00010148814309710967 \n",
      "SNR: 20/35, LS, Val Loss: 9.012172919635002e-05\n",
      "SNR: 20/35, LS, Epoch 17/20, Loss: 9.034257237772181e-05 \n",
      "SNR: 20/35, LS, Val Loss: 9.113764129627573e-05\n",
      "SNR: 20/35, LS, Epoch 18/20, Loss: 8.071470498786464e-05 \n",
      "SNR: 20/35, LS, Val Loss: 7.87975166834561e-05\n",
      "SNR: 20/35, LS, Epoch 19/20, Loss: 7.344440287700611e-05 \n",
      "SNR: 20/35, LS, Val Loss: 6.566676059568029e-05\n",
      "SNR: 20/35, LS, Epoch 20/20, Loss: 6.622509086658586e-05 \n",
      "SNR: 20/35, LS, Val Loss: 5.893424213354592e-05\n",
      "LS+CNN NMSE: 0.0023460988886654377\n",
      " SNR: 25/35\n",
      " Training for LS+LI\n",
      "SNR: 25/35, LS+LI, Epoch 1/20, Loss: 0.09469559805196089 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.015348927622350553\n",
      "SNR: 25/35, LS+LI, Epoch 2/20, Loss: 0.00424032053949001 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.0005922590353293344\n",
      "SNR: 25/35, LS+LI, Epoch 3/20, Loss: 0.0004761904607827698 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.00038419044843370404\n",
      "SNR: 25/35, LS+LI, Epoch 4/20, Loss: 0.00029278528624369454 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.0002198339194971292\n",
      "SNR: 25/35, LS+LI, Epoch 5/20, Loss: 0.00016895906935587846 \n",
      "SNR: 25/35, LS+LI, Val Loss: 0.00013648940481895502\n",
      "SNR: 25/35, LS+LI, Epoch 6/20, Loss: 0.00011224927538933116 \n",
      "SNR: 25/35, LS+LI, Val Loss: 9.836117442318937e-05\n",
      "SNR: 25/35, LS+LI, Epoch 7/20, Loss: 8.366501697310014e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 7.579266609051653e-05\n",
      "SNR: 25/35, LS+LI, Epoch 8/20, Loss: 6.558145598016078e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 6.069601704439265e-05\n",
      "SNR: 25/35, LS+LI, Epoch 9/20, Loss: 5.209032413707367e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 4.756097420492248e-05\n",
      "SNR: 25/35, LS+LI, Epoch 10/20, Loss: 3.9753050354344545e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 3.5952635850359606e-05\n",
      "SNR: 25/35, LS+LI, Epoch 11/20, Loss: 2.9515523730575904e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 2.6789315597852692e-05\n",
      "SNR: 25/35, LS+LI, Epoch 12/20, Loss: 2.2085923925866762e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 2.063704929848124e-05\n",
      "SNR: 25/35, LS+LI, Epoch 13/20, Loss: 1.694578732269747e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.6163811361972574e-05\n",
      "SNR: 25/35, LS+LI, Epoch 14/20, Loss: 1.3326453109622586e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.2999435170968354e-05\n",
      "SNR: 25/35, LS+LI, Epoch 15/20, Loss: 1.0743281142329883e-05 \n",
      "SNR: 25/35, LS+LI, Val Loss: 1.0696552256680055e-05\n",
      "SNR: 25/35, LS+LI, Epoch 16/20, Loss: 8.863391078269464e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 8.94665623718538e-06\n",
      "SNR: 25/35, LS+LI, Epoch 17/20, Loss: 7.424381315956907e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 7.572167551946525e-06\n",
      "SNR: 25/35, LS+LI, Epoch 18/20, Loss: 6.307990856176578e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 6.551116276417209e-06\n",
      "SNR: 25/35, LS+LI, Epoch 19/20, Loss: 5.442809680289429e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 5.681660240952624e-06\n",
      "SNR: 25/35, LS+LI, Epoch 20/20, Loss: 4.738834526563096e-06 \n",
      "SNR: 25/35, LS+LI, Val Loss: 5.021774522144066e-06\n",
      "LS+LI NMSE: 0.0003099165915045887\n",
      "LS+LI+CNN NMSE: 0.00017645148909650743\n",
      " Training for LS\n",
      "SNR: 25/35, LS, Epoch 1/20, Loss: 0.11000294568172346 \n",
      "SNR: 25/35, LS, Val Loss: 0.03835649943600098\n",
      "SNR: 25/35, LS, Epoch 2/20, Loss: 0.02684301044791937 \n",
      "SNR: 25/35, LS, Val Loss: 0.02283543107720713\n",
      "SNR: 25/35, LS, Epoch 3/20, Loss: 0.014837872697777735 \n",
      "SNR: 25/35, LS, Val Loss: 0.00697698238460968\n",
      "SNR: 25/35, LS, Epoch 4/20, Loss: 0.002664559006007039 \n",
      "SNR: 25/35, LS, Val Loss: 0.0014634876958249758\n",
      "SNR: 25/35, LS, Epoch 5/20, Loss: 0.0010712905562589488 \n",
      "SNR: 25/35, LS, Val Loss: 0.0009342849637808589\n",
      "SNR: 25/35, LS, Epoch 6/20, Loss: 0.0007445342172710904 \n",
      "SNR: 25/35, LS, Val Loss: 0.0006836950803214373\n",
      "SNR: 25/35, LS, Epoch 7/20, Loss: 0.0005526457616724656 \n",
      "SNR: 25/35, LS, Val Loss: 0.0005062778109277133\n",
      "SNR: 25/35, LS, Epoch 8/20, Loss: 0.0004076286310616221 \n",
      "SNR: 25/35, LS, Val Loss: 0.0003898112493819402\n",
      "SNR: 25/35, LS, Epoch 9/20, Loss: 0.0003079305608935101 \n",
      "SNR: 25/35, LS, Val Loss: 0.0002875709384776807\n",
      "SNR: 25/35, LS, Epoch 10/20, Loss: 0.0002420511793843616 \n",
      "SNR: 25/35, LS, Val Loss: 0.00023494261161734661\n",
      "SNR: 25/35, LS, Epoch 11/20, Loss: 0.00020333551189348023 \n",
      "SNR: 25/35, LS, Val Loss: 0.0002064560200475777\n",
      "SNR: 25/35, LS, Epoch 12/20, Loss: 0.00017924731965498117 \n",
      "SNR: 25/35, LS, Val Loss: 0.00018360967381643908\n",
      "SNR: 25/35, LS, Epoch 13/20, Loss: 0.0001641952791260337 \n",
      "SNR: 25/35, LS, Val Loss: 0.00016624186658494486\n",
      "SNR: 25/35, LS, Epoch 14/20, Loss: 0.00015032975227313727 \n",
      "SNR: 25/35, LS, Val Loss: 0.00015429906397912418\n",
      "SNR: 25/35, LS, Epoch 15/20, Loss: 0.00014041781302391124 \n",
      "SNR: 25/35, LS, Val Loss: 0.00014348377984182056\n",
      "SNR: 25/35, LS, Epoch 16/20, Loss: 0.00013004835246495836 \n",
      "SNR: 25/35, LS, Val Loss: 0.00014002081600968572\n",
      "SNR: 25/35, LS, Epoch 17/20, Loss: 0.0001247710473156379 \n",
      "SNR: 25/35, LS, Val Loss: 0.0001258417660210398\n",
      "SNR: 25/35, LS, Epoch 18/20, Loss: 0.00011773561360920819 \n",
      "SNR: 25/35, LS, Val Loss: 0.00011825774618046125\n",
      "SNR: 25/35, LS, Epoch 19/20, Loss: 0.00011139663293609677 \n",
      "SNR: 25/35, LS, Val Loss: 0.00011212080092567096\n",
      "SNR: 25/35, LS, Epoch 20/20, Loss: 0.00010392672944211274 \n",
      "SNR: 25/35, LS, Val Loss: 0.00011434809948696056\n",
      "LS+CNN NMSE: 0.00400895532220602\n",
      " SNR: 30/35\n",
      " Training for LS+LI\n",
      "SNR: 30/35, LS+LI, Epoch 1/20, Loss: 0.07561619628783471 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.007819735949548582\n",
      "SNR: 30/35, LS+LI, Epoch 2/20, Loss: 0.002264285717956227 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.0005417804143993029\n",
      "SNR: 30/35, LS+LI, Epoch 3/20, Loss: 0.0004097560912062666 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.0003197556882999682\n",
      "SNR: 30/35, LS+LI, Epoch 4/20, Loss: 0.0002648269445823341 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.00020420852100263195\n",
      "SNR: 30/35, LS+LI, Epoch 5/20, Loss: 0.0001593570719175356 \n",
      "SNR: 30/35, LS+LI, Val Loss: 0.00011563300692311411\n",
      "SNR: 30/35, LS+LI, Epoch 6/20, Loss: 9.584894424582065e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 7.822374936949927e-05\n",
      "SNR: 30/35, LS+LI, Epoch 7/20, Loss: 7.08067961454617e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 6.189381504858223e-05\n",
      "SNR: 30/35, LS+LI, Epoch 8/20, Loss: 5.732743712390705e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 5.087343606646755e-05\n",
      "SNR: 30/35, LS+LI, Epoch 9/20, Loss: 4.7510575427622825e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 4.246426321212008e-05\n",
      "SNR: 30/35, LS+LI, Epoch 10/20, Loss: 3.9589378786786256e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 3.506700863908918e-05\n",
      "SNR: 30/35, LS+LI, Epoch 11/20, Loss: 3.210975950196371e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 2.8560595334662747e-05\n",
      "SNR: 30/35, LS+LI, Epoch 12/20, Loss: 2.6524962805751784e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 2.3858473696236615e-05\n",
      "SNR: 30/35, LS+LI, Epoch 13/20, Loss: 2.2169221836065844e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 2.000691680829429e-05\n",
      "SNR: 30/35, LS+LI, Epoch 14/20, Loss: 1.8550483266229396e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 1.6649926313524095e-05\n",
      "SNR: 30/35, LS+LI, Epoch 15/20, Loss: 1.4978174557237859e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 1.2622703820852621e-05\n",
      "SNR: 30/35, LS+LI, Epoch 16/20, Loss: 1.088326932574546e-05 \n",
      "SNR: 30/35, LS+LI, Val Loss: 9.011121126908014e-06\n",
      "SNR: 30/35, LS+LI, Epoch 17/20, Loss: 8.03126779184519e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 6.9785944560862845e-06\n",
      "SNR: 30/35, LS+LI, Epoch 18/20, Loss: 6.375778490053108e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 5.6390589217395854e-06\n",
      "SNR: 30/35, LS+LI, Epoch 19/20, Loss: 5.232999428746628e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 4.7459488049147085e-06\n",
      "SNR: 30/35, LS+LI, Epoch 20/20, Loss: 4.388461000814914e-06 \n",
      "SNR: 30/35, LS+LI, Val Loss: 3.973701420060631e-06\n",
      "LS+LI NMSE: 0.0001340549933956936\n",
      "LS+LI+CNN NMSE: 0.000153163869981654\n",
      " Training for LS\n",
      "SNR: 30/35, LS, Epoch 1/20, Loss: 0.11134836224179405 \n",
      "SNR: 30/35, LS, Val Loss: 0.03567996465911468\n",
      "SNR: 30/35, LS, Epoch 2/20, Loss: 0.027025486012765516 \n",
      "SNR: 30/35, LS, Val Loss: 0.02254232958269616\n",
      "SNR: 30/35, LS, Epoch 3/20, Loss: 0.018493001407478005 \n",
      "SNR: 30/35, LS, Val Loss: 0.013219542723769942\n",
      "SNR: 30/35, LS, Epoch 4/20, Loss: 0.005855577193263646 \n",
      "SNR: 30/35, LS, Val Loss: 0.001453036490905409\n",
      "SNR: 30/35, LS, Epoch 5/20, Loss: 0.0010136670807696646 \n",
      "SNR: 30/35, LS, Val Loss: 0.0007355993996801166\n",
      "SNR: 30/35, LS, Epoch 6/20, Loss: 0.0005902900497858354 \n",
      "SNR: 30/35, LS, Val Loss: 0.00047273927824183676\n",
      "SNR: 30/35, LS, Epoch 7/20, Loss: 0.00038537593187963165 \n",
      "SNR: 30/35, LS, Val Loss: 0.0003132178687034563\n",
      "SNR: 30/35, LS, Epoch 8/20, Loss: 0.00026649632347168034 \n",
      "SNR: 30/35, LS, Val Loss: 0.00022299782964788997\n",
      "SNR: 30/35, LS, Epoch 9/20, Loss: 0.00020423465609079963 \n",
      "SNR: 30/35, LS, Val Loss: 0.00018368005900507947\n",
      "SNR: 30/35, LS, Epoch 10/20, Loss: 0.00017294228477264065 \n",
      "SNR: 30/35, LS, Val Loss: 0.000162810595005188\n",
      "SNR: 30/35, LS, Epoch 11/20, Loss: 0.00015426926696212226 \n",
      "SNR: 30/35, LS, Val Loss: 0.00014452205171740692\n",
      "SNR: 30/35, LS, Epoch 12/20, Loss: 0.00013919280532566822 \n",
      "SNR: 30/35, LS, Val Loss: 0.00013030845517884396\n",
      "SNR: 30/35, LS, Epoch 13/20, Loss: 0.00012714051069906418 \n",
      "SNR: 30/35, LS, Val Loss: 0.00012008475793360655\n",
      "SNR: 30/35, LS, Epoch 14/20, Loss: 0.0001181993535131672 \n",
      "SNR: 30/35, LS, Val Loss: 0.0001146666339385168\n",
      "SNR: 30/35, LS, Epoch 15/20, Loss: 0.00010885709749193968 \n",
      "SNR: 30/35, LS, Val Loss: 0.00010606702623287372\n",
      "SNR: 30/35, LS, Epoch 16/20, Loss: 0.00010027627911313175 \n",
      "SNR: 30/35, LS, Val Loss: 9.564335080843496e-05\n",
      "SNR: 30/35, LS, Epoch 17/20, Loss: 9.232279198082931e-05 \n",
      "SNR: 30/35, LS, Val Loss: 8.677615520961506e-05\n",
      "SNR: 30/35, LS, Epoch 18/20, Loss: 8.656146176614736e-05 \n",
      "SNR: 30/35, LS, Val Loss: 8.119493334864576e-05\n",
      "SNR: 30/35, LS, Epoch 19/20, Loss: 8.050977436369067e-05 \n",
      "SNR: 30/35, LS, Val Loss: 7.910138083389029e-05\n",
      "SNR: 30/35, LS, Epoch 20/20, Loss: 7.533044534587437e-05 \n",
      "SNR: 30/35, LS, Val Loss: 7.120077392149445e-05\n",
      "LS+CNN NMSE: 0.002728343242779374\n",
      " SNR: 35/35\n",
      " Training for LS+LI\n",
      "SNR: 35/35, LS+LI, Epoch 1/20, Loss: 0.09411842248421938 \n",
      "SNR: 35/35, LS+LI, Val Loss: 0.01441851801549395\n",
      "SNR: 35/35, LS+LI, Epoch 2/20, Loss: 0.004317102098260269 \n",
      "SNR: 35/35, LS+LI, Val Loss: 0.000592997093917802\n",
      "SNR: 35/35, LS+LI, Epoch 3/20, Loss: 0.0004028437836041121 \n",
      "SNR: 35/35, LS+LI, Val Loss: 0.00025335247058440774\n",
      "SNR: 35/35, LS+LI, Epoch 4/20, Loss: 0.00018934336571874155 \n",
      "SNR: 35/35, LS+LI, Val Loss: 0.0001254383032573969\n",
      "SNR: 35/35, LS+LI, Epoch 5/20, Loss: 0.00010881710109818717 \n",
      "SNR: 35/35, LS+LI, Val Loss: 8.80281331774313e-05\n",
      "SNR: 35/35, LS+LI, Epoch 6/20, Loss: 7.815422823872116e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 6.456895774438938e-05\n",
      "SNR: 35/35, LS+LI, Epoch 7/20, Loss: 5.793528148008894e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 4.848401628502567e-05\n",
      "SNR: 35/35, LS+LI, Epoch 8/20, Loss: 4.401943275903856e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 3.751333815671387e-05\n",
      "SNR: 35/35, LS+LI, Epoch 9/20, Loss: 3.4542650600618195e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 2.985120083091412e-05\n",
      "SNR: 35/35, LS+LI, Epoch 10/20, Loss: 2.7835240937671795e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 2.421523155741549e-05\n",
      "SNR: 35/35, LS+LI, Epoch 11/20, Loss: 2.2747461088101772e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 1.9894307721794274e-05\n",
      "SNR: 35/35, LS+LI, Epoch 12/20, Loss: 1.860456213857257e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 1.630211939603517e-05\n",
      "SNR: 35/35, LS+LI, Epoch 13/20, Loss: 1.5122784333243544e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 1.3110150083169477e-05\n",
      "SNR: 35/35, LS+LI, Epoch 14/20, Loss: 1.17833324111416e-05 \n",
      "SNR: 35/35, LS+LI, Val Loss: 9.85209423258008e-06\n",
      "SNR: 35/35, LS+LI, Epoch 15/20, Loss: 8.767461044575006e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 7.42190529005408e-06\n",
      "SNR: 35/35, LS+LI, Epoch 16/20, Loss: 6.662950096843663e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 5.708955616986107e-06\n",
      "SNR: 35/35, LS+LI, Epoch 17/20, Loss: 5.137282176548297e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 4.427342190638228e-06\n",
      "SNR: 35/35, LS+LI, Epoch 18/20, Loss: 4.025320857673857e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 3.5188220692816685e-06\n",
      "SNR: 35/35, LS+LI, Epoch 19/20, Loss: 3.2371989936071563e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 2.8529002804589254e-06\n",
      "SNR: 35/35, LS+LI, Epoch 20/20, Loss: 2.6505193169157337e-06 \n",
      "SNR: 35/35, LS+LI, Val Loss: 2.3536397482833613e-06\n",
      "LS+LI NMSE: 7.730881770839915e-05\n",
      "LS+LI+CNN NMSE: 8.78399150678888e-05\n",
      " Training for LS\n",
      "SNR: 35/35, LS, Epoch 1/20, Loss: 0.12766329990699887 \n",
      "SNR: 35/35, LS, Val Loss: 0.03832683262104789\n",
      "SNR: 35/35, LS, Epoch 2/20, Loss: 0.02730062596189479 \n",
      "SNR: 35/35, LS, Val Loss: 0.021115042191619676\n",
      "SNR: 35/35, LS, Epoch 3/20, Loss: 0.01664684148757563 \n",
      "SNR: 35/35, LS, Val Loss: 0.011677255543569723\n",
      "SNR: 35/35, LS, Epoch 4/20, Loss: 0.004925277326037758 \n",
      "SNR: 35/35, LS, Val Loss: 0.0012697694716431822\n",
      "SNR: 35/35, LS, Epoch 5/20, Loss: 0.0009678785660677628 \n",
      "SNR: 35/35, LS, Val Loss: 0.0007677479661651887\n",
      "SNR: 35/35, LS, Epoch 6/20, Loss: 0.0006640211915206843 \n",
      "SNR: 35/35, LS, Val Loss: 0.0005545185049413703\n",
      "SNR: 35/35, LS, Epoch 7/20, Loss: 0.0004715092068181548 \n",
      "SNR: 35/35, LS, Val Loss: 0.0003952613127088019\n",
      "SNR: 35/35, LS, Epoch 8/20, Loss: 0.0003487057191856972 \n",
      "SNR: 35/35, LS, Val Loss: 0.00030072032010745414\n",
      "SNR: 35/35, LS, Epoch 9/20, Loss: 0.0002746332072547375 \n",
      "SNR: 35/35, LS, Val Loss: 0.00024029637703885479\n",
      "SNR: 35/35, LS, Epoch 10/20, Loss: 0.00022339147471939214 \n",
      "SNR: 35/35, LS, Val Loss: 0.00020054438634057684\n",
      "SNR: 35/35, LS, Epoch 11/20, Loss: 0.0001936392914103635 \n",
      "SNR: 35/35, LS, Val Loss: 0.00018815280903557627\n",
      "SNR: 35/35, LS, Epoch 12/20, Loss: 0.00017550608174587978 \n",
      "SNR: 35/35, LS, Val Loss: 0.00017564358919723114\n",
      "SNR: 35/35, LS, Epoch 13/20, Loss: 0.00016197193186447598 \n",
      "SNR: 35/35, LS, Val Loss: 0.00015371406516351271\n",
      "SNR: 35/35, LS, Epoch 14/20, Loss: 0.00014962878985140074 \n",
      "SNR: 35/35, LS, Val Loss: 0.00014425149705251292\n",
      "SNR: 35/35, LS, Epoch 15/20, Loss: 0.00013901410360025088 \n",
      "SNR: 35/35, LS, Val Loss: 0.00013180853026521314\n",
      "SNR: 35/35, LS, Epoch 16/20, Loss: 0.00012966655015134165 \n",
      "SNR: 35/35, LS, Val Loss: 0.00012555606129656857\n",
      "SNR: 35/35, LS, Epoch 17/20, Loss: 0.00012150339250638353 \n",
      "SNR: 35/35, LS, Val Loss: 0.0001175489166295544\n",
      "SNR: 35/35, LS, Epoch 18/20, Loss: 0.00011288855504668997 \n",
      "SNR: 35/35, LS, Val Loss: 0.0001120476626965683\n",
      "SNR: 35/35, LS, Epoch 19/20, Loss: 0.00010576405577467085 \n",
      "SNR: 35/35, LS, Val Loss: 0.00010053836255489539\n",
      "SNR: 35/35, LS, Epoch 20/20, Loss: 9.880596746825177e-05 \n",
      "SNR: 35/35, LS, Val Loss: 9.283672382783455e-05\n",
      "LS+CNN NMSE: 0.0034710473846644163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['550', '568']] # , ['5100','5109']\n",
    "rowss = \"550_568\"\n",
    "SNR = np.arange(0, 36, 5) # 0:5:35 dB\n",
    "outer_file_path = os.path.join(config.FILE_PATH, '..', 'DeepMIMOv2', 'Gan_Data', 'Static_612x14', 'freq_symb_1ant_612sub')\n",
    "for snr in SNR:\n",
    "\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    H_true = np.empty((0, 2, 612, 14)) # true channel\n",
    "\n",
    "    H_equal = np.empty((0, 2, 612, 14)) # noisy channel # LS channel\n",
    "    H_linear = np.empty((0, 2, 612, 14)) # noisy channel # LS+Linear Interpolated channel\n",
    "    H_practical = np.empty((0, 2, 612, 14)) # noisy channel # Practical Estimated channel\n",
    "\n",
    "    # read data from ifferent .mat file, then concatenate them\n",
    "    for i in range(len(rows)):\n",
    "        file_path_partial = 'Gan_' + str(snr) +'_dBOutdoor1_60_1ant_612subcs_Row_' + rows[i][0] +'_' + rows[i][1] + '.mat'\n",
    "\n",
    "        file_path = os.path.join(outer_file_path, file_path_partial)\n",
    "        file_path = os.path.normpath(file_path)\n",
    "        file = h5py.File(file_path, 'r')\n",
    "        \n",
    "        H_true = np.concatenate((H_true, np.array(file['H_data'])), axis = 0) # N_samples x channel(2) x height(614) x width(14)\n",
    "        H_equal = np.concatenate((H_equal, np.array(file['H_equalized_data'])), axis = 0)\n",
    "        H_linear = np.concatenate((H_linear, np.array(file['H_linear_data'])), axis=0)\n",
    "        H_practical = np.concatenate((H_practical, np.array(file['H_practical_data'])), axis=0)\n",
    "\n",
    "    shuffle_order = np.random.permutation(H_true.shape[0]);\n",
    "    H_true = torch.tensor(H_true[shuffle_order])\n",
    "    H_equal = torch.tensor(H_equal[shuffle_order])\n",
    "    H_linear = torch.tensor(H_linear[shuffle_order])\n",
    "    H_practical = torch.tensor(H_practical[shuffle_order])\n",
    "\n",
    "    train_size = np.floor(H_practical.shape[0]*0.9) //BATCH_SIZE *BATCH_SIZE\n",
    "    # print(train_size)\n",
    "    # print(train_size/64)\n",
    "    # print(train_size/input_data.size(0))\n",
    "    train_size = int(train_size)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # 1.1 Split into training and validation sets for H_NN training\n",
    "    trainData   = H_linear[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Split H_equal, H_linear, H_practical for validation later\n",
    "    H_equal_val = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_linear_val = H_linear[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    H_practical_val = H_practical[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # 1.2 Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    # for evaluation, output of model(valData) will be de-normalized and compared with valLabels\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    # 1.3 Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 1.4 model\n",
    "    model = utils.CNN_Est().to(device)\n",
    "\n",
    "    learning_rate = 0.00001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(config.FILE_PATH, 'model/static/CNN', rowss, str(snr)+'dB')\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate\n",
    "    }\n",
    "    savemat(params_save_path, params)\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                'train_min_LI': trainData_min.cpu(),\n",
    "                'train_max_LI': trainData_max.cpu(),\n",
    "                'val_min': trainLabels_min.cpu(),\n",
    "                'val_max': trainLabels_max.cpu,\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_LI_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_true[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('True Channel')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results',  'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_trueChannel.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Linear interpolated channel\n",
    "    H_val_linInterp = valData.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI = torch.mean(torch.abs(H_val_true_complex - H_val_linInterp_complex) ** 2)\n",
    "    # Calculate the variance of the reference tensor (complex_tensor1)\n",
    "    variance = torch.var(H_val_true_complex)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = mse_LI / variance\n",
    "    variables['NMSE_LI'] = nmse_LI.cpu()\n",
    "    print(f\"LS+LI NMSE: {nmse_LI.item()}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_linInterp[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS + Interpolate Estimated Channel, NMSE: {nmse_LI:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_LI_estimatedChan.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title('LI+CNN Estimated Channel (before de-normlized)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, \"results\", 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_LI_CNN_estimatedChan_before_denorm.png') )\n",
    "    # plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # De-normalized\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "\n",
    "    # NMSE of Linear Interpolation + NN\n",
    "    # Calculate the mean squared error\n",
    "    mse_LI_NN = torch.mean(torch.abs(H_val_true_complex - H_val_NN_denormd_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI_NN = mse_LI_NN / variance\n",
    "    print(f\"LS+LI+CNN NMSE: {nmse_LI_NN.item()}\")\n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LI+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LI_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_LI_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    # Split into training and validation sets for H_NN training\n",
    "    trainData   = H_equal[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "    trainLabels = H_true[0:train_size,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    valData   = H_equal[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "    valLabels = H_true[train_size:,:,:,:].to(device, dtype=torch.float)\n",
    "\n",
    "    # Normalization\n",
    "    trainData_min = trainData.min()\n",
    "    trainData_max = trainData.max()\n",
    "    trainLabels_min = trainLabels.min()\n",
    "    trainLabels_max = trainLabels.max()\n",
    "\n",
    "    trainData_normd   = (trainData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    trainLabels_normd = (trainLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "    valData_normd     = (valData - trainData_min)/ (trainData_max - trainData_min)\n",
    "    valLabels_normd   = (valLabels - trainLabels_min)/ (trainLabels_max - trainLabels_min)\n",
    "\n",
    "\n",
    "    # Split real and imaginary grids into 2 image sets, then concatenate\n",
    "    trainData_normd   = torch.cat((trainData_normd[:,0,:,:], trainData_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "    trainLabels_normd = torch.cat((trainLabels_normd[:,0,:,:], trainLabels_normd[:,1,:,:]), dim=0).unsqueeze(1)  # 612 x 14 x (Nsamples*2)\n",
    "\n",
    "    H_temp = trainData.cpu()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_temp[0,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS Channel')\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_Chan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    # Create a DataLoader for dataset\n",
    "    dataset = TensorDataset(trainData_normd, trainLabels_normd)  # [4224, 1, 612, 14]\n",
    "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_dataset = TensorDataset(valData_normd, valLabels_normd)  # [241, 2, 612, 14]\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model2 = utils.CNN_Est().to(device)\n",
    "    learning_rate = 0.00001\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_Loss.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    H_val_NN_denormd = H_NN_val * (trainLabels_max - trainLabels_min) + trainLabels_min\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "    variables['train_min_LS']= trainData_min.cpu()\n",
    "    variables['train_max_LS']= trainData_max.cpu()\n",
    "\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the mean squared error\n",
    "    mse_LS_NN = torch.mean(torch.abs(H_val_true_complex - H_val_LS_NN_complex) ** 2)\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = mse_LS_NN / variance\n",
    "    print(f\"LS+CNN NMSE: {nmse_LS_NN.item()}\")\n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(H_val_NN_denormd[-1,0,:,:],  aspect='auto', cmap='viridis', interpolation='none')\n",
    "    plt.xlabel('OFDM symbol')\n",
    "    plt.ylabel('Subcarrier')\n",
    "    plt.title(f'LS+CNN Estimated Channel (after de-normlized), NMSE: {nmse_LS_NN:.4f}')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(config.FILE_PATH, 'results', 'static', 'CNN', rowss, str(snr) + 'dB',  str(index_save) + '_LS_CNN_estimatedChan.png') )\n",
    "    plt.clf()\n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SNR': 0, 'epoc': 20, 'rows': '550_568', 'learning_rate': 1e-05, 'train_track_LI': [0.12542229983955622, 0.016818697966906864, 0.006570089958889487, 0.0017958001614412449, 0.0010687704604303387, 0.0006360203134742429, 0.0004226578427430165, 0.000339401617641973, 0.00029624920997169585, 0.00026810644628009567, 0.0002501570282523365, 0.00023476741269708631, 0.0002248910150986679, 0.00021715459956794803, 0.00021035958222152354, 0.00020660342367288345, 0.00019989069134377738, 0.00019464028150650847, 0.00019122100115964713, 0.00018718416041944388], 'val_track_LI': [0.028704328772922356, 0.01160938641987741, 0.0027627505478449166, 0.0013673651604525123, 0.0008469064535650735, 0.0005033311208535451, 0.0003792883859811506, 0.00032053827332371537, 0.00029038065440545324, 0.00026359001640230417, 0.00025747243004540604, 0.00023620072109527732, 0.0002252046312302506, 0.00022641037867288105, 0.0002112559110779936, 0.0002063743898664446, 0.00020225443404342514, 0.00019736855877757384, 0.00019304889610793907, 0.0001906198000748797], 'train_min_LI': tensor(-2.2338e-06, device='cuda:0'), 'train_max_LI': tensor(1.5294e-06, device='cuda:0'), 'val_min': tensor(-5.3256e-07, device='cuda:0'), 'val_max': tensor(5.3266e-07, device='cuda:0'), 'NMSE_LI': tensor(0.0828), 'NMSE_LI_NN': tensor(0.0071), 'H_val_LS_NN': tensor([[[[-1.5693e-07, -1.3738e-07, -8.0280e-08,  ..., -3.9861e-08,\n",
      "           -9.2171e-08, -1.4545e-07],\n",
      "          [-1.2300e-07, -1.2390e-07, -1.0826e-07,  ..., -5.9200e-08,\n",
      "           -6.9611e-08, -9.5470e-08],\n",
      "          [-1.1514e-07, -1.3042e-07, -1.2567e-07,  ..., -8.2031e-08,\n",
      "           -6.3485e-08, -5.5495e-08],\n",
      "          ...,\n",
      "          [ 8.3253e-08,  1.1420e-07,  8.2593e-08,  ...,  1.1321e-07,\n",
      "            1.1645e-07,  8.4898e-08],\n",
      "          [ 1.1728e-08,  4.9471e-08,  5.7555e-08,  ...,  9.5033e-08,\n",
      "            8.4412e-08,  3.6459e-08],\n",
      "          [-9.1061e-08, -9.2238e-09,  4.1867e-08,  ...,  7.0843e-08,\n",
      "            4.5306e-08, -3.1016e-08]],\n",
      "\n",
      "         [[-1.6304e-08,  3.4429e-08,  1.1166e-07,  ...,  1.0229e-07,\n",
      "            1.3879e-08, -5.9032e-08],\n",
      "          [ 8.5516e-08,  1.2374e-07,  1.5741e-07,  ...,  1.2782e-07,\n",
      "            8.9644e-08,  3.8778e-08],\n",
      "          [ 1.4022e-07,  1.6300e-07,  1.8613e-07,  ...,  1.5252e-07,\n",
      "            1.4490e-07,  1.3606e-07],\n",
      "          ...,\n",
      "          [-5.4824e-08, -4.7665e-08, -7.3904e-08,  ..., -9.7947e-08,\n",
      "           -7.7475e-08, -9.3211e-08],\n",
      "          [-8.2778e-08, -7.4122e-08, -7.0561e-08,  ..., -7.8208e-08,\n",
      "           -6.5381e-08, -1.0555e-07],\n",
      "          [-1.5258e-07, -9.6463e-08, -5.8639e-08,  ..., -5.6202e-08,\n",
      "           -6.6519e-08, -1.3158e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.9478e-07, -1.8412e-07, -1.2991e-07,  ..., -9.5167e-08,\n",
      "           -1.3376e-07, -1.8365e-07],\n",
      "          [-1.8117e-07, -1.8891e-07, -1.7850e-07,  ..., -1.3115e-07,\n",
      "           -1.3518e-07, -1.5582e-07],\n",
      "          [-1.8795e-07, -2.0265e-07, -2.1047e-07,  ..., -1.7093e-07,\n",
      "           -1.5191e-07, -1.3669e-07],\n",
      "          ...,\n",
      "          [-5.9537e-08, -5.2941e-08, -7.8629e-08,  ..., -9.1498e-08,\n",
      "           -7.0898e-08, -8.6910e-08],\n",
      "          [-8.6067e-08, -7.8039e-08, -7.4290e-08,  ..., -7.2117e-08,\n",
      "           -5.9450e-08, -9.9446e-08],\n",
      "          [-1.5471e-07, -9.9267e-08, -6.1623e-08,  ..., -5.1463e-08,\n",
      "           -6.1666e-08, -1.2703e-07]],\n",
      "\n",
      "         [[-5.9082e-08, -1.7504e-08,  5.3045e-08,  ...,  4.0929e-08,\n",
      "           -3.3311e-08, -9.6011e-08],\n",
      "          [ 2.3806e-08,  4.8657e-08,  7.7504e-08,  ...,  4.6580e-08,\n",
      "            2.0506e-08, -1.7100e-08],\n",
      "          [ 6.2427e-08,  7.0015e-08,  8.7301e-08,  ...,  5.4772e-08,\n",
      "            6.0384e-08,  5.7454e-08],\n",
      "          ...,\n",
      "          [ 4.2315e-09,  1.8283e-08, -1.1946e-08,  ..., -6.7369e-08,\n",
      "           -4.9790e-08, -6.9280e-08],\n",
      "          [-4.0512e-08, -2.0469e-08, -1.8802e-08,  ..., -5.0415e-08,\n",
      "           -4.2399e-08, -8.3577e-08],\n",
      "          [-1.2432e-07, -5.7386e-08, -1.4667e-08,  ..., -3.5100e-08,\n",
      "           -4.8327e-08, -1.1532e-07]]],\n",
      "\n",
      "\n",
      "        [[[-7.2806e-08, -3.4475e-08,  3.3609e-08,  ...,  3.7991e-08,\n",
      "           -3.4684e-08, -9.7239e-08],\n",
      "          [ 1.2786e-09,  2.0133e-08,  4.6928e-08,  ...,  3.8979e-08,\n",
      "            1.5246e-08, -2.1995e-08],\n",
      "          [ 2.9734e-08,  3.2273e-08,  4.6560e-08,  ...,  4.1062e-08,\n",
      "            4.9495e-08,  4.5977e-08],\n",
      "          ...,\n",
      "          [ 1.0604e-08,  2.6645e-08, -3.2151e-09,  ..., -2.8243e-08,\n",
      "           -1.0729e-08, -3.3234e-08],\n",
      "          [-3.7270e-08, -1.5766e-08, -1.3229e-08,  ..., -1.9858e-08,\n",
      "           -1.4418e-08, -5.6198e-08],\n",
      "          [-1.2285e-07, -5.5033e-08, -1.1617e-08,  ..., -1.3746e-08,\n",
      "           -2.8325e-08, -9.6160e-08]],\n",
      "\n",
      "         [[-8.3313e-08, -4.7457e-08,  1.8727e-08,  ...,  2.4528e-08,\n",
      "           -4.4843e-08, -1.0559e-07],\n",
      "          [-1.4928e-08,  2.7313e-10,  2.5522e-08,  ...,  2.0781e-08,\n",
      "           -3.4419e-10, -3.5719e-08],\n",
      "          [ 8.6478e-09,  8.1704e-09,  2.0887e-08,  ...,  1.6991e-08,\n",
      "            2.8582e-08,  2.5569e-08],\n",
      "          ...,\n",
      "          [ 3.3007e-08,  5.3034e-08,  2.2094e-08,  ...,  2.9432e-09,\n",
      "            1.7518e-08, -6.4024e-09],\n",
      "          [-2.1845e-08,  4.5071e-09,  8.1293e-09,  ...,  5.1649e-09,\n",
      "            7.8743e-09, -3.5467e-08],\n",
      "          [-1.1265e-07, -4.0537e-08,  5.0628e-09,  ...,  4.3772e-09,\n",
      "           -1.1874e-08, -8.0984e-08]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.2636e-07, -2.2234e-07, -1.7229e-07,  ..., -1.5391e-07,\n",
      "           -1.8357e-07, -2.2960e-07],\n",
      "          [-2.2564e-07, -2.3815e-07, -2.3073e-07,  ..., -2.1061e-07,\n",
      "           -2.0450e-07, -2.2426e-07],\n",
      "          [-2.4172e-07, -2.5755e-07, -2.7414e-07,  ..., -2.5883e-07,\n",
      "           -2.4192e-07, -2.2346e-07],\n",
      "          ...,\n",
      "          [ 2.1639e-07,  2.7851e-07,  2.4720e-07,  ...,  2.2509e-07,\n",
      "            2.1096e-07,  1.6842e-07],\n",
      "          [ 1.0438e-07,  1.6863e-07,  1.9273e-07,  ...,  1.8821e-07,\n",
      "            1.5981e-07,  1.0055e-07],\n",
      "          [-2.9845e-08,  7.8405e-08,  1.4544e-07,  ...,  1.3968e-07,\n",
      "            1.0207e-07,  1.3035e-08]],\n",
      "\n",
      "         [[-1.1182e-07, -8.2206e-08, -1.9601e-08,  ..., -7.1150e-09,\n",
      "           -6.8994e-08, -1.2566e-07],\n",
      "          [-5.2185e-08, -4.2340e-08, -2.0644e-08,  ..., -1.5736e-08,\n",
      "           -3.2184e-08, -6.3101e-08],\n",
      "          [-2.8003e-08, -3.5132e-08, -2.4111e-08,  ..., -2.3892e-08,\n",
      "           -8.5320e-09, -7.7695e-09],\n",
      "          ...,\n",
      "          [-5.1649e-08, -4.5777e-08, -7.3918e-08,  ..., -1.8165e-07,\n",
      "           -1.6209e-07, -1.7297e-07],\n",
      "          [-8.1849e-08, -7.3634e-08, -7.1957e-08,  ..., -1.4555e-07,\n",
      "           -1.3281e-07, -1.6802e-07],\n",
      "          [-1.5258e-07, -9.7072e-08, -6.0490e-08,  ..., -1.0695e-07,\n",
      "           -1.1585e-07, -1.7496e-07]]],\n",
      "\n",
      "\n",
      "        [[[-1.0195e-07, -7.0923e-08, -7.8102e-09,  ...,  5.1683e-09,\n",
      "           -5.9263e-08, -1.1757e-07],\n",
      "          [-4.2974e-08, -3.2265e-08, -1.0140e-08,  ..., -2.9615e-09,\n",
      "           -2.0643e-08, -5.3130e-08],\n",
      "          [-2.3935e-08, -2.9366e-08, -1.8609e-08,  ..., -1.1647e-08,\n",
      "            3.2424e-09,  2.7492e-09],\n",
      "          ...,\n",
      "          [ 9.5277e-09,  2.5563e-08, -4.1606e-09,  ..., -3.1479e-08,\n",
      "           -1.3749e-08, -3.6224e-08],\n",
      "          [-3.8733e-08, -1.7470e-08, -1.4996e-08,  ..., -2.3130e-08,\n",
      "           -1.7473e-08, -5.9075e-08],\n",
      "          [-1.2418e-07, -5.6862e-08, -1.3706e-08,  ..., -1.6472e-08,\n",
      "           -3.0876e-08, -9.8540e-08]],\n",
      "\n",
      "         [[-7.7363e-08, -3.9906e-08,  2.7603e-08,  ...,  3.3629e-08,\n",
      "           -3.8066e-08, -1.0002e-07],\n",
      "          [-5.0240e-09,  1.2481e-08,  3.8852e-08,  ...,  3.3040e-08,\n",
      "            1.0030e-08, -2.6625e-08],\n",
      "          [ 2.2302e-08,  2.3618e-08,  3.7425e-08,  ...,  3.3080e-08,\n",
      "            4.2496e-08,  3.9067e-08],\n",
      "          ...,\n",
      "          [-1.7870e-08, -6.4493e-09, -3.5115e-08,  ..., -7.0024e-08,\n",
      "           -5.1219e-08, -6.9990e-08],\n",
      "          [-5.6731e-08, -4.1112e-08, -3.9103e-08,  ..., -5.3982e-08,\n",
      "           -4.4791e-08, -8.5458e-08],\n",
      "          [-1.3551e-07, -7.2946e-08, -3.2359e-08,  ..., -3.8391e-08,\n",
      "           -5.0767e-08, -1.1716e-07]]],\n",
      "\n",
      "\n",
      "        [[[-7.5487e-08, -3.6999e-08,  3.1472e-08,  ...,  6.0019e-08,\n",
      "           -1.7727e-08, -8.3391e-08],\n",
      "          [-1.9447e-09,  1.7227e-08,  4.4912e-08,  ...,  6.8019e-08,\n",
      "            4.1084e-08,  2.9223e-10],\n",
      "          [ 2.6802e-08,  2.9605e-08,  4.5023e-08,  ...,  7.8421e-08,\n",
      "            8.2874e-08,  7.8734e-08],\n",
      "          ...,\n",
      "          [ 2.7608e-08,  4.6142e-08,  1.5106e-08,  ..., -1.5786e-08,\n",
      "            3.9279e-10, -2.2829e-08],\n",
      "          [-2.4487e-08,  6.4171e-10,  3.8276e-09,  ..., -8.8301e-09,\n",
      "           -4.6314e-09, -4.7349e-08],\n",
      "          [-1.1378e-07, -4.2357e-08,  2.8182e-09,  ..., -5.1458e-09,\n",
      "           -2.0743e-08, -8.9296e-08]],\n",
      "\n",
      "         [[-5.1523e-08, -8.5163e-09,  6.3071e-08,  ...,  6.0616e-08,\n",
      "           -1.7635e-08, -8.3783e-08],\n",
      "          [ 3.1836e-08,  5.8043e-08,  8.7665e-08,  ...,  6.7752e-08,\n",
      "            4.0038e-08, -1.2530e-09],\n",
      "          [ 6.7333e-08,  7.6764e-08,  9.4655e-08,  ...,  7.6618e-08,\n",
      "            8.0357e-08,  7.5183e-08],\n",
      "          ...,\n",
      "          [ 1.6251e-07,  2.1195e-07,  1.7807e-07,  ...,  1.8880e-07,\n",
      "            1.8029e-07,  1.4223e-07],\n",
      "          [ 6.7722e-08,  1.2229e-07,  1.4013e-07,  ...,  1.5944e-07,\n",
      "            1.3674e-07,  8.1404e-08],\n",
      "          [-5.3691e-08,  4.4692e-08,  1.0600e-07,  ...,  1.1901e-07,\n",
      "            8.5517e-08,  2.6779e-10]]]]), 'train_track_LS': [0.09253137288033031, 0.02707118182055031, 0.022697088119457476, 0.01688235917633089, 0.004919052914071169, 0.001491880999613689, 0.0008795766161711072, 0.0006376907819382419, 0.000525684531112347, 0.0004552998026762604, 0.00040890439307380194, 0.0003842583566135242, 0.0003557589483686267, 0.0003430423846566555, 0.00033121222857820004, 0.0003214094568496269, 0.00031454122707449034, 0.0003094477513059246, 0.00030568611002005736, 0.0002940441999423153], 'val_track_LS': [0.03515757263327638, 0.024704243910188477, 0.021781118974710505, 0.010815930513975522, 0.002192846043423439, 0.0010950490250252187, 0.0007332135161656576, 0.0005701962860863811, 0.0004859864784521051, 0.0004385589236335363, 0.0003927061055340649, 0.000374694349981534, 0.00035232724136828136, 0.00034168312898448977, 0.00034002182898499694, 0.0003184652559866663, 0.00031024163460339577, 0.0003316323151617932, 0.00030048692860873416, 0.000313391944776716], 'train_min_LS': tensor(-8.1074e-07, device='cuda:0'), 'train_max_LS': tensor(7.6044e-07, device='cuda:0'), 'NMSE_LS_NN': tensor(0.0117)}\n"
     ]
    }
   ],
   "source": [
    "print(variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
