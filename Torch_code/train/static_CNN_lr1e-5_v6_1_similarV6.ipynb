{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 0.00001 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                                                '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver11_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver11_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# create readme.txt file\n",
    "content = \"\"\"Generated by file 'train/static_CNN_lr1e-5_v6_1_(...).ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows 3500_3516,\n",
    "DeepMIMOv2/DeepMIMO_Dta_Static_BS16/freq_sym_1ant_612sub_ver4,\n",
    "Using min-max [-1 1] scaler for each sample\n",
    "Using Tanh as activation function of CNN\"\"\"\n",
    "\n",
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "\n",
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snr = 0\n",
    "# [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      " Training for LS+LI\n",
      "SNR: 0/30, LS+LI, Epoch 1/20, Loss: 0.09457873953722937 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.04513332891193303\n",
      "SNR: 0/30, LS+LI, Epoch 2/20, Loss: 0.034217666726299494 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.027831414291127163\n",
      "SNR: 0/30, LS+LI, Epoch 3/20, Loss: 0.025679973365609034 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02641200464726849\n",
      "SNR: 0/30, LS+LI, Epoch 4/20, Loss: 0.02529281448183018 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026245014361021193\n",
      "SNR: 0/30, LS+LI, Epoch 5/20, Loss: 0.025181596021189592 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026252764869819988\n",
      "SNR: 0/30, LS+LI, Epoch 6/20, Loss: 0.025161173638649458 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026126967870037664\n",
      "SNR: 0/30, LS+LI, Epoch 7/20, Loss: 0.02506728798995704 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02612044382840395\n",
      "SNR: 0/30, LS+LI, Epoch 8/20, Loss: 0.025052275779375504 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02615024538880045\n",
      "SNR: 0/30, LS+LI, Epoch 9/20, Loss: 0.024979835895951406 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.026032223535532303\n",
      "SNR: 0/30, LS+LI, Epoch 10/20, Loss: 0.024933571900176102 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02597935167564587\n",
      "SNR: 0/30, LS+LI, Epoch 11/20, Loss: 0.024881445445380238 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025887926532463593\n",
      "SNR: 0/30, LS+LI, Epoch 12/20, Loss: 0.024866956324035 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025912335481156002\n",
      "SNR: 0/30, LS+LI, Epoch 13/20, Loss: 0.024803024765407276 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025852675846015864\n",
      "SNR: 0/30, LS+LI, Epoch 14/20, Loss: 0.024743226703343002 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025795857930047947\n",
      "SNR: 0/30, LS+LI, Epoch 15/20, Loss: 0.024707508674108012 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025740144012326546\n",
      "SNR: 0/30, LS+LI, Epoch 16/20, Loss: 0.02464011623415836 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025681536729362877\n",
      "SNR: 0/30, LS+LI, Epoch 17/20, Loss: 0.024590858799773595 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.02556756968525323\n",
      "SNR: 0/30, LS+LI, Epoch 18/20, Loss: 0.02451009394297766 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025508860041472046\n",
      "SNR: 0/30, LS+LI, Epoch 19/20, Loss: 0.024524731409930906 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025453529701652853\n",
      "SNR: 0/30, LS+LI, Epoch 20/20, Loss: 0.02449685239861178 \n",
      "SNR: 0/30, LS+LI, Val Loss: 0.025686150120401926\n",
      "LI+NN NMSE: 0.0700932964682579\n",
      "LS+LI NMSE: 0.08203641325235367\n",
      " Training for LS\n",
      "SNR: 0/30, LS, Epoch 1/20, Loss: 0.33668539655763047 \n",
      "SNR: 0/30, LS, Val Loss: 0.31361360441554675\n",
      "SNR: 0/30, LS, Epoch 2/20, Loss: 0.2362328225010356 \n",
      "SNR: 0/30, LS, Val Loss: 0.09843404929746281\n",
      "SNR: 0/30, LS, Epoch 3/20, Loss: 0.03610385572104607 \n",
      "SNR: 0/30, LS, Val Loss: 0.012391890737820755\n",
      "SNR: 0/30, LS, Epoch 4/20, Loss: 0.009551973740007122 \n",
      "SNR: 0/30, LS, Val Loss: 0.007624815408648415\n",
      "SNR: 0/30, LS, Epoch 5/20, Loss: 0.007438525952788633 \n",
      "SNR: 0/30, LS, Val Loss: 0.00731290375221182\n",
      "SNR: 0/30, LS, Epoch 6/20, Loss: 0.007025826500382188 \n",
      "SNR: 0/30, LS, Val Loss: 0.006501429100436243\n",
      "SNR: 0/30, LS, Epoch 7/20, Loss: 0.006754641954483854 \n",
      "SNR: 0/30, LS, Val Loss: 0.006179450460794297\n",
      "SNR: 0/30, LS, Epoch 8/20, Loss: 0.006624277889576935 \n",
      "SNR: 0/30, LS, Val Loss: 0.006910538470203226\n",
      "SNR: 0/30, LS, Epoch 9/20, Loss: 0.00647838061762064 \n",
      "SNR: 0/30, LS, Val Loss: 0.00606342894025147\n",
      "SNR: 0/30, LS, Epoch 10/20, Loss: 0.006476125671788183 \n",
      "SNR: 0/30, LS, Val Loss: 0.007744633804329417\n",
      "SNR: 0/30, LS, Epoch 11/20, Loss: 0.0064458420397280605 \n",
      "SNR: 0/30, LS, Val Loss: 0.006048215151002461\n",
      "SNR: 0/30, LS, Epoch 12/20, Loss: 0.0064912832174233576 \n",
      "SNR: 0/30, LS, Val Loss: 0.005917410048740831\n",
      "SNR: 0/30, LS, Epoch 13/20, Loss: 0.006412832889445993 \n",
      "SNR: 0/30, LS, Val Loss: 0.006096285132860596\n",
      "SNR: 0/30, LS, Epoch 14/20, Loss: 0.006292523919106569 \n",
      "SNR: 0/30, LS, Val Loss: 0.006306000964038752\n",
      "SNR: 0/30, LS, Epoch 15/20, Loss: 0.006261446372454249 \n",
      "SNR: 0/30, LS, Val Loss: 0.00619547636332837\n",
      "SNR: 0/30, LS, Epoch 16/20, Loss: 0.006306341399850194 \n",
      "SNR: 0/30, LS, Val Loss: 0.007657950892197815\n",
      "SNR: 0/30, LS, Epoch 17/20, Loss: 0.006362425057802263 \n",
      "SNR: 0/30, LS, Val Loss: 0.006047377468679439\n",
      "SNR: 0/30, LS, Epoch 18/20, Loss: 0.006333532502203313 \n",
      "SNR: 0/30, LS, Val Loss: 0.006307370410385457\n",
      "SNR: 0/30, LS, Epoch 19/20, Loss: 0.0062927748942964296 \n",
      "SNR: 0/30, LS, Val Loss: 0.006122127958488735\n",
      "SNR: 0/30, LS, Epoch 20/20, Loss: 0.006191347709445413 \n",
      "SNR: 0/30, LS, Val Loss: 0.006119647867638956\n",
      "LS+LI NMSE: 0.01647772267460823\n",
      " SNR: 5/30\n",
      " Training for LS+LI\n",
      "SNR: 5/30, LS+LI, Epoch 1/20, Loss: 0.085369655126056 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.02792477971789512\n",
      "SNR: 5/30, LS+LI, Epoch 2/20, Loss: 0.017197502495417762 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.013227400412275032\n",
      "SNR: 5/30, LS+LI, Epoch 3/20, Loss: 0.011920803621801179 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.012312037446959452\n",
      "SNR: 5/30, LS+LI, Epoch 4/20, Loss: 0.011364138974851473 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011938990813425997\n",
      "SNR: 5/30, LS+LI, Epoch 5/20, Loss: 0.011068807809267106 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011678438083353367\n",
      "SNR: 5/30, LS+LI, Epoch 6/20, Loss: 0.010848283932847513 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011523168280043385\n",
      "SNR: 5/30, LS+LI, Epoch 7/20, Loss: 0.010680205632694239 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011471980420703238\n",
      "SNR: 5/30, LS+LI, Epoch 8/20, Loss: 0.010561463612586607 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011245339939540083\n",
      "SNR: 5/30, LS+LI, Epoch 9/20, Loss: 0.010467641551025905 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01148576649244536\n",
      "SNR: 5/30, LS+LI, Epoch 10/20, Loss: 0.010389611774752306 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011228753190318292\n",
      "SNR: 5/30, LS+LI, Epoch 11/20, Loss: 0.01030707416980159 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.011017343622039665\n",
      "SNR: 5/30, LS+LI, Epoch 12/20, Loss: 0.01021004990176406 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010859331751072948\n",
      "SNR: 5/30, LS+LI, Epoch 13/20, Loss: 0.010123413478479136 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01078977916305038\n",
      "SNR: 5/30, LS+LI, Epoch 14/20, Loss: 0.010060567549581444 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010741348420693115\n",
      "SNR: 5/30, LS+LI, Epoch 15/20, Loss: 0.009993709956815595 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010872311826626008\n",
      "SNR: 5/30, LS+LI, Epoch 16/20, Loss: 0.009913011172483133 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.01064581944691864\n",
      "SNR: 5/30, LS+LI, Epoch 17/20, Loss: 0.009853611713773462 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010617741574109956\n",
      "SNR: 5/30, LS+LI, Epoch 18/20, Loss: 0.009778524020708404 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010424527911130677\n",
      "SNR: 5/30, LS+LI, Epoch 19/20, Loss: 0.009680114835392424 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010556566613641653\n",
      "SNR: 5/30, LS+LI, Epoch 20/20, Loss: 0.00959052873482971 \n",
      "SNR: 5/30, LS+LI, Val Loss: 0.010312122271650216\n",
      "LI+NN NMSE: 0.02893080562353134\n",
      "LS+LI NMSE: 0.025902029126882553\n",
      " Training for LS\n",
      "SNR: 5/30, LS, Epoch 1/20, Loss: 0.32743734259938084 \n",
      "SNR: 5/30, LS, Val Loss: 0.2966563633897088\n",
      "SNR: 5/30, LS, Epoch 2/20, Loss: 0.20253565764531148 \n",
      "SNR: 5/30, LS, Val Loss: 0.06657939471981743\n",
      "SNR: 5/30, LS, Epoch 3/20, Loss: 0.021784600956083904 \n",
      "SNR: 5/30, LS, Val Loss: 0.007575794906270775\n",
      "SNR: 5/30, LS, Epoch 4/20, Loss: 0.005194626821659852 \n",
      "SNR: 5/30, LS, Val Loss: 0.004565891735679047\n",
      "SNR: 5/30, LS, Epoch 5/20, Loss: 0.0043262765921522365 \n",
      "SNR: 5/30, LS, Val Loss: 0.004187644300559027\n",
      "SNR: 5/30, LS, Epoch 6/20, Loss: 0.004090336082384077 \n",
      "SNR: 5/30, LS, Val Loss: 0.003956574290482836\n",
      "SNR: 5/30, LS, Epoch 7/20, Loss: 0.003860118525470932 \n",
      "SNR: 5/30, LS, Val Loss: 0.0038226031782952223\n",
      "SNR: 5/30, LS, Epoch 8/20, Loss: 0.0037359901416916834 \n",
      "SNR: 5/30, LS, Val Loss: 0.003760302100669254\n",
      "SNR: 5/30, LS, Epoch 9/20, Loss: 0.0035499703737387305 \n",
      "SNR: 5/30, LS, Val Loss: 0.003557205443609167\n",
      "SNR: 5/30, LS, Epoch 10/20, Loss: 0.0034791069378708166 \n",
      "SNR: 5/30, LS, Val Loss: 0.003463504666631872\n",
      "SNR: 5/30, LS, Epoch 11/20, Loss: 0.0034369233573332083 \n",
      "SNR: 5/30, LS, Val Loss: 0.004152205042456361\n",
      "SNR: 5/30, LS, Epoch 12/20, Loss: 0.003468777414487112 \n",
      "SNR: 5/30, LS, Val Loss: 0.003312589357268404\n",
      "SNR: 5/30, LS, Epoch 13/20, Loss: 0.0033290520808551202 \n",
      "SNR: 5/30, LS, Val Loss: 0.0032384824431078\n",
      "SNR: 5/30, LS, Epoch 14/20, Loss: 0.003255120548961121 \n",
      "SNR: 5/30, LS, Val Loss: 0.0032394628400321712\n",
      "SNR: 5/30, LS, Epoch 15/20, Loss: 0.0032973796586765972 \n",
      "SNR: 5/30, LS, Val Loss: 0.0034685466036369853\n",
      "SNR: 5/30, LS, Epoch 16/20, Loss: 0.0032818959673953266 \n",
      "SNR: 5/30, LS, Val Loss: 0.003267225237901915\n",
      "SNR: 5/30, LS, Epoch 17/20, Loss: 0.0032245472227872976 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031098049790175123\n",
      "SNR: 5/30, LS, Epoch 18/20, Loss: 0.003158500279992992 \n",
      "SNR: 5/30, LS, Val Loss: 0.003112450273792175\n",
      "SNR: 5/30, LS, Epoch 19/20, Loss: 0.003203706771167818 \n",
      "SNR: 5/30, LS, Val Loss: 0.0031154376814480533\n",
      "SNR: 5/30, LS, Epoch 20/20, Loss: 0.003150628774080339 \n",
      "SNR: 5/30, LS, Val Loss: 0.003045138077471744\n",
      "LS+LI NMSE: 0.008597330190241337\n",
      " SNR: 10/30\n",
      " Training for LS+LI\n",
      "SNR: 10/30, LS+LI, Epoch 1/20, Loss: 0.06805042198014467 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.018483547493815422\n",
      "SNR: 10/30, LS+LI, Epoch 2/20, Loss: 0.010871097088120011 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.008477744582871144\n",
      "SNR: 10/30, LS+LI, Epoch 3/20, Loss: 0.0071402107944798674 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.007236850913614035\n",
      "SNR: 10/30, LS+LI, Epoch 4/20, Loss: 0.006198245923706266 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.006498439216308973\n",
      "SNR: 10/30, LS+LI, Epoch 5/20, Loss: 0.0055585438250239155 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00595948072573678\n",
      "SNR: 10/30, LS+LI, Epoch 6/20, Loss: 0.005043925300543738 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00560939909932627\n",
      "SNR: 10/30, LS+LI, Epoch 7/20, Loss: 0.004692083561717165 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.005249880201352591\n",
      "SNR: 10/30, LS+LI, Epoch 8/20, Loss: 0.004494633670452289 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.00511549323246899\n",
      "SNR: 10/30, LS+LI, Epoch 9/20, Loss: 0.004400000834382724 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004989920025268061\n",
      "SNR: 10/30, LS+LI, Epoch 10/20, Loss: 0.004284769235731124 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004864854801615531\n",
      "SNR: 10/30, LS+LI, Epoch 11/20, Loss: 0.0042170504565610615 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004794300650246441\n",
      "SNR: 10/30, LS+LI, Epoch 12/20, Loss: 0.0041455383423369295 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.0047303206837651405\n",
      "SNR: 10/30, LS+LI, Epoch 13/20, Loss: 0.004049787767567174 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004638953261416067\n",
      "SNR: 10/30, LS+LI, Epoch 14/20, Loss: 0.003985224261901579 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004558743390424008\n",
      "SNR: 10/30, LS+LI, Epoch 15/20, Loss: 0.003909864571205405 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004524569132957946\n",
      "SNR: 10/30, LS+LI, Epoch 16/20, Loss: 0.0038488800271934027 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004449492606165057\n",
      "SNR: 10/30, LS+LI, Epoch 17/20, Loss: 0.003795482576987165 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004479872549630024\n",
      "SNR: 10/30, LS+LI, Epoch 18/20, Loss: 0.003761049808100472 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004322445221160623\n",
      "SNR: 10/30, LS+LI, Epoch 19/20, Loss: 0.003719050629432638 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004335431440267712\n",
      "SNR: 10/30, LS+LI, Epoch 20/20, Loss: 0.0037072439201522706 \n",
      "SNR: 10/30, LS+LI, Val Loss: 0.004323601008350538\n",
      "LI+NN NMSE: 0.011771740391850471\n",
      "LS+LI NMSE: 0.008208531886339188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS\n",
      "SNR: 10/30, LS, Epoch 1/20, Loss: 0.32264337272838106 \n",
      "SNR: 10/30, LS, Val Loss: 0.29347367042844946\n",
      "SNR: 10/30, LS, Epoch 2/20, Loss: 0.1734222123009521 \n",
      "SNR: 10/30, LS, Val Loss: 0.04902777685360475\n",
      "SNR: 10/30, LS, Epoch 3/20, Loss: 0.019831174248179723 \n",
      "SNR: 10/30, LS, Val Loss: 0.00971178033135154\n",
      "SNR: 10/30, LS, Epoch 4/20, Loss: 0.00521756416500741 \n",
      "SNR: 10/30, LS, Val Loss: 0.0035833016418936577\n",
      "SNR: 10/30, LS, Epoch 5/20, Loss: 0.0028675675302808888 \n",
      "SNR: 10/30, LS, Val Loss: 0.0029450713614509864\n",
      "SNR: 10/30, LS, Epoch 6/20, Loss: 0.002510883417630265 \n",
      "SNR: 10/30, LS, Val Loss: 0.0024402350854043934\n",
      "SNR: 10/30, LS, Epoch 7/20, Loss: 0.002371533327129518 \n",
      "SNR: 10/30, LS, Val Loss: 0.0025503222132101655\n",
      "SNR: 10/30, LS, Epoch 8/20, Loss: 0.002183648859161537 \n",
      "SNR: 10/30, LS, Val Loss: 0.0022082889865321868\n",
      "SNR: 10/30, LS, Epoch 9/20, Loss: 0.0021975486455376933 \n",
      "SNR: 10/30, LS, Val Loss: 0.002466667295348915\n",
      "SNR: 10/30, LS, Epoch 10/20, Loss: 0.002048731585260654 \n",
      "SNR: 10/30, LS, Val Loss: 0.002207285280085423\n",
      "SNR: 10/30, LS, Epoch 11/20, Loss: 0.002040288723100973 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020796356892043896\n",
      "SNR: 10/30, LS, Epoch 12/20, Loss: 0.001984813010325482 \n",
      "SNR: 10/30, LS, Val Loss: 0.0020384163574569607\n",
      "SNR: 10/30, LS, Epoch 13/20, Loss: 0.001938006998348418 \n",
      "SNR: 10/30, LS, Val Loss: 0.002121963771060109\n",
      "SNR: 10/30, LS, Epoch 14/20, Loss: 0.001969508281205023 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018344009877182543\n",
      "SNR: 10/30, LS, Epoch 15/20, Loss: 0.0018858453725886985 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018121191162870011\n",
      "SNR: 10/30, LS, Epoch 16/20, Loss: 0.0018399027379251323 \n",
      "SNR: 10/30, LS, Val Loss: 0.0018129676675677977\n",
      "SNR: 10/30, LS, Epoch 17/20, Loss: 0.0018314969141122906 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017869811695577068\n",
      "SNR: 10/30, LS, Epoch 18/20, Loss: 0.0018989522366102266 \n",
      "SNR: 10/30, LS, Val Loss: 0.001823107955384661\n",
      "SNR: 10/30, LS, Epoch 19/20, Loss: 0.001820176539991354 \n",
      "SNR: 10/30, LS, Val Loss: 0.001723586158318953\n",
      "SNR: 10/30, LS, Epoch 20/20, Loss: 0.0017837567937148864 \n",
      "SNR: 10/30, LS, Val Loss: 0.0017425499919971282\n",
      "LS+LI NMSE: 0.004809786565601826\n",
      " SNR: 15/30\n",
      " Training for LS+LI\n",
      "SNR: 15/30, LS+LI, Epoch 1/20, Loss: 0.0612742159309862 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.012709780807860872\n",
      "SNR: 15/30, LS+LI, Epoch 2/20, Loss: 0.007342723533944335 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.005432489751414819\n",
      "SNR: 15/30, LS+LI, Epoch 3/20, Loss: 0.004785749989529248 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0043453058143231\n",
      "SNR: 15/30, LS+LI, Epoch 4/20, Loss: 0.0037527649005506796 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.003177868075330149\n",
      "SNR: 15/30, LS+LI, Epoch 5/20, Loss: 0.0028195234251121967 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.002659445438026027\n",
      "SNR: 15/30, LS+LI, Epoch 6/20, Loss: 0.002577602780061276 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0025216892827302217\n",
      "SNR: 15/30, LS+LI, Epoch 7/20, Loss: 0.0024267753997687684 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0023689061847769403\n",
      "SNR: 15/30, LS+LI, Epoch 8/20, Loss: 0.0022827843163530665 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0022056649269705467\n",
      "SNR: 15/30, LS+LI, Epoch 9/20, Loss: 0.002163751390600187 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0021586231781508436\n",
      "SNR: 15/30, LS+LI, Epoch 10/20, Loss: 0.002057532054307156 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019999045550569213\n",
      "SNR: 15/30, LS+LI, Epoch 11/20, Loss: 0.001960566321517839 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0019292503870515661\n",
      "SNR: 15/30, LS+LI, Epoch 12/20, Loss: 0.001891982890557238 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0018845722132193093\n",
      "SNR: 15/30, LS+LI, Epoch 13/20, Loss: 0.0017957701604964947 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017746146768331528\n",
      "SNR: 15/30, LS+LI, Epoch 14/20, Loss: 0.0017304972983723463 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0017162419919093902\n",
      "SNR: 15/30, LS+LI, Epoch 15/20, Loss: 0.0016573312540733537 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001618731184862554\n",
      "SNR: 15/30, LS+LI, Epoch 16/20, Loss: 0.0016076924955488595 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.00167400958228179\n",
      "SNR: 15/30, LS+LI, Epoch 17/20, Loss: 0.001568321295984111 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.001557704315266826\n",
      "SNR: 15/30, LS+LI, Epoch 18/20, Loss: 0.0015377163806480768 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0016005115520039742\n",
      "SNR: 15/30, LS+LI, Epoch 19/20, Loss: 0.00150539169120494 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0014677263732830231\n",
      "SNR: 15/30, LS+LI, Epoch 20/20, Loss: 0.0015027247877591181 \n",
      "SNR: 15/30, LS+LI, Val Loss: 0.0015105494901283898\n",
      "LI+NN NMSE: 0.004204137250781059\n",
      "LS+LI NMSE: 0.0025808236096054316\n",
      " Training for LS\n",
      "SNR: 15/30, LS, Epoch 1/20, Loss: 0.32306066709895465 \n",
      "SNR: 15/30, LS, Val Loss: 0.2981213060292331\n",
      "SNR: 15/30, LS, Epoch 2/20, Loss: 0.1860939762230183 \n",
      "SNR: 15/30, LS, Val Loss: 0.05941698734055866\n",
      "SNR: 15/30, LS, Epoch 3/20, Loss: 0.023584252599691755 \n",
      "SNR: 15/30, LS, Val Loss: 0.011064682769673791\n",
      "SNR: 15/30, LS, Epoch 4/20, Loss: 0.005554889564315767 \n",
      "SNR: 15/30, LS, Val Loss: 0.003573922789655626\n",
      "SNR: 15/30, LS, Epoch 5/20, Loss: 0.0026182576805504777 \n",
      "SNR: 15/30, LS, Val Loss: 0.00240836934377016\n",
      "SNR: 15/30, LS, Epoch 6/20, Loss: 0.002088180131977424 \n",
      "SNR: 15/30, LS, Val Loss: 0.002184465569867329\n",
      "SNR: 15/30, LS, Epoch 7/20, Loss: 0.0018967085688504888 \n",
      "SNR: 15/30, LS, Val Loss: 0.0017882249191064727\n",
      "SNR: 15/30, LS, Epoch 8/20, Loss: 0.001703294127405253 \n",
      "SNR: 15/30, LS, Val Loss: 0.0016379844058643687\n",
      "SNR: 15/30, LS, Epoch 9/20, Loss: 0.001540083290608383 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015373697599650106\n",
      "SNR: 15/30, LS, Epoch 10/20, Loss: 0.001446087116397224 \n",
      "SNR: 15/30, LS, Val Loss: 0.0015803411475975406\n",
      "SNR: 15/30, LS, Epoch 11/20, Loss: 0.001425136849933932 \n",
      "SNR: 15/30, LS, Val Loss: 0.001459135636898943\n",
      "SNR: 15/30, LS, Epoch 12/20, Loss: 0.0016389603958042816 \n",
      "SNR: 15/30, LS, Val Loss: 0.0020252296976237135\n",
      "SNR: 15/30, LS, Epoch 13/20, Loss: 0.0014307622579170045 \n",
      "SNR: 15/30, LS, Val Loss: 0.001285032882482152\n",
      "SNR: 15/30, LS, Epoch 14/20, Loss: 0.0012974044156455716 \n",
      "SNR: 15/30, LS, Val Loss: 0.001333011642352424\n",
      "SNR: 15/30, LS, Epoch 15/20, Loss: 0.0012557883922898665 \n",
      "SNR: 15/30, LS, Val Loss: 0.0013758583809249103\n",
      "SNR: 15/30, LS, Epoch 16/20, Loss: 0.0012233966286700263 \n",
      "SNR: 15/30, LS, Val Loss: 0.0014253140120259063\n",
      "SNR: 15/30, LS, Epoch 17/20, Loss: 0.0012322694620220424 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012727385778403418\n",
      "SNR: 15/30, LS, Epoch 18/20, Loss: 0.0011754328754546425 \n",
      "SNR: 15/30, LS, Val Loss: 0.0012673834254118528\n",
      "SNR: 15/30, LS, Epoch 19/20, Loss: 0.0011628019473878233 \n",
      "SNR: 15/30, LS, Val Loss: 0.001270236823157492\n",
      "SNR: 15/30, LS, Epoch 20/20, Loss: 0.0011242923677389964 \n",
      "SNR: 15/30, LS, Val Loss: 0.001124945871362632\n",
      "LS+LI NMSE: 0.003140872111544013\n",
      " SNR: 20/30\n",
      " Training for LS+LI\n",
      "SNR: 20/30, LS+LI, Epoch 1/20, Loss: 0.07144284356645374 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.019701490009372883\n",
      "SNR: 20/30, LS+LI, Epoch 2/20, Loss: 0.009896965158648442 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.005201683443208987\n",
      "SNR: 20/30, LS+LI, Epoch 3/20, Loss: 0.004474124918572691 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.00398952456783842\n",
      "SNR: 20/30, LS+LI, Epoch 4/20, Loss: 0.003605655035772902 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0033138759794052353\n",
      "SNR: 20/30, LS+LI, Epoch 5/20, Loss: 0.003016714530531317 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0027817411517555065\n",
      "SNR: 20/30, LS+LI, Epoch 6/20, Loss: 0.0025091458038903427 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.002282354589128359\n",
      "SNR: 20/30, LS+LI, Epoch 7/20, Loss: 0.002023255991272975 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0018050363287329674\n",
      "SNR: 20/30, LS+LI, Epoch 8/20, Loss: 0.0016016497819543664 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0015053940905173395\n",
      "SNR: 20/30, LS+LI, Epoch 9/20, Loss: 0.0013585221442004103 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0012699303201357411\n",
      "SNR: 20/30, LS+LI, Epoch 10/20, Loss: 0.0012269320354260894 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0011639472001909533\n",
      "SNR: 20/30, LS+LI, Epoch 11/20, Loss: 0.0011226416201341551 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.001114876255583526\n",
      "SNR: 20/30, LS+LI, Epoch 12/20, Loss: 0.0010505290898267007 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0010077419177502054\n",
      "SNR: 20/30, LS+LI, Epoch 13/20, Loss: 0.000977841246504943 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0009399735030125488\n",
      "SNR: 20/30, LS+LI, Epoch 14/20, Loss: 0.000915845837119187 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000929290949980813\n",
      "SNR: 20/30, LS+LI, Epoch 15/20, Loss: 0.000863617354784659 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008183741949985481\n",
      "SNR: 20/30, LS+LI, Epoch 16/20, Loss: 0.0008058890928433082 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0008435406383465637\n",
      "SNR: 20/30, LS+LI, Epoch 17/20, Loss: 0.0007703805773459419 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000735443544478833\n",
      "SNR: 20/30, LS+LI, Epoch 18/20, Loss: 0.0007237128270072537 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006994412119225176\n",
      "SNR: 20/30, LS+LI, Epoch 19/20, Loss: 0.0006987657237237558 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.000682292429370467\n",
      "SNR: 20/30, LS+LI, Epoch 20/20, Loss: 0.0006868925396025419 \n",
      "SNR: 20/30, LS+LI, Val Loss: 0.0006594280275749043\n",
      "LI+NN NMSE: 0.0018193046562373638\n",
      "LS+LI NMSE: 0.0008236871217377484\n",
      " Training for LS\n",
      "SNR: 20/30, LS, Epoch 1/20, Loss: 0.3246948213078255 \n",
      "SNR: 20/30, LS, Val Loss: 0.2943829298019409\n",
      "SNR: 20/30, LS, Epoch 2/20, Loss: 0.18829018707105585 \n",
      "SNR: 20/30, LS, Val Loss: 0.053411835465918885\n",
      "SNR: 20/30, LS, Epoch 3/20, Loss: 0.020028010235427943 \n",
      "SNR: 20/30, LS, Val Loss: 0.007134723297150975\n",
      "SNR: 20/30, LS, Epoch 4/20, Loss: 0.004225159456498574 \n",
      "SNR: 20/30, LS, Val Loss: 0.0028781515905972233\n",
      "SNR: 20/30, LS, Epoch 5/20, Loss: 0.002436347016766884 \n",
      "SNR: 20/30, LS, Val Loss: 0.002275478777433322\n",
      "SNR: 20/30, LS, Epoch 6/20, Loss: 0.002059898964605879 \n",
      "SNR: 20/30, LS, Val Loss: 0.001962323524904522\n",
      "SNR: 20/30, LS, Epoch 7/20, Loss: 0.0017961584171009531 \n",
      "SNR: 20/30, LS, Val Loss: 0.001723065400834788\n",
      "SNR: 20/30, LS, Epoch 8/20, Loss: 0.001611061932297077 \n",
      "SNR: 20/30, LS, Val Loss: 0.0016949747964231806\n",
      "SNR: 20/30, LS, Epoch 9/20, Loss: 0.0014979975165387745 \n",
      "SNR: 20/30, LS, Val Loss: 0.0016893760026009245\n",
      "SNR: 20/30, LS, Epoch 10/20, Loss: 0.001388690244206119 \n",
      "SNR: 20/30, LS, Val Loss: 0.0015104517753405328\n",
      "SNR: 20/30, LS, Epoch 11/20, Loss: 0.0014099812887738957 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012665181526575577\n",
      "SNR: 20/30, LS, Epoch 12/20, Loss: 0.001267690881599434 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012092772098681467\n",
      "SNR: 20/30, LS, Epoch 13/20, Loss: 0.0012363967422103553 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012192388372072442\n",
      "SNR: 20/30, LS, Epoch 14/20, Loss: 0.0012105985982533067 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011287388280669059\n",
      "SNR: 20/30, LS, Epoch 15/20, Loss: 0.0011111566283182393 \n",
      "SNR: 20/30, LS, Val Loss: 0.0012468680189075794\n",
      "SNR: 20/30, LS, Epoch 16/20, Loss: 0.0010938651644527306 \n",
      "SNR: 20/30, LS, Val Loss: 0.0010666808467993344\n",
      "SNR: 20/30, LS, Epoch 17/20, Loss: 0.0010616637896313224 \n",
      "SNR: 20/30, LS, Val Loss: 0.0011062947265930813\n",
      "SNR: 20/30, LS, Epoch 18/20, Loss: 0.0011140635964016668 \n",
      "SNR: 20/30, LS, Val Loss: 0.001004574113969945\n",
      "SNR: 20/30, LS, Epoch 19/20, Loss: 0.001000462637315396 \n",
      "SNR: 20/30, LS, Val Loss: 0.000979078989158469\n",
      "SNR: 20/30, LS, Epoch 20/20, Loss: 0.0010249416823065731 \n",
      "SNR: 20/30, LS, Val Loss: 0.001668179000262171\n",
      "LS+LI NMSE: 0.004807798657566309\n",
      " SNR: 25/30\n",
      " Training for LS+LI\n",
      "SNR: 25/30, LS+LI, Epoch 1/20, Loss: 0.06721272499322198 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.017095718109472233\n",
      "SNR: 25/30, LS+LI, Epoch 2/20, Loss: 0.008804831929981362 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.004940959307449785\n",
      "SNR: 25/30, LS+LI, Epoch 3/20, Loss: 0.00418976140019029 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0035517812410200186\n",
      "SNR: 25/30, LS+LI, Epoch 4/20, Loss: 0.0030996476402939403 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.002628540683707053\n",
      "SNR: 25/30, LS+LI, Epoch 5/20, Loss: 0.002205799664722669 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00176672396694564\n",
      "SNR: 25/30, LS+LI, Epoch 6/20, Loss: 0.0014310363073681677 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0011548203156880018\n",
      "SNR: 25/30, LS+LI, Epoch 7/20, Loss: 0.001033276904626143 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0009333541807295246\n",
      "SNR: 25/30, LS+LI, Epoch 8/20, Loss: 0.0008829168188196152 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0008289624952753497\n",
      "SNR: 25/30, LS+LI, Epoch 9/20, Loss: 0.0007894299362602015 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0007549723112871023\n",
      "SNR: 25/30, LS+LI, Epoch 10/20, Loss: 0.0007120832262105893 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006709151890721511\n",
      "SNR: 25/30, LS+LI, Epoch 11/20, Loss: 0.0006477688300439568 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0006085221645083617\n",
      "SNR: 25/30, LS+LI, Epoch 12/20, Loss: 0.0005837047322339183 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005655181501589885\n",
      "SNR: 25/30, LS+LI, Epoch 13/20, Loss: 0.0005293389676385126 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0005298364267218858\n",
      "SNR: 25/30, LS+LI, Epoch 14/20, Loss: 0.0004730431593448292 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00045321506067094475\n",
      "SNR: 25/30, LS+LI, Epoch 15/20, Loss: 0.00042881983008132815 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0004158801139882681\n",
      "SNR: 25/30, LS+LI, Epoch 16/20, Loss: 0.0003961702984037571 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00037022459781093693\n",
      "SNR: 25/30, LS+LI, Epoch 17/20, Loss: 0.00037319658271329435 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003537496681515635\n",
      "SNR: 25/30, LS+LI, Epoch 18/20, Loss: 0.0003539898137015096 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.0003372109938275323\n",
      "SNR: 25/30, LS+LI, Epoch 19/20, Loss: 0.0003360563609613712 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00033612836176127365\n",
      "SNR: 25/30, LS+LI, Epoch 20/20, Loss: 0.0003238545635445747 \n",
      "SNR: 25/30, LS+LI, Val Loss: 0.00031285802833735943\n",
      "LI+NN NMSE: 0.0008809802820906043\n",
      "LS+LI NMSE: 0.00025972857838496566\n",
      " Training for LS\n",
      "SNR: 25/30, LS, Epoch 1/20, Loss: 0.3275642213086749 \n",
      "SNR: 25/30, LS, Val Loss: 0.2981224710291082\n",
      "SNR: 25/30, LS, Epoch 2/20, Loss: 0.2131704976565616 \n",
      "SNR: 25/30, LS, Val Loss: 0.07178174230185422\n",
      "SNR: 25/30, LS, Epoch 3/20, Loss: 0.025293044353358794 \n",
      "SNR: 25/30, LS, Val Loss: 0.005999958491884172\n",
      "SNR: 25/30, LS, Epoch 4/20, Loss: 0.0043144307348357384 \n",
      "SNR: 25/30, LS, Val Loss: 0.0032103764295408673\n",
      "SNR: 25/30, LS, Epoch 5/20, Loss: 0.003045183953661255 \n",
      "SNR: 25/30, LS, Val Loss: 0.0025501481934704566\n",
      "SNR: 25/30, LS, Epoch 6/20, Loss: 0.0024634753177917106 \n",
      "SNR: 25/30, LS, Val Loss: 0.0022458921938033945\n",
      "SNR: 25/30, LS, Epoch 7/20, Loss: 0.0021318097559594397 \n",
      "SNR: 25/30, LS, Val Loss: 0.001828960322944278\n",
      "SNR: 25/30, LS, Epoch 8/20, Loss: 0.0018972894413732426 \n",
      "SNR: 25/30, LS, Val Loss: 0.0016668343292125924\n",
      "SNR: 25/30, LS, Epoch 9/20, Loss: 0.001643933916903036 \n",
      "SNR: 25/30, LS, Val Loss: 0.0015004304269413378\n",
      "SNR: 25/30, LS, Epoch 10/20, Loss: 0.0015092889932634005 \n",
      "SNR: 25/30, LS, Val Loss: 0.0014088706970638173\n",
      "SNR: 25/30, LS, Epoch 11/20, Loss: 0.0014186035043040161 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012754283591427586\n",
      "SNR: 25/30, LS, Epoch 12/20, Loss: 0.0013474883223331513 \n",
      "SNR: 25/30, LS, Val Loss: 0.0012044764642434363\n",
      "SNR: 25/30, LS, Epoch 13/20, Loss: 0.001253971124411734 \n",
      "SNR: 25/30, LS, Val Loss: 0.0011474156053736806\n",
      "SNR: 25/30, LS, Epoch 14/20, Loss: 0.0012486745091696639 \n",
      "SNR: 25/30, LS, Val Loss: 0.001133292839354412\n",
      "SNR: 25/30, LS, Epoch 15/20, Loss: 0.001152604112745436 \n",
      "SNR: 25/30, LS, Val Loss: 0.001283318547807126\n",
      "SNR: 25/30, LS, Epoch 16/20, Loss: 0.001116525983846703 \n",
      "SNR: 25/30, LS, Val Loss: 0.0010444985448636792\n",
      "SNR: 25/30, LS, Epoch 17/20, Loss: 0.001092285751013172 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009874954597431827\n",
      "SNR: 25/30, LS, Epoch 18/20, Loss: 0.001066870247298137 \n",
      "SNR: 25/30, LS, Val Loss: 0.0009892040159849619\n",
      "SNR: 25/30, LS, Epoch 19/20, Loss: 0.001003267862806963 \n",
      "SNR: 25/30, LS, Val Loss: 0.000927154062082991\n",
      "SNR: 25/30, LS, Epoch 20/20, Loss: 0.0009838128804234615 \n",
      "SNR: 25/30, LS, Val Loss: 0.000921168271981349\n",
      "LS+LI NMSE: 0.0026306193321943283\n",
      " SNR: 30/30\n",
      " Training for LS+LI\n",
      "SNR: 30/30, LS+LI, Epoch 1/20, Loss: 0.05984762192942029 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.016985833644866943\n",
      "SNR: 30/30, LS+LI, Epoch 2/20, Loss: 0.00819922190668538 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.004645449659702453\n",
      "SNR: 30/30, LS+LI, Epoch 3/20, Loss: 0.003951352953282726 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0034138217822394586\n",
      "SNR: 30/30, LS+LI, Epoch 4/20, Loss: 0.0029503323738788102 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0025155155559663067\n",
      "SNR: 30/30, LS+LI, Epoch 5/20, Loss: 0.002009209174375851 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0015927101220850918\n",
      "SNR: 30/30, LS+LI, Epoch 6/20, Loss: 0.0014210473556548011 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0012886088701303709\n",
      "SNR: 30/30, LS+LI, Epoch 7/20, Loss: 0.0011681561682476164 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0010597267140507358\n",
      "SNR: 30/30, LS+LI, Epoch 8/20, Loss: 0.000961321834840292 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0008757566366429356\n",
      "SNR: 30/30, LS+LI, Epoch 9/20, Loss: 0.0008035296483539304 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0007425417716149241\n",
      "SNR: 30/30, LS+LI, Epoch 10/20, Loss: 0.000690310429998262 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0006491339088163593\n",
      "SNR: 30/30, LS+LI, Epoch 11/20, Loss: 0.0006070122844268849 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005701055554461411\n",
      "SNR: 30/30, LS+LI, Epoch 12/20, Loss: 0.0005399209542300141 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0005039702241033824\n",
      "SNR: 30/30, LS+LI, Epoch 13/20, Loss: 0.0004767862112710772 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.000443642222142609\n",
      "SNR: 30/30, LS+LI, Epoch 14/20, Loss: 0.0004190351390333976 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00038877950944218105\n",
      "SNR: 30/30, LS+LI, Epoch 15/20, Loss: 0.0003710148059411061 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00033981308462733233\n",
      "SNR: 30/30, LS+LI, Epoch 16/20, Loss: 0.00032361957101086373 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00029956980804193086\n",
      "SNR: 30/30, LS+LI, Epoch 17/20, Loss: 0.00028687006640613493 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00027464636580341244\n",
      "SNR: 30/30, LS+LI, Epoch 18/20, Loss: 0.000257866782069255 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002456075506581163\n",
      "SNR: 30/30, LS+LI, Epoch 19/20, Loss: 0.0002379658443143938 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.00022642626109617677\n",
      "SNR: 30/30, LS+LI, Epoch 20/20, Loss: 0.0002216534723079666 \n",
      "SNR: 30/30, LS+LI, Val Loss: 0.0002174385511104695\n",
      "LI+NN NMSE: 0.0006083224434405565\n",
      "LS+LI NMSE: 8.423432882409543e-05\n",
      " Training for LS\n",
      "SNR: 30/30, LS, Epoch 1/20, Loss: 0.3266928944476815 \n",
      "SNR: 30/30, LS, Val Loss: 0.3053243796933781\n",
      "SNR: 30/30, LS, Epoch 2/20, Loss: 0.20759633254952903 \n",
      "SNR: 30/30, LS, Val Loss: 0.0787856053899635\n",
      "SNR: 30/30, LS, Epoch 3/20, Loss: 0.02293341794473574 \n",
      "SNR: 30/30, LS, Val Loss: 0.005566113437949257\n",
      "SNR: 30/30, LS, Epoch 4/20, Loss: 0.003403078772799047 \n",
      "SNR: 30/30, LS, Val Loss: 0.002956063169139353\n",
      "SNR: 30/30, LS, Epoch 5/20, Loss: 0.002496660963854168 \n",
      "SNR: 30/30, LS, Val Loss: 0.0024211458036337385\n",
      "SNR: 30/30, LS, Epoch 6/20, Loss: 0.002074354437862111 \n",
      "SNR: 30/30, LS, Val Loss: 0.002053693873511458\n",
      "SNR: 30/30, LS, Epoch 7/20, Loss: 0.0017831392652560892 \n",
      "SNR: 30/30, LS, Val Loss: 0.0018940033041872084\n",
      "SNR: 30/30, LS, Epoch 8/20, Loss: 0.0015878738398219696 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016012527524832296\n",
      "SNR: 30/30, LS, Epoch 9/20, Loss: 0.0014434109738388986 \n",
      "SNR: 30/30, LS, Val Loss: 0.0014258381931788542\n",
      "SNR: 30/30, LS, Epoch 10/20, Loss: 0.001410981536325782 \n",
      "SNR: 30/30, LS, Val Loss: 0.0016111691736362197\n",
      "SNR: 30/30, LS, Epoch 11/20, Loss: 0.0013100266890454127 \n",
      "SNR: 30/30, LS, Val Loss: 0.001316848666068505\n",
      "SNR: 30/30, LS, Epoch 12/20, Loss: 0.0011946055253014662 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012407008696093478\n",
      "SNR: 30/30, LS, Epoch 13/20, Loss: 0.0011921526510864063 \n",
      "SNR: 30/30, LS, Val Loss: 0.0012056546349247749\n",
      "SNR: 30/30, LS, Epoch 14/20, Loss: 0.0011165541309733377 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011090851330664009\n",
      "SNR: 30/30, LS, Epoch 15/20, Loss: 0.0010720517870098309 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010703619416083463\n",
      "SNR: 30/30, LS, Epoch 16/20, Loss: 0.0010249169037791057 \n",
      "SNR: 30/30, LS, Val Loss: 0.0011855193191546607\n",
      "SNR: 30/30, LS, Epoch 17/20, Loss: 0.0009853317298070896 \n",
      "SNR: 30/30, LS, Val Loss: 0.0010711842094844376\n",
      "SNR: 30/30, LS, Epoch 18/20, Loss: 0.0009866207343970188 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009567276468839158\n",
      "SNR: 30/30, LS, Epoch 19/20, Loss: 0.00095313964283018 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009317793856925247\n",
      "SNR: 30/30, LS, Epoch 20/20, Loss: 0.00089026651809501 \n",
      "SNR: 30/30, LS, Val Loss: 0.0009261591397014192\n",
      "LS+LI NMSE: 0.0025549069978296757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                    # of valLabels\n",
    "        # train_loader, val_loader are already normalized by their own min, max\n",
    "        # scale to range [-1 1]\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est(act = 'Tanh').to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    \n",
    "    nmse_LI_NN = utils.calNMSE(H_val_NN_denormd_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu().mean()\n",
    "    nmse_LI_NN_val.append(variables['NMSE_LI_NN'].item())\n",
    "    print(f\"LI+NN NMSE: {variables['NMSE_LI_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN[-1], index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "#####\n",
    "##### above is LS+LI+NN \n",
    "\n",
    "##### following is Linear interpolated channel (only LS+LI)\n",
    "    H_val_linInterp = H_linear_val.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI'] = nmse_LI.cpu().mean()\n",
    "    nmse_LS_LI_val.append(variables['NMSE_LI'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LI'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI[-1], index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    H_LS_train = H_equal_train.cpu()\n",
    "    plotfig.figTrueChan(H_LS_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est(act = 'Tanh').to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deMinMax(H_NN_val, valLabel_min, valLabel_max)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = utils.calNMSE(H_val_LS_NN_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu().mean()\n",
    "    nmse_LS_NN_val.append(variables['NMSE_LS_NN'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LS_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN[-1], index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver11_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+NN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+NN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE1.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
