{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: DeepMIMO data: BS16, row3500_3516, 3.4 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Add the Torch_code directory to the Python path\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "# import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_PATH = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# print(FILE_PATH)\n",
    "# print(config.temp_path)\n",
    "# print(config.FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "\n",
    "# rows from DeepMIMO dataset settings\n",
    "# change rows according to the .mat dataset file \n",
    "rows = [['3500', '3516']] \n",
    "fc = '3p4' #Hz can change to '60'\n",
    "rowss = \"3500_3516\"\n",
    "learning_rate = 1e-5 \n",
    "SNR = np.arange(-25, -4, 5) # -25:5:-5 # 0:5:30 dB\n",
    "outer_file_path = os.path.abspath(os.path.join(config.FILE_PATH, \n",
    "                        '..', 'DeepMIMOv2', 'DeepMIMO_Data', 'Static_BS16', 'freq_symb_1ant_612sub_ver4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "lower_range = -1 \n",
    "    # if norm_approach = 'minmax': \n",
    "        # =  0 for scaling to  [0 1]\n",
    "        # = -1 for scaling to [-1 1]\n",
    "    # if norm_approach = 'std': can be any value, but need to be defined\n",
    "    \n",
    "if norm_approach == 'minmax':\n",
    "    if lower_range == 0:\n",
    "        norm_txt = 'Using min-max [0 1]'\n",
    "    elif lower_range ==-1:\n",
    "        norm_txt = 'Using min-max [-1 1]'\n",
    "elif norm_approach == 'no':\n",
    "    norm_txt = 'No'\n",
    "    \n",
    "CNN_activation = 'Tanh'\n",
    "CNN_DropOut = 0.2\n",
    "if CNN_DropOut != 0:\n",
    "    dropOut_txt = f'Add p={CNN_DropOut} DropOut'\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'train/static_CNN_lr1e-5_v11_(...).ipynb'.\n",
    "Correspond with BS16, 3.4 GHz fc, rows {rowss},\n",
    "Data got from {outer_file_path},\n",
    "Learning rate {learning_rate}, {NUM_EPOCHS} epochs\n",
    "{norm_txt} scaler for each sample\n",
    "Using {CNN_activation} as activation function of CNN\n",
    "{dropOut_txt}\n",
    "Results of SNR = -25:5:-5\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../model/static/CNN/BS16/3500_3516/ver27_/readme.txt' and ' ../figure/static/CNN/BS16/3500_3516/ver27_/readme.txt ' created and content written.\n"
     ]
    }
   ],
   "source": [
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename('../model/static/CNN/BS16/'+ rowss,'ver', '_', '')\n",
    "model_path = '../model/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "figure_path = '../figure/static/CNN/BS16/' + rowss + '/ver' + str(idx_save_path) + '_/readme.txt'\n",
    "\n",
    "if not os.path.exists(os.path.dirname(model_path)):\n",
    "    os.makedirs(os.path.dirname(model_path))\n",
    "if not os.path.exists(os.path.dirname(figure_path)):\n",
    "    os.makedirs(os.path.dirname(figure_path))\n",
    "\n",
    "# Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "with open(model_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "with open(figure_path, 'w') as file:\n",
    "    # Write the content to the file\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File '{model_path}' and ' {figure_path} ' created and content written.\")\n",
    "\n",
    "save_folder_model = os.path.join(config.FILE_PATH, 'model/static/CNN', 'BS16', rowss, 'ver' + str(idx_save_path) + '_')\n",
    "save_folder_fig = os.path.join(config.FILE_PATH, 'figure', 'static', 'CNN', 'BS16' ,  rowss, 'ver' + str(idx_save_path) +'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: -25/-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS+LI\n",
      "SNR: -25/-5, LS+LI, Epoch 1/50, Loss: 0.35215229367793993 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34945748204534705\n",
      "SNR: -25/-5, LS+LI, Epoch 2/50, Loss: 0.3496341568439506 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3480597206137397\n",
      "SNR: -25/-5, LS+LI, Epoch 3/50, Loss: 0.3486568806476371 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3470958037809892\n",
      "SNR: -25/-5, LS+LI, Epoch 4/50, Loss: 0.3486582938321801 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3471182869239287\n",
      "SNR: -25/-5, LS+LI, Epoch 5/50, Loss: 0.3484798255701398 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34713229672475293\n",
      "SNR: -25/-5, LS+LI, Epoch 6/50, Loss: 0.34823907998412157 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3470262058756568\n",
      "SNR: -25/-5, LS+LI, Epoch 7/50, Loss: 0.3482712294126666 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34660338271747937\n",
      "SNR: -25/-5, LS+LI, Epoch 8/50, Loss: 0.3481345987597177 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34688911654732446\n",
      "SNR: -25/-5, LS+LI, Epoch 9/50, Loss: 0.3480861148861952 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3462717600844123\n",
      "SNR: -25/-5, LS+LI, Epoch 10/50, Loss: 0.3479930874566699 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34657652947035705\n",
      "SNR: -25/-5, LS+LI, Epoch 11/50, Loss: 0.34777873650539753 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.346256975423206\n",
      "SNR: -25/-5, LS+LI, Epoch 12/50, Loss: 0.34795870718567873 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34660095382820477\n",
      "SNR: -25/-5, LS+LI, Epoch 13/50, Loss: 0.3476685380866361 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34608435088937933\n",
      "SNR: -25/-5, LS+LI, Epoch 14/50, Loss: 0.3476013222406077 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3460584743456407\n",
      "SNR: -25/-5, LS+LI, Epoch 15/50, Loss: 0.3477719521453214 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34590211510658264\n",
      "SNR: -25/-5, LS+LI, Epoch 16/50, Loss: 0.34745536848556163 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3458485102111643\n",
      "SNR: -25/-5, LS+LI, Epoch 17/50, Loss: 0.3478490569910338 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3460592153397473\n",
      "SNR: -25/-5, LS+LI, Epoch 18/50, Loss: 0.3473880902625794 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3459204855290326\n",
      "SNR: -25/-5, LS+LI, Epoch 19/50, Loss: 0.3473612335185672 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3461996994235299\n",
      "SNR: -25/-5, LS+LI, Epoch 20/50, Loss: 0.34760842177756995 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3458903580904007\n",
      "SNR: -25/-5, LS+LI, Epoch 21/50, Loss: 0.34753429543140324 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34590553830970416\n",
      "SNR: -25/-5, LS+LI, Epoch 22/50, Loss: 0.3473890004462974 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3458730917085301\n",
      "SNR: -25/-5, LS+LI, Epoch 23/50, Loss: 0.3473143700596898 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3456841612404043\n",
      "SNR: -25/-5, LS+LI, Epoch 24/50, Loss: 0.3472321461452994 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34552353620529175\n",
      "SNR: -25/-5, LS+LI, Epoch 25/50, Loss: 0.34708561367073726 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3455855372277173\n",
      "SNR: -25/-5, LS+LI, Epoch 26/50, Loss: 0.34713101248408473 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34597137705846265\n",
      "SNR: -25/-5, LS+LI, Epoch 27/50, Loss: 0.3471901603909426 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3472055765715512\n",
      "SNR: -25/-5, LS+LI, Epoch 28/50, Loss: 0.346949903944204 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34552958472208545\n",
      "SNR: -25/-5, LS+LI, Epoch 29/50, Loss: 0.3470838182540827 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3457496017217636\n",
      "SNR: -25/-5, LS+LI, Epoch 30/50, Loss: 0.3469173605012339 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34526512162251904\n",
      "SNR: -25/-5, LS+LI, Epoch 31/50, Loss: 0.34686175335285274 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34520585293119604\n",
      "SNR: -25/-5, LS+LI, Epoch 32/50, Loss: 0.34663048507862315 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34514341300184076\n",
      "SNR: -25/-5, LS+LI, Epoch 33/50, Loss: 0.34690619987803833 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3455942476337606\n",
      "SNR: -25/-5, LS+LI, Epoch 34/50, Loss: 0.3465865663317747 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3456418758088892\n",
      "SNR: -25/-5, LS+LI, Epoch 35/50, Loss: 0.34656319819217507 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34511917016722937\n",
      "SNR: -25/-5, LS+LI, Epoch 36/50, Loss: 0.34660150387952493 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34515426511114294\n",
      "SNR: -25/-5, LS+LI, Epoch 37/50, Loss: 0.34663042668686356 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34505563838915393\n",
      "SNR: -25/-5, LS+LI, Epoch 38/50, Loss: 0.34658373736364895 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3447593721476468\n",
      "SNR: -25/-5, LS+LI, Epoch 39/50, Loss: 0.3465256155576817 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34568824686787347\n",
      "SNR: -25/-5, LS+LI, Epoch 40/50, Loss: 0.34633876054092894 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34477485851808026\n",
      "SNR: -25/-5, LS+LI, Epoch 41/50, Loss: 0.3462951529857724 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34468329494649713\n",
      "SNR: -25/-5, LS+LI, Epoch 42/50, Loss: 0.3464740258316661 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34496595100923017\n",
      "SNR: -25/-5, LS+LI, Epoch 43/50, Loss: 0.34637946739446285 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34604734588753094\n",
      "SNR: -25/-5, LS+LI, Epoch 44/50, Loss: 0.34624316543340683 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34636041251095856\n",
      "SNR: -25/-5, LS+LI, Epoch 45/50, Loss: 0.34649783528821415 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3447253947908228\n",
      "SNR: -25/-5, LS+LI, Epoch 46/50, Loss: 0.34613876391288845 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34462120858105744\n",
      "SNR: -25/-5, LS+LI, Epoch 47/50, Loss: 0.346220234452292 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34564598175612365\n",
      "SNR: -25/-5, LS+LI, Epoch 48/50, Loss: 0.346180617462757 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3452072048729116\n",
      "SNR: -25/-5, LS+LI, Epoch 49/50, Loss: 0.3465173549430315 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.34522668610919605\n",
      "SNR: -25/-5, LS+LI, Epoch 50/50, Loss: 0.34647041784469473 \n",
      "SNR: -25/-5, LS+LI, Val Loss: 0.3445535749197006\n",
      "LI+NN NMSE: 0.9313288927078247\n",
      "LS+LI NMSE: 25.8493595123291\n",
      " Training for LS\n",
      "SNR: -25/-5, LS, Epoch 1/50, Loss: 0.35788018412368244 \n",
      "SNR: -25/-5, LS, Val Loss: 0.3281486142765392\n",
      "SNR: -25/-5, LS, Epoch 2/50, Loss: 0.26715244586731113 \n",
      "SNR: -25/-5, LS, Val Loss: 0.23390409485860306\n",
      "SNR: -25/-5, LS, Epoch 3/50, Loss: 0.22896657424957254 \n",
      "SNR: -25/-5, LS, Val Loss: 0.22446697476235303\n",
      "SNR: -25/-5, LS, Epoch 4/50, Loss: 0.22239809032789495 \n",
      "SNR: -25/-5, LS, Val Loss: 0.21919540857726877\n",
      "SNR: -25/-5, LS, Epoch 5/50, Loss: 0.2185813872100309 \n",
      "SNR: -25/-5, LS, Val Loss: 0.21669117835435\n",
      "SNR: -25/-5, LS, Epoch 6/50, Loss: 0.2141894070041734 \n",
      "SNR: -25/-5, LS, Val Loss: 0.21266228773377158\n",
      "SNR: -25/-5, LS, Epoch 7/50, Loss: 0.21160790419509246 \n",
      "SNR: -25/-5, LS, Val Loss: 0.21057578243992545\n",
      "SNR: -25/-5, LS, Epoch 8/50, Loss: 0.2093520077855088 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20772335746071555\n",
      "SNR: -25/-5, LS, Epoch 9/50, Loss: 0.2069005009739898 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20592343333092603\n",
      "SNR: -25/-5, LS, Epoch 10/50, Loss: 0.2052273588298365 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20641661841760983\n",
      "SNR: -25/-5, LS, Epoch 11/50, Loss: 0.20346200344867485 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20272483879869635\n",
      "SNR: -25/-5, LS, Epoch 12/50, Loss: 0.20217435365152914 \n",
      "SNR: -25/-5, LS, Val Loss: 0.2013257403265346\n",
      "SNR: -25/-5, LS, Epoch 13/50, Loss: 0.20149491077592208 \n",
      "SNR: -25/-5, LS, Val Loss: 0.2000490907918323\n",
      "SNR: -25/-5, LS, Epoch 14/50, Loss: 0.19994947279608527 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20254107971083035\n",
      "SNR: -25/-5, LS, Epoch 15/50, Loss: 0.19915506027119104 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19983915510502728\n",
      "SNR: -25/-5, LS, Epoch 16/50, Loss: 0.19824437615136767 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1973692551255226\n",
      "SNR: -25/-5, LS, Epoch 17/50, Loss: 0.1973153428975926 \n",
      "SNR: -25/-5, LS, Val Loss: 0.197024174711921\n",
      "SNR: -25/-5, LS, Epoch 18/50, Loss: 0.19687106590284859 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1975871900265867\n",
      "SNR: -25/-5, LS, Epoch 19/50, Loss: 0.19602732074468635 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19556781175461682\n",
      "SNR: -25/-5, LS, Epoch 20/50, Loss: 0.19585790909653486 \n",
      "SNR: -25/-5, LS, Val Loss: 0.20222115313464945\n",
      "SNR: -25/-5, LS, Epoch 21/50, Loss: 0.19501489400863647 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19489951634948904\n",
      "SNR: -25/-5, LS, Epoch 22/50, Loss: 0.1943044464082219 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19378683174198325\n",
      "SNR: -25/-5, LS, Epoch 23/50, Loss: 0.19446004034821376 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19350005212155255\n",
      "SNR: -25/-5, LS, Epoch 24/50, Loss: 0.19408766812709874 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19312655925750732\n",
      "SNR: -25/-5, LS, Epoch 25/50, Loss: 0.19297438132208447 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19271709837696768\n",
      "SNR: -25/-5, LS, Epoch 26/50, Loss: 0.19280561155011489 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19259345057335767\n",
      "SNR: -25/-5, LS, Epoch 27/50, Loss: 0.1923838975124581 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19241285662759433\n",
      "SNR: -25/-5, LS, Epoch 28/50, Loss: 0.19193267822265625 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19243823804638602\n",
      "SNR: -25/-5, LS, Epoch 29/50, Loss: 0.19169384163132933 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19128347730094736\n",
      "SNR: -25/-5, LS, Epoch 30/50, Loss: 0.19163022250976675 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19205450063402002\n",
      "SNR: -25/-5, LS, Epoch 31/50, Loss: 0.19079965327021686 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19131290980360724\n",
      "SNR: -25/-5, LS, Epoch 32/50, Loss: 0.19063887840440108 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1910178458148783\n",
      "SNR: -25/-5, LS, Epoch 33/50, Loss: 0.190690599295289 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19022766839374194\n",
      "SNR: -25/-5, LS, Epoch 34/50, Loss: 0.19013624655645947 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19051932678981262\n",
      "SNR: -25/-5, LS, Epoch 35/50, Loss: 0.19008176669824955 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19160001115365463\n",
      "SNR: -25/-5, LS, Epoch 36/50, Loss: 0.18997373206670895 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1895953667434779\n",
      "SNR: -25/-5, LS, Epoch 37/50, Loss: 0.18916221881328626 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18956482410430908\n",
      "SNR: -25/-5, LS, Epoch 38/50, Loss: 0.18921631643938464 \n",
      "SNR: -25/-5, LS, Val Loss: 0.19068303365599026\n",
      "SNR: -25/-5, LS, Epoch 39/50, Loss: 0.1893209760445495 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1889046864076094\n",
      "SNR: -25/-5, LS, Epoch 40/50, Loss: 0.18886024756140488 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1888874972408468\n",
      "SNR: -25/-5, LS, Epoch 41/50, Loss: 0.1890392394433188 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18967433206059717\n",
      "SNR: -25/-5, LS, Epoch 42/50, Loss: 0.1886806007214757 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18880281326445666\n",
      "SNR: -25/-5, LS, Epoch 43/50, Loss: 0.18853407101922257 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1898634284734726\n",
      "SNR: -25/-5, LS, Epoch 44/50, Loss: 0.1888435031612252 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1897975511171601\n",
      "SNR: -25/-5, LS, Epoch 45/50, Loss: 0.18807216473790103 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1879761970855973\n",
      "SNR: -25/-5, LS, Epoch 46/50, Loss: 0.1881180199426274 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18842445449395614\n",
      "SNR: -25/-5, LS, Epoch 47/50, Loss: 0.18788344820224961 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18805213408036667\n",
      "SNR: -25/-5, LS, Epoch 48/50, Loss: 0.18760220767107122 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18805831399830905\n",
      "SNR: -25/-5, LS, Epoch 49/50, Loss: 0.18760099573883898 \n",
      "SNR: -25/-5, LS, Val Loss: 0.1875351227142594\n",
      "SNR: -25/-5, LS, Epoch 50/50, Loss: 0.18739848973792653 \n",
      "SNR: -25/-5, LS, Val Loss: 0.18729846450415524\n",
      "LS+LI NMSE: 0.5087278485298157\n",
      " SNR: -20/-5\n",
      " Training for LS+LI\n",
      "SNR: -20/-5, LS+LI, Epoch 1/50, Loss: 0.3234881550766701 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31493330137296155\n",
      "SNR: -20/-5, LS+LI, Epoch 2/50, Loss: 0.31409676269043324 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3127738007090308\n",
      "SNR: -20/-5, LS+LI, Epoch 3/50, Loss: 0.31311028242804284 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3125070441852916\n",
      "SNR: -20/-5, LS+LI, Epoch 4/50, Loss: 0.3129167040420133 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31095838004892523\n",
      "SNR: -20/-5, LS+LI, Epoch 5/50, Loss: 0.31220650906826175 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3116969249465249\n",
      "SNR: -20/-5, LS+LI, Epoch 6/50, Loss: 0.31188535014557284 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3105975226922469\n",
      "SNR: -20/-5, LS+LI, Epoch 7/50, Loss: 0.3115552473206853 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3109409605914896\n",
      "SNR: -20/-5, LS+LI, Epoch 8/50, Loss: 0.31114528137584063 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31026002900166944\n",
      "SNR: -20/-5, LS+LI, Epoch 9/50, Loss: 0.3112103731133217 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31020874055949127\n",
      "SNR: -20/-5, LS+LI, Epoch 10/50, Loss: 0.31116603626761324 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3099295063452287\n",
      "SNR: -20/-5, LS+LI, Epoch 11/50, Loss: 0.31040981775799464 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3103590336712924\n",
      "SNR: -20/-5, LS+LI, Epoch 12/50, Loss: 0.31065968458735665 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31015273386781866\n",
      "SNR: -20/-5, LS+LI, Epoch 13/50, Loss: 0.31033498066109283 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30986359986391937\n",
      "SNR: -20/-5, LS+LI, Epoch 14/50, Loss: 0.31033021402220395 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30942714485255157\n",
      "SNR: -20/-5, LS+LI, Epoch 15/50, Loss: 0.30994054380544395 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.309874641624364\n",
      "SNR: -20/-5, LS+LI, Epoch 16/50, Loss: 0.3095760426895563 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3089007789438421\n",
      "SNR: -20/-5, LS+LI, Epoch 17/50, Loss: 0.3103294705235681 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31154232539913873\n",
      "SNR: -20/-5, LS+LI, Epoch 18/50, Loss: 0.3097564853554548 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.31174988502805884\n",
      "SNR: -20/-5, LS+LI, Epoch 19/50, Loss: 0.3095168838667315 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3098612278699875\n",
      "SNR: -20/-5, LS+LI, Epoch 20/50, Loss: 0.3095974346926046 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30856069786982104\n",
      "SNR: -20/-5, LS+LI, Epoch 21/50, Loss: 0.3096437073031137 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30875051427971234\n",
      "SNR: -20/-5, LS+LI, Epoch 22/50, Loss: 0.3097186656885369 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30949858779256995\n",
      "SNR: -20/-5, LS+LI, Epoch 23/50, Loss: 0.30935962749428525 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30830362710085785\n",
      "SNR: -20/-5, LS+LI, Epoch 24/50, Loss: 0.30959192438181055 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3083447285673835\n",
      "SNR: -20/-5, LS+LI, Epoch 25/50, Loss: 0.3099694936427959 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30875455655834894\n",
      "SNR: -20/-5, LS+LI, Epoch 26/50, Loss: 0.3099249797158463 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3087369203567505\n",
      "SNR: -20/-5, LS+LI, Epoch 27/50, Loss: 0.30885247799546217 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3083479106426239\n",
      "SNR: -20/-5, LS+LI, Epoch 28/50, Loss: 0.30857896960751957 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3090826909650456\n",
      "SNR: -20/-5, LS+LI, Epoch 29/50, Loss: 0.30885832115661266 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30798944289034064\n",
      "SNR: -20/-5, LS+LI, Epoch 30/50, Loss: 0.3088859090971392 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3098351833495227\n",
      "SNR: -20/-5, LS+LI, Epoch 31/50, Loss: 0.30829789576142336 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30799348787827924\n",
      "SNR: -20/-5, LS+LI, Epoch 32/50, Loss: 0.3093869512857393 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3085497319698334\n",
      "SNR: -20/-5, LS+LI, Epoch 33/50, Loss: 0.3086217789109363 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3078930079936981\n",
      "SNR: -20/-5, LS+LI, Epoch 34/50, Loss: 0.3087060607449953 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30878260325301776\n",
      "SNR: -20/-5, LS+LI, Epoch 35/50, Loss: 0.30874700584383896 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30964613367210736\n",
      "SNR: -20/-5, LS+LI, Epoch 36/50, Loss: 0.30828641770884047 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30782052739100024\n",
      "SNR: -20/-5, LS+LI, Epoch 37/50, Loss: 0.30832476913928986 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3082846579226581\n",
      "SNR: -20/-5, LS+LI, Epoch 38/50, Loss: 0.30871803937263265 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3076903928409923\n",
      "SNR: -20/-5, LS+LI, Epoch 39/50, Loss: 0.3082418777914934 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3077213154597716\n",
      "SNR: -20/-5, LS+LI, Epoch 40/50, Loss: 0.3086960786130539 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3077642335133119\n",
      "SNR: -20/-5, LS+LI, Epoch 41/50, Loss: 0.30838501176168753 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30829678746786987\n",
      "SNR: -20/-5, LS+LI, Epoch 42/50, Loss: 0.3085114853673203 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30755690282041376\n",
      "SNR: -20/-5, LS+LI, Epoch 43/50, Loss: 0.30786621882471926 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3104073032736778\n",
      "SNR: -20/-5, LS+LI, Epoch 44/50, Loss: 0.30784229605003843 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3076153966513547\n",
      "SNR: -20/-5, LS+LI, Epoch 45/50, Loss: 0.3083791765709256 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30732866444370965\n",
      "SNR: -20/-5, LS+LI, Epoch 46/50, Loss: 0.308150659900072 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30753667517141864\n",
      "SNR: -20/-5, LS+LI, Epoch 47/50, Loss: 0.3077176329354907 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3071706416932019\n",
      "SNR: -20/-5, LS+LI, Epoch 48/50, Loss: 0.3079718067202457 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30720196257938037\n",
      "SNR: -20/-5, LS+LI, Epoch 49/50, Loss: 0.30748104546652283 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.30707433413375507\n",
      "SNR: -20/-5, LS+LI, Epoch 50/50, Loss: 0.3079129525048788 \n",
      "SNR: -20/-5, LS+LI, Val Loss: 0.3068400187925859\n",
      "LI+NN NMSE: 0.8345285058021545\n",
      "LS+LI NMSE: 8.165925025939941\n",
      " Training for LS\n",
      "SNR: -20/-5, LS, Epoch 1/50, Loss: 0.3299556619725948 \n",
      "SNR: -20/-5, LS, Val Loss: 0.23671472140333868\n",
      "SNR: -20/-5, LS, Epoch 2/50, Loss: 0.16213691555136858 \n",
      "SNR: -20/-5, LS, Val Loss: 0.1364935114979744\n",
      "SNR: -20/-5, LS, Epoch 3/50, Loss: 0.1332901844451594 \n",
      "SNR: -20/-5, LS, Val Loss: 0.1293425207788294\n",
      "SNR: -20/-5, LS, Epoch 4/50, Loss: 0.1272580770039281 \n",
      "SNR: -20/-5, LS, Val Loss: 0.12482958591797134\n",
      "SNR: -20/-5, LS, Epoch 5/50, Loss: 0.12284990586340427 \n",
      "SNR: -20/-5, LS, Val Loss: 0.12101835825226524\n",
      "SNR: -20/-5, LS, Epoch 6/50, Loss: 0.12025642711236033 \n",
      "SNR: -20/-5, LS, Val Loss: 0.11800507964058356\n",
      "SNR: -20/-5, LS, Epoch 7/50, Loss: 0.11822402763158776 \n",
      "SNR: -20/-5, LS, Val Loss: 0.11539625173265283\n",
      "SNR: -20/-5, LS, Epoch 8/50, Loss: 0.11462182027482709 \n",
      "SNR: -20/-5, LS, Val Loss: 0.11490801179950888\n",
      "SNR: -20/-5, LS, Epoch 9/50, Loss: 0.11301011141649513 \n",
      "SNR: -20/-5, LS, Val Loss: 0.11174706301905891\n",
      "SNR: -20/-5, LS, Epoch 10/50, Loss: 0.11129977666707926 \n",
      "SNR: -20/-5, LS, Val Loss: 0.11100597815080122\n",
      "SNR: -20/-5, LS, Epoch 11/50, Loss: 0.11005033058829086 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10893824425610629\n",
      "SNR: -20/-5, LS, Epoch 12/50, Loss: 0.10929101385002912 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10764548622749069\n",
      "SNR: -20/-5, LS, Epoch 13/50, Loss: 0.10787493402008401 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10652893307534131\n",
      "SNR: -20/-5, LS, Epoch 14/50, Loss: 0.1072371972421574 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10611528903245926\n",
      "SNR: -20/-5, LS, Epoch 15/50, Loss: 0.10573370338872422 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10501111806793646\n",
      "SNR: -20/-5, LS, Epoch 16/50, Loss: 0.10481493894097417 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10468837449496443\n",
      "SNR: -20/-5, LS, Epoch 17/50, Loss: 0.10438039461367352 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10733924602920358\n",
      "SNR: -20/-5, LS, Epoch 18/50, Loss: 0.10365806524316933 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10710615021261302\n",
      "SNR: -20/-5, LS, Epoch 19/50, Loss: 0.1029910646638898 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10467297516085884\n",
      "SNR: -20/-5, LS, Epoch 20/50, Loss: 0.1019263094680947 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10178333216092804\n",
      "SNR: -20/-5, LS, Epoch 21/50, Loss: 0.10137321401474088 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10074663636359302\n",
      "SNR: -20/-5, LS, Epoch 22/50, Loss: 0.10080543424674245 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10001326826485721\n",
      "SNR: -20/-5, LS, Epoch 23/50, Loss: 0.10003133191792078 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09951764412901619\n",
      "SNR: -20/-5, LS, Epoch 24/50, Loss: 0.10030948717233747 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10468742319128731\n",
      "SNR: -20/-5, LS, Epoch 25/50, Loss: 0.09899193247736887 \n",
      "SNR: -20/-5, LS, Val Loss: 0.10015402463349429\n",
      "SNR: -20/-5, LS, Epoch 26/50, Loss: 0.09862562286299328 \n",
      "SNR: -20/-5, LS, Val Loss: 0.0992706109854308\n",
      "SNR: -20/-5, LS, Epoch 27/50, Loss: 0.0981507727139911 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09863030199300159\n",
      "SNR: -20/-5, LS, Epoch 28/50, Loss: 0.09839152284832887 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09795575859871777\n",
      "SNR: -20/-5, LS, Epoch 29/50, Loss: 0.09740173249223898 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09711791913617741\n",
      "SNR: -20/-5, LS, Epoch 30/50, Loss: 0.09708361877778242 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09695762531323866\n",
      "SNR: -20/-5, LS, Epoch 31/50, Loss: 0.09703644547005032 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09654376689683307\n",
      "SNR: -20/-5, LS, Epoch 32/50, Loss: 0.09661553449235684 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09617388485507532\n",
      "SNR: -20/-5, LS, Epoch 33/50, Loss: 0.09617993235588074 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09592213447798383\n",
      "SNR: -20/-5, LS, Epoch 34/50, Loss: 0.09578695590066355 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09589568830349228\n",
      "SNR: -20/-5, LS, Epoch 35/50, Loss: 0.09580298015024773 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09891981766982512\n",
      "SNR: -20/-5, LS, Epoch 36/50, Loss: 0.09555255470061025 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09699178012934598\n",
      "SNR: -20/-5, LS, Epoch 37/50, Loss: 0.09521600985249808 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09500718861818314\n",
      "SNR: -20/-5, LS, Epoch 38/50, Loss: 0.09503121496459772 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09480723908001726\n",
      "SNR: -20/-5, LS, Epoch 39/50, Loss: 0.09506577456933121 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09466790780425072\n",
      "SNR: -20/-5, LS, Epoch 40/50, Loss: 0.09469580771618111 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09460728988051414\n",
      "SNR: -20/-5, LS, Epoch 41/50, Loss: 0.09453366662180701 \n",
      "SNR: -20/-5, LS, Val Loss: 0.0943238264457746\n",
      "SNR: -20/-5, LS, Epoch 42/50, Loss: 0.09441472646282163 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09573957933620973\n",
      "SNR: -20/-5, LS, Epoch 43/50, Loss: 0.09434548570492933 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09510337324305014\n",
      "SNR: -20/-5, LS, Epoch 44/50, Loss: 0.09388430906069833 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09442084316502918\n",
      "SNR: -20/-5, LS, Epoch 45/50, Loss: 0.09388778796202915 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09375959194519302\n",
      "SNR: -20/-5, LS, Epoch 46/50, Loss: 0.09380506754441317 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09419758076017554\n",
      "SNR: -20/-5, LS, Epoch 47/50, Loss: 0.09364342078739821 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09370985153046521\n",
      "SNR: -20/-5, LS, Epoch 48/50, Loss: 0.09317186946958997 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09346635097807104\n",
      "SNR: -20/-5, LS, Epoch 49/50, Loss: 0.09313457723447056 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09327546913515437\n",
      "SNR: -20/-5, LS, Epoch 50/50, Loss: 0.09339681731233763 \n",
      "SNR: -20/-5, LS, Val Loss: 0.09360606832937761\n",
      "LS+LI NMSE: 0.25702574849128723\n",
      " SNR: -15/-5\n",
      " Training for LS+LI\n",
      "SNR: -15/-5, LS+LI, Epoch 1/50, Loss: 0.2572085603551809 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24573306807062842\n",
      "SNR: -15/-5, LS+LI, Epoch 2/50, Loss: 0.24280315057136292 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2439998984336853\n",
      "SNR: -15/-5, LS+LI, Epoch 3/50, Loss: 0.2409334573461566 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24258267269893127\n",
      "SNR: -15/-5, LS+LI, Epoch 4/50, Loss: 0.23943440061669016 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24153667214241895\n",
      "SNR: -15/-5, LS+LI, Epoch 5/50, Loss: 0.24008181128044462 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24088036878542465\n",
      "SNR: -15/-5, LS+LI, Epoch 6/50, Loss: 0.2403615051230719 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24122551422227512\n",
      "SNR: -15/-5, LS+LI, Epoch 7/50, Loss: 0.23939997382288755 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2403879321434281\n",
      "SNR: -15/-5, LS+LI, Epoch 8/50, Loss: 0.23942588564268377 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24016351794654672\n",
      "SNR: -15/-5, LS+LI, Epoch 9/50, Loss: 0.23924678728677506 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2402829263697971\n",
      "SNR: -15/-5, LS+LI, Epoch 10/50, Loss: 0.2388804747268211 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23992574892260812\n",
      "SNR: -15/-5, LS+LI, Epoch 11/50, Loss: 0.23935927156099054 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24032906781543384\n",
      "SNR: -15/-5, LS+LI, Epoch 12/50, Loss: 0.23842888100202694 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2399631901220842\n",
      "SNR: -15/-5, LS+LI, Epoch 13/50, Loss: 0.23862338048774143 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23939720134843478\n",
      "SNR: -15/-5, LS+LI, Epoch 14/50, Loss: 0.23903547582584758 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2400384938175028\n",
      "SNR: -15/-5, LS+LI, Epoch 15/50, Loss: 0.23817041117784588 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23965668949213895\n",
      "SNR: -15/-5, LS+LI, Epoch 16/50, Loss: 0.23823761732079263 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2398064055226066\n",
      "SNR: -15/-5, LS+LI, Epoch 17/50, Loss: 0.23825044245567434 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23890522528778424\n",
      "SNR: -15/-5, LS+LI, Epoch 18/50, Loss: 0.23808241661551388 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24017669192769311\n",
      "SNR: -15/-5, LS+LI, Epoch 19/50, Loss: 0.23802450767090155 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23894994164055045\n",
      "SNR: -15/-5, LS+LI, Epoch 20/50, Loss: 0.23699065523092136 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2398323897611011\n",
      "SNR: -15/-5, LS+LI, Epoch 21/50, Loss: 0.23811675183648287 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23867406018755652\n",
      "SNR: -15/-5, LS+LI, Epoch 22/50, Loss: 0.2376957420519618 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23871366476470773\n",
      "SNR: -15/-5, LS+LI, Epoch 23/50, Loss: 0.23679148769655892 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.24000665680928665\n",
      "SNR: -15/-5, LS+LI, Epoch 24/50, Loss: 0.2376428438827049 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23970809985290875\n",
      "SNR: -15/-5, LS+LI, Epoch 25/50, Loss: 0.2372385823969231 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23806465349414133\n",
      "SNR: -15/-5, LS+LI, Epoch 26/50, Loss: 0.23630865654626557 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23771631311286578\n",
      "SNR: -15/-5, LS+LI, Epoch 27/50, Loss: 0.23609814957477326 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23756524310870605\n",
      "SNR: -15/-5, LS+LI, Epoch 28/50, Loss: 0.23649649677235027 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2413113151084293\n",
      "SNR: -15/-5, LS+LI, Epoch 29/50, Loss: 0.2369477719415066 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2392033264040947\n",
      "SNR: -15/-5, LS+LI, Epoch 30/50, Loss: 0.23701169653687365 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2373261790383946\n",
      "SNR: -15/-5, LS+LI, Epoch 31/50, Loss: 0.2357491522507612 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2367386662147262\n",
      "SNR: -15/-5, LS+LI, Epoch 32/50, Loss: 0.23635604899636534 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23740058663216504\n",
      "SNR: -15/-5, LS+LI, Epoch 33/50, Loss: 0.2365952883522178 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2367130145430565\n",
      "SNR: -15/-5, LS+LI, Epoch 34/50, Loss: 0.23626323737377344 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23944109746000983\n",
      "SNR: -15/-5, LS+LI, Epoch 35/50, Loss: 0.23539717859307 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23616175150329416\n",
      "SNR: -15/-5, LS+LI, Epoch 36/50, Loss: 0.2352829081721084 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2372156246141954\n",
      "SNR: -15/-5, LS+LI, Epoch 37/50, Loss: 0.23565799794917883 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23664424026554282\n",
      "SNR: -15/-5, LS+LI, Epoch 38/50, Loss: 0.2354863082426925 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23711419444192539\n",
      "SNR: -15/-5, LS+LI, Epoch 39/50, Loss: 0.23457028768783392 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23544783077456735\n",
      "SNR: -15/-5, LS+LI, Epoch 40/50, Loss: 0.23523611315461093 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23624668405814606\n",
      "SNR: -15/-5, LS+LI, Epoch 41/50, Loss: 0.23460356778530186 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23499914665113797\n",
      "SNR: -15/-5, LS+LI, Epoch 42/50, Loss: 0.23510593790994133 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23575454814867539\n",
      "SNR: -15/-5, LS+LI, Epoch 43/50, Loss: 0.23499121395654457 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23513055457310242\n",
      "SNR: -15/-5, LS+LI, Epoch 44/50, Loss: 0.2352768459119076 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23522573506290262\n",
      "SNR: -15/-5, LS+LI, Epoch 45/50, Loss: 0.2348027860009393 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2362189380960031\n",
      "SNR: -15/-5, LS+LI, Epoch 46/50, Loss: 0.23424810110483058 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2346365668556907\n",
      "SNR: -15/-5, LS+LI, Epoch 47/50, Loss: 0.23352859281869823 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.2351988757198507\n",
      "SNR: -15/-5, LS+LI, Epoch 48/50, Loss: 0.23410509206181349 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23679868606003848\n",
      "SNR: -15/-5, LS+LI, Epoch 49/50, Loss: 0.2342200258443522 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23619256168603897\n",
      "SNR: -15/-5, LS+LI, Epoch 50/50, Loss: 0.23368188756149869 \n",
      "SNR: -15/-5, LS+LI, Val Loss: 0.23467148434032092\n",
      "LI+NN NMSE: 0.6304013729095459\n",
      "LS+LI NMSE: 2.59553861618042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training for LS\n",
      "SNR: -15/-5, LS, Epoch 1/50, Loss: 0.31132872636581577 \n",
      "SNR: -15/-5, LS, Val Loss: 0.18679084967483173\n",
      "SNR: -15/-5, LS, Epoch 2/50, Loss: 0.09037472407311894 \n",
      "SNR: -15/-5, LS, Val Loss: 0.06563830392604525\n",
      "SNR: -15/-5, LS, Epoch 3/50, Loss: 0.06461210832606222 \n",
      "SNR: -15/-5, LS, Val Loss: 0.06212334775111892\n",
      "SNR: -15/-5, LS, Epoch 4/50, Loss: 0.061075364217855206 \n",
      "SNR: -15/-5, LS, Val Loss: 0.06026597134768963\n",
      "SNR: -15/-5, LS, Epoch 5/50, Loss: 0.05883785109793724 \n",
      "SNR: -15/-5, LS, Val Loss: 0.0562784881754355\n",
      "SNR: -15/-5, LS, Epoch 6/50, Loss: 0.056899065238445304 \n",
      "SNR: -15/-5, LS, Val Loss: 0.05493341098454865\n",
      "SNR: -15/-5, LS, Epoch 7/50, Loss: 0.05492415328964938 \n",
      "SNR: -15/-5, LS, Val Loss: 0.05322824909605763\n",
      "SNR: -15/-5, LS, Epoch 8/50, Loss: 0.053337976401455184 \n",
      "SNR: -15/-5, LS, Val Loss: 0.051794052801348946\n",
      "SNR: -15/-5, LS, Epoch 9/50, Loss: 0.05197279036131709 \n",
      "SNR: -15/-5, LS, Val Loss: 0.05045738663863052\n",
      "SNR: -15/-5, LS, Epoch 10/50, Loss: 0.051146241208148556 \n",
      "SNR: -15/-5, LS, Val Loss: 0.0498090899464759\n",
      "SNR: -15/-5, LS, Epoch 11/50, Loss: 0.05007445706097886 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04850892959670587\n",
      "SNR: -15/-5, LS, Epoch 12/50, Loss: 0.049575721065318865 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04846057346598669\n",
      "SNR: -15/-5, LS, Epoch 13/50, Loss: 0.04872001982618903 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04784568026661873\n",
      "SNR: -15/-5, LS, Epoch 14/50, Loss: 0.04802479503979517 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04751285859806971\n",
      "SNR: -15/-5, LS, Epoch 15/50, Loss: 0.04793775833190181 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04606458239934661\n",
      "SNR: -15/-5, LS, Epoch 16/50, Loss: 0.04714368565311266 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04583314416760748\n",
      "SNR: -15/-5, LS, Epoch 17/50, Loss: 0.0467150604872163 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04535287669436498\n",
      "SNR: -15/-5, LS, Epoch 18/50, Loss: 0.04657125392885402 \n",
      "SNR: -15/-5, LS, Val Loss: 0.0452497565949505\n",
      "SNR: -15/-5, LS, Epoch 19/50, Loss: 0.04598807292275651 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04740365018898791\n",
      "SNR: -15/-5, LS, Epoch 20/50, Loss: 0.046045567038967165 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04437373002821749\n",
      "SNR: -15/-5, LS, Epoch 21/50, Loss: 0.04539779922383469 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04430046880787069\n",
      "SNR: -15/-5, LS, Epoch 22/50, Loss: 0.04529955183957205 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04421090351586992\n",
      "SNR: -15/-5, LS, Epoch 23/50, Loss: 0.04541481305780106 \n",
      "SNR: -15/-5, LS, Val Loss: 0.044468565082008187\n",
      "SNR: -15/-5, LS, Epoch 24/50, Loss: 0.04471736986103446 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04357891208068891\n",
      "SNR: -15/-5, LS, Epoch 25/50, Loss: 0.04454799390636211 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04481395181607117\n",
      "SNR: -15/-5, LS, Epoch 26/50, Loss: 0.04482619154678528 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04439511336386204\n",
      "SNR: -15/-5, LS, Epoch 27/50, Loss: 0.04434179560129726 \n",
      "SNR: -15/-5, LS, Val Loss: 0.043758184564384545\n",
      "SNR: -15/-5, LS, Epoch 28/50, Loss: 0.04392755048912625 \n",
      "SNR: -15/-5, LS, Val Loss: 0.044469786299900574\n",
      "SNR: -15/-5, LS, Epoch 29/50, Loss: 0.04420602429918079 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04328550974076444\n",
      "SNR: -15/-5, LS, Epoch 30/50, Loss: 0.04384363163262606 \n",
      "SNR: -15/-5, LS, Val Loss: 0.042909020388668236\n",
      "SNR: -15/-5, LS, Epoch 31/50, Loss: 0.04395125799834035 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04277634468268265\n",
      "SNR: -15/-5, LS, Epoch 32/50, Loss: 0.043649006050166694 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04263625547967174\n",
      "SNR: -15/-5, LS, Epoch 33/50, Loss: 0.04359381141271009 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04394043372436003\n",
      "SNR: -15/-5, LS, Epoch 34/50, Loss: 0.04359724052077116 \n",
      "SNR: -15/-5, LS, Val Loss: 0.042639741504734215\n",
      "SNR: -15/-5, LS, Epoch 35/50, Loss: 0.04333649376450583 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04234130003235557\n",
      "SNR: -15/-5, LS, Epoch 36/50, Loss: 0.043373411846195545 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04352538948031989\n",
      "SNR: -15/-5, LS, Epoch 37/50, Loss: 0.04302764573502679 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04209111732515422\n",
      "SNR: -15/-5, LS, Epoch 38/50, Loss: 0.04312823195183693 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04291530732404102\n",
      "SNR: -15/-5, LS, Epoch 39/50, Loss: 0.04327257278613573 \n",
      "SNR: -15/-5, LS, Val Loss: 0.042077609253200615\n",
      "SNR: -15/-5, LS, Epoch 40/50, Loss: 0.04319877032363831 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04234226945449005\n",
      "SNR: -15/-5, LS, Epoch 41/50, Loss: 0.043036634730564995 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04183963059701703\n",
      "SNR: -15/-5, LS, Epoch 42/50, Loss: 0.04308201682342346 \n",
      "SNR: -15/-5, LS, Val Loss: 0.0422885004769672\n",
      "SNR: -15/-5, LS, Epoch 43/50, Loss: 0.04274919743887907 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04217716509645635\n",
      "SNR: -15/-5, LS, Epoch 44/50, Loss: 0.042599153618306615 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04172602803869681\n",
      "SNR: -15/-5, LS, Epoch 45/50, Loss: 0.04267141870547866 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04200731962919235\n",
      "SNR: -15/-5, LS, Epoch 46/50, Loss: 0.04233413518861283 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04211348515342583\n",
      "SNR: -15/-5, LS, Epoch 47/50, Loss: 0.04289115592837334 \n",
      "SNR: -15/-5, LS, Val Loss: 0.041612619534134865\n",
      "SNR: -15/-5, LS, Epoch 48/50, Loss: 0.04258409317929384 \n",
      "SNR: -15/-5, LS, Val Loss: 0.04160842959853736\n",
      "SNR: -15/-5, LS, Epoch 49/50, Loss: 0.04228067774932052 \n",
      "SNR: -15/-5, LS, Val Loss: 0.043205527419393715\n",
      "SNR: -15/-5, LS, Epoch 50/50, Loss: 0.04224728039184282 \n",
      "SNR: -15/-5, LS, Val Loss: 0.042028017680753364\n",
      "LS+LI NMSE: 0.11567473411560059\n",
      " SNR: -10/-5\n",
      " Training for LS+LI\n",
      "SNR: -10/-5, LS+LI, Epoch 1/50, Loss: 0.17815766111016273 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1431912309066816\n",
      "SNR: -10/-5, LS+LI, Epoch 2/50, Loss: 0.14978469981876916 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1392266872254285\n",
      "SNR: -10/-5, LS+LI, Epoch 3/50, Loss: 0.14752859977442165 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13916099511764266\n",
      "SNR: -10/-5, LS+LI, Epoch 4/50, Loss: 0.1471088392183531 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1390082033520395\n",
      "SNR: -10/-5, LS+LI, Epoch 5/50, Loss: 0.1473130365443784 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13917844065211035\n",
      "SNR: -10/-5, LS+LI, Epoch 6/50, Loss: 0.14648567529958348 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13842004198919644\n",
      "SNR: -10/-5, LS+LI, Epoch 7/50, Loss: 0.1465218179794245 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13766968148675832\n",
      "SNR: -10/-5, LS+LI, Epoch 8/50, Loss: 0.1459078868894383 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13894268701022322\n",
      "SNR: -10/-5, LS+LI, Epoch 9/50, Loss: 0.14567568863547126 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1400392505932938\n",
      "SNR: -10/-5, LS+LI, Epoch 10/50, Loss: 0.1457420762541682 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13761561126871544\n",
      "SNR: -10/-5, LS+LI, Epoch 11/50, Loss: 0.14546050092335358 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13790948858315294\n",
      "SNR: -10/-5, LS+LI, Epoch 12/50, Loss: 0.14533517964530823 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1375350014052608\n",
      "SNR: -10/-5, LS+LI, Epoch 13/50, Loss: 0.14552720319912876 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13751419328830458\n",
      "SNR: -10/-5, LS+LI, Epoch 14/50, Loss: 0.14549316959672196 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13745998083190483\n",
      "SNR: -10/-5, LS+LI, Epoch 15/50, Loss: 0.14508811471074126 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13740926066582854\n",
      "SNR: -10/-5, LS+LI, Epoch 16/50, Loss: 0.14461370956066044 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13731725344603712\n",
      "SNR: -10/-5, LS+LI, Epoch 17/50, Loss: 0.14475172740775485 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13907487961378964\n",
      "SNR: -10/-5, LS+LI, Epoch 18/50, Loss: 0.1447059804530338 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13679152727127075\n",
      "SNR: -10/-5, LS+LI, Epoch 19/50, Loss: 0.14482495271016 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13689133965156294\n",
      "SNR: -10/-5, LS+LI, Epoch 20/50, Loss: 0.1439627628167008 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13778335397893732\n",
      "SNR: -10/-5, LS+LI, Epoch 21/50, Loss: 0.14498009844574816 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13742699948224155\n",
      "SNR: -10/-5, LS+LI, Epoch 22/50, Loss: 0.14385514221219128 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13776185329664836\n",
      "SNR: -10/-5, LS+LI, Epoch 23/50, Loss: 0.1440052047458499 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1366709866984324\n",
      "SNR: -10/-5, LS+LI, Epoch 24/50, Loss: 0.1445476643654496 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13637815991585905\n",
      "SNR: -10/-5, LS+LI, Epoch 25/50, Loss: 0.14366795516811137 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1364439366893335\n",
      "SNR: -10/-5, LS+LI, Epoch 26/50, Loss: 0.14348309708022794 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13689587366851894\n",
      "SNR: -10/-5, LS+LI, Epoch 27/50, Loss: 0.14357183609417704 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1362536647780375\n",
      "SNR: -10/-5, LS+LI, Epoch 28/50, Loss: 0.14397102828289188 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13823857056823644\n",
      "SNR: -10/-5, LS+LI, Epoch 29/50, Loss: 0.1431925782370706 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13686915690248663\n",
      "SNR: -10/-5, LS+LI, Epoch 30/50, Loss: 0.14347766746961793 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13635479387911884\n",
      "SNR: -10/-5, LS+LI, Epoch 31/50, Loss: 0.14372716272293135 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13609213991598648\n",
      "SNR: -10/-5, LS+LI, Epoch 32/50, Loss: 0.14319953924521459 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13939997960220685\n",
      "SNR: -10/-5, LS+LI, Epoch 33/50, Loss: 0.14330533506392046 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13902603631669824\n",
      "SNR: -10/-5, LS+LI, Epoch 34/50, Loss: 0.14357084824248803 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1361923414197835\n",
      "SNR: -10/-5, LS+LI, Epoch 35/50, Loss: 0.14356926300151404 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13636077432469887\n",
      "SNR: -10/-5, LS+LI, Epoch 36/50, Loss: 0.14289111773981605 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13559515435587277\n",
      "SNR: -10/-5, LS+LI, Epoch 37/50, Loss: 0.14315672474371832 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13580002669583668\n",
      "SNR: -10/-5, LS+LI, Epoch 38/50, Loss: 0.14234305666976196 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13540221987800163\n",
      "SNR: -10/-5, LS+LI, Epoch 39/50, Loss: 0.14301177473782106 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13574156910181046\n",
      "SNR: -10/-5, LS+LI, Epoch 40/50, Loss: 0.14270665747828262 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1364340494302186\n",
      "SNR: -10/-5, LS+LI, Epoch 41/50, Loss: 0.14201133594263432 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1356608640741218\n",
      "SNR: -10/-5, LS+LI, Epoch 42/50, Loss: 0.14268381083600742 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1355573203076016\n",
      "SNR: -10/-5, LS+LI, Epoch 43/50, Loss: 0.14252982072012368 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13610017570582303\n",
      "SNR: -10/-5, LS+LI, Epoch 44/50, Loss: 0.1415579915479865 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13662373342297293\n",
      "SNR: -10/-5, LS+LI, Epoch 45/50, Loss: 0.14216607180965501 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13481461290608754\n",
      "SNR: -10/-5, LS+LI, Epoch 46/50, Loss: 0.14254349773359853 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13548247719352896\n",
      "SNR: -10/-5, LS+LI, Epoch 47/50, Loss: 0.1417982472583305 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13468077372420917\n",
      "SNR: -10/-5, LS+LI, Epoch 48/50, Loss: 0.14215050797996132 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13478322022340514\n",
      "SNR: -10/-5, LS+LI, Epoch 49/50, Loss: 0.14255093423606352 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.1356977911835367\n",
      "SNR: -10/-5, LS+LI, Epoch 50/50, Loss: 0.14154294501383638 \n",
      "SNR: -10/-5, LS+LI, Val Loss: 0.13453152132305232\n",
      "LI+NN NMSE: 0.3571516275405884\n",
      "LS+LI NMSE: 0.8159411549568176\n",
      " Training for LS\n",
      "SNR: -10/-5, LS, Epoch 1/50, Loss: 0.27579882792955224 \n",
      "SNR: -10/-5, LS, Val Loss: 0.0964808538556099\n",
      "SNR: -10/-5, LS, Epoch 2/50, Loss: 0.04406844408706177 \n",
      "SNR: -10/-5, LS, Val Loss: 0.033689720132811504\n",
      "SNR: -10/-5, LS, Epoch 3/50, Loss: 0.033197401448824375 \n",
      "SNR: -10/-5, LS, Val Loss: 0.030645537613467735\n",
      "SNR: -10/-5, LS, Epoch 4/50, Loss: 0.030843481583910627 \n",
      "SNR: -10/-5, LS, Val Loss: 0.029152094217186623\n",
      "SNR: -10/-5, LS, Epoch 5/50, Loss: 0.030129736126941996 \n",
      "SNR: -10/-5, LS, Val Loss: 0.027709131383083084\n",
      "SNR: -10/-5, LS, Epoch 6/50, Loss: 0.02919748542440492 \n",
      "SNR: -10/-5, LS, Val Loss: 0.027071297846057198\n",
      "SNR: -10/-5, LS, Epoch 7/50, Loss: 0.028279923184146714 \n",
      "SNR: -10/-5, LS, Val Loss: 0.028118649412962524\n",
      "SNR: -10/-5, LS, Epoch 8/50, Loss: 0.027581256002101096 \n",
      "SNR: -10/-5, LS, Val Loss: 0.025836243040182373\n",
      "SNR: -10/-5, LS, Epoch 9/50, Loss: 0.02692772639742078 \n",
      "SNR: -10/-5, LS, Val Loss: 0.025255483913828026\n",
      "SNR: -10/-5, LS, Epoch 10/50, Loss: 0.026382464536487363 \n",
      "SNR: -10/-5, LS, Val Loss: 0.025679756633260033\n",
      "SNR: -10/-5, LS, Epoch 11/50, Loss: 0.026028203583040904 \n",
      "SNR: -10/-5, LS, Val Loss: 0.025069971399551087\n",
      "SNR: -10/-5, LS, Epoch 12/50, Loss: 0.02584938638908572 \n",
      "SNR: -10/-5, LS, Val Loss: 0.024292891929772766\n",
      "SNR: -10/-5, LS, Epoch 13/50, Loss: 0.02542896453984255 \n",
      "SNR: -10/-5, LS, Val Loss: 0.024672803469002247\n",
      "SNR: -10/-5, LS, Epoch 14/50, Loss: 0.024956835650427396 \n",
      "SNR: -10/-5, LS, Val Loss: 0.023844423703849316\n",
      "SNR: -10/-5, LS, Epoch 15/50, Loss: 0.024719834132769774 \n",
      "SNR: -10/-5, LS, Val Loss: 0.025403185239569706\n",
      "SNR: -10/-5, LS, Epoch 16/50, Loss: 0.024789846697172453 \n",
      "SNR: -10/-5, LS, Val Loss: 0.023289802568879994\n",
      "SNR: -10/-5, LS, Epoch 17/50, Loss: 0.024668217571668847 \n",
      "SNR: -10/-5, LS, Val Loss: 0.0229841862720522\n",
      "SNR: -10/-5, LS, Epoch 18/50, Loss: 0.02411326876473288 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02477125340903347\n",
      "SNR: -10/-5, LS, Epoch 19/50, Loss: 0.02389056153248909 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02316151855682785\n",
      "SNR: -10/-5, LS, Epoch 20/50, Loss: 0.023487690587116535 \n",
      "SNR: -10/-5, LS, Val Loss: 0.023432283916256645\n",
      "SNR: -10/-5, LS, Epoch 21/50, Loss: 0.023701825005890326 \n",
      "SNR: -10/-5, LS, Val Loss: 0.022321726110848514\n",
      "SNR: -10/-5, LS, Epoch 22/50, Loss: 0.023427673723808554 \n",
      "SNR: -10/-5, LS, Val Loss: 0.022780111398209225\n",
      "SNR: -10/-5, LS, Epoch 23/50, Loss: 0.023142595342252145 \n",
      "SNR: -10/-5, LS, Val Loss: 0.0223809787156907\n",
      "SNR: -10/-5, LS, Epoch 24/50, Loss: 0.02331693705474568 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02199024571613832\n",
      "SNR: -10/-5, LS, Epoch 25/50, Loss: 0.02306993353332198 \n",
      "SNR: -10/-5, LS, Val Loss: 0.0221871654079719\n",
      "SNR: -10/-5, LS, Epoch 26/50, Loss: 0.022894187408044588 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02185862579128959\n",
      "SNR: -10/-5, LS, Epoch 27/50, Loss: 0.022527255366967862 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021566208959980446\n",
      "SNR: -10/-5, LS, Epoch 28/50, Loss: 0.023057329327647768 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021764091808687557\n",
      "SNR: -10/-5, LS, Epoch 29/50, Loss: 0.023004806697975066 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021709982729093594\n",
      "SNR: -10/-5, LS, Epoch 30/50, Loss: 0.022623379000051076 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021631974303586918\n",
      "SNR: -10/-5, LS, Epoch 31/50, Loss: 0.02235050535176036 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02120345018126748\n",
      "SNR: -10/-5, LS, Epoch 32/50, Loss: 0.02225665536947375 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02135764875195243\n",
      "SNR: -10/-5, LS, Epoch 33/50, Loss: 0.022382554002539364 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021568438630889763\n",
      "SNR: -10/-5, LS, Epoch 34/50, Loss: 0.02234195312485099 \n",
      "SNR: -10/-5, LS, Val Loss: 0.0210115649652752\n",
      "SNR: -10/-5, LS, Epoch 35/50, Loss: 0.02227557267517198 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020975725979290226\n",
      "SNR: -10/-5, LS, Epoch 36/50, Loss: 0.022367499129803375 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02131815237755125\n",
      "SNR: -10/-5, LS, Epoch 37/50, Loss: 0.02204552251672329 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02093965763395483\n",
      "SNR: -10/-5, LS, Epoch 38/50, Loss: 0.021884078300709642 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02108526746319099\n",
      "SNR: -10/-5, LS, Epoch 39/50, Loss: 0.02233028899185186 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020816419188949196\n",
      "SNR: -10/-5, LS, Epoch 40/50, Loss: 0.022280359597400178 \n",
      "SNR: -10/-5, LS, Val Loss: 0.021330123259262604\n",
      "SNR: -10/-5, LS, Epoch 41/50, Loss: 0.02210982062658945 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02092333756048571\n",
      "SNR: -10/-5, LS, Epoch 42/50, Loss: 0.02169706206768751 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020756428214636715\n",
      "SNR: -10/-5, LS, Epoch 43/50, Loss: 0.02160195804872485 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02073027735406702\n",
      "SNR: -10/-5, LS, Epoch 44/50, Loss: 0.021635242824464343 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020524865270338276\n",
      "SNR: -10/-5, LS, Epoch 45/50, Loss: 0.02182146124974933 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020458691668781368\n",
      "SNR: -10/-5, LS, Epoch 46/50, Loss: 0.021407127683592396 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020597780208018692\n",
      "SNR: -10/-5, LS, Epoch 47/50, Loss: 0.02149457852681016 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02126365832307122\n",
      "SNR: -10/-5, LS, Epoch 48/50, Loss: 0.021544509653955005 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02098455728793686\n",
      "SNR: -10/-5, LS, Epoch 49/50, Loss: 0.021211227196333712 \n",
      "SNR: -10/-5, LS, Val Loss: 0.020231107165190308\n",
      "SNR: -10/-5, LS, Epoch 50/50, Loss: 0.021625114063364127 \n",
      "SNR: -10/-5, LS, Val Loss: 0.02038754370402206\n",
      "LS+LI NMSE: 0.056958120316267014\n",
      " SNR: -5/-5\n",
      " Training for LS+LI\n",
      "SNR: -5/-5, LS+LI, Epoch 1/50, Loss: 0.10547804139381231 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0742825735360384\n",
      "SNR: -5/-5, LS+LI, Epoch 2/50, Loss: 0.06965697463601828 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06899444894357161\n",
      "SNR: -5/-5, LS+LI, Epoch 3/50, Loss: 0.06793315972872944 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0683077455244281\n",
      "SNR: -5/-5, LS+LI, Epoch 4/50, Loss: 0.0673839038584468 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06860713745382699\n",
      "SNR: -5/-5, LS+LI, Epoch 5/50, Loss: 0.06675418485822372 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06800797784870322\n",
      "SNR: -5/-5, LS+LI, Epoch 6/50, Loss: 0.06663904088917513 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06841181523420593\n",
      "SNR: -5/-5, LS+LI, Epoch 7/50, Loss: 0.06662190746689259 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06833918358791959\n",
      "SNR: -5/-5, LS+LI, Epoch 8/50, Loss: 0.06592161539768757 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06789243813942779\n",
      "SNR: -5/-5, LS+LI, Epoch 9/50, Loss: 0.06627784756033919 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06771573424339294\n",
      "SNR: -5/-5, LS+LI, Epoch 10/50, Loss: 0.06567738146716079 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06771129115738651\n",
      "SNR: -5/-5, LS+LI, Epoch 11/50, Loss: 0.06567941403536257 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06753984855657275\n",
      "SNR: -5/-5, LS+LI, Epoch 12/50, Loss: 0.06557156071933203 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06727845475754955\n",
      "SNR: -5/-5, LS+LI, Epoch 13/50, Loss: 0.06547200263932694 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06715271943672137\n",
      "SNR: -5/-5, LS+LI, Epoch 14/50, Loss: 0.0656445199233848 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0674054492264986\n",
      "SNR: -5/-5, LS+LI, Epoch 15/50, Loss: 0.06570734891520683 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0673265548592264\n",
      "SNR: -5/-5, LS+LI, Epoch 16/50, Loss: 0.06518386592438748 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06704310734163631\n",
      "SNR: -5/-5, LS+LI, Epoch 17/50, Loss: 0.06530383877932679 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06792565316639164\n",
      "SNR: -5/-5, LS+LI, Epoch 18/50, Loss: 0.0648844163799875 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06697918948802081\n",
      "SNR: -5/-5, LS+LI, Epoch 19/50, Loss: 0.06511073038631747 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0668717644770037\n",
      "SNR: -5/-5, LS+LI, Epoch 20/50, Loss: 0.06477582629033646 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06752655858343298\n",
      "SNR: -5/-5, LS+LI, Epoch 21/50, Loss: 0.0647062394811317 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06671810505742376\n",
      "SNR: -5/-5, LS+LI, Epoch 22/50, Loss: 0.0644324158946442 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06699378822337497\n",
      "SNR: -5/-5, LS+LI, Epoch 23/50, Loss: 0.06482168501459581 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06709024750373581\n",
      "SNR: -5/-5, LS+LI, Epoch 24/50, Loss: 0.06450662900542103 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06683513318950479\n",
      "SNR: -5/-5, LS+LI, Epoch 25/50, Loss: 0.06490025613023791 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06760360588404266\n",
      "SNR: -5/-5, LS+LI, Epoch 26/50, Loss: 0.0645464654838623 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06664889932356098\n",
      "SNR: -5/-5, LS+LI, Epoch 27/50, Loss: 0.06446436279301726 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06695354560559447\n",
      "SNR: -5/-5, LS+LI, Epoch 28/50, Loss: 0.06436357610360828 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06689798256213014\n",
      "SNR: -5/-5, LS+LI, Epoch 29/50, Loss: 0.06423558847069047 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06658446077596057\n",
      "SNR: -5/-5, LS+LI, Epoch 30/50, Loss: 0.06387657350535657 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06659183820540254\n",
      "SNR: -5/-5, LS+LI, Epoch 31/50, Loss: 0.06449366501684106 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06640769050202587\n",
      "SNR: -5/-5, LS+LI, Epoch 32/50, Loss: 0.06449253323249692 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0664315272799947\n",
      "SNR: -5/-5, LS+LI, Epoch 33/50, Loss: 0.06407803478975628 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0665618662129749\n",
      "SNR: -5/-5, LS+LI, Epoch 34/50, Loss: 0.06409023264639599 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06668629361824556\n",
      "SNR: -5/-5, LS+LI, Epoch 35/50, Loss: 0.06414735093063047 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06629721972752702\n",
      "SNR: -5/-5, LS+LI, Epoch 36/50, Loss: 0.0638949645379948 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0669168069620024\n",
      "SNR: -5/-5, LS+LI, Epoch 37/50, Loss: 0.06409374197815047 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06641776097769087\n",
      "SNR: -5/-5, LS+LI, Epoch 38/50, Loss: 0.06393014929842117 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06650035184892741\n",
      "SNR: -5/-5, LS+LI, Epoch 39/50, Loss: 0.06404127232557119 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06648674471811815\n",
      "SNR: -5/-5, LS+LI, Epoch 40/50, Loss: 0.06368425501467184 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06657053140754049\n",
      "SNR: -5/-5, LS+LI, Epoch 41/50, Loss: 0.06403863170119219 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06621535156260837\n",
      "SNR: -5/-5, LS+LI, Epoch 42/50, Loss: 0.06396047460175185 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06636203893206337\n",
      "SNR: -5/-5, LS+LI, Epoch 43/50, Loss: 0.06389285732320575 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06633905914019454\n",
      "SNR: -5/-5, LS+LI, Epoch 44/50, Loss: 0.06378687004190545 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06625427102500742\n",
      "SNR: -5/-5, LS+LI, Epoch 45/50, Loss: 0.06371587885240483 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06646264513785188\n",
      "SNR: -5/-5, LS+LI, Epoch 46/50, Loss: 0.06355654252259883 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06625622070648453\n",
      "SNR: -5/-5, LS+LI, Epoch 47/50, Loss: 0.06373576921692421 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06623089432039043\n",
      "SNR: -5/-5, LS+LI, Epoch 48/50, Loss: 0.06367532484406649 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06631038727408106\n",
      "SNR: -5/-5, LS+LI, Epoch 49/50, Loss: 0.06375732820827601 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.0665967891162092\n",
      "SNR: -5/-5, LS+LI, Epoch 50/50, Loss: 0.06380646353111018 \n",
      "SNR: -5/-5, LS+LI, Val Loss: 0.06635115761309862\n",
      "LI+NN NMSE: 0.18604883551597595\n",
      "LS+LI NMSE: 0.25997328758239746\n",
      " Training for LS\n",
      "SNR: -5/-5, LS, Epoch 1/50, Loss: 0.24953126485004676 \n",
      "SNR: -5/-5, LS, Val Loss: 0.04421568204733459\n",
      "SNR: -5/-5, LS, Epoch 2/50, Loss: 0.020834559092817957 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01761420282789252\n",
      "SNR: -5/-5, LS, Epoch 3/50, Loss: 0.01639533282235958 \n",
      "SNR: -5/-5, LS, Val Loss: 0.015506509437479755\n",
      "SNR: -5/-5, LS, Epoch 4/50, Loss: 0.015554115614788823 \n",
      "SNR: -5/-5, LS, Val Loss: 0.015543679537420923\n",
      "SNR: -5/-5, LS, Epoch 5/50, Loss: 0.015002052792412944 \n",
      "SNR: -5/-5, LS, Val Loss: 0.014011087065393274\n",
      "SNR: -5/-5, LS, Epoch 6/50, Loss: 0.014782857296035387 \n",
      "SNR: -5/-5, LS, Val Loss: 0.014580448412082413\n",
      "SNR: -5/-5, LS, Epoch 7/50, Loss: 0.014165392903567747 \n",
      "SNR: -5/-5, LS, Val Loss: 0.013682855801148848\n",
      "SNR: -5/-5, LS, Epoch 8/50, Loss: 0.014063065037737752 \n",
      "SNR: -5/-5, LS, Val Loss: 0.014377806970680302\n",
      "SNR: -5/-5, LS, Epoch 9/50, Loss: 0.013788405789582188 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01317874782464721\n",
      "SNR: -5/-5, LS, Epoch 10/50, Loss: 0.013757902825641077 \n",
      "SNR: -5/-5, LS, Val Loss: 0.013043299867686901\n",
      "SNR: -5/-5, LS, Epoch 11/50, Loss: 0.013500111827323602 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012600162447514858\n",
      "SNR: -5/-5, LS, Epoch 12/50, Loss: 0.013359097346966697 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012667708818546751\n",
      "SNR: -5/-5, LS, Epoch 13/50, Loss: 0.013312425410245047 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012450370514257387\n",
      "SNR: -5/-5, LS, Epoch 14/50, Loss: 0.013185720143536495 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012343887112696062\n",
      "SNR: -5/-5, LS, Epoch 15/50, Loss: 0.012966624401553078 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012144430836831982\n",
      "SNR: -5/-5, LS, Epoch 16/50, Loss: 0.012902677795568179 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01195660237730904\n",
      "SNR: -5/-5, LS, Epoch 17/50, Loss: 0.012515940660134305 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012150595260953361\n",
      "SNR: -5/-5, LS, Epoch 18/50, Loss: 0.012559966140881527 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01181296326897361\n",
      "SNR: -5/-5, LS, Epoch 19/50, Loss: 0.01258347166139026 \n",
      "SNR: -5/-5, LS, Val Loss: 0.0120256471616978\n",
      "SNR: -5/-5, LS, Epoch 20/50, Loss: 0.012159826060713724 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011623874730007215\n",
      "SNR: -5/-5, LS, Epoch 21/50, Loss: 0.012229728794028593 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01155436115170067\n",
      "SNR: -5/-5, LS, Epoch 22/50, Loss: 0.012086043486285001 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012165817855433985\n",
      "SNR: -5/-5, LS, Epoch 23/50, Loss: 0.012119752436139903 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011381204959682444\n",
      "SNR: -5/-5, LS, Epoch 24/50, Loss: 0.012003569663393983 \n",
      "SNR: -5/-5, LS, Val Loss: 0.012070352253927425\n",
      "SNR: -5/-5, LS, Epoch 25/50, Loss: 0.01221364471779833 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011126344007524576\n",
      "SNR: -5/-5, LS, Epoch 26/50, Loss: 0.012208608406877448 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011079214301637628\n",
      "SNR: -5/-5, LS, Epoch 27/50, Loss: 0.011789877108449852 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011068776419216936\n",
      "SNR: -5/-5, LS, Epoch 28/50, Loss: 0.011717210951542784 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010903934567150745\n",
      "SNR: -5/-5, LS, Epoch 29/50, Loss: 0.011760875084545723 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010841083670543\n",
      "SNR: -5/-5, LS, Epoch 30/50, Loss: 0.011575613360375513 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010791739787567745\n",
      "SNR: -5/-5, LS, Epoch 31/50, Loss: 0.011565231647732299 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010827905329113657\n",
      "SNR: -5/-5, LS, Epoch 32/50, Loss: 0.011320654606056768 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01095654417506673\n",
      "SNR: -5/-5, LS, Epoch 33/50, Loss: 0.011626774927081411 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01091579669578509\n",
      "SNR: -5/-5, LS, Epoch 34/50, Loss: 0.011784660575781451 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01060485357249325\n",
      "SNR: -5/-5, LS, Epoch 35/50, Loss: 0.011511196864249056 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011223764539780941\n",
      "SNR: -5/-5, LS, Epoch 36/50, Loss: 0.011515153699207964 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010573175566440279\n",
      "SNR: -5/-5, LS, Epoch 37/50, Loss: 0.011120087239718022 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010474501220001415\n",
      "SNR: -5/-5, LS, Epoch 38/50, Loss: 0.0111717194600334 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011605165475471453\n",
      "SNR: -5/-5, LS, Epoch 39/50, Loss: 0.01135648739372575 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010858570267869667\n",
      "SNR: -5/-5, LS, Epoch 40/50, Loss: 0.011150271160701332 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010958104648373344\n",
      "SNR: -5/-5, LS, Epoch 41/50, Loss: 0.011107657624538554 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01063568407500332\n",
      "SNR: -5/-5, LS, Epoch 42/50, Loss: 0.011402277939216516 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010868163588880137\n",
      "SNR: -5/-5, LS, Epoch 43/50, Loss: 0.01155725961312825 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010718216103586283\n",
      "SNR: -5/-5, LS, Epoch 44/50, Loss: 0.011154896798976806 \n",
      "SNR: -5/-5, LS, Val Loss: 0.01032626781273972\n",
      "SNR: -5/-5, LS, Epoch 45/50, Loss: 0.01094639312129381 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010710266524587165\n",
      "SNR: -5/-5, LS, Epoch 46/50, Loss: 0.011298848194243429 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010473237288269129\n",
      "SNR: -5/-5, LS, Epoch 47/50, Loss: 0.010978001381032342 \n",
      "SNR: -5/-5, LS, Val Loss: 0.0102075995369391\n",
      "SNR: -5/-5, LS, Epoch 48/50, Loss: 0.01106081554547039 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010399339911104604\n",
      "SNR: -5/-5, LS, Epoch 49/50, Loss: 0.010879066255658345 \n",
      "SNR: -5/-5, LS, Val Loss: 0.010453491746871308\n",
      "SNR: -5/-5, LS, Epoch 50/50, Loss: 0.01092157872707778 \n",
      "SNR: -5/-5, LS, Val Loss: 0.011352390897544947\n",
      "LS+LI NMSE: 0.032009199261665344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_data(outer_file_path, rows, fc, device, snr)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 1. When input is H_linear (after LS+LI)\n",
    "    print(f\" Training for LS+LI\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "    val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "        # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                    # of valLabels\n",
    "        # train_loader, val_loader are already normalized by their own min, max\n",
    "        # scale to range [0 1]\n",
    "        \n",
    "    # model\n",
    "    model = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 1.5 Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    min_H_true = []\n",
    "    max_H_true = []\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1): # the results after the last training \n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    \n",
    "                    i = i+val_outputs_imag.size(0)       \n",
    "                    \n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS+LI, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "    save_folder = os.path.join(save_folder_model, str(snr)+'dB')\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    index_save = loader.find_incremental_filename(save_folder, 'CNN_', '_variable')\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_LI_CNN_model.pth')\n",
    "    variable_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_variable.pth')\n",
    "    params_save_path = os.path.join(save_folder, 'CNN_' +str(index_save)+'_params.mat')\n",
    "    \n",
    "    params = {   \n",
    "                'SNR': snr,\n",
    "                'epoc': NUM_EPOCHS,\n",
    "                'rows': rowss,\n",
    "                'learning_rate': learning_rate,\n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "    }\n",
    "    variables = {             \n",
    "                'train_track_LI': train_loss,\n",
    "                'val_track_LI': val_loss,\n",
    "                # 'train_min_LI': trainData_min.cpu(),\n",
    "                # 'train_max_LI': trainData_max.cpu(),\n",
    "                # 'train_label_min': trainLabels_min.cpu(),\n",
    "                # 'train_label_max': trainLabels_max.cpu(),\n",
    "    }\n",
    "    # variable to save \n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, model_save_path)\n",
    "\n",
    "    figure_save_path = os.path.join(save_folder_fig, str(snr) + 'dB') \n",
    "    \n",
    "    os.makedirs(figure_save_path, exist_ok=True)\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_LI_Loss.png')\n",
    "\n",
    "\n",
    "    # True channel\n",
    "    H_val_true = valLabels.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "    # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "\n",
    "    plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', index_save, figure_save_path, '_trueChannel.png')\n",
    "\n",
    "    # Estimated Channel \n",
    "    H_val_NN = H_NN_val.cpu()    \n",
    "    plotfig.figTrueChan(H_val_NN[-1,0,:,:], 'LI+CNN Estimated Channel (before de-normlized)', \n",
    "                            index_save, figure_save_path, '_LS_LI_CNN_estimatedChan_before_denorm.png')\n",
    "\n",
    "    # De-normalized                                                               \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "                        \n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "    # variables['H_val_LI_NN'] = H_val_NN_denormd # (nVal, 2, 612, 14)\n",
    "\n",
    "    # convert to complex matrices\n",
    "    H_val_NN_denormd_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    \n",
    "    nmse_LI_NN = utils.calNMSE(H_val_NN_denormd_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI_NN'] = nmse_LI_NN.cpu().mean()\n",
    "    nmse_LI_NN_val.append(variables['NMSE_LI_NN'].item())\n",
    "    print(f\"LI+NN NMSE: {variables['NMSE_LI_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LI+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LI_NN[-1], index_save, figure_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "#####\n",
    "##### above is LS+LI+NN \n",
    "\n",
    "##### following is Linear interpolated channel (only LS+LI)\n",
    "    H_val_linInterp = H_linear_val.cpu()\n",
    "    # convert to complex matrices\n",
    "    H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "\n",
    "    # NMSE of Linear Interpolation\n",
    "    # Calculate the NMSE\n",
    "    nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LI'] = nmse_LI.cpu().mean()\n",
    "    nmse_LS_LI_val.append(variables['NMSE_LI'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LI'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                            nmse_LI[-1], index_save, figure_save_path, '_LS_LI_estimatedChan.png')\n",
    "\n",
    "\n",
    "##########################################\n",
    "    # ------------------------------------------------------\n",
    "    # When Input of the NN is just H_equalized\n",
    "    print(f\" Training for LS\")\n",
    "    # [samples, 2, 612, 14]\n",
    "    H_LS_train = H_equal_train.cpu()\n",
    "    plotfig.figTrueChan(H_LS_train[0,0,:,:], 'LS Channel', index_save, figure_save_path, '_LS_Chan.png')\n",
    "    \n",
    "    # Split into training and validation sets for H_NN training\n",
    "    train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train',  True, norm_approach)\n",
    "    val_loader,     valLabel_min,   vallabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach)\n",
    "\n",
    "\n",
    "    model2 = utils.CNN_Est(dropOut=0, act =CNN_activation).to(device)\n",
    "    optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate) \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    train_loss =[]\n",
    "    val_loss = []\n",
    "    H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "    num_epochs = NUM_EPOCHS\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        running_loss = 0.0\n",
    "        if (epoch == num_epochs-1):\n",
    "            i = 0\n",
    "        for inputs, targets, targets_min, targets_max in train_loader:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer2.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "        \n",
    "        # Validation \n",
    "        model2.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                \n",
    "                val_outputs_real = model2(val_inputs_real)\n",
    "                val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                running_val_loss += val_loss_real.item()\n",
    "                \n",
    "                val_outputs_imag = model2(val_inputs_imag)\n",
    "                val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                running_val_loss += val_loss_imag.item()\n",
    "                \n",
    "                if (epoch == num_epochs-1):\n",
    "                    H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                    H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                    i = i+val_outputs_imag.size(0)\n",
    "                \n",
    "        avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "        val_loss.append(avg_val_loss)    \n",
    "                \n",
    "        print(f\"SNR: {snr}/{SNR[-1]}, LS, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    plotfig.figLoss(train_loss, val_loss, index_save, figure_save_path, '_LS_Loss.png')\n",
    "\n",
    "    # De-normalized                                                                \n",
    "    H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                        #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                        # valLabel_min == [nVal,1]\n",
    "    H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "\n",
    "    model_save_path = os.path.join(save_folder,  'CNN_' +str(index_save)+'_LS_CNN_model.pth')\n",
    "\n",
    "    # variables['H_val_LS_NN']= H_val_NN_denormd.cpu() # (nVal, 2, 612, 14)\n",
    "    variables['train_track_LS']= train_loss\n",
    "    variables['val_track_LS']= val_loss\n",
    "\n",
    "    # Save parameters\n",
    "    params['train_track_LS']= train_loss\n",
    "    params['val_track_LS']= val_loss\n",
    "    savemat(params_save_path, params)\n",
    "    # Save the models' state dictionaries \n",
    "    torch.save({'model_state_dict': model2.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "                }, model_save_path)\n",
    "\n",
    "\n",
    "    # NMSE of LS + NN\n",
    "    H_val_LS_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])\n",
    "    # Calculate the NMSE\n",
    "    nmse_LS_NN = utils.calNMSE(H_val_LS_NN_complex, H_val_true_complex)\n",
    "    \n",
    "    variables['NMSE_LS_NN'] = nmse_LS_NN.cpu().mean()\n",
    "    nmse_LS_NN_val.append(variables['NMSE_LS_NN'].item())\n",
    "    print(f\"LS+LI NMSE: {variables['NMSE_LS_NN'].item()}\")\n",
    "    \n",
    "    plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel (after de-normlized)',\n",
    "                            nmse_LS_NN[-1], index_save, figure_save_path, '_LS_CNN_estimatedChan.png')\n",
    "    \n",
    "\n",
    "    torch.save( variables,variable_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver27_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE1.png\"))\n",
    "\n",
    "\n",
    "nmse_compare ={\n",
    "    'nmse_LS_LI_val': nmse_LS_LI_val, \n",
    "    'nmse_LS_NN_val':nmse_LS_NN_val, \n",
    "    'nmse_LI_NN_val':nmse_LI_NN_val\n",
    "}\n",
    "\n",
    "savemat(os.path.join(save_folder_fig, 'NMSE.mat'), nmse_compare)\n",
    "\n",
    "torch.save( nmse_compare, os.path.join(save_folder_fig, 'NMSE.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/figure/static/CNN/BS16/3500_3516/ver27_/NMSE2.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder_fig, \"NMSE2.png\"))\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(save_folder_fig, \"NMSE2.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
