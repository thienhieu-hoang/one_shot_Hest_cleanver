{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "import utils_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir  = \"../model/static/CNN/BS16/3500_3516/ver14_\"\n",
    "target_data_dir    = \"../../CDL Customization/Data/ver29_\"\n",
    "\n",
    "# Min-max Scaler to [-1 1] range\n",
    "norm_approach = 'minmax'\n",
    "lower_range = -1\n",
    "CNN_DropOut = 0.2\n",
    "CNN_activation = 'Tanh'\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/transfer_v4.ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "1000 samples in target dataset (map-based dataset), 0.9 for training, 0.1 for validating\n",
    "Finetune models don't have padding at 2 last layers \n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "os.makedirs(os.path.dirname(f'{transferd_save_path}/readme.txt'), exist_ok=True)\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightly applying trained model to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      "LS_CNN model\n",
      "SNR: 0/30, LS_CNN, Epoch 1/50, Loss: 0.39448792753475054 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.39298032596707344\n",
      "SNR: 0/30, LS_CNN, Epoch 2/50, Loss: 0.38098046130367685 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.380418598651886\n",
      "SNR: 0/30, LS_CNN, Epoch 3/50, Loss: 0.36825685309512274 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.36606693640351295\n",
      "SNR: 0/30, LS_CNN, Epoch 4/50, Loss: 0.3560507318803242 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.35399800166487694\n",
      "SNR: 0/30, LS_CNN, Epoch 5/50, Loss: 0.34557159298232626 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3441658429801464\n",
      "SNR: 0/30, LS_CNN, Epoch 6/50, Loss: 0.3370942920446396 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3347167521715164\n",
      "SNR: 0/30, LS_CNN, Epoch 7/50, Loss: 0.32917196143950733 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3248017057776451\n",
      "SNR: 0/30, LS_CNN, Epoch 8/50, Loss: 0.32167282540883335 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3163437806069851\n",
      "SNR: 0/30, LS_CNN, Epoch 9/50, Loss: 0.31501929249082294 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31156957522034645\n",
      "SNR: 0/30, LS_CNN, Epoch 10/50, Loss: 0.30922974912183626 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.30249034240841866\n",
      "SNR: 0/30, LS_CNN, Epoch 11/50, Loss: 0.3040133198457105 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2955555319786072\n",
      "SNR: 0/30, LS_CNN, Epoch 12/50, Loss: 0.29661650583148 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2905813157558441\n",
      "SNR: 0/30, LS_CNN, Epoch 13/50, Loss: 0.2900444838617529 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28382566571235657\n",
      "SNR: 0/30, LS_CNN, Epoch 14/50, Loss: 0.2885901028556483 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.27775827050209045\n",
      "SNR: 0/30, LS_CNN, Epoch 15/50, Loss: 0.2808975058474711 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2681809812784195\n",
      "SNR: 0/30, LS_CNN, Epoch 16/50, Loss: 0.27522476336785723 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2592698112130165\n",
      "SNR: 0/30, LS_CNN, Epoch 17/50, Loss: 0.26985297352075577 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2532826401293278\n",
      "SNR: 0/30, LS_CNN, Epoch 18/50, Loss: 0.2637021757130112 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2481027152389288\n",
      "SNR: 0/30, LS_CNN, Epoch 19/50, Loss: 0.25698433071374893 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2466543521732092\n",
      "SNR: 0/30, LS_CNN, Epoch 20/50, Loss: 0.256087959344898 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.23569181188941002\n",
      "SNR: 0/30, LS_CNN, Epoch 21/50, Loss: 0.2508592012205294 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2324392069131136\n",
      "SNR: 0/30, LS_CNN, Epoch 22/50, Loss: 0.24375446140766144 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2313708048313856\n",
      "SNR: 0/30, LS_CNN, Epoch 23/50, Loss: 0.24449307631169045 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2223549224436283\n",
      "SNR: 0/30, LS_CNN, Epoch 24/50, Loss: 0.23965735786727496 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2148824092000723\n",
      "SNR: 0/30, LS_CNN, Epoch 25/50, Loss: 0.2314296191824334 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.21047398075461388\n",
      "SNR: 0/30, LS_CNN, Epoch 26/50, Loss: 0.2265736875789506 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20831414684653282\n",
      "SNR: 0/30, LS_CNN, Epoch 27/50, Loss: 0.23322551750711032 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20355894975364208\n",
      "SNR: 0/30, LS_CNN, Epoch 28/50, Loss: 0.2275395699377571 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2035784050822258\n",
      "SNR: 0/30, LS_CNN, Epoch 29/50, Loss: 0.23124687746167183 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20146102644503117\n",
      "SNR: 0/30, LS_CNN, Epoch 30/50, Loss: 0.23009318060108594 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19829716347157955\n",
      "SNR: 0/30, LS_CNN, Epoch 31/50, Loss: 0.22532833474023 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1944197081029415\n",
      "SNR: 0/30, LS_CNN, Epoch 32/50, Loss: 0.22946989589503833 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19484088942408562\n",
      "SNR: 0/30, LS_CNN, Epoch 33/50, Loss: 0.21960434184542724 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18687155283987522\n",
      "SNR: 0/30, LS_CNN, Epoch 34/50, Loss: 0.2282348152782236 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1883775256574154\n",
      "SNR: 0/30, LS_CNN, Epoch 35/50, Loss: 0.218090989493898 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18504060991108418\n",
      "SNR: 0/30, LS_CNN, Epoch 36/50, Loss: 0.2181122555796589 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18677323311567307\n",
      "SNR: 0/30, LS_CNN, Epoch 37/50, Loss: 0.210237608690347 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18416466936469078\n",
      "SNR: 0/30, LS_CNN, Epoch 38/50, Loss: 0.22324751636811666 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1855021733790636\n",
      "SNR: 0/30, LS_CNN, Epoch 39/50, Loss: 0.21756813994475774 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18265289068222046\n",
      "SNR: 0/30, LS_CNN, Epoch 40/50, Loss: 0.21036873199045658 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17881732806563377\n",
      "SNR: 0/30, LS_CNN, Epoch 41/50, Loss: 0.2042554414698056 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17566224560141563\n",
      "SNR: 0/30, LS_CNN, Epoch 42/50, Loss: 0.2140633384031909 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17564652301371098\n",
      "SNR: 0/30, LS_CNN, Epoch 43/50, Loss: 0.22355541719921998 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17747751995921135\n",
      "SNR: 0/30, LS_CNN, Epoch 44/50, Loss: 0.21951244611825263 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17924925312399864\n",
      "SNR: 0/30, LS_CNN, Epoch 45/50, Loss: 0.21458655702216284 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17705438286066055\n",
      "SNR: 0/30, LS_CNN, Epoch 46/50, Loss: 0.21920214806284224 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17470949329435825\n",
      "SNR: 0/30, LS_CNN, Epoch 47/50, Loss: 0.22059225237795285 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1735470201820135\n",
      "SNR: 0/30, LS_CNN, Epoch 48/50, Loss: 0.2145079874566623 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17593981139361858\n",
      "SNR: 0/30, LS_CNN, Epoch 49/50, Loss: 0.2041601716939892 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.18057021871209145\n",
      "SNR: 0/30, LS_CNN, Epoch 50/50, Loss: 0.21025302101458823 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.17727119475603104\n",
      "LS+CNN NMSE: 0.02199067920446396\n",
      "LS+LI NMSE: 0.08237525075674057\n",
      "LS_LI_CNN model\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 1/50, Loss: 0.39374675495283945 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3885490112006664\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3735124697642667 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.36578454449772835\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 3/50, Loss: 0.34952491521835327 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.33866361528635025\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3216692406151976 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3092600144445896\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 5/50, Loss: 0.2921523454466036 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2772503811866045\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 6/50, Loss: 0.26532593422702383 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.25247033312916756\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 7/50, Loss: 0.24431148969701358 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23610412701964378\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 8/50, Loss: 0.23069702993546212 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22284160554409027\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 9/50, Loss: 0.22349041381052562 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21715435944497585\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 10/50, Loss: 0.21989598125219345 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2152497060596943\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 11/50, Loss: 0.21852328761347703 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21401138417422771\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 12/50, Loss: 0.21786812373570033 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21406499110162258\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 13/50, Loss: 0.21797575322645052 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2121362704783678\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 14/50, Loss: 0.2176307442464999 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.212638882920146\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 15/50, Loss: 0.21610125340521336 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21299693174660206\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 16/50, Loss: 0.2174321130982467 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21165095083415508\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 17/50, Loss: 0.21609938889741898 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21177064254879951\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 18/50, Loss: 0.21628969801323755 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21151600778102875\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 19/50, Loss: 0.21629215590655804 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21130147576332092\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 20/50, Loss: 0.21608079384480203 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21174761094152927\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 21/50, Loss: 0.2164943284754242 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2117469534277916\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 22/50, Loss: 0.21518137917986938 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2113876026123762\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 23/50, Loss: 0.21611125847058638 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21120741963386536\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 24/50, Loss: 0.21575250237115792 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21121573075652122\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 25/50, Loss: 0.21638304793408938 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21096346713602543\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 26/50, Loss: 0.2153354821992772 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21104738116264343\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 27/50, Loss: 0.2157996895589999 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2110989447683096\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 28/50, Loss: 0.21498013979622296 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21090932562947273\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 29/50, Loss: 0.21629299276641437 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21085385419428349\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 30/50, Loss: 0.2157301139086485 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21075765416026115\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 31/50, Loss: 0.21473664870219572 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21073301322758198\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 32/50, Loss: 0.2155133725277015 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21063674241304398\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 33/50, Loss: 0.2146965337118932 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2105735708028078\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 34/50, Loss: 0.21567838293101108 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21057600155472755\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 35/50, Loss: 0.21507760669503892 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2105916664004326\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 36/50, Loss: 0.21539012795048101 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21063522063195705\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 37/50, Loss: 0.21470879843192442 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2105151228606701\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 38/50, Loss: 0.21456652720059669 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2104924526065588\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 39/50, Loss: 0.2153567224740982 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2110266461968422\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 40/50, Loss: 0.2150867437677724 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21045838296413422\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 41/50, Loss: 0.21440331611250127 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2103993073105812\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 42/50, Loss: 0.2146617009171418 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21034784242510796\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 43/50, Loss: 0.21370445005595684 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21048341132700443\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 44/50, Loss: 0.21476532385817595 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.210353909060359\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 45/50, Loss: 0.2140062680201871 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21057607978582382\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 46/50, Loss: 0.21423252671957016 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2104313038289547\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 47/50, Loss: 0.21462190390697547 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21024877205491066\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 48/50, Loss: 0.21501734480261803 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21024934761226177\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 49/50, Loss: 0.21507488962795054 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21035377122461796\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 50/50, Loss: 0.21460540632584266 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21095388568937778\n",
      "LS+CNN NMSE: 0.0317482091486454\n",
      " SNR: 5/30\n",
      "LS_CNN model\n",
      "SNR: 5/30, LS_CNN, Epoch 1/50, Loss: 0.40605129886950764 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.39770038053393364\n",
      "SNR: 5/30, LS_CNN, Epoch 2/50, Loss: 0.39895512589386534 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3907109312713146\n",
      "SNR: 5/30, LS_CNN, Epoch 3/50, Loss: 0.39066452958754133 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.38173094764351845\n",
      "SNR: 5/30, LS_CNN, Epoch 4/50, Loss: 0.3813229687511921 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3711738660931587\n",
      "SNR: 5/30, LS_CNN, Epoch 5/50, Loss: 0.36994533240795135 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3594985231757164\n",
      "SNR: 5/30, LS_CNN, Epoch 6/50, Loss: 0.3568929891501154 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.34450995177030563\n",
      "SNR: 5/30, LS_CNN, Epoch 7/50, Loss: 0.34316516082201687 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3312239572405815\n",
      "SNR: 5/30, LS_CNN, Epoch 8/50, Loss: 0.33002731470125063 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.31653816998004913\n",
      "SNR: 5/30, LS_CNN, Epoch 9/50, Loss: 0.31704000011086464 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30383835919201374\n",
      "SNR: 5/30, LS_CNN, Epoch 10/50, Loss: 0.30606620013713837 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.293955298140645\n",
      "SNR: 5/30, LS_CNN, Epoch 11/50, Loss: 0.29789512710911886 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.282074810937047\n",
      "SNR: 5/30, LS_CNN, Epoch 12/50, Loss: 0.28949104994535446 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27260679565370083\n",
      "SNR: 5/30, LS_CNN, Epoch 13/50, Loss: 0.2827909884176084 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26577310264110565\n",
      "SNR: 5/30, LS_CNN, Epoch 14/50, Loss: 0.27344989244427 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25318436324596405\n",
      "SNR: 5/30, LS_CNN, Epoch 15/50, Loss: 0.272397463076881 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24518234096467495\n",
      "SNR: 5/30, LS_CNN, Epoch 16/50, Loss: 0.26390960519867285 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24111813120543957\n",
      "SNR: 5/30, LS_CNN, Epoch 17/50, Loss: 0.2616389151662588 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23331360705196857\n",
      "SNR: 5/30, LS_CNN, Epoch 18/50, Loss: 0.25612873238112244 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22774224914610386\n",
      "SNR: 5/30, LS_CNN, Epoch 19/50, Loss: 0.24846184573003224 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2193122860044241\n",
      "SNR: 5/30, LS_CNN, Epoch 20/50, Loss: 0.24448894123945916 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.21092899329960346\n",
      "SNR: 5/30, LS_CNN, Epoch 21/50, Loss: 0.23893828211086138 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.21133849397301674\n",
      "SNR: 5/30, LS_CNN, Epoch 22/50, Loss: 0.23755155503749847 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20312762074172497\n",
      "SNR: 5/30, LS_CNN, Epoch 23/50, Loss: 0.23286463054163115 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1998777613043785\n",
      "SNR: 5/30, LS_CNN, Epoch 24/50, Loss: 0.23248718519295966 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19320213422179222\n",
      "SNR: 5/30, LS_CNN, Epoch 25/50, Loss: 0.22879163175821304 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1897335136309266\n",
      "SNR: 5/30, LS_CNN, Epoch 26/50, Loss: 0.23735660766916616 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18933065980672836\n",
      "SNR: 5/30, LS_CNN, Epoch 27/50, Loss: 0.2259547228791884 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18349415622651577\n",
      "SNR: 5/30, LS_CNN, Epoch 28/50, Loss: 0.2196540300335203 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17951250821352005\n",
      "SNR: 5/30, LS_CNN, Epoch 29/50, Loss: 0.2197643941534417 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1793171837925911\n",
      "SNR: 5/30, LS_CNN, Epoch 30/50, Loss: 0.21934784283595427 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1733098393306136\n",
      "SNR: 5/30, LS_CNN, Epoch 31/50, Loss: 0.2150361921106066 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17419129330664873\n",
      "SNR: 5/30, LS_CNN, Epoch 32/50, Loss: 0.215148800984025 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17264047171920538\n",
      "SNR: 5/30, LS_CNN, Epoch 33/50, Loss: 0.21360674952822073 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16887528263032436\n",
      "SNR: 5/30, LS_CNN, Epoch 34/50, Loss: 0.22054291729416167 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16745972633361816\n",
      "SNR: 5/30, LS_CNN, Epoch 35/50, Loss: 0.21023421920835972 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16722579766064882\n",
      "SNR: 5/30, LS_CNN, Epoch 36/50, Loss: 0.21473001475845063 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17151972651481628\n",
      "SNR: 5/30, LS_CNN, Epoch 37/50, Loss: 0.2174348048865795 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16535164788365364\n",
      "SNR: 5/30, LS_CNN, Epoch 38/50, Loss: 0.21081840539617197 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16447942610830069\n",
      "SNR: 5/30, LS_CNN, Epoch 39/50, Loss: 0.2165102091218744 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16316328570246696\n",
      "SNR: 5/30, LS_CNN, Epoch 40/50, Loss: 0.20836723409593105 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16040382720530033\n",
      "SNR: 5/30, LS_CNN, Epoch 41/50, Loss: 0.20501252822577953 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1575962146744132\n",
      "SNR: 5/30, LS_CNN, Epoch 42/50, Loss: 0.20998338889330626 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15791407134383917\n",
      "SNR: 5/30, LS_CNN, Epoch 43/50, Loss: 0.2079479969771845 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1587392957881093\n",
      "SNR: 5/30, LS_CNN, Epoch 44/50, Loss: 0.21806688739785127 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15941744297742844\n",
      "SNR: 5/30, LS_CNN, Epoch 45/50, Loss: 0.20966187492012978 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15938572213053703\n",
      "SNR: 5/30, LS_CNN, Epoch 46/50, Loss: 0.2093207189547164 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1587490802630782\n",
      "SNR: 5/30, LS_CNN, Epoch 47/50, Loss: 0.2124019076249429 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15655800234526396\n",
      "SNR: 5/30, LS_CNN, Epoch 48/50, Loss: 0.2163931048874344 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15718623343855143\n",
      "SNR: 5/30, LS_CNN, Epoch 49/50, Loss: 0.2162792296814067 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.16047119349241257\n",
      "SNR: 5/30, LS_CNN, Epoch 50/50, Loss: 0.2187920045107603 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.15767441596835852\n",
      "LS+CNN NMSE: 0.019696785137057304\n",
      "LS+LI NMSE: 0.025552358478307724\n",
      "LS_LI_CNN model\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 1/50, Loss: 0.39287962338754107 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.371172696352005\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 2/50, Loss: 0.35752546414732933 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3355425260961056\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 3/50, Loss: 0.31950147237096516 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.29613152146339417\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 4/50, Loss: 0.2807708715221712 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2589468378573656\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 5/50, Loss: 0.24450887713049138 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.22382557019591331\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 6/50, Loss: 0.21349448497806275 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.19608642160892487\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 7/50, Loss: 0.1882542824106557 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1751166069880128\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 8/50, Loss: 0.17118712754121848 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16051052138209343\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 9/50, Loss: 0.15957649650850467 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1509170364588499\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 10/50, Loss: 0.15293263816939934 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1462762365117669\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 11/50, Loss: 0.14956115678484952 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1423480911180377\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 12/50, Loss: 0.14707615173288754 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13940543867647648\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 13/50, Loss: 0.14592861557113274 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13868641713634133\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 14/50, Loss: 0.1460803137826068 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.136699628084898\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 15/50, Loss: 0.1455712949058839 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13632369553670287\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 16/50, Loss: 0.14410906910364116 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13718470046296716\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 17/50, Loss: 0.143876020796597 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1355095086619258\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 18/50, Loss: 0.14388017130217381 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1365242674946785\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 19/50, Loss: 0.14360494898366077 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13647789135575294\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 20/50, Loss: 0.14394852053374052 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13645132398232818\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 21/50, Loss: 0.1435462228421654 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1354992645792663\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 22/50, Loss: 0.1430686768144369 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13602076843380928\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 23/50, Loss: 0.14332338316099985 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13503346592187881\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 24/50, Loss: 0.14304022956639528 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1346671786159277\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 25/50, Loss: 0.14249779550092562 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1344143282622099\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 26/50, Loss: 0.14142899867147207 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13447396783158183\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 27/50, Loss: 0.14208436956895248 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13386537646874785\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 28/50, Loss: 0.14210994581558875 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13407617202028632\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 29/50, Loss: 0.14156097745788948 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13328254641965032\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 30/50, Loss: 0.1419959720224142 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13341224985197186\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 31/50, Loss: 0.1414475922605821 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13372688088566065\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 32/50, Loss: 0.1408245065914733 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13372300192713737\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 33/50, Loss: 0.1417008320401822 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13332799775525928\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 34/50, Loss: 0.1413178550345557 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13288447633385658\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 35/50, Loss: 0.14111976152552025 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1331948763690889\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 36/50, Loss: 0.1402138832158276 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13281868258491158\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 37/50, Loss: 0.14028057921677828 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13335832860320807\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 38/50, Loss: 0.14092000533959695 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13270362233743072\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 39/50, Loss: 0.14054175333252975 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13275629142299294\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 40/50, Loss: 0.1397532800744687 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13249427545815706\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 41/50, Loss: 0.14037842782480375 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13290762715041637\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 42/50, Loss: 0.1408652872113245 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13265098817646503\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 43/50, Loss: 0.14022047697965587 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13270008098334074\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 44/50, Loss: 0.14065125411642448 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13247575191780925\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 45/50, Loss: 0.14083331237946237 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13246802426874638\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 46/50, Loss: 0.14020871011806385 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13245776062831283\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 47/50, Loss: 0.1403203864714929 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13223630329594016\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 48/50, Loss: 0.14103386511227914 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1322064041160047\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 49/50, Loss: 0.14041427788989885 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13229186134412885\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 50/50, Loss: 0.14014303152050292 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13225399563089013\n",
      "LS+CNN NMSE: 0.014789135195314884\n",
      " SNR: 10/30\n",
      "LS_CNN model\n",
      "SNR: 10/30, LS_CNN, Epoch 1/50, Loss: 0.39167402258941103 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38103190809488297\n",
      "SNR: 10/30, LS_CNN, Epoch 2/50, Loss: 0.3812235785382135 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3711214251816273\n",
      "SNR: 10/30, LS_CNN, Epoch 3/50, Loss: 0.3703327865472862 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36069008335471153\n",
      "SNR: 10/30, LS_CNN, Epoch 4/50, Loss: 0.3595696677054678 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3505758233368397\n",
      "SNR: 10/30, LS_CNN, Epoch 5/50, Loss: 0.3504880352744034 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.344890832901001\n",
      "SNR: 10/30, LS_CNN, Epoch 6/50, Loss: 0.34172824770212173 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33643246814608574\n",
      "SNR: 10/30, LS_CNN, Epoch 7/50, Loss: 0.33547373009579523 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32834194600582123\n",
      "SNR: 10/30, LS_CNN, Epoch 8/50, Loss: 0.33075939917138647 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32151130959391594\n",
      "SNR: 10/30, LS_CNN, Epoch 9/50, Loss: 0.3237788421767099 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31947161257267\n",
      "SNR: 10/30, LS_CNN, Epoch 10/50, Loss: 0.31841555344206945 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31407178565859795\n",
      "SNR: 10/30, LS_CNN, Epoch 11/50, Loss: 0.3117528297007084 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.30456082709133625\n",
      "SNR: 10/30, LS_CNN, Epoch 12/50, Loss: 0.3062605919050319 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2993033938109875\n",
      "SNR: 10/30, LS_CNN, Epoch 13/50, Loss: 0.3004542410905872 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2928698193281889\n",
      "SNR: 10/30, LS_CNN, Epoch 14/50, Loss: 0.29570082681519644 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2804972883313894\n",
      "SNR: 10/30, LS_CNN, Epoch 15/50, Loss: 0.28602015173860956 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27878457121551037\n",
      "SNR: 10/30, LS_CNN, Epoch 16/50, Loss: 0.2805349004587957 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2695278711616993\n",
      "SNR: 10/30, LS_CNN, Epoch 17/50, Loss: 0.27723940408655573 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27307771705091\n",
      "SNR: 10/30, LS_CNN, Epoch 18/50, Loss: 0.2728431046541248 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.26272641494870186\n",
      "SNR: 10/30, LS_CNN, Epoch 19/50, Loss: 0.26715447115046637 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24691743403673172\n",
      "SNR: 10/30, LS_CNN, Epoch 20/50, Loss: 0.2576409059443644 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24404354952275753\n",
      "SNR: 10/30, LS_CNN, Epoch 21/50, Loss: 0.2601754888892174 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24280014634132385\n",
      "SNR: 10/30, LS_CNN, Epoch 22/50, Loss: 0.2522382768137114 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2432282753288746\n",
      "SNR: 10/30, LS_CNN, Epoch 23/50, Loss: 0.2382697601403509 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.23078949935734272\n",
      "SNR: 10/30, LS_CNN, Epoch 24/50, Loss: 0.2389737404882908 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22285979613661766\n",
      "SNR: 10/30, LS_CNN, Epoch 25/50, Loss: 0.2384214491716453 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2195730097591877\n",
      "SNR: 10/30, LS_CNN, Epoch 26/50, Loss: 0.22900697030127048 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.20820513367652893\n",
      "SNR: 10/30, LS_CNN, Epoch 27/50, Loss: 0.2276434422071491 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2060632538050413\n",
      "SNR: 10/30, LS_CNN, Epoch 28/50, Loss: 0.22621021951947892 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2123949509114027\n",
      "SNR: 10/30, LS_CNN, Epoch 29/50, Loss: 0.21900782893810952 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.19714022986590862\n",
      "SNR: 10/30, LS_CNN, Epoch 30/50, Loss: 0.21557464956172875 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.19843858666718006\n",
      "SNR: 10/30, LS_CNN, Epoch 31/50, Loss: 0.209931774863175 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.19249192997813225\n",
      "SNR: 10/30, LS_CNN, Epoch 32/50, Loss: 0.21708477661013603 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1887520607560873\n",
      "SNR: 10/30, LS_CNN, Epoch 33/50, Loss: 0.21128665655851364 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.18677723035216331\n",
      "SNR: 10/30, LS_CNN, Epoch 34/50, Loss: 0.21864169303859984 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.18429728224873543\n",
      "SNR: 10/30, LS_CNN, Epoch 35/50, Loss: 0.2097089628555945 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1852884404361248\n",
      "SNR: 10/30, LS_CNN, Epoch 36/50, Loss: 0.20110085313873632 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17686393950134516\n",
      "SNR: 10/30, LS_CNN, Epoch 37/50, Loss: 0.2064086432967867 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.18094946164637804\n",
      "SNR: 10/30, LS_CNN, Epoch 38/50, Loss: 0.20283187446849688 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17597322259098291\n",
      "SNR: 10/30, LS_CNN, Epoch 39/50, Loss: 0.20442872707332885 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17431816272437572\n",
      "SNR: 10/30, LS_CNN, Epoch 40/50, Loss: 0.2123586256057024 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17711124941706657\n",
      "SNR: 10/30, LS_CNN, Epoch 41/50, Loss: 0.20169516493167197 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17307148780673742\n",
      "SNR: 10/30, LS_CNN, Epoch 42/50, Loss: 0.2114692639027323 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17276181280612946\n",
      "SNR: 10/30, LS_CNN, Epoch 43/50, Loss: 0.20210375929517405 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1732258852571249\n",
      "SNR: 10/30, LS_CNN, Epoch 44/50, Loss: 0.1963746382721833 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17096357606351376\n",
      "SNR: 10/30, LS_CNN, Epoch 45/50, Loss: 0.20138377217309816 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.16954398714005947\n",
      "SNR: 10/30, LS_CNN, Epoch 46/50, Loss: 0.20877866047833646 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.16851163748651743\n",
      "SNR: 10/30, LS_CNN, Epoch 47/50, Loss: 0.22045302337833814 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17093404289335012\n",
      "SNR: 10/30, LS_CNN, Epoch 48/50, Loss: 0.20153675015483583 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1766203325241804\n",
      "SNR: 10/30, LS_CNN, Epoch 49/50, Loss: 0.2065753409905093 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17043324001133442\n",
      "SNR: 10/30, LS_CNN, Epoch 50/50, Loss: 0.2043235223474247 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17189297825098038\n",
      "LS+CNN NMSE: 0.02928438037633896\n",
      "LS+LI NMSE: 0.008305445313453674\n",
      "LS_LI_CNN model\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 1/50, Loss: 0.35699179023504257 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3325534500181675\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 2/50, Loss: 0.31091019404785974 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2854018770158291\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 3/50, Loss: 0.2608782968350819 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.23783020488917828\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 4/50, Loss: 0.21147224812635354 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1924984958022833\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 5/50, Loss: 0.16841436017836844 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.15591166354715824\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 6/50, Loss: 0.13530346205724136 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.12812872510403395\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 7/50, Loss: 0.11407241837254592 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.11170655116438866\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 8/50, Loss: 0.10088790740285601 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10266209673136473\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 9/50, Loss: 0.094929930887052 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09742374997586012\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 10/50, Loss: 0.09216371531199131 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09525270946323872\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 11/50, Loss: 0.09135118499398232 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09437567740678787\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 12/50, Loss: 0.09048780645909053 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09422498103231192\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 13/50, Loss: 0.0907661026077611 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09417580347508192\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 14/50, Loss: 0.09062033984810114 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09377715922892094\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 15/50, Loss: 0.09022392272683126 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09384478256106377\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 16/50, Loss: 0.09040675079450011 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09366110619157553\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 17/50, Loss: 0.09036437295643347 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09340599924325943\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 18/50, Loss: 0.09064589959702321 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.093590940348804\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 19/50, Loss: 0.09046020551717707 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09343354403972626\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 20/50, Loss: 0.08978892849492175 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09312824066728354\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 21/50, Loss: 0.08992797402398926 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09315055795013905\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 22/50, Loss: 0.09008678341550487 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09299722127616405\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 23/50, Loss: 0.09013643302023411 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09325097035616636\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 24/50, Loss: 0.0895892138858991 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09277169872075319\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 25/50, Loss: 0.08909980500383037 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.092664853669703\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 26/50, Loss: 0.08944290457293391 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09279688727110624\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 27/50, Loss: 0.08970197596188102 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09248598106205463\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 28/50, Loss: 0.08951117457555872 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09273299295455217\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 29/50, Loss: 0.08980037684419326 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09244051948189735\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 30/50, Loss: 0.08935471856966615 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09231001604348421\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 31/50, Loss: 0.08919123440448727 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09256288688629866\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 32/50, Loss: 0.08922590435083423 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09227374661713839\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 33/50, Loss: 0.08921078945110951 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09257151745259762\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 34/50, Loss: 0.089286906711225 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09264304395765066\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 35/50, Loss: 0.0886969501817865 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09222329594194889\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 36/50, Loss: 0.08889691864273377 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09201306570321321\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 37/50, Loss: 0.08881897791954023 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09163743443787098\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 38/50, Loss: 0.08877766464969941 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09179868176579475\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 39/50, Loss: 0.08880525341789637 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09158313553780317\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 40/50, Loss: 0.08848159547363009 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09204309713095427\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 41/50, Loss: 0.08872263386313405 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09183039609342813\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 42/50, Loss: 0.08829325291195086 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09146435838192701\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 43/50, Loss: 0.08857812559498209 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0916305286809802\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 44/50, Loss: 0.0886300152300724 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0915717501193285\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 45/50, Loss: 0.08834493133638587 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09151353314518929\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 46/50, Loss: 0.08850868877821735 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09138199873268604\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 47/50, Loss: 0.08825235208496451 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0914797643199563\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 48/50, Loss: 0.08811409558568682 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09113138914108276\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 49/50, Loss: 0.0880796834161239 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09115592483431101\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 50/50, Loss: 0.08799629385716148 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09095465578138828\n",
      "LS+CNN NMSE: 0.010371590964496136\n",
      " SNR: 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS_CNN model\n",
      "SNR: 15/30, LS_CNN, Epoch 1/50, Loss: 0.38676247213568005 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.39137184992432594\n",
      "SNR: 15/30, LS_CNN, Epoch 2/50, Loss: 0.3737824277154037 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3780176192522049\n",
      "SNR: 15/30, LS_CNN, Epoch 3/50, Loss: 0.35880849457212854 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.363409161567688\n",
      "SNR: 15/30, LS_CNN, Epoch 4/50, Loss: 0.34263556769915987 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3467584066092968\n",
      "SNR: 15/30, LS_CNN, Epoch 5/50, Loss: 0.32615057059696745 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.33041292428970337\n",
      "SNR: 15/30, LS_CNN, Epoch 6/50, Loss: 0.31081521085330416 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.31525585427880287\n",
      "SNR: 15/30, LS_CNN, Epoch 7/50, Loss: 0.29470449686050415 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.30035550333559513\n",
      "SNR: 15/30, LS_CNN, Epoch 8/50, Loss: 0.2864215067986931 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29040287993848324\n",
      "SNR: 15/30, LS_CNN, Epoch 9/50, Loss: 0.27356275809662683 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.27860758639872074\n",
      "SNR: 15/30, LS_CNN, Epoch 10/50, Loss: 0.26499650361282484 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2670441847294569\n",
      "SNR: 15/30, LS_CNN, Epoch 11/50, Loss: 0.25674483818667276 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25369932502508163\n",
      "SNR: 15/30, LS_CNN, Epoch 12/50, Loss: 0.2505990567484072 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24603072926402092\n",
      "SNR: 15/30, LS_CNN, Epoch 13/50, Loss: 0.24575428611465863 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23611794970929623\n",
      "SNR: 15/30, LS_CNN, Epoch 14/50, Loss: 0.23706005726541793 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23155917786061764\n",
      "SNR: 15/30, LS_CNN, Epoch 15/50, Loss: 0.2298076232629163 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22067473828792572\n",
      "SNR: 15/30, LS_CNN, Epoch 16/50, Loss: 0.22691997406738146 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22269942238926888\n",
      "SNR: 15/30, LS_CNN, Epoch 17/50, Loss: 0.22526198998093605 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2063609268516302\n",
      "SNR: 15/30, LS_CNN, Epoch 18/50, Loss: 0.2114992237516812 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20045175775885582\n",
      "SNR: 15/30, LS_CNN, Epoch 19/50, Loss: 0.22319550759025983 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19700688682496548\n",
      "SNR: 15/30, LS_CNN, Epoch 20/50, Loss: 0.20752139868480818 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19119154661893845\n",
      "SNR: 15/30, LS_CNN, Epoch 21/50, Loss: 0.20119300484657288 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18394128512591124\n",
      "SNR: 15/30, LS_CNN, Epoch 22/50, Loss: 0.2028129654271262 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18435889948159456\n",
      "SNR: 15/30, LS_CNN, Epoch 23/50, Loss: 0.20861728436180524 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18047897797077894\n",
      "SNR: 15/30, LS_CNN, Epoch 24/50, Loss: 0.21064458388303006 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.17589650955051184\n",
      "SNR: 15/30, LS_CNN, Epoch 25/50, Loss: 0.2043593946312155 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1772423405200243\n",
      "SNR: 15/30, LS_CNN, Epoch 26/50, Loss: 0.2016082967498473 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.17334613762795925\n",
      "SNR: 15/30, LS_CNN, Epoch 27/50, Loss: 0.19802342780998775 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.17412796895951033\n",
      "SNR: 15/30, LS_CNN, Epoch 28/50, Loss: 0.192385394392269 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.17104041576385498\n",
      "SNR: 15/30, LS_CNN, Epoch 29/50, Loss: 0.19167558316673552 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1662983074784279\n",
      "SNR: 15/30, LS_CNN, Epoch 30/50, Loss: 0.20975474906819208 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.17012115754187107\n",
      "SNR: 15/30, LS_CNN, Epoch 31/50, Loss: 0.18813790793397597 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16380911599844694\n",
      "SNR: 15/30, LS_CNN, Epoch 32/50, Loss: 0.1969510064061199 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1637599803507328\n",
      "SNR: 15/30, LS_CNN, Epoch 33/50, Loss: 0.1998274362246905 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16473684553056955\n",
      "SNR: 15/30, LS_CNN, Epoch 34/50, Loss: 0.18713597487658262 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.161053704097867\n",
      "SNR: 15/30, LS_CNN, Epoch 35/50, Loss: 0.19852754500295436 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16139303613454103\n",
      "SNR: 15/30, LS_CNN, Epoch 36/50, Loss: 0.1953681990770357 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16056290548294783\n",
      "SNR: 15/30, LS_CNN, Epoch 37/50, Loss: 0.19631800773952687 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16382756922394037\n",
      "SNR: 15/30, LS_CNN, Epoch 38/50, Loss: 0.19937486201524734 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16290294472128153\n",
      "SNR: 15/30, LS_CNN, Epoch 39/50, Loss: 0.190785481727549 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16546559613198042\n",
      "SNR: 15/30, LS_CNN, Epoch 40/50, Loss: 0.20701613037713937 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1617681160569191\n",
      "SNR: 15/30, LS_CNN, Epoch 41/50, Loss: 0.19838884898594447 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16175783891230822\n",
      "SNR: 15/30, LS_CNN, Epoch 42/50, Loss: 0.1924831180700234 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1609829431399703\n",
      "SNR: 15/30, LS_CNN, Epoch 43/50, Loss: 0.20033504627645016 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1618002513423562\n",
      "SNR: 15/30, LS_CNN, Epoch 44/50, Loss: 0.19487272721848317 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.15986355300992727\n",
      "SNR: 15/30, LS_CNN, Epoch 45/50, Loss: 0.19162047627781117 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.15996538009494543\n",
      "SNR: 15/30, LS_CNN, Epoch 46/50, Loss: 0.19813611997025354 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.15943642612546682\n",
      "SNR: 15/30, LS_CNN, Epoch 47/50, Loss: 0.19522290317607777 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.16079134307801723\n",
      "SNR: 15/30, LS_CNN, Epoch 48/50, Loss: 0.18762589166206972 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1594351315870881\n",
      "SNR: 15/30, LS_CNN, Epoch 49/50, Loss: 0.19348108688635485 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.15947616565972567\n",
      "SNR: 15/30, LS_CNN, Epoch 50/50, Loss: 0.20713967816638096 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.15927171986550093\n",
      "LS+CNN NMSE: 0.025207938626408577\n",
      "LS+LI NMSE: 0.0025704121217131615\n",
      "LS_LI_CNN model\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3698629694325583 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.36583319678902626\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3377016080277307 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.32789771631360054\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 3/50, Loss: 0.29590095207095146 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.27956385165452957\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 4/50, Loss: 0.24519249956522668 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2260982133448124\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 5/50, Loss: 0.19192624198538916 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.17056156136095524\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 6/50, Loss: 0.1443363775366119 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.12802490312606096\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 7/50, Loss: 0.10752166488340922 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.09309180546551943\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 8/50, Loss: 0.08318146697378584 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07308644847944379\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 9/50, Loss: 0.0693494024287377 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0639790277928114\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 10/50, Loss: 0.06221209453152759 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057582154870033264\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 11/50, Loss: 0.05879639627944146 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05527818761765957\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 12/50, Loss: 0.05785872165246734 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05388442100957036\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 13/50, Loss: 0.05715929374231824 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05330883525311947\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 14/50, Loss: 0.057055970620630045 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.053484184201806784\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 15/50, Loss: 0.057173402913446934 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.052962653106078506\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 16/50, Loss: 0.056735279936609526 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05281667085364461\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 17/50, Loss: 0.0568405528153692 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05266250856220722\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 18/50, Loss: 0.056848495067762475 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0525583871640265\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 19/50, Loss: 0.05655546386593154 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05249257246032357\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 20/50, Loss: 0.056438773637637496 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05271751177497208\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 21/50, Loss: 0.05641314646761332 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05239256634376943\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 22/50, Loss: 0.05663426985431995 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05225256271660328\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 23/50, Loss: 0.05637079617008567 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05263858754187822\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 24/50, Loss: 0.056115757540932724 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05208365502767265\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 25/50, Loss: 0.05617759523114988 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05211363662965596\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 26/50, Loss: 0.056125040764787366 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05198688665404916\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 27/50, Loss: 0.05588024971075356 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05190007807686925\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 28/50, Loss: 0.056101757899991105 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.052191473077982664\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 29/50, Loss: 0.05594118761031756 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.051761530339717865\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 30/50, Loss: 0.05567429697008005 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05161264119669795\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 31/50, Loss: 0.05580741789058915 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05155583587475121\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 32/50, Loss: 0.05579030347455825 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05159182706847787\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 33/50, Loss: 0.05547017890161702 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.051510659512132406\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 34/50, Loss: 0.05552248463832906 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05160048417747021\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 35/50, Loss: 0.05547950074209699 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05134258442558348\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 36/50, Loss: 0.05593247023145003 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.051504682982340455\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 37/50, Loss: 0.055320848211912174 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.051202530739828944\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 38/50, Loss: 0.05525452171319297 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05133917438797653\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 39/50, Loss: 0.05577862921303937 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.051208255579695106\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 40/50, Loss: 0.05533413598979158 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05103837721981108\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 41/50, Loss: 0.05501290447344737 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05116075347177684\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 42/50, Loss: 0.05512854603252241 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05098970723338425\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 43/50, Loss: 0.05521245387249759 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05091453390195966\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 44/50, Loss: 0.05485601344012788 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05107237305492163\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 45/50, Loss: 0.055065000629318614 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05106483050622046\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 46/50, Loss: 0.05522907292470336 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05062048207037151\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 47/50, Loss: 0.055214472813531756 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.050692447228357196\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 48/50, Loss: 0.054795356666935344 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.050829478772357106\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 49/50, Loss: 0.05421689425462058 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05055504199117422\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 50/50, Loss: 0.05483101085493607 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.050506574334576726\n",
      "LS+CNN NMSE: 0.005383447743952274\n",
      " SNR: 20/30\n",
      "LS_CNN model\n",
      "SNR: 20/30, LS_CNN, Epoch 1/50, Loss: 0.39710418401019915 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.39658523723483086\n",
      "SNR: 20/30, LS_CNN, Epoch 2/50, Loss: 0.39130175166896414 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.39011139795184135\n",
      "SNR: 20/30, LS_CNN, Epoch 3/50, Loss: 0.38410114656601635 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.38184696808457375\n",
      "SNR: 20/30, LS_CNN, Epoch 4/50, Loss: 0.3747704119554588 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3714706338942051\n",
      "SNR: 20/30, LS_CNN, Epoch 5/50, Loss: 0.3636179986808981 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.35899174585938454\n",
      "SNR: 20/30, LS_CNN, Epoch 6/50, Loss: 0.35075930239898817 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.34543778374791145\n",
      "SNR: 20/30, LS_CNN, Epoch 7/50, Loss: 0.33950702260647503 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3332015685737133\n",
      "SNR: 20/30, LS_CNN, Epoch 8/50, Loss: 0.3285484431045396 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3254047706723213\n",
      "SNR: 20/30, LS_CNN, Epoch 9/50, Loss: 0.3198444837970393 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.31151267513632774\n",
      "SNR: 20/30, LS_CNN, Epoch 10/50, Loss: 0.31214003291513237 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.29690310545265675\n",
      "SNR: 20/30, LS_CNN, Epoch 11/50, Loss: 0.3051559565854924 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2907912917435169\n",
      "SNR: 20/30, LS_CNN, Epoch 12/50, Loss: 0.29695732119892326 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2904162388294935\n",
      "SNR: 20/30, LS_CNN, Epoch 13/50, Loss: 0.2915333871330534 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2817185316234827\n",
      "SNR: 20/30, LS_CNN, Epoch 14/50, Loss: 0.2822008345808302 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.272103626281023\n",
      "SNR: 20/30, LS_CNN, Epoch 15/50, Loss: 0.277313300541469 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2669086903333664\n",
      "SNR: 20/30, LS_CNN, Epoch 16/50, Loss: 0.27151291338460787 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2597505636513233\n",
      "SNR: 20/30, LS_CNN, Epoch 17/50, Loss: 0.26565096128199783 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24697552435100079\n",
      "SNR: 20/30, LS_CNN, Epoch 18/50, Loss: 0.2597634220229728 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25340603291988373\n",
      "SNR: 20/30, LS_CNN, Epoch 19/50, Loss: 0.2558236675603049 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2420475333929062\n",
      "SNR: 20/30, LS_CNN, Epoch 20/50, Loss: 0.2555647622793913 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24886663630604744\n",
      "SNR: 20/30, LS_CNN, Epoch 21/50, Loss: 0.24797753430902958 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22864700481295586\n",
      "SNR: 20/30, LS_CNN, Epoch 22/50, Loss: 0.2405250615307263 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2225488256663084\n",
      "SNR: 20/30, LS_CNN, Epoch 23/50, Loss: 0.23397389905793325 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21812839806079865\n",
      "SNR: 20/30, LS_CNN, Epoch 24/50, Loss: 0.2273410356470517 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21326216496527195\n",
      "SNR: 20/30, LS_CNN, Epoch 25/50, Loss: 0.22451529279351234 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20721879228949547\n",
      "SNR: 20/30, LS_CNN, Epoch 26/50, Loss: 0.22524920584900038 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2002609372138977\n",
      "SNR: 20/30, LS_CNN, Epoch 27/50, Loss: 0.2244298213294574 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19848880171775818\n",
      "SNR: 20/30, LS_CNN, Epoch 28/50, Loss: 0.22143432231886045 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19585187174379826\n",
      "SNR: 20/30, LS_CNN, Epoch 29/50, Loss: 0.2134421675332955 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19175195787101984\n",
      "SNR: 20/30, LS_CNN, Epoch 30/50, Loss: 0.2224273524646248 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19114589784294367\n",
      "SNR: 20/30, LS_CNN, Epoch 31/50, Loss: 0.21027409684445178 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1878070207312703\n",
      "SNR: 20/30, LS_CNN, Epoch 32/50, Loss: 0.20366171614399978 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18323263805359602\n",
      "SNR: 20/30, LS_CNN, Epoch 33/50, Loss: 0.21203173750213214 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18475309666246176\n",
      "SNR: 20/30, LS_CNN, Epoch 34/50, Loss: 0.19787469053907053 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17855542432516813\n",
      "SNR: 20/30, LS_CNN, Epoch 35/50, Loss: 0.20803082840783255 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1774446852505207\n",
      "SNR: 20/30, LS_CNN, Epoch 36/50, Loss: 0.2041231667889016 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1766324257478118\n",
      "SNR: 20/30, LS_CNN, Epoch 37/50, Loss: 0.21186423408133642 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17689302284270525\n",
      "SNR: 20/30, LS_CNN, Epoch 38/50, Loss: 0.19792004328753268 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17391255218535662\n",
      "SNR: 20/30, LS_CNN, Epoch 39/50, Loss: 0.2111885960080794 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1744486102834344\n",
      "SNR: 20/30, LS_CNN, Epoch 40/50, Loss: 0.2035814912191459 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17418034002184868\n",
      "SNR: 20/30, LS_CNN, Epoch 41/50, Loss: 0.19453759092305387 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17158036772161722\n",
      "SNR: 20/30, LS_CNN, Epoch 42/50, Loss: 0.19001352707190172 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16950518544763327\n",
      "SNR: 20/30, LS_CNN, Epoch 43/50, Loss: 0.19873241654464177 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.172632260248065\n",
      "SNR: 20/30, LS_CNN, Epoch 44/50, Loss: 0.19946235258664405 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16810965444892645\n",
      "SNR: 20/30, LS_CNN, Epoch 45/50, Loss: 0.2019128320472581 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16782574448734522\n",
      "SNR: 20/30, LS_CNN, Epoch 46/50, Loss: 0.19775870934660947 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16753577627241611\n",
      "SNR: 20/30, LS_CNN, Epoch 47/50, Loss: 0.18813447268413647 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16698376089334488\n",
      "SNR: 20/30, LS_CNN, Epoch 48/50, Loss: 0.20415849225329502 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16593674942851067\n",
      "SNR: 20/30, LS_CNN, Epoch 49/50, Loss: 0.20053078846207686 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17181235365569592\n",
      "SNR: 20/30, LS_CNN, Epoch 50/50, Loss: 0.20216508489102125 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1661094706505537\n",
      "LS+CNN NMSE: 0.025769971311092377\n",
      "LS+LI NMSE: 0.0008134252857416868\n",
      "LS_LI_CNN model\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 1/50, Loss: 0.38133047255022184 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.35706550627946854\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3205155943121229 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.295627661049366\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 3/50, Loss: 0.2559699112815516 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.22874045744538307\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 4/50, Loss: 0.19045446600232804 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1678893342614174\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 5/50, Loss: 0.13192853850445577 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.11550230626016855\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 6/50, Loss: 0.08783300194357123 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.08152924804016948\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 7/50, Loss: 0.06031043761010681 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06080330861732364\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 8/50, Loss: 0.04614671113501702 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05384762492030859\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 9/50, Loss: 0.03985603905415961 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04814515425823629\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 10/50, Loss: 0.0377766668264355 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04718964756466448\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 11/50, Loss: 0.036537456359448175 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0475506610237062\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 12/50, Loss: 0.03623653386187341 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04584230110049248\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 13/50, Loss: 0.03599064630855407 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0460514547303319\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 14/50, Loss: 0.03567396105998861 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.045574838761240244\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 15/50, Loss: 0.035179275553673506 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.045206986367702484\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 16/50, Loss: 0.0349073134961405 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.045153222512453794\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 17/50, Loss: 0.03479196926179741 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04462579824030399\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 18/50, Loss: 0.03461891076793628 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.044698814395815134\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 19/50, Loss: 0.0344139550080789 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04404273210093379\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 20/50, Loss: 0.03411114284036947 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.044201410142704844\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 21/50, Loss: 0.03402372858753162 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04421894554980099\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 22/50, Loss: 0.03367524584090071 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.043612009612843394\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 23/50, Loss: 0.03360124446252095 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.043488837545737624\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 24/50, Loss: 0.033505284876030474 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.043396844528615475\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 25/50, Loss: 0.033516811223567596 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04334820155054331\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 26/50, Loss: 0.03317824912457062 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04310366907157004\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 27/50, Loss: 0.03303830308972725 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04304284090176225\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 28/50, Loss: 0.03312641884466367 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04293719120323658\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 29/50, Loss: 0.03294383463383253 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04293926409445703\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 30/50, Loss: 0.03281488367688975 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04289023787714541\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 31/50, Loss: 0.03291585815272161 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04272443545050919\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 32/50, Loss: 0.032821758716766326 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04272884479723871\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 33/50, Loss: 0.03258098414101239 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04255859274417162\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 34/50, Loss: 0.032405847417456765 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.042476134141907096\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 35/50, Loss: 0.03234512749726751 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04242313397116959\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 36/50, Loss: 0.03246536756133927 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04235106473788619\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 37/50, Loss: 0.03246181516442448 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04225346399471164\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 38/50, Loss: 0.03263401128684303 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04226911976002157\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 39/50, Loss: 0.03208112736631717 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04221175145357847\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 40/50, Loss: 0.0323534006518977 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.042116090189665556\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 41/50, Loss: 0.03206391524456974 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.042050864547491074\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 42/50, Loss: 0.03227529545048518 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04204314132221043\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 43/50, Loss: 0.03225338937980788 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04214541963301599\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 44/50, Loss: 0.03192689795313137 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.041874001268297434\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 45/50, Loss: 0.03198875831107476 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04184976452961564\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 46/50, Loss: 0.03215554649276393 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04180938727222383\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 47/50, Loss: 0.032056737025933604 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04175173933617771\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 48/50, Loss: 0.032106068301280696 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.041745945112779737\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 49/50, Loss: 0.03212956334131637 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04175295680761337\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 50/50, Loss: 0.031998443650081754 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.041620036121457815\n",
      "LS+CNN NMSE: 0.0027965805493295193\n",
      " SNR: 25/30\n",
      "LS_CNN model\n",
      "SNR: 25/30, LS_CNN, Epoch 1/50, Loss: 0.3937517250222819 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.4005473367869854\n",
      "SNR: 25/30, LS_CNN, Epoch 2/50, Loss: 0.38013619290930883 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3871268555521965\n",
      "SNR: 25/30, LS_CNN, Epoch 3/50, Loss: 0.3655762906585421 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.37270721793174744\n",
      "SNR: 25/30, LS_CNN, Epoch 4/50, Loss: 0.3508040245090212 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3588787317276001\n",
      "SNR: 25/30, LS_CNN, Epoch 5/50, Loss: 0.336231458399977 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3452562838792801\n",
      "SNR: 25/30, LS_CNN, Epoch 6/50, Loss: 0.3235728655542646 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3318013846874237\n",
      "SNR: 25/30, LS_CNN, Epoch 7/50, Loss: 0.31379771871226175 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3161848559975624\n",
      "SNR: 25/30, LS_CNN, Epoch 8/50, Loss: 0.30059422286493437 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.30412333831191063\n",
      "SNR: 25/30, LS_CNN, Epoch 9/50, Loss: 0.28920672674264225 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28984441608190536\n",
      "SNR: 25/30, LS_CNN, Epoch 10/50, Loss: 0.28296917650316444 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28365209326148033\n",
      "SNR: 25/30, LS_CNN, Epoch 11/50, Loss: 0.2740833338882242 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.27125867642462254\n",
      "SNR: 25/30, LS_CNN, Epoch 12/50, Loss: 0.26160503923892975 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2637984938919544\n",
      "SNR: 25/30, LS_CNN, Epoch 13/50, Loss: 0.2536333719534533 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2479712050408125\n",
      "SNR: 25/30, LS_CNN, Epoch 14/50, Loss: 0.24951470457017422 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24466828629374504\n",
      "SNR: 25/30, LS_CNN, Epoch 15/50, Loss: 0.23467119623507773 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23258494213223457\n",
      "SNR: 25/30, LS_CNN, Epoch 16/50, Loss: 0.2356338453079973 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2310612816363573\n",
      "SNR: 25/30, LS_CNN, Epoch 17/50, Loss: 0.2329148884330477 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2263229638338089\n",
      "SNR: 25/30, LS_CNN, Epoch 18/50, Loss: 0.22180413507989474 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.21898492611944675\n",
      "SNR: 25/30, LS_CNN, Epoch 19/50, Loss: 0.21891398940767562 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2122887745499611\n",
      "SNR: 25/30, LS_CNN, Epoch 20/50, Loss: 0.21802327728697232 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2085256539285183\n",
      "SNR: 25/30, LS_CNN, Epoch 21/50, Loss: 0.21528444306126662 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.205400126054883\n",
      "SNR: 25/30, LS_CNN, Epoch 22/50, Loss: 0.20891941817743437 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2059410735964775\n",
      "SNR: 25/30, LS_CNN, Epoch 23/50, Loss: 0.20594204403460026 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1998679917305708\n",
      "SNR: 25/30, LS_CNN, Epoch 24/50, Loss: 0.2192787794130189 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1996846366673708\n",
      "SNR: 25/30, LS_CNN, Epoch 25/50, Loss: 0.21840503253042698 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19933769665658474\n",
      "SNR: 25/30, LS_CNN, Epoch 26/50, Loss: 0.20697836843984468 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1970809530466795\n",
      "SNR: 25/30, LS_CNN, Epoch 27/50, Loss: 0.2047757940100772 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19349995627999306\n",
      "SNR: 25/30, LS_CNN, Epoch 28/50, Loss: 0.2103468935404505 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19283320382237434\n",
      "SNR: 25/30, LS_CNN, Epoch 29/50, Loss: 0.20433185329394682 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19449002481997013\n",
      "SNR: 25/30, LS_CNN, Epoch 30/50, Loss: 0.20462278250072682 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1917015127837658\n",
      "SNR: 25/30, LS_CNN, Epoch 31/50, Loss: 0.20768038822071894 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19151613116264343\n",
      "SNR: 25/30, LS_CNN, Epoch 32/50, Loss: 0.20391930852617537 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1896192841231823\n",
      "SNR: 25/30, LS_CNN, Epoch 33/50, Loss: 0.1964239478111267 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1894284039735794\n",
      "SNR: 25/30, LS_CNN, Epoch 34/50, Loss: 0.20102438357259547 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18762205727398396\n",
      "SNR: 25/30, LS_CNN, Epoch 35/50, Loss: 0.21191411279141903 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18944748491048813\n",
      "SNR: 25/30, LS_CNN, Epoch 36/50, Loss: 0.20223653822072915 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18882170133292675\n",
      "SNR: 25/30, LS_CNN, Epoch 37/50, Loss: 0.194363304280809 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18489726353436708\n",
      "SNR: 25/30, LS_CNN, Epoch 38/50, Loss: 0.19502013336334909 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18502793088555336\n",
      "SNR: 25/30, LS_CNN, Epoch 39/50, Loss: 0.21294105798006058 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1876691384240985\n",
      "SNR: 25/30, LS_CNN, Epoch 40/50, Loss: 0.19912574307194778 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18594647385179996\n",
      "SNR: 25/30, LS_CNN, Epoch 41/50, Loss: 0.2038780501378434 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18601729720830917\n",
      "SNR: 25/30, LS_CNN, Epoch 42/50, Loss: 0.19472977040069445 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1837473912164569\n",
      "SNR: 25/30, LS_CNN, Epoch 43/50, Loss: 0.19405001774430275 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18339166045188904\n",
      "SNR: 25/30, LS_CNN, Epoch 44/50, Loss: 0.20908565100814616 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18631668761372566\n",
      "SNR: 25/30, LS_CNN, Epoch 45/50, Loss: 0.1972462816962174 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18505792878568172\n",
      "SNR: 25/30, LS_CNN, Epoch 46/50, Loss: 0.20222597010433674 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18500026315450668\n",
      "SNR: 25/30, LS_CNN, Epoch 47/50, Loss: 0.20319589067782676 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18328680749982595\n",
      "SNR: 25/30, LS_CNN, Epoch 48/50, Loss: 0.2031871961163623 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1839573523029685\n",
      "SNR: 25/30, LS_CNN, Epoch 49/50, Loss: 0.20804725427712714 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18484829738736153\n",
      "SNR: 25/30, LS_CNN, Epoch 50/50, Loss: 0.1965368648192712 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18415810447186232\n",
      "LS+CNN NMSE: 0.02613881416618824\n",
      "LS+LI NMSE: 0.0002627856738399714\n",
      "LS_LI_CNN model\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 1/50, Loss: 0.4083055188613279 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3987674042582512\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 2/50, Loss: 0.36109527147242 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.35077840089797974\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 3/50, Loss: 0.31006034091115 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.29799172654747963\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 4/50, Loss: 0.2547679924006973 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.24125690758228302\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 5/50, Loss: 0.19804045504757337 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.1855468787252903\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 6/50, Loss: 0.1457709970750979 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.13628824707120657\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 7/50, Loss: 0.10341767594218254 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.10055822599679232\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 8/50, Loss: 0.07311083383059927 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.076742525678128\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 9/50, Loss: 0.05409742778699313 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.06094495300203562\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 10/50, Loss: 0.04354393093048462 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0523396385833621\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 11/50, Loss: 0.037939643287765126 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.047318649012595415\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 12/50, Loss: 0.035074536821671894 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04365766770206392\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 13/50, Loss: 0.03343802800268999 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04499840713106096\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 14/50, Loss: 0.03253589023370296 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04443038580939174\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 15/50, Loss: 0.031578046352868636 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.041816615499556065\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 16/50, Loss: 0.031210446247964034 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04228628659620881\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 17/50, Loss: 0.030216458569546894 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.039955614833161235\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 18/50, Loss: 0.029749490121113404 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03919499064795673\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 19/50, Loss: 0.029176634420374676 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03911727317608893\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 20/50, Loss: 0.028380671998352876 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03748581581749022\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 21/50, Loss: 0.02795084471082581 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.038334516109898686\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 22/50, Loss: 0.02744726637112243 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0370690927375108\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 23/50, Loss: 0.026869308602597033 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03627480147406459\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 24/50, Loss: 0.02652352356484958 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03588125645183027\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 25/50, Loss: 0.02610306685424543 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03526468714699149\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 26/50, Loss: 0.025672861890468215 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03446611715480685\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 27/50, Loss: 0.025269183346868625 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03498661518096924\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 28/50, Loss: 0.02496549618496959 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.033347869059070945\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 29/50, Loss: 0.024491303833201528 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0341017572209239\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 30/50, Loss: 0.024215339350381067 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.033068505581468344\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 31/50, Loss: 0.024055115562597557 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03287350502796471\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 32/50, Loss: 0.02367543156391808 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03271362348459661\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 33/50, Loss: 0.02338876141168709 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03256723191589117\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 34/50, Loss: 0.023168413417546878 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.031546878861263394\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 35/50, Loss: 0.023098044280361916 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03165925247594714\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 36/50, Loss: 0.022786934727004597 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03118112008087337\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 37/50, Loss: 0.022604224355226115 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.031135477358475327\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 38/50, Loss: 0.022374084568582475 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03159062401391566\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 39/50, Loss: 0.02223673023815666 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03096294146962464\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 40/50, Loss: 0.022096144534381374 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030133909545838833\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 41/50, Loss: 0.02202809919669692 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030368970008566976\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 42/50, Loss: 0.02206268163198339 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030487563693895936\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 43/50, Loss: 0.021722666470200887 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030128116253763437\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 44/50, Loss: 0.021523834987809614 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030256718629971147\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 45/50, Loss: 0.021240460204093585 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029794754227623343\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 46/50, Loss: 0.021395123422345414 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029908089200034738\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 47/50, Loss: 0.021196087240241468 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029384839348495007\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 48/50, Loss: 0.021095738679702793 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029650264186784625\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 49/50, Loss: 0.021322302079559968 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029128543566912413\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 50/50, Loss: 0.020930193888489157 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029372918885201216\n",
      "LS+CNN NMSE: 0.0016428364906460047\n",
      " SNR: 30/30\n",
      "LS_CNN model\n",
      "SNR: 30/30, LS_CNN, Epoch 1/50, Loss: 0.3893124594220093 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.38831914216279984\n",
      "SNR: 30/30, LS_CNN, Epoch 2/50, Loss: 0.3779291350926672 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3753690719604492\n",
      "SNR: 30/30, LS_CNN, Epoch 3/50, Loss: 0.3667371688144548 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.36299828812479973\n",
      "SNR: 30/30, LS_CNN, Epoch 4/50, Loss: 0.35599948306168827 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3510066345334053\n",
      "SNR: 30/30, LS_CNN, Epoch 5/50, Loss: 0.34597728454640936 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.34105151519179344\n",
      "SNR: 30/30, LS_CNN, Epoch 6/50, Loss: 0.3376988113990852 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32997923716902733\n",
      "SNR: 30/30, LS_CNN, Epoch 7/50, Loss: 0.32782783465726034 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3222612924873829\n",
      "SNR: 30/30, LS_CNN, Epoch 8/50, Loss: 0.31923542437808855 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3103145770728588\n",
      "SNR: 30/30, LS_CNN, Epoch 9/50, Loss: 0.31015834638050627 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3025808371603489\n",
      "SNR: 30/30, LS_CNN, Epoch 10/50, Loss: 0.3031346042241369 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2906972039490938\n",
      "SNR: 30/30, LS_CNN, Epoch 11/50, Loss: 0.2933461626193353 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.28119688853621483\n",
      "SNR: 30/30, LS_CNN, Epoch 12/50, Loss: 0.28262788749166895 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2736632917076349\n",
      "SNR: 30/30, LS_CNN, Epoch 13/50, Loss: 0.2777231106800692 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26038913056254387\n",
      "SNR: 30/30, LS_CNN, Epoch 14/50, Loss: 0.2688450858529125 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2519385851919651\n",
      "SNR: 30/30, LS_CNN, Epoch 15/50, Loss: 0.2560194291706596 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2431080210953951\n",
      "SNR: 30/30, LS_CNN, Epoch 16/50, Loss: 0.25267721712589264 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2301597110927105\n",
      "SNR: 30/30, LS_CNN, Epoch 17/50, Loss: 0.24386036662118776 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.22396418824791908\n",
      "SNR: 30/30, LS_CNN, Epoch 18/50, Loss: 0.23641167740736688 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.21469487808644772\n",
      "SNR: 30/30, LS_CNN, Epoch 19/50, Loss: 0.23974724220378058 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2099070157855749\n",
      "SNR: 30/30, LS_CNN, Epoch 20/50, Loss: 0.22666127580617154 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2007383517920971\n",
      "SNR: 30/30, LS_CNN, Epoch 21/50, Loss: 0.2240918864096914 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1967404205352068\n",
      "SNR: 30/30, LS_CNN, Epoch 22/50, Loss: 0.22727320343255997 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1936880312860012\n",
      "SNR: 30/30, LS_CNN, Epoch 23/50, Loss: 0.2135355437972716 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.18791459035128355\n",
      "SNR: 30/30, LS_CNN, Epoch 24/50, Loss: 0.21532812900841236 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.18336660135537386\n",
      "SNR: 30/30, LS_CNN, Epoch 25/50, Loss: 0.21822927838989667 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1825652765110135\n",
      "SNR: 30/30, LS_CNN, Epoch 26/50, Loss: 0.21457725656884058 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.18001830112189054\n",
      "SNR: 30/30, LS_CNN, Epoch 27/50, Loss: 0.2015353153858866 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17581707518547773\n",
      "SNR: 30/30, LS_CNN, Epoch 28/50, Loss: 0.20416515293930257 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17014287691563368\n",
      "SNR: 30/30, LS_CNN, Epoch 29/50, Loss: 0.21109652652272157 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17394280433654785\n",
      "SNR: 30/30, LS_CNN, Epoch 30/50, Loss: 0.20504198409616947 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16828439477831125\n",
      "SNR: 30/30, LS_CNN, Epoch 31/50, Loss: 0.2050785826785224 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1681426577270031\n",
      "SNR: 30/30, LS_CNN, Epoch 32/50, Loss: 0.20974753318088396 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17030285019427538\n",
      "SNR: 30/30, LS_CNN, Epoch 33/50, Loss: 0.19782226319823945 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1664505610242486\n",
      "SNR: 30/30, LS_CNN, Epoch 34/50, Loss: 0.19714469648897648 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16267322190105915\n",
      "SNR: 30/30, LS_CNN, Epoch 35/50, Loss: 0.20088651829532214 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1619550073519349\n",
      "SNR: 30/30, LS_CNN, Epoch 36/50, Loss: 0.2070502359420061 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1643850551918149\n",
      "SNR: 30/30, LS_CNN, Epoch 37/50, Loss: 0.19604961201548576 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16373656503856182\n",
      "SNR: 30/30, LS_CNN, Epoch 38/50, Loss: 0.1979812698970948 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15949163865298033\n",
      "SNR: 30/30, LS_CNN, Epoch 39/50, Loss: 0.209219152373927 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16460385359823704\n",
      "SNR: 30/30, LS_CNN, Epoch 40/50, Loss: 0.2044826869719795 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16659595724195242\n",
      "SNR: 30/30, LS_CNN, Epoch 41/50, Loss: 0.19503825423972948 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15801895316690207\n",
      "SNR: 30/30, LS_CNN, Epoch 42/50, Loss: 0.19882038501756533 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16081351228058338\n",
      "SNR: 30/30, LS_CNN, Epoch 43/50, Loss: 0.19609340732651098 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16107358038425446\n",
      "SNR: 30/30, LS_CNN, Epoch 44/50, Loss: 0.2070594664130892 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15996721014380455\n",
      "SNR: 30/30, LS_CNN, Epoch 45/50, Loss: 0.19354809993611916 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16140545159578323\n",
      "SNR: 30/30, LS_CNN, Epoch 46/50, Loss: 0.18759634851344995 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15580917801707983\n",
      "SNR: 30/30, LS_CNN, Epoch 47/50, Loss: 0.19939829036593437 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15646894369274378\n",
      "SNR: 30/30, LS_CNN, Epoch 48/50, Loss: 0.2041245231937085 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16079055704176426\n",
      "SNR: 30/30, LS_CNN, Epoch 49/50, Loss: 0.20097610806780203 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16388050094246864\n",
      "SNR: 30/30, LS_CNN, Epoch 50/50, Loss: 0.1938570554235152 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.15889042988419533\n",
      "LS+CNN NMSE: 0.03077622875571251\n",
      "LS+LI NMSE: 8.526214514859021e-05\n",
      "LS_LI_CNN model\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37607938636626514 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.35756903141736984\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3284358674926417 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3052849806845188\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 3/50, Loss: 0.2734175329761846 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.2454851046204567\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 4/50, Loss: 0.21378715096839837 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.18596188351511955\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 5/50, Loss: 0.15581076658729995 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.13046268559992313\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 6/50, Loss: 0.10618757070707423 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.08604084327816963\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 7/50, Loss: 0.06874010671994515 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.05469840671867132\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 8/50, Loss: 0.044168665572734814 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03498418931849301\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 9/50, Loss: 0.03003017933640097 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0242630357388407\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 10/50, Loss: 0.023035530067448105 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.020237171673215926\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 11/50, Loss: 0.01963044686375984 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017382528982125223\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 12/50, Loss: 0.018131794665740535 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01647334755398333\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 13/50, Loss: 0.0175830417429097 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016083838767372072\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 14/50, Loss: 0.017426799725009396 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015636693919077516\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 15/50, Loss: 0.017219863640743176 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015759442816488445\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 16/50, Loss: 0.017097344680223614 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015380687895230949\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 17/50, Loss: 0.0168438142697726 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01507525669876486\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 18/50, Loss: 0.016676017091543014 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015120977885089815\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 19/50, Loss: 0.01662452590452241 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014925192692317069\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 20/50, Loss: 0.016334554945517863 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01485703163780272\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 21/50, Loss: 0.01631366849012141 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014779060846194625\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 22/50, Loss: 0.016374214901588857 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014772429247386754\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 23/50, Loss: 0.016179014354877706 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014619145775213838\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 24/50, Loss: 0.01607627356757543 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014579883427359164\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 25/50, Loss: 0.016008939843491783 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014516315190121531\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 26/50, Loss: 0.01573872922121414 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014409326366148889\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 27/50, Loss: 0.015653273074089417 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014332111459225416\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 28/50, Loss: 0.015701751665411785 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014236174407415092\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 29/50, Loss: 0.015619821114731687 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014239226933568716\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 30/50, Loss: 0.01560578792123124 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01410262892022729\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 31/50, Loss: 0.01524188436867137 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014047506963834167\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 32/50, Loss: 0.015195252057830138 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013921700767241418\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 33/50, Loss: 0.015053902777643608 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013914771028794348\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 34/50, Loss: 0.015253187780867197 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013809834781568497\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 35/50, Loss: 0.01497540173087535 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013790136494208127\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 36/50, Loss: 0.01516908113678385 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013734378619119525\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 37/50, Loss: 0.014993049013095774 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013585867069195956\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 38/50, Loss: 0.014701864174899779 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013532028358895332\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 39/50, Loss: 0.015107600217951196 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01351855107350275\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 40/50, Loss: 0.014810611651877739 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013354969443753362\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 41/50, Loss: 0.01456119611559968 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013497712614480406\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 42/50, Loss: 0.014515191366496896 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013279673119541258\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 43/50, Loss: 0.014617838081903756 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013215528626460582\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 44/50, Loss: 0.014472227003092744 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013456903980113566\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 45/50, Loss: 0.014438189017320318 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013169598125386983\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 46/50, Loss: 0.014250422528545772 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01294068933930248\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 47/50, Loss: 0.014094824703144175 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.012963369197677821\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 48/50, Loss: 0.014170725904737733 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.012904288654681295\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 49/50, Loss: 0.014130171604587563 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.012776212417520583\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 50/50, Loss: 0.01398383517101008 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.012804956699255854\n",
      "LS+CNN NMSE: 0.0012954847188666463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "learning_rate = 1e-5 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    # load target dataset\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_map_data(target_data_dir, device, snr)\n",
    "            \n",
    "    # training at target set\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        \n",
    "        if model_name == 'LS_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "        \n",
    "        # source model\n",
    "        model_source = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model_fineTune = utils_transfer.FineTuneModel2(model_source).to(device)\n",
    "        optimizer = torch.optim.Adam(model_fineTune.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_loss =[]\n",
    "        val_loss = []\n",
    "        H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "        min_H_true = []\n",
    "        max_H_true = []\n",
    "        num_epochs = NUM_EPOCHS\n",
    "        for epoch in range(num_epochs):\n",
    "            model_fineTune.train()\n",
    "            running_loss = 0.0\n",
    "            if (epoch == num_epochs-1):\n",
    "                i = 0\n",
    "            for inputs, targets, targets_min, targets_max in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fineTune(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "            \n",
    "            # Validation \n",
    "            model_fineTune.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                    val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                    val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                    val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                    val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                    \n",
    "                    val_outputs_real = model_fineTune(val_inputs_real)\n",
    "                    val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                    running_val_loss += val_loss_real.item()\n",
    "                    \n",
    "                    val_outputs_imag = model_fineTune(val_inputs_imag)\n",
    "                    val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                    running_val_loss += val_loss_imag.item()\n",
    "                    \n",
    "                    if (epoch == num_epochs-1): # the results after the last training epoch\n",
    "                        H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                        H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                        \n",
    "                        i = i+val_outputs_imag.size(0)       \n",
    "                        \n",
    "                    \n",
    "            avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "            val_loss.append(avg_val_loss)    \n",
    "                    \n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Val Loss: {avg_val_loss}\")\n",
    "        # end loop epochs\n",
    "        \n",
    "        train_save_path = f'{transferd_save_path}/{snr}dB/train'\n",
    "        os.makedirs(train_save_path, exist_ok=True)\n",
    "        \n",
    "        savemat(f'{train_save_path}/{model_name}_loss.mat', {f'val_loss': val_loss, \n",
    "                                                            f'train_loss': train_loss})\n",
    "        \n",
    "        plotfig.figLoss(train_loss, val_loss, 1, train_save_path, f'_{model_name}_Loss.png')\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model_fineTune.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f'{transferd_save_path}/{snr}dB/{model_name}_model.pth')\n",
    "        \n",
    "        \n",
    "        # Denormalize True Channel\n",
    "        H_val_true = valLabels.cpu()\n",
    "        # convert to complex matrices\n",
    "        H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "        # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "        plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', 1, train_save_path, '_trueChannel.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "\n",
    "        \n",
    "        # CNN Estimated Channel                                                               \n",
    "        H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                            #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                            # valLabel_min == [nVal,1]\n",
    "        H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "        \n",
    "        # NMSE of LS (+ LI) + CNN\n",
    "        H_val_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])# Calculate the NMSE\n",
    "        nmse_NN = utils.calNMSE(H_val_NN_complex, H_val_true_complex)\n",
    "            \n",
    "        if model_name == 'LS_CNN':\n",
    "            nmse_LS_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "        \n",
    "            # NMSE of Linear Interpolation   # just need to calculate this 1 time  --> calculate at case model_name == 'LS_CNN'\n",
    "            H_val_linInterp = H_linear_val.cpu()\n",
    "            # convert to complex matrices\n",
    "            H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "            nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "            \n",
    "            nmse_LS_LI_val.append(nmse_LI.cpu().mean())\n",
    "            print(f\"LS+LI NMSE: {nmse_LI.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                                    nmse_LI[-1], 1, train_save_path, '_LS_LI_estimatedChan.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "                            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            nmse_LI_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+LI+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "    \n",
    "    # end model_phase ['LS_CNN', 'LS_LI_CNN']\n",
    "# end loop SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12           [-1, 1, 612, 14]             801\n",
      "================================================================\n",
      "Total params: 262,211\n",
      "Trainable params: 803\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 35.69\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 36.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_source, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12          [-1, 16, 616, 18]          12,816\n",
      "             Tanh-13          [-1, 16, 616, 18]               0\n",
      "           Conv2d-14           [-1, 8, 614, 16]           1,160\n",
      "             Tanh-15           [-1, 8, 614, 16]               0\n",
      "           Conv2d-16           [-1, 1, 612, 14]              73\n",
      "================================================================\n",
      "Total params: 275,459\n",
      "Trainable params: 14,051\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 39.60\n",
      "Params size (MB): 1.05\n",
      "Estimated Total Size (MB): 40.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_fineTune, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "transferd_model/static/CNN/ver5_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(transferd_save_path, \"NMSE1.png\")) # transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(transferd_save_path, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(transferd_save_path, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
