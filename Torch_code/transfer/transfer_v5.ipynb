{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "import utils_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir  = \"../model/static/CNN/BS16/3500_3516/ver14_\"\n",
    "target_data_dir    = \"../../CDL Customization/Data/ver29_\"\n",
    "\n",
    "# Min-max Scaler to [-1 1] range\n",
    "norm_approach = 'minmax'\n",
    "lower_range = -1\n",
    "CNN_DropOut = 0.2\n",
    "CNN_activation = 'Tanh'\n",
    "train_rate = 0.3\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/transfer_v5.ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "1000 samples in target dataset (map-based dataset), {str(train_rate)} for training, {str(1-train_rate)} for validating and evaluating\n",
    "Finetune models don't have padding at 2 last layers \n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "os.makedirs(os.path.dirname(f'{transferd_save_path}/readme.txt'), exist_ok=True)\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightly applying trained model to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      "LS_CNN model\n",
      "SNR: 0/30, LS_CNN, Epoch 1/50, Loss: 0.39757703244686127 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.4011835617863614\n",
      "SNR: 0/30, LS_CNN, Epoch 2/50, Loss: 0.3954697863923179 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.39905250202054565\n",
      "SNR: 0/30, LS_CNN, Epoch 3/50, Loss: 0.393533887134658 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3972526322240415\n",
      "SNR: 0/30, LS_CNN, Epoch 4/50, Loss: 0.39161359932687545 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3954157835763434\n",
      "SNR: 0/30, LS_CNN, Epoch 5/50, Loss: 0.3897497107585271 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.393625944852829\n",
      "SNR: 0/30, LS_CNN, Epoch 6/50, Loss: 0.38791977365811664 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3918800062459448\n",
      "SNR: 0/30, LS_CNN, Epoch 7/50, Loss: 0.38599499728944564 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.39003955734812695\n",
      "SNR: 0/30, LS_CNN, Epoch 8/50, Loss: 0.38414771523740554 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3881615704816321\n",
      "SNR: 0/30, LS_CNN, Epoch 9/50, Loss: 0.3819505174954732 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3862355493980905\n",
      "SNR: 0/30, LS_CNN, Epoch 10/50, Loss: 0.38017582065529293 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.38418914312901703\n",
      "SNR: 0/30, LS_CNN, Epoch 11/50, Loss: 0.37802433636453414 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3823475079691928\n",
      "SNR: 0/30, LS_CNN, Epoch 12/50, Loss: 0.3759433759583367 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.38013457085775293\n",
      "SNR: 0/30, LS_CNN, Epoch 13/50, Loss: 0.37343916131390464 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.37800761539003125\n",
      "SNR: 0/30, LS_CNN, Epoch 14/50, Loss: 0.3717644198073281 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3757673035497251\n",
      "SNR: 0/30, LS_CNN, Epoch 15/50, Loss: 0.3693937708934148 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.37389154732227325\n",
      "SNR: 0/30, LS_CNN, Epoch 16/50, Loss: 0.36687997149096596 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3709910946047824\n",
      "SNR: 0/30, LS_CNN, Epoch 17/50, Loss: 0.3644546965758006 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3687181926291922\n",
      "SNR: 0/30, LS_CNN, Epoch 18/50, Loss: 0.3622621562745836 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.36681993629621423\n",
      "SNR: 0/30, LS_CNN, Epoch 19/50, Loss: 0.36078551411628723 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3647468213153922\n",
      "SNR: 0/30, LS_CNN, Epoch 20/50, Loss: 0.3578597042295668 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3614370589670928\n",
      "SNR: 0/30, LS_CNN, Epoch 21/50, Loss: 0.35582561790943146 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.35978256360344263\n",
      "SNR: 0/30, LS_CNN, Epoch 22/50, Loss: 0.3534963246848848 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3571920219970786\n",
      "SNR: 0/30, LS_CNN, Epoch 23/50, Loss: 0.3517816778686311 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.35428484172924707\n",
      "SNR: 0/30, LS_CNN, Epoch 24/50, Loss: 0.3487837546401554 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3530797206837198\n",
      "SNR: 0/30, LS_CNN, Epoch 25/50, Loss: 0.34742459654808044 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34940866218960803\n",
      "SNR: 0/30, LS_CNN, Epoch 26/50, Loss: 0.345401621527142 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34702240772869275\n",
      "SNR: 0/30, LS_CNN, Epoch 27/50, Loss: 0.3419712252087063 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34463035801182623\n",
      "SNR: 0/30, LS_CNN, Epoch 28/50, Loss: 0.3398711896604962 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34269466218741046\n",
      "SNR: 0/30, LS_CNN, Epoch 29/50, Loss: 0.33821580476231045 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34031613300675934\n",
      "SNR: 0/30, LS_CNN, Epoch 30/50, Loss: 0.3346906337473128 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33755677420160046\n",
      "SNR: 0/30, LS_CNN, Epoch 31/50, Loss: 0.3335213147931629 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3359986193802046\n",
      "SNR: 0/30, LS_CNN, Epoch 32/50, Loss: 0.33034463889069027 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33032854290112207\n",
      "SNR: 0/30, LS_CNN, Epoch 33/50, Loss: 0.3286978883875741 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33064252656439075\n",
      "SNR: 0/30, LS_CNN, Epoch 34/50, Loss: 0.3269971360762914 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3278375313333843\n",
      "SNR: 0/30, LS_CNN, Epoch 35/50, Loss: 0.32287639048364425 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3236756791239199\n",
      "SNR: 0/30, LS_CNN, Epoch 36/50, Loss: 0.3244687335358726 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.32053452406240546\n",
      "SNR: 0/30, LS_CNN, Epoch 37/50, Loss: 0.320078076587783 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3188538829917493\n",
      "SNR: 0/30, LS_CNN, Epoch 38/50, Loss: 0.31433694064617157 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3145812775777734\n",
      "SNR: 0/30, LS_CNN, Epoch 39/50, Loss: 0.3116301695505778 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3113434366557909\n",
      "SNR: 0/30, LS_CNN, Epoch 40/50, Loss: 0.30927859743436176 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3081374595994535\n",
      "SNR: 0/30, LS_CNN, Epoch 41/50, Loss: 0.3080741647217009 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3046346455812454\n",
      "SNR: 0/30, LS_CNN, Epoch 42/50, Loss: 0.3051002629929119 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.30225658481535705\n",
      "SNR: 0/30, LS_CNN, Epoch 43/50, Loss: 0.29938965539137524 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3002856263647909\n",
      "SNR: 0/30, LS_CNN, Epoch 44/50, Loss: 0.29743892037206227 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2972299100264259\n",
      "SNR: 0/30, LS_CNN, Epoch 45/50, Loss: 0.3012937588824166 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2932997579159944\n",
      "SNR: 0/30, LS_CNN, Epoch 46/50, Loss: 0.2933840850989024 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2926144765123077\n",
      "SNR: 0/30, LS_CNN, Epoch 47/50, Loss: 0.29280045131842297 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2895643856862317\n",
      "SNR: 0/30, LS_CNN, Epoch 48/50, Loss: 0.28832575182120007 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28480294929898303\n",
      "SNR: 0/30, LS_CNN, Epoch 49/50, Loss: 0.28529923492007786 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28288082843241485\n",
      "SNR: 0/30, LS_CNN, Epoch 50/50, Loss: 0.28384938918881947 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2781789672115575\n",
      "LS+CNN NMSE: 0.06166816130280495\n",
      "LS+LI NMSE: 0.0819515809416771\n",
      "LS_LI_CNN model\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3873861034711202 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.39041452692902606\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 2/50, Loss: 0.38033803304036456 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3819948311733163\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3732965456114875 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.37465980778569763\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 4/50, Loss: 0.36598832574155593 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.36713613051435223\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 5/50, Loss: 0.35847511225276524 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.35930417413296906\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3504202084408866 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.35122887595840124\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3420967294110192 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3425544811331708\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 8/50, Loss: 0.33328308827347225 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3333353316006453\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 9/50, Loss: 0.32464128401544357 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.32398383448953216\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 10/50, Loss: 0.31565728618039024 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.315040722489357\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 11/50, Loss: 0.306000229385164 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3050010806840399\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2974563042322795 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.29644142188455747\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 13/50, Loss: 0.28907963467968834 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.28783399773680646\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 14/50, Loss: 0.2807539800802867 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.28006765991449356\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2725885940922631 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.27015983442897384\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 16/50, Loss: 0.2658294166127841 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26335891012264334\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 17/50, Loss: 0.25987980431980556 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.25895680713912717\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 18/50, Loss: 0.2536905176109738 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2524584454038869\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 19/50, Loss: 0.24861556622717115 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.24779244155987448\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 20/50, Loss: 0.24357904742161432 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.24378954619169235\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 21/50, Loss: 0.23937926275862587 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23925950572542523\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 22/50, Loss: 0.23760264863570532 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23597951751688254\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 23/50, Loss: 0.2345023974776268 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2330225310895754\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 24/50, Loss: 0.23479966157012516 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23125044029691946\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 25/50, Loss: 0.23240801195303598 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2304691558946734\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 26/50, Loss: 0.23159271478652954 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2300188628875691\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 27/50, Loss: 0.23070665117767122 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22891241409208463\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 28/50, Loss: 0.23037206464343601 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22914687122987665\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 29/50, Loss: 0.2294482265909513 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22730177576127258\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 30/50, Loss: 0.22787042044930989 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2262574175129766\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 31/50, Loss: 0.22616977410184014 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2250939708041108\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 32/50, Loss: 0.2267751395702362 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22488456802523654\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 33/50, Loss: 0.22661293877495658 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2247141735709232\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 34/50, Loss: 0.22694280826383167 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2232384931134141\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 35/50, Loss: 0.2258959652649032 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22450953657212463\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 36/50, Loss: 0.22501671645376417 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22558525301839993\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 37/50, Loss: 0.22275716728634304 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22457988430624423\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 38/50, Loss: 0.22298502839273876 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2224010047705277\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 39/50, Loss: 0.22425700310203764 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22271792331467505\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 40/50, Loss: 0.22449242075284323 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22194744257823282\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 41/50, Loss: 0.22572389990091324 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22217409280331238\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 42/50, Loss: 0.22415676795774037 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22286066574894864\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 43/50, Loss: 0.2241833508014679 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22180598585501962\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 44/50, Loss: 0.2226917470494906 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22109541556109552\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 45/50, Loss: 0.22125714355044895 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2219290147009103\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 46/50, Loss: 0.22435909923579958 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2218310191579487\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 47/50, Loss: 0.22328505747848088 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22237058210632074\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 48/50, Loss: 0.22311534070306355 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22109847094701685\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 49/50, Loss: 0.22230670187208387 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22140620843223904\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 50/50, Loss: 0.22350103904803595 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2212642959278563\n",
      "LS+CNN NMSE: 0.034597743302583694\n",
      " SNR: 5/30\n",
      "LS_CNN model\n",
      "SNR: 5/30, LS_CNN, Epoch 1/50, Loss: 0.4035021397802565 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.396276558222978\n",
      "SNR: 5/30, LS_CNN, Epoch 2/50, Loss: 0.40115994877285427 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.39396613253199536\n",
      "SNR: 5/30, LS_CNN, Epoch 3/50, Loss: 0.3987087541156345 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.39160565384056256\n",
      "SNR: 5/30, LS_CNN, Epoch 4/50, Loss: 0.39632046388255227 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3890751995470213\n",
      "SNR: 5/30, LS_CNN, Epoch 5/50, Loss: 0.39367137021488613 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.38640169021875964\n",
      "SNR: 5/30, LS_CNN, Epoch 6/50, Loss: 0.3905246886942122 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3831173531387163\n",
      "SNR: 5/30, LS_CNN, Epoch 7/50, Loss: 0.3875824742847019 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.37992690827535547\n",
      "SNR: 5/30, LS_CNN, Epoch 8/50, Loss: 0.38415176007482743 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.37661247020182403\n",
      "SNR: 5/30, LS_CNN, Epoch 9/50, Loss: 0.38037869334220886 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3726446285195973\n",
      "SNR: 5/30, LS_CNN, Epoch 10/50, Loss: 0.3766293211115731 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3681248102499091\n",
      "SNR: 5/30, LS_CNN, Epoch 11/50, Loss: 0.37198787596490646 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3635719710070154\n",
      "SNR: 5/30, LS_CNN, Epoch 12/50, Loss: 0.367022294137213 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3587687047927276\n",
      "SNR: 5/30, LS_CNN, Epoch 13/50, Loss: 0.36322575476434493 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3543015420436859\n",
      "SNR: 5/30, LS_CNN, Epoch 14/50, Loss: 0.35836363169882035 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3493681498195814\n",
      "SNR: 5/30, LS_CNN, Epoch 15/50, Loss: 0.3529437763823403 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3426637591227241\n",
      "SNR: 5/30, LS_CNN, Epoch 16/50, Loss: 0.3484831237130695 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3383940050135488\n",
      "SNR: 5/30, LS_CNN, Epoch 17/50, Loss: 0.3436107784509659 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.33295006855674414\n",
      "SNR: 5/30, LS_CNN, Epoch 18/50, Loss: 0.33815233574973214 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.32817394383575604\n",
      "SNR: 5/30, LS_CNN, Epoch 19/50, Loss: 0.33281755778524613 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3241229446037956\n",
      "SNR: 5/30, LS_CNN, Epoch 20/50, Loss: 0.327576670381758 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3175812357145807\n",
      "SNR: 5/30, LS_CNN, Epoch 21/50, Loss: 0.3224753522210651 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.31285597060037695\n",
      "SNR: 5/30, LS_CNN, Epoch 22/50, Loss: 0.318058032128546 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30842557355113653\n",
      "SNR: 5/30, LS_CNN, Epoch 23/50, Loss: 0.3149281144142151 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3025940540044204\n",
      "SNR: 5/30, LS_CNN, Epoch 24/50, Loss: 0.31048116584618884 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.29899871802848316\n",
      "SNR: 5/30, LS_CNN, Epoch 25/50, Loss: 0.3054347137610118 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.29480956624383514\n",
      "SNR: 5/30, LS_CNN, Epoch 26/50, Loss: 0.3010084496604072 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2902715549520824\n",
      "SNR: 5/30, LS_CNN, Epoch 27/50, Loss: 0.2993685371345944 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.28612790418707806\n",
      "SNR: 5/30, LS_CNN, Epoch 28/50, Loss: 0.2957041834791501 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2815473802063776\n",
      "SNR: 5/30, LS_CNN, Epoch 29/50, Loss: 0.29003944330745274 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27787219959756604\n",
      "SNR: 5/30, LS_CNN, Epoch 30/50, Loss: 0.2870626449584961 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27354956418275833\n",
      "SNR: 5/30, LS_CNN, Epoch 31/50, Loss: 0.2847483298844761 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2698909222431805\n",
      "SNR: 5/30, LS_CNN, Epoch 32/50, Loss: 0.2850216387046708 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26753860874020535\n",
      "SNR: 5/30, LS_CNN, Epoch 33/50, Loss: 0.28306517004966736 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26453173063371493\n",
      "SNR: 5/30, LS_CNN, Epoch 34/50, Loss: 0.27564194467332626 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26139152633107227\n",
      "SNR: 5/30, LS_CNN, Epoch 35/50, Loss: 0.2714647369252311 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25786105089861416\n",
      "SNR: 5/30, LS_CNN, Epoch 36/50, Loss: 0.2791935172345903 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25357134154309396\n",
      "SNR: 5/30, LS_CNN, Epoch 37/50, Loss: 0.27105283737182617 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25294312543195224\n",
      "SNR: 5/30, LS_CNN, Epoch 38/50, Loss: 0.26625097625785404 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24932074611601623\n",
      "SNR: 5/30, LS_CNN, Epoch 39/50, Loss: 0.2708396009272999 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24683031472175018\n",
      "SNR: 5/30, LS_CNN, Epoch 40/50, Loss: 0.2626490816473961 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2436716614857964\n",
      "SNR: 5/30, LS_CNN, Epoch 41/50, Loss: 0.25787855519188774 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24081461585086325\n",
      "SNR: 5/30, LS_CNN, Epoch 42/50, Loss: 0.26440485566854477 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23712560242932776\n",
      "SNR: 5/30, LS_CNN, Epoch 43/50, Loss: 0.250692760778798 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2357642355820407\n",
      "SNR: 5/30, LS_CNN, Epoch 44/50, Loss: 0.25450900114244884 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23262943165457767\n",
      "SNR: 5/30, LS_CNN, Epoch 45/50, Loss: 0.25323085652457344 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23141485452651978\n",
      "SNR: 5/30, LS_CNN, Epoch 46/50, Loss: 0.2526253287990888 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22775738491960193\n",
      "SNR: 5/30, LS_CNN, Epoch 47/50, Loss: 0.26062068425946766 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22483664265145425\n",
      "SNR: 5/30, LS_CNN, Epoch 48/50, Loss: 0.246740053097407 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22367187718982282\n",
      "SNR: 5/30, LS_CNN, Epoch 49/50, Loss: 0.23812057740158504 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.222671194244986\n",
      "SNR: 5/30, LS_CNN, Epoch 50/50, Loss: 0.2425541016790602 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22138278348290402\n",
      "LS+CNN NMSE: 0.038039013743400574\n",
      "LS+LI NMSE: 0.025839267298579216\n",
      "LS_LI_CNN model\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 1/50, Loss: 0.4063155518637763 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.39700534615827643\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3992383082707723 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.39000446187413257\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 3/50, Loss: 0.39205318027072483 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.38271010181178217\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3844634426964654 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3751234885143197\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3763371623224682 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.36658027120258496\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 6/50, Loss: 0.36767245994673836 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3578037995359172\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3582018233007855 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.34786318242549896\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 8/50, Loss: 0.34788694646623397 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3378868491753288\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 9/50, Loss: 0.3369508186976115 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.32680445391198865\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 10/50, Loss: 0.3256533245245616 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.31496417911156366\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 11/50, Loss: 0.3135305345058441 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3035324416730715\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 12/50, Loss: 0.3010457191202376 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.29022144493849383\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 13/50, Loss: 0.2880640708737903 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2776537067864252\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 14/50, Loss: 0.27515988051891327 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.26592329889535904\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 15/50, Loss: 0.26226580556895995 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.25377755158621335\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 16/50, Loss: 0.24947814229461882 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2414093775593716\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 17/50, Loss: 0.2376906159851286 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.23014058820579364\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 18/50, Loss: 0.2262996824251281 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.21870680995609448\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 19/50, Loss: 0.21483605686161253 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.20807362121084463\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 20/50, Loss: 0.20400409897168478 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.19951657788909\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 21/50, Loss: 0.19466673417223823 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.18967329775509628\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 22/50, Loss: 0.18616711348295212 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.18282790805982507\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 23/50, Loss: 0.1792249000734753 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1759820654988289\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 24/50, Loss: 0.17172626819875506 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17045413637938706\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 25/50, Loss: 0.1664473596546385 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16618033045012018\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 26/50, Loss: 0.1616284851398733 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1612217960798222\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 27/50, Loss: 0.15808587190177706 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15840095378782437\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 28/50, Loss: 0.15407897821731037 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15496085082059322\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 29/50, Loss: 0.15129619754023022 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15320135701609694\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 30/50, Loss: 0.14833933694495094 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15150462819830232\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 31/50, Loss: 0.14644763867060342 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14942922491742217\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 32/50, Loss: 0.14479876847730744 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.147794005015622\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 33/50, Loss: 0.14458118834429318 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1473033235448858\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 34/50, Loss: 0.14402384062608084 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1467193813751573\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 35/50, Loss: 0.14229418254560894 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14610909379046896\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 36/50, Loss: 0.14089903152651256 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1460567997849506\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 37/50, Loss: 0.14244741532537672 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14570083031835762\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 38/50, Loss: 0.14050524309277534 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1454482033200886\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 39/50, Loss: 0.14165593683719635 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14550604314907736\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 40/50, Loss: 0.14094926251305473 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14529631189678027\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 41/50, Loss: 0.14040972002678448 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1452189628844676\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 42/50, Loss: 0.1411772138542599 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1452124575557916\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 43/50, Loss: 0.13999294779366916 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1451595440182997\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 44/50, Loss: 0.14015381120973164 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1453071209075658\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 45/50, Loss: 0.14012574942575562 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1451713666319847\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 46/50, Loss: 0.1396199795934889 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14512159302830696\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 47/50, Loss: 0.14124017912480566 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14509883571578108\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 48/50, Loss: 0.14030596241354942 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14507294527214507\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 49/50, Loss: 0.1408272787100739 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1450586529529613\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 50/50, Loss: 0.13915997371077538 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1450788825750351\n",
      "LS+CNN NMSE: 0.017850516363978386\n",
      " SNR: 10/30\n",
      "LS_CNN model\n",
      "SNR: 10/30, LS_CNN, Epoch 1/50, Loss: 0.4063951439327664 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.4009882982658303\n",
      "SNR: 10/30, LS_CNN, Epoch 2/50, Loss: 0.40502193404568565 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.400115641562835\n",
      "SNR: 10/30, LS_CNN, Epoch 3/50, Loss: 0.40350113477971816 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.39863030223742774\n",
      "SNR: 10/30, LS_CNN, Epoch 4/50, Loss: 0.4018869184785419 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.39732172048610187\n",
      "SNR: 10/30, LS_CNN, Epoch 5/50, Loss: 0.400293724404441 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3956018511367881\n",
      "SNR: 10/30, LS_CNN, Epoch 6/50, Loss: 0.39872808423307204 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3935746511687403\n",
      "SNR: 10/30, LS_CNN, Epoch 7/50, Loss: 0.3968358768357171 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3918377057365749\n",
      "SNR: 10/30, LS_CNN, Epoch 8/50, Loss: 0.39532124002774555 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.39002745501373126\n",
      "SNR: 10/30, LS_CNN, Epoch 9/50, Loss: 0.3935470051235623 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38810838305431866\n",
      "SNR: 10/30, LS_CNN, Epoch 10/50, Loss: 0.39153619441721177 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38640618129916815\n",
      "SNR: 10/30, LS_CNN, Epoch 11/50, Loss: 0.3895813673734665 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3838264734848686\n",
      "SNR: 10/30, LS_CNN, Epoch 12/50, Loss: 0.3881017102135552 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38281083430932916\n",
      "SNR: 10/30, LS_CNN, Epoch 13/50, Loss: 0.38581305411126876 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38072096070517664\n",
      "SNR: 10/30, LS_CNN, Epoch 14/50, Loss: 0.3835311151213116 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37792882517628046\n",
      "SNR: 10/30, LS_CNN, Epoch 15/50, Loss: 0.3817509164412816 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3765362695507381\n",
      "SNR: 10/30, LS_CNN, Epoch 16/50, Loss: 0.38081056873003644 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37372149656648224\n",
      "SNR: 10/30, LS_CNN, Epoch 17/50, Loss: 0.378795497947269 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3723351871189864\n",
      "SNR: 10/30, LS_CNN, Epoch 18/50, Loss: 0.37622349295351243 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37133224114127783\n",
      "SNR: 10/30, LS_CNN, Epoch 19/50, Loss: 0.37468578583664364 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3685242067212644\n",
      "SNR: 10/30, LS_CNN, Epoch 20/50, Loss: 0.3739084386163288 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3653949751802113\n",
      "SNR: 10/30, LS_CNN, Epoch 21/50, Loss: 0.3715794583161672 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36307709307774255\n",
      "SNR: 10/30, LS_CNN, Epoch 22/50, Loss: 0.37149106628364986 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3600213281486345\n",
      "SNR: 10/30, LS_CNN, Epoch 23/50, Loss: 0.367975362473064 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36083300346913544\n",
      "SNR: 10/30, LS_CNN, Epoch 24/50, Loss: 0.3665755059983995 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.35783281663189764\n",
      "SNR: 10/30, LS_CNN, Epoch 25/50, Loss: 0.3653646045260959 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.35673457513684814\n",
      "SNR: 10/30, LS_CNN, Epoch 26/50, Loss: 0.36341998477776843 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.35319612790708954\n",
      "SNR: 10/30, LS_CNN, Epoch 27/50, Loss: 0.3642184916469786 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.35301409856132837\n",
      "SNR: 10/30, LS_CNN, Epoch 28/50, Loss: 0.35991592870818245 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34851066703381745\n",
      "SNR: 10/30, LS_CNN, Epoch 29/50, Loss: 0.3585566497511334 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34892062972421234\n",
      "SNR: 10/30, LS_CNN, Epoch 30/50, Loss: 0.3558693147367901 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3457655621611554\n",
      "SNR: 10/30, LS_CNN, Epoch 31/50, Loss: 0.35434598392910427 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34153634568919305\n",
      "SNR: 10/30, LS_CNN, Epoch 32/50, Loss: 0.3533652259243859 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33996044941570447\n",
      "SNR: 10/30, LS_CNN, Epoch 33/50, Loss: 0.35729821357462144 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33957982063293457\n",
      "SNR: 10/30, LS_CNN, Epoch 34/50, Loss: 0.3515035394165251 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33854520515255304\n",
      "SNR: 10/30, LS_CNN, Epoch 35/50, Loss: 0.3484369781282213 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33717960637548694\n",
      "SNR: 10/30, LS_CNN, Epoch 36/50, Loss: 0.3447640273306105 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33614353511644446\n",
      "SNR: 10/30, LS_CNN, Epoch 37/50, Loss: 0.3432406584421794 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32864996596522955\n",
      "SNR: 10/30, LS_CNN, Epoch 38/50, Loss: 0.34332864317629075 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3282640984524851\n",
      "SNR: 10/30, LS_CNN, Epoch 39/50, Loss: 0.33732981317573124 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3239210973615232\n",
      "SNR: 10/30, LS_CNN, Epoch 40/50, Loss: 0.3360898610618379 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3247517250154329\n",
      "SNR: 10/30, LS_CNN, Epoch 41/50, Loss: 0.3343709144327376 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3228436773237975\n",
      "SNR: 10/30, LS_CNN, Epoch 42/50, Loss: 0.33307064904106987 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3180632656035216\n",
      "SNR: 10/30, LS_CNN, Epoch 43/50, Loss: 0.32917163769404095 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3138670597387397\n",
      "SNR: 10/30, LS_CNN, Epoch 44/50, Loss: 0.3250652667548921 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31125867463972257\n",
      "SNR: 10/30, LS_CNN, Epoch 45/50, Loss: 0.32166754537158543 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3088511614047963\n",
      "SNR: 10/30, LS_CNN, Epoch 46/50, Loss: 0.3236004428731071 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3085226283773132\n",
      "SNR: 10/30, LS_CNN, Epoch 47/50, Loss: 0.32146550714969635 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3022093076420867\n",
      "SNR: 10/30, LS_CNN, Epoch 48/50, Loss: 0.31724223163392806 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.29938293734322424\n",
      "SNR: 10/30, LS_CNN, Epoch 49/50, Loss: 0.3156670067045424 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2956939154992933\n",
      "SNR: 10/30, LS_CNN, Epoch 50/50, Loss: 0.31019649240705705 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2955585633930953\n",
      "LS+CNN NMSE: 0.06987450271844864\n",
      "LS+LI NMSE: 0.00820944458246231\n",
      "LS_LI_CNN model\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3813805927832921 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.37275310638158216\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3743894812133577 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.36405497595019964\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 3/50, Loss: 0.36684231294525993 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3557311529698579\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3586847020520104 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3467529241157615\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 5/50, Loss: 0.34968824684619904 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3370536436205325\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 6/50, Loss: 0.34004396862453884 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.32643006353274634\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3295606490638521 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3147787827512492\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 8/50, Loss: 0.3183026611804962 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3030050209035044\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 9/50, Loss: 0.306171221865548 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.29121198861495307\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 10/50, Loss: 0.29362718926535714 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2769708918488544\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 11/50, Loss: 0.2805362559027142 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2631977459658747\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 12/50, Loss: 0.266644106970893 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.24909011598514474\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 13/50, Loss: 0.2530607332785924 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2358421301064284\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 14/50, Loss: 0.23910031219323477 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2215395142202792\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2254737483130561 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.20677761150443036\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 16/50, Loss: 0.21230273776584202 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.19253456560165985\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 17/50, Loss: 0.19879169679350323 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1814032277983168\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 18/50, Loss: 0.18696901781691444 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.16919882627932922\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 19/50, Loss: 0.17568010174565846 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1578380538393622\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 20/50, Loss: 0.16485432452625698 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.14788379698343898\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 21/50, Loss: 0.15480050775739881 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13895488368428272\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 22/50, Loss: 0.14615579611725277 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13101285809408064\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 23/50, Loss: 0.13875415465897983 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.12347260862588882\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 24/50, Loss: 0.1315481745534473 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.11677892943439276\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 25/50, Loss: 0.1256200468374623 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.11111477276553279\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 26/50, Loss: 0.11955869322021802 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10679141934151234\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 27/50, Loss: 0.11642538963092698 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10243080248651297\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 28/50, Loss: 0.11262125356329812 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09922000134120816\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 29/50, Loss: 0.10913045124875174 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09643669847560965\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 30/50, Loss: 0.10687962836689419 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09423876286524793\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 31/50, Loss: 0.10346826745404138 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09256588797206464\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 32/50, Loss: 0.10279026668932703 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09179168137843194\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 33/50, Loss: 0.10200284380051824 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09033178125062714\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 34/50, Loss: 0.10023010356558694 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08937534025829771\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 35/50, Loss: 0.09919793200161722 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08881916024762651\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 36/50, Loss: 0.09875144147210652 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08847811429396919\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 37/50, Loss: 0.09768630812565486 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08807604678946993\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 38/50, Loss: 0.09801423673828442 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08774305005436359\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 39/50, Loss: 0.09714705062409242 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08753920071150946\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 40/50, Loss: 0.09705640334222052 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08773044642546902\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 41/50, Loss: 0.09676921243468921 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08728103112915288\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 42/50, Loss: 0.09670516289770603 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0872195826276489\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 43/50, Loss: 0.09711545829971631 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0871549479501403\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 44/50, Loss: 0.09647558629512787 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08717554078801819\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 45/50, Loss: 0.09647736636300881 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0870931780208712\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 46/50, Loss: 0.09604652598500252 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08711840058474438\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 47/50, Loss: 0.09668723079893324 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08715403663075488\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 48/50, Loss: 0.09604489182432492 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08715500755478507\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 49/50, Loss: 0.09619431611564425 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0870390213702036\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 50/50, Loss: 0.09589709403614204 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08706250057920166\n",
      "LS+CNN NMSE: 0.01085060928016901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 15/30\n",
      "LS_CNN model\n",
      "SNR: 15/30, LS_CNN, Epoch 1/50, Loss: 0.39344020850128597 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3935002237558365\n",
      "SNR: 15/30, LS_CNN, Epoch 2/50, Loss: 0.39028530650668675 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3901467543581258\n",
      "SNR: 15/30, LS_CNN, Epoch 3/50, Loss: 0.38691238396697575 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.38673176843187085\n",
      "SNR: 15/30, LS_CNN, Epoch 4/50, Loss: 0.38368864523039925 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3829949912817582\n",
      "SNR: 15/30, LS_CNN, Epoch 5/50, Loss: 0.3801284001933204 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.379023675037467\n",
      "SNR: 15/30, LS_CNN, Epoch 6/50, Loss: 0.3763608783483505 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3748582731122556\n",
      "SNR: 15/30, LS_CNN, Epoch 7/50, Loss: 0.3725404457913505 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.37044883033503656\n",
      "SNR: 15/30, LS_CNN, Epoch 8/50, Loss: 0.3680146469010247 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3654761722554331\n",
      "SNR: 15/30, LS_CNN, Epoch 9/50, Loss: 0.3634537259737651 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3609367427618607\n",
      "SNR: 15/30, LS_CNN, Epoch 10/50, Loss: 0.35902824335628086 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.35509808815043903\n",
      "SNR: 15/30, LS_CNN, Epoch 11/50, Loss: 0.35387636886702645 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3499445098897685\n",
      "SNR: 15/30, LS_CNN, Epoch 12/50, Loss: 0.34838779270648956 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3444399036791014\n",
      "SNR: 15/30, LS_CNN, Epoch 13/50, Loss: 0.3439286831352446 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3394169360399246\n",
      "SNR: 15/30, LS_CNN, Epoch 14/50, Loss: 0.3376704785558913 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.33341937220614887\n",
      "SNR: 15/30, LS_CNN, Epoch 15/50, Loss: 0.33358582688702476 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3275196461573891\n",
      "SNR: 15/30, LS_CNN, Epoch 16/50, Loss: 0.32944601939784157 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.32231381924256036\n",
      "SNR: 15/30, LS_CNN, Epoch 17/50, Loss: 0.32447761793931323 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3152816353932671\n",
      "SNR: 15/30, LS_CNN, Epoch 18/50, Loss: 0.3206855207681656 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.31116559583207837\n",
      "SNR: 15/30, LS_CNN, Epoch 19/50, Loss: 0.3146304057704078 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3059019932280416\n",
      "SNR: 15/30, LS_CNN, Epoch 20/50, Loss: 0.3099437306324641 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3015216712070548\n",
      "SNR: 15/30, LS_CNN, Epoch 21/50, Loss: 0.307693706618415 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2960785821728084\n",
      "SNR: 15/30, LS_CNN, Epoch 22/50, Loss: 0.3019704404804442 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2916986961727557\n",
      "SNR: 15/30, LS_CNN, Epoch 23/50, Loss: 0.29906782507896423 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.28707291704157123\n",
      "SNR: 15/30, LS_CNN, Epoch 24/50, Loss: 0.2961840546793408 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.28270910000023636\n",
      "SNR: 15/30, LS_CNN, Epoch 25/50, Loss: 0.2928953170776367 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.27926636325276416\n",
      "SNR: 15/30, LS_CNN, Epoch 26/50, Loss: 0.2886769349376361 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2751321348807086\n",
      "SNR: 15/30, LS_CNN, Epoch 27/50, Loss: 0.28889428906970555 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2714512940982114\n",
      "SNR: 15/30, LS_CNN, Epoch 28/50, Loss: 0.2858586385846138 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.268681567972121\n",
      "SNR: 15/30, LS_CNN, Epoch 29/50, Loss: 0.2808122742507193 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2644124215711718\n",
      "SNR: 15/30, LS_CNN, Epoch 30/50, Loss: 0.2781200822856691 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2600868982465371\n",
      "SNR: 15/30, LS_CNN, Epoch 31/50, Loss: 0.27792611221472424 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2571792988025624\n",
      "SNR: 15/30, LS_CNN, Epoch 32/50, Loss: 0.2789006390505367 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25358885526657104\n",
      "SNR: 15/30, LS_CNN, Epoch 33/50, Loss: 0.2740132783850034 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25088823845852976\n",
      "SNR: 15/30, LS_CNN, Epoch 34/50, Loss: 0.2685319698519177 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.250067807086136\n",
      "SNR: 15/30, LS_CNN, Epoch 35/50, Loss: 0.26678522759013706 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24706745795581653\n",
      "SNR: 15/30, LS_CNN, Epoch 36/50, Loss: 0.26872944252358544 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24357008901627167\n",
      "SNR: 15/30, LS_CNN, Epoch 37/50, Loss: 0.26942961249086594 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24137687359167181\n",
      "SNR: 15/30, LS_CNN, Epoch 38/50, Loss: 0.26051242152849835 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24004246715618216\n",
      "SNR: 15/30, LS_CNN, Epoch 39/50, Loss: 0.25586171199878055 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23578420994074448\n",
      "SNR: 15/30, LS_CNN, Epoch 40/50, Loss: 0.2646197784278128 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2330524487339932\n",
      "SNR: 15/30, LS_CNN, Epoch 41/50, Loss: 0.25316225820117527 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2303480266228966\n",
      "SNR: 15/30, LS_CNN, Epoch 42/50, Loss: 0.24994982365104887 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22968979633372763\n",
      "SNR: 15/30, LS_CNN, Epoch 43/50, Loss: 0.24645937234163284 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22447609156370163\n",
      "SNR: 15/30, LS_CNN, Epoch 44/50, Loss: 0.24231814593076706 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2218776432716328\n",
      "SNR: 15/30, LS_CNN, Epoch 45/50, Loss: 0.2412660519282023 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21833450671123422\n",
      "SNR: 15/30, LS_CNN, Epoch 46/50, Loss: 0.247453017367257 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21650927189899527\n",
      "SNR: 15/30, LS_CNN, Epoch 47/50, Loss: 0.25214337060848874 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21456124212430872\n",
      "SNR: 15/30, LS_CNN, Epoch 48/50, Loss: 0.23900756239891052 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21170816181794458\n",
      "SNR: 15/30, LS_CNN, Epoch 49/50, Loss: 0.24768895655870438 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21112875834755276\n",
      "SNR: 15/30, LS_CNN, Epoch 50/50, Loss: 0.23542300115029016 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20826260389193244\n",
      "LS+CNN NMSE: 0.04118458554148674\n",
      "LS+LI NMSE: 0.0025963347870856524\n",
      "LS_LI_CNN model\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3863402025567161 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3783913695293924\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3709146860573027 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3624532462462135\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3555601437886556 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3465347782425258\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 4/50, Loss: 0.339977416727278 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3310970981483874\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 5/50, Loss: 0.32418351868788403 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3146282842625742\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 6/50, Loss: 0.30808330906762016 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.29761530005413556\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2915449109342363 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2812905000603717\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 8/50, Loss: 0.27471253275871277 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.26420522060083307\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 9/50, Loss: 0.2577713330586751 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.24656490139339282\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 10/50, Loss: 0.2408653042382664 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.22916681060324545\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 11/50, Loss: 0.22374674512280357 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.21262700628975165\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2073731521765391 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.19637110213870587\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 13/50, Loss: 0.19089363515377045 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.18046093472967978\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 14/50, Loss: 0.17521304388840994 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.16454217323790427\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 15/50, Loss: 0.16070609208610323 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.15037000422244487\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 16/50, Loss: 0.14688892869485748 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1364316715170508\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 17/50, Loss: 0.13429616722795698 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.12430942884605864\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 18/50, Loss: 0.12279868167307642 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1138547095267669\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 19/50, Loss: 0.11206599407725865 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.10392560404927834\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 20/50, Loss: 0.10307182371616364 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.09640601180169893\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 21/50, Loss: 0.09479327955179745 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08822858892381191\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 22/50, Loss: 0.08809136826958922 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08240389767224374\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 23/50, Loss: 0.08259973881973161 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07715744889624741\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 24/50, Loss: 0.07787147950794962 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07287982397753259\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 25/50, Loss: 0.0737045719805691 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06943400439036929\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 26/50, Loss: 0.07095619891252783 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06629591435194016\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 27/50, Loss: 0.06799614843395022 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0639742953783792\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 28/50, Loss: 0.06571459501153892 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.062272880874250244\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 29/50, Loss: 0.06420474892689122 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06167261326766532\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 30/50, Loss: 0.06316402554512024 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06055977122615213\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 31/50, Loss: 0.061918790348702006 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05944639274283596\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 32/50, Loss: 0.06115405551261372 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05910738031177417\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 33/50, Loss: 0.06102367531922129 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05869373314730499\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 34/50, Loss: 0.060431344227658376 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05841857559331085\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 35/50, Loss: 0.0601104318888651 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05812290011216765\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 36/50, Loss: 0.05964990105066034 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05811297002693881\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 37/50, Loss: 0.05970022744602627 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05794537164594816\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 38/50, Loss: 0.059965652517146535 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05780507413589436\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 39/50, Loss: 0.05994670776029428 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05777080757948368\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 40/50, Loss: 0.05980215614868535 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057708614708288856\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 41/50, Loss: 0.0595135185867548 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057643002344538334\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 42/50, Loss: 0.05984548034353389 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05760171742218992\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 43/50, Loss: 0.0594372840391265 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057555467335750225\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 44/50, Loss: 0.059956829994916916 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05751865268077539\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 45/50, Loss: 0.05928287241193983 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0574754405685741\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 46/50, Loss: 0.058963973075151443 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05745350630225047\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 47/50, Loss: 0.059024946867591806 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057404598504628826\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 48/50, Loss: 0.05926206107768747 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05735359085804742\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 49/50, Loss: 0.05929757199353642 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057356387133831566\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 50/50, Loss: 0.05942336366408401 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05727552942445745\n",
      "LS+CNN NMSE: 0.006714772433042526\n",
      " SNR: 20/30\n",
      "LS_CNN model\n",
      "SNR: 20/30, LS_CNN, Epoch 1/50, Loss: 0.3972594125403298 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3995327379392541\n",
      "SNR: 20/30, LS_CNN, Epoch 2/50, Loss: 0.39394764933321214 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3962150682573733\n",
      "SNR: 20/30, LS_CNN, Epoch 3/50, Loss: 0.3906894127527873 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.39312984956347424\n",
      "SNR: 20/30, LS_CNN, Epoch 4/50, Loss: 0.3874778813785977 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.39005907139052515\n",
      "SNR: 20/30, LS_CNN, Epoch 5/50, Loss: 0.38422010507848525 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3867959529161453\n",
      "SNR: 20/30, LS_CNN, Epoch 6/50, Loss: 0.38088397681713104 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3833889941806379\n",
      "SNR: 20/30, LS_CNN, Epoch 7/50, Loss: 0.3770926528506809 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3797051640956298\n",
      "SNR: 20/30, LS_CNN, Epoch 8/50, Loss: 0.3736530939737956 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3760477187840835\n",
      "SNR: 20/30, LS_CNN, Epoch 9/50, Loss: 0.369503657023112 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.37204075961009314\n",
      "SNR: 20/30, LS_CNN, Epoch 10/50, Loss: 0.3662921157148149 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3679270757281262\n",
      "SNR: 20/30, LS_CNN, Epoch 11/50, Loss: 0.36214812762207454 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.36378607607406116\n",
      "SNR: 20/30, LS_CNN, Epoch 12/50, Loss: 0.35797837542163 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.35965031320634094\n",
      "SNR: 20/30, LS_CNN, Epoch 13/50, Loss: 0.35375205675760907 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.35512808483579883\n",
      "SNR: 20/30, LS_CNN, Epoch 14/50, Loss: 0.3493093616432614 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.35183376980864484\n",
      "SNR: 20/30, LS_CNN, Epoch 15/50, Loss: 0.3470008456044727 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3469536544188209\n",
      "SNR: 20/30, LS_CNN, Epoch 16/50, Loss: 0.34191136062145233 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.34336658664371655\n",
      "SNR: 20/30, LS_CNN, Epoch 17/50, Loss: 0.3391440179612901 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.33997733826222626\n",
      "SNR: 20/30, LS_CNN, Epoch 18/50, Loss: 0.33712487088309395 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3364474021870157\n",
      "SNR: 20/30, LS_CNN, Epoch 19/50, Loss: 0.3320514228608873 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3321867293637732\n",
      "SNR: 20/30, LS_CNN, Epoch 20/50, Loss: 0.3289124038484361 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.33001212775707245\n",
      "SNR: 20/30, LS_CNN, Epoch 21/50, Loss: 0.3250034832292133 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.32673606730025745\n",
      "SNR: 20/30, LS_CNN, Epoch 22/50, Loss: 0.32362747689088184 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.32417477926482324\n",
      "SNR: 20/30, LS_CNN, Epoch 23/50, Loss: 0.317879362238778 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.32223456644493603\n",
      "SNR: 20/30, LS_CNN, Epoch 24/50, Loss: 0.320047559009658 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.31754103821256885\n",
      "SNR: 20/30, LS_CNN, Epoch 25/50, Loss: 0.312596845957968 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.31410579966462177\n",
      "SNR: 20/30, LS_CNN, Epoch 26/50, Loss: 0.3102157761653264 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3098694189735081\n",
      "SNR: 20/30, LS_CNN, Epoch 27/50, Loss: 0.3059048040045632 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.30812301259973773\n",
      "SNR: 20/30, LS_CNN, Epoch 28/50, Loss: 0.303837882147895 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3043989156899245\n",
      "SNR: 20/30, LS_CNN, Epoch 29/50, Loss: 0.3007979633079635 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3014380986923757\n",
      "SNR: 20/30, LS_CNN, Epoch 30/50, Loss: 0.2963928547170427 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.29852205968421436\n",
      "SNR: 20/30, LS_CNN, Epoch 31/50, Loss: 0.2944698515865538 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2905595231315364\n",
      "SNR: 20/30, LS_CNN, Epoch 32/50, Loss: 0.29389682246579063 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.28916046282519464\n",
      "SNR: 20/30, LS_CNN, Epoch 33/50, Loss: 0.2970338902539677 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2877433750292529\n",
      "SNR: 20/30, LS_CNN, Epoch 34/50, Loss: 0.2915501304798656 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.28830674711776816\n",
      "SNR: 20/30, LS_CNN, Epoch 35/50, Loss: 0.28323791010512245 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2807391548286314\n",
      "SNR: 20/30, LS_CNN, Epoch 36/50, Loss: 0.2842529242237409 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2816333498643792\n",
      "SNR: 20/30, LS_CNN, Epoch 37/50, Loss: 0.2777058788471752 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.27692438111357065\n",
      "SNR: 20/30, LS_CNN, Epoch 38/50, Loss: 0.27968041847149533 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2797416361129802\n",
      "SNR: 20/30, LS_CNN, Epoch 39/50, Loss: 0.27393033852179843 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.27622406508611597\n",
      "SNR: 20/30, LS_CNN, Epoch 40/50, Loss: 0.27535009963644874 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.27118081405110983\n",
      "SNR: 20/30, LS_CNN, Epoch 41/50, Loss: 0.27044590148660874 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2668428252572599\n",
      "SNR: 20/30, LS_CNN, Epoch 42/50, Loss: 0.26832085351149243 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2604090820835984\n",
      "SNR: 20/30, LS_CNN, Epoch 43/50, Loss: 0.27531688743167454 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.26222389936447144\n",
      "SNR: 20/30, LS_CNN, Epoch 44/50, Loss: 0.2685147565272119 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25896455347537994\n",
      "SNR: 20/30, LS_CNN, Epoch 45/50, Loss: 0.2580680060717795 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25701327719118283\n",
      "SNR: 20/30, LS_CNN, Epoch 46/50, Loss: 0.26078616579373676 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25452969579592993\n",
      "SNR: 20/30, LS_CNN, Epoch 47/50, Loss: 0.25085028923220104 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2528092031893523\n",
      "SNR: 20/30, LS_CNN, Epoch 48/50, Loss: 0.2509795187248124 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2466238076272218\n",
      "SNR: 20/30, LS_CNN, Epoch 49/50, Loss: 0.24928798278172812 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2431737207200216\n",
      "SNR: 20/30, LS_CNN, Epoch 50/50, Loss: 0.2530626464221213 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24448683663554813\n",
      "LS+CNN NMSE: 0.05173153430223465\n",
      "LS+LI NMSE: 0.0008196238777600229\n",
      "LS_LI_CNN model\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 1/50, Loss: 0.39761433170901406 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3941632470358973\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 2/50, Loss: 0.38711226814323 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3833184585623119\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3763183222876655 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.37216705407785333\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 4/50, Loss: 0.36499866677655113 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3602544483931168\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3530127654472987 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3473548921553985\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3400212791230943 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3339525325142819\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 7/50, Loss: 0.32636869781547123 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.31955623821071955\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 8/50, Loss: 0.31163940330346424 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3047576760468276\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 9/50, Loss: 0.29607916209432816 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.28890847058399866\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 10/50, Loss: 0.28000275293986004 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.27131682407596835\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 11/50, Loss: 0.263097431924608 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.25382735644993576\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2458098464541965 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.23616327636915704\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 13/50, Loss: 0.22825798557864296 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.21942125811525012\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 14/50, Loss: 0.21079426341586643 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.20170286816099417\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 15/50, Loss: 0.1936183621486028 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.18441281726826791\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 16/50, Loss: 0.1766572106215689 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.16768023501271787\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 17/50, Loss: 0.16072809199492136 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.15090860005306161\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 18/50, Loss: 0.1454504273004002 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.13668062359742497\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 19/50, Loss: 0.13091934182577664 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1226370218007461\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 20/50, Loss: 0.11801603270901574 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.11054378553577092\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 21/50, Loss: 0.10626321037610371 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.09925032309863878\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 22/50, Loss: 0.09556340881519848 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0894272996355658\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 23/50, Loss: 0.08617525009645356 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.08048523695248624\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 24/50, Loss: 0.07818528678682116 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.07289835049406342\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 25/50, Loss: 0.07119668357902104 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06674158654135207\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 26/50, Loss: 0.06544001483254963 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06152820668142775\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 27/50, Loss: 0.060814076827632055 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05597815662622452\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 28/50, Loss: 0.05657561433811983 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.053281448133613754\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 29/50, Loss: 0.05363135722776254 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.049890058196109276\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 30/50, Loss: 0.050459598294562764 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04775694344678651\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 31/50, Loss: 0.048334587986270584 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.046013651699151684\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 32/50, Loss: 0.046519908847080335 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04439967433395593\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 33/50, Loss: 0.04526740591973066 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.042995074035032936\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 34/50, Loss: 0.04421914006686873 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04242320196784061\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 35/50, Loss: 0.043543564362658396 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04211761814582607\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 36/50, Loss: 0.04313577608101898 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04146441829431316\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 37/50, Loss: 0.043152214545342654 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04096734098604192\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 38/50, Loss: 0.04235008400347498 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04017841783554658\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 39/50, Loss: 0.04230669358124336 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04027583150436049\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 40/50, Loss: 0.041721481933361955 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03971693964432115\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 41/50, Loss: 0.041348649395836726 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03974115411224573\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 42/50, Loss: 0.04105893232756191 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03929387648468432\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 43/50, Loss: 0.04098494568218788 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0390046421924363\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 44/50, Loss: 0.04113873922162586 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0390551626763266\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 45/50, Loss: 0.040853563903106585 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0385073555390472\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 46/50, Loss: 0.04099107099076112 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03872824427874192\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 47/50, Loss: 0.04071991994149155 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03876700049833111\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 48/50, Loss: 0.04031674563884735 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03867398105237795\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 49/50, Loss: 0.040876631521516375 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03832287313011677\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 50/50, Loss: 0.03984012444400125 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.038298169839317386\n",
      "LS+CNN NMSE: 0.004667338915169239\n",
      " SNR: 25/30\n",
      "LS_CNN model\n",
      "SNR: 25/30, LS_CNN, Epoch 1/50, Loss: 0.4043687681357066 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3938295543193817\n",
      "SNR: 25/30, LS_CNN, Epoch 2/50, Loss: 0.39689863059255814 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3869454510833906\n",
      "SNR: 25/30, LS_CNN, Epoch 3/50, Loss: 0.3896242810620202 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38057252570338873\n",
      "SNR: 25/30, LS_CNN, Epoch 4/50, Loss: 0.38266480300161576 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3740430189215619\n",
      "SNR: 25/30, LS_CNN, Epoch 5/50, Loss: 0.37621166474289364 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.36761768810127093\n",
      "SNR: 25/30, LS_CNN, Epoch 6/50, Loss: 0.3696776413255268 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3617818044579547\n",
      "SNR: 25/30, LS_CNN, Epoch 7/50, Loss: 0.3632663670513365 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.35613236219986627\n",
      "SNR: 25/30, LS_CNN, Epoch 8/50, Loss: 0.356983987821473 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3502138704061508\n",
      "SNR: 25/30, LS_CNN, Epoch 9/50, Loss: 0.35270198186238605 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.343828027015147\n",
      "SNR: 25/30, LS_CNN, Epoch 10/50, Loss: 0.3454143835438622 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.33901780001495196\n",
      "SNR: 25/30, LS_CNN, Epoch 11/50, Loss: 0.3404517438676622 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3348722237607707\n",
      "SNR: 25/30, LS_CNN, Epoch 12/50, Loss: 0.33419857256942326 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.32909864899904834\n",
      "SNR: 25/30, LS_CNN, Epoch 13/50, Loss: 0.32921116219626534 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3234318689159725\n",
      "SNR: 25/30, LS_CNN, Epoch 14/50, Loss: 0.32546276019679177 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3185994450164878\n",
      "SNR: 25/30, LS_CNN, Epoch 15/50, Loss: 0.31910960872968036 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3122105666476747\n",
      "SNR: 25/30, LS_CNN, Epoch 16/50, Loss: 0.31476211216714645 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.30655683674242185\n",
      "SNR: 25/30, LS_CNN, Epoch 17/50, Loss: 0.31139063835144043 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3044856744615928\n",
      "SNR: 25/30, LS_CNN, Epoch 18/50, Loss: 0.3053008367617925 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3014292150087979\n",
      "SNR: 25/30, LS_CNN, Epoch 19/50, Loss: 0.3039926555421617 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2961913003869679\n",
      "SNR: 25/30, LS_CNN, Epoch 20/50, Loss: 0.29700348774592084 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2900226478991301\n",
      "SNR: 25/30, LS_CNN, Epoch 21/50, Loss: 0.30089090019464493 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28616183121567185\n",
      "SNR: 25/30, LS_CNN, Epoch 22/50, Loss: 0.29036689715252983 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28083478853754373\n",
      "SNR: 25/30, LS_CNN, Epoch 23/50, Loss: 0.2915575752655665 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.27896299018808035\n",
      "SNR: 25/30, LS_CNN, Epoch 24/50, Loss: 0.2808179077174928 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.27325706831786944\n",
      "SNR: 25/30, LS_CNN, Epoch 25/50, Loss: 0.2802590388390753 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2668432078283766\n",
      "SNR: 25/30, LS_CNN, Epoch 26/50, Loss: 0.2807075166039997 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.26582915206318314\n",
      "SNR: 25/30, LS_CNN, Epoch 27/50, Loss: 0.27370113713873756 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2624515651360802\n",
      "SNR: 25/30, LS_CNN, Epoch 28/50, Loss: 0.2730609087480439 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.25507392766682996\n",
      "SNR: 25/30, LS_CNN, Epoch 29/50, Loss: 0.2651082020666864 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.25288924672033475\n",
      "SNR: 25/30, LS_CNN, Epoch 30/50, Loss: 0.26415567182832295 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2500186860561371\n",
      "SNR: 25/30, LS_CNN, Epoch 31/50, Loss: 0.2561519369482994 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24776154432607733\n",
      "SNR: 25/30, LS_CNN, Epoch 32/50, Loss: 0.26057474729087615 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23900680017212164\n",
      "SNR: 25/30, LS_CNN, Epoch 33/50, Loss: 0.24927697247929043 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2394314430977987\n",
      "SNR: 25/30, LS_CNN, Epoch 34/50, Loss: 0.2510516684916284 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23787130901347037\n",
      "SNR: 25/30, LS_CNN, Epoch 35/50, Loss: 0.24158028844330046 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23242093979016595\n",
      "SNR: 25/30, LS_CNN, Epoch 36/50, Loss: 0.24618321657180786 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2273381245524987\n",
      "SNR: 25/30, LS_CNN, Epoch 37/50, Loss: 0.23867643707328373 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22437226318794748\n",
      "SNR: 25/30, LS_CNN, Epoch 38/50, Loss: 0.23253100944889915 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22325382284496142\n",
      "SNR: 25/30, LS_CNN, Epoch 39/50, Loss: 0.23028186874257195 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22065880765085635\n",
      "SNR: 25/30, LS_CNN, Epoch 40/50, Loss: 0.22633401138914955 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.21679195470136145\n",
      "SNR: 25/30, LS_CNN, Epoch 41/50, Loss: 0.2428742754790518 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.213399485077547\n",
      "SNR: 25/30, LS_CNN, Epoch 42/50, Loss: 0.22586247573296228 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.21074259507915247\n",
      "SNR: 25/30, LS_CNN, Epoch 43/50, Loss: 0.22567695462041432 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.21170647183190222\n",
      "SNR: 25/30, LS_CNN, Epoch 44/50, Loss: 0.22428685509496266 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.20563186024842056\n",
      "SNR: 25/30, LS_CNN, Epoch 45/50, Loss: 0.2161886634098159 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.20421445207751315\n",
      "SNR: 25/30, LS_CNN, Epoch 46/50, Loss: 0.2416316784090466 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2047978024119916\n",
      "SNR: 25/30, LS_CNN, Epoch 47/50, Loss: 0.21406429674890307 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2012230609746083\n",
      "SNR: 25/30, LS_CNN, Epoch 48/50, Loss: 0.2166734379198816 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19961294045914774\n",
      "SNR: 25/30, LS_CNN, Epoch 49/50, Loss: 0.21894134084383646 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19645963155704996\n",
      "SNR: 25/30, LS_CNN, Epoch 50/50, Loss: 0.2128673642873764 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19483842765507492\n",
      "LS+CNN NMSE: 0.03759782016277313\n",
      "LS+LI NMSE: 0.00026197833358310163\n",
      "LS_LI_CNN model\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 1/50, Loss: 0.4161265989144643 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.4027061449444812\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 2/50, Loss: 0.39958859648969436 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3868457882300667\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3832559552457597 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.37079608310823853\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3666721416844262 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.35480555762415344\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 5/50, Loss: 0.34981509215301937 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3379654437303543\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 6/50, Loss: 0.33241354756885105 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3207033885561902\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3146060225036409 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.30339375267858093\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 8/50, Loss: 0.29619211951891583 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.28549286334410956\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 9/50, Loss: 0.277380324072308 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.26672997455234115\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 10/50, Loss: 0.2584907172454728 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.2475103667896727\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 11/50, Loss: 0.2393074424730407 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.23015922502331113\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 12/50, Loss: 0.22045917312304178 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.21195084018551785\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 13/50, Loss: 0.20190061628818512 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.19449072946672855\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 14/50, Loss: 0.18399598449468613 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.17695302419040515\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 15/50, Loss: 0.16687610414293078 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.16134365810000378\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 16/50, Loss: 0.1505614055527581 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.14653755497673285\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 17/50, Loss: 0.1354136508372095 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.13195886867849724\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 18/50, Loss: 0.12147486334045728 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.1183514761859956\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 19/50, Loss: 0.10865623545315531 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.10594717251217883\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 20/50, Loss: 0.09704503996504678 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0951576728535735\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 21/50, Loss: 0.08701693266630173 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.08568124181550482\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 22/50, Loss: 0.07791746200786696 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0771778348185446\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 23/50, Loss: 0.07011166421903504 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.07044469864796037\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 24/50, Loss: 0.06372008638249503 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.06366281292360762\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 25/50, Loss: 0.05788692459464073 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.05995758776755437\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 26/50, Loss: 0.05291210052867731 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.05497518108914728\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 27/50, Loss: 0.048984124014774956 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.05149495949887711\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 28/50, Loss: 0.04597949909253253 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04897098903260801\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 29/50, Loss: 0.0433820676472452 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.046735521648889\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 30/50, Loss: 0.041153467984663114 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04468630748274534\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 31/50, Loss: 0.03935227729380131 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04363643001441075\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 32/50, Loss: 0.03818744865970479 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04114448951314325\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 33/50, Loss: 0.03687645908859041 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04069276004219833\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 34/50, Loss: 0.035994228493008346 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03951072802200266\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 35/50, Loss: 0.03562958569576343 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.039426063308897225\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 36/50, Loss: 0.03500854306750827 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.039393501315751804\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 37/50, Loss: 0.03455108549031946 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.038668796258128205\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 38/50, Loss: 0.03384841409408384 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03690394556716732\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 39/50, Loss: 0.03365457347697682 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03623291833893112\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 40/50, Loss: 0.03307277326368623 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.036140210278656174\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 41/50, Loss: 0.03295894660469559 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.037043823982062546\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 42/50, Loss: 0.03256653880493508 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.036665147210916745\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 43/50, Loss: 0.03225579205900431 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.036241653294343014\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 44/50, Loss: 0.0316945334068603 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03545534112693175\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 45/50, Loss: 0.03158862961249219 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.035821673622273884\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 46/50, Loss: 0.03157254122197628 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03415826048054125\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 47/50, Loss: 0.031248260496391192 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.034709245978814106\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 48/50, Loss: 0.030872238489488762 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03488801990676185\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 49/50, Loss: 0.030672490286330383 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03430938728801582\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 50/50, Loss: 0.03025826956662867 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.032616913419864745\n",
      "LS+CNN NMSE: 0.004883703775703907\n",
      " SNR: 30/30\n",
      "LS_CNN model\n",
      "SNR: 30/30, LS_CNN, Epoch 1/50, Loss: 0.39853430291016895 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.4019963054553322\n",
      "SNR: 30/30, LS_CNN, Epoch 2/50, Loss: 0.3932203600804011 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3966501471788987\n",
      "SNR: 30/30, LS_CNN, Epoch 3/50, Loss: 0.38819579283396405 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.39196354215559753\n",
      "SNR: 30/30, LS_CNN, Epoch 4/50, Loss: 0.38345395856433445 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3876467826573745\n",
      "SNR: 30/30, LS_CNN, Epoch 5/50, Loss: 0.3785308202107747 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.38312173084072443\n",
      "SNR: 30/30, LS_CNN, Epoch 6/50, Loss: 0.3739320801364051 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.37864791180776514\n",
      "SNR: 30/30, LS_CNN, Epoch 7/50, Loss: 0.3685549729400211 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3734145734621131\n",
      "SNR: 30/30, LS_CNN, Epoch 8/50, Loss: 0.3637556897269355 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3686590913845145\n",
      "SNR: 30/30, LS_CNN, Epoch 9/50, Loss: 0.3588665939039654 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3636556643506755\n",
      "SNR: 30/30, LS_CNN, Epoch 10/50, Loss: 0.3524347808625963 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3584278621103453\n",
      "SNR: 30/30, LS_CNN, Epoch 11/50, Loss: 0.34814370340771145 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3537416043488876\n",
      "SNR: 30/30, LS_CNN, Epoch 12/50, Loss: 0.3428636391957601 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3489711427170297\n",
      "SNR: 30/30, LS_CNN, Epoch 13/50, Loss: 0.33772199518150753 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.34391899601272913\n",
      "SNR: 30/30, LS_CNN, Epoch 14/50, Loss: 0.3330796973572837 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.33860268281853717\n",
      "SNR: 30/30, LS_CNN, Epoch 15/50, Loss: 0.3274435881111357 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3343978180833485\n",
      "SNR: 30/30, LS_CNN, Epoch 16/50, Loss: 0.323282649119695 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3301798435656921\n",
      "SNR: 30/30, LS_CNN, Epoch 17/50, Loss: 0.32051508625348407 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32577586951463117\n",
      "SNR: 30/30, LS_CNN, Epoch 18/50, Loss: 0.31679244008329177 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32200840504273126\n",
      "SNR: 30/30, LS_CNN, Epoch 19/50, Loss: 0.3117359048790402 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3191522288581599\n",
      "SNR: 30/30, LS_CNN, Epoch 20/50, Loss: 0.30935032334592605 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.31503498748592706\n",
      "SNR: 30/30, LS_CNN, Epoch 21/50, Loss: 0.3064892556932237 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3117400666941767\n",
      "SNR: 30/30, LS_CNN, Epoch 22/50, Loss: 0.3039511177274916 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3090621984523276\n",
      "SNR: 30/30, LS_CNN, Epoch 23/50, Loss: 0.29873156878683305 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3062438232743222\n",
      "SNR: 30/30, LS_CNN, Epoch 24/50, Loss: 0.30010298060046303 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3027909624835719\n",
      "SNR: 30/30, LS_CNN, Epoch 25/50, Loss: 0.2945038692818748 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3014349736597227\n",
      "SNR: 30/30, LS_CNN, Epoch 26/50, Loss: 0.29215142130851746 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.29887285634227423\n",
      "SNR: 30/30, LS_CNN, Epoch 27/50, Loss: 0.28910627795590293 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.297174492607946\n",
      "SNR: 30/30, LS_CNN, Epoch 28/50, Loss: 0.28528552419609493 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2917794050729793\n",
      "SNR: 30/30, LS_CNN, Epoch 29/50, Loss: 0.28446132524145973 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2879254746696223\n",
      "SNR: 30/30, LS_CNN, Epoch 30/50, Loss: 0.27988758352067733 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2853645131639812\n",
      "SNR: 30/30, LS_CNN, Epoch 31/50, Loss: 0.27952780491775936 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2843573618194331\n",
      "SNR: 30/30, LS_CNN, Epoch 32/50, Loss: 0.2745513253741794 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2807092848031417\n",
      "SNR: 30/30, LS_CNN, Epoch 33/50, Loss: 0.277650873694155 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27655005778955377\n",
      "SNR: 30/30, LS_CNN, Epoch 34/50, Loss: 0.2706892978813913 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2735800224801768\n",
      "SNR: 30/30, LS_CNN, Epoch 35/50, Loss: 0.268759210076597 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27205629679171933\n",
      "SNR: 30/30, LS_CNN, Epoch 36/50, Loss: 0.2697474956512451 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26797668441482214\n",
      "SNR: 30/30, LS_CNN, Epoch 37/50, Loss: 0.2657018171416389 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2679286158603171\n",
      "SNR: 30/30, LS_CNN, Epoch 38/50, Loss: 0.26300821867254043 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26254746609407925\n",
      "SNR: 30/30, LS_CNN, Epoch 39/50, Loss: 0.26309530933698017 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2595945674440135\n",
      "SNR: 30/30, LS_CNN, Epoch 40/50, Loss: 0.26426530877749127 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2605161919541981\n",
      "SNR: 30/30, LS_CNN, Epoch 41/50, Loss: 0.25838370041714775 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.25564553167508997\n",
      "SNR: 30/30, LS_CNN, Epoch 42/50, Loss: 0.25864144000742173 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.25307146168273426\n",
      "SNR: 30/30, LS_CNN, Epoch 43/50, Loss: 0.2574533315168487 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.25260083928056387\n",
      "SNR: 30/30, LS_CNN, Epoch 44/50, Loss: 0.25414372566673493 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2507264944522277\n",
      "SNR: 30/30, LS_CNN, Epoch 45/50, Loss: 0.24971596151590347 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24596156503843225\n",
      "SNR: 30/30, LS_CNN, Epoch 46/50, Loss: 0.24738430976867676 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24321372936601224\n",
      "SNR: 30/30, LS_CNN, Epoch 47/50, Loss: 0.24756116420030594 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23977919182051782\n",
      "SNR: 30/30, LS_CNN, Epoch 48/50, Loss: 0.25117361379994285 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24046702942122583\n",
      "SNR: 30/30, LS_CNN, Epoch 49/50, Loss: 0.2379734507865376 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24109135794898737\n",
      "SNR: 30/30, LS_CNN, Epoch 50/50, Loss: 0.23721914490063986 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2364326751102572\n",
      "LS+CNN NMSE: 0.0490584596991539\n",
      "LS+LI NMSE: 8.333200094057247e-05\n",
      "LS_LI_CNN model\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 1/50, Loss: 0.35381922291384804 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3525793196066566\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 2/50, Loss: 0.34233249723911285 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3406773863927178\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3306272327899933 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.32860195895899896\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 4/50, Loss: 0.31842443015840316 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3162568606760191\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 5/50, Loss: 0.30588027669323814 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3029100927321807\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 6/50, Loss: 0.2927558869123459 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.28874660445296246\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 7/50, Loss: 0.27914383510748547 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.27476070335377817\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 8/50, Loss: 0.2650278988811705 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.260408922382023\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 9/50, Loss: 0.25049223668045467 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.24533541889294333\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 10/50, Loss: 0.23562944100962746 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.22987602359574774\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 11/50, Loss: 0.22031034363640678 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.21475887007039526\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 12/50, Loss: 0.20506708406739765 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.2000032660105954\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 13/50, Loss: 0.1897561194168197 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.18454370485699695\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 14/50, Loss: 0.17472887287537256 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.1697150174042453\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 15/50, Loss: 0.1600410317381223 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.15381102361108945\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 16/50, Loss: 0.14565253174967235 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.14021157748673274\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 17/50, Loss: 0.13207296654582024 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.1263914644394232\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 18/50, Loss: 0.11882537975907326 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.11354811003674632\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 19/50, Loss: 0.10668725147843361 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.10112725846145464\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 20/50, Loss: 0.09523510974314478 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.09013078134992848\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 21/50, Loss: 0.08480984510646926 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.07930434349438419\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 22/50, Loss: 0.07515436949001418 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.07073910955501639\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 23/50, Loss: 0.0667386810398764 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.06290039598293927\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 24/50, Loss: 0.05938994532657994 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.05600626904355443\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 25/50, Loss: 0.05236808893581232 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.04936635915351951\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 26/50, Loss: 0.04626470307509104 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0441219756865631\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 27/50, Loss: 0.04155227386703094 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03923159643359806\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 28/50, Loss: 0.03696267079148027 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03477059932344634\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 29/50, Loss: 0.03344077979111009 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.031701917274166706\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 30/50, Loss: 0.03059622852338685 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.028994916735783867\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 31/50, Loss: 0.027699619117710326 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02690175363955938\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 32/50, Loss: 0.025819268284572497 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.024837998167166243\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 33/50, Loss: 0.02418361386905114 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.023191189130201288\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 34/50, Loss: 0.02254813914704654 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0221430998214561\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 35/50, Loss: 0.02163876650027103 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.021071893082040806\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 36/50, Loss: 0.020939540376679763 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.020191314367010542\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 37/50, Loss: 0.020032980841481023 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.019622706403226955\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 38/50, Loss: 0.019839297824849684 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01936104531278429\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 39/50, Loss: 0.019060242843503755 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018863992907268846\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 40/50, Loss: 0.018759947528855667 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01876282252614265\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 41/50, Loss: 0.018611369499315817 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018662122746362635\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 42/50, Loss: 0.018405778747465875 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018362300146533096\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 43/50, Loss: 0.018259879615571763 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0181661623975505\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 44/50, Loss: 0.01837273971695039 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018082972453988117\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 45/50, Loss: 0.018221108941361308 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018133472813212353\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 46/50, Loss: 0.018046307067076366 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01799411425852905\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 47/50, Loss: 0.01802698326193624 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017893571285126003\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 48/50, Loss: 0.017808778521915276 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017850064125883837\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 49/50, Loss: 0.017875763587653637 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017785608231940347\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 50/50, Loss: 0.018007694226172235 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017710183372559106\n",
      "LS+CNN NMSE: 0.0022130573634058237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "learning_rate = 1e-5 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    # load target dataset\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_map_data(target_data_dir, device, snr, train_rate=train_rate)\n",
    "            \n",
    "    # training at target set\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        \n",
    "        if model_name == 'LS_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "        \n",
    "        # source model\n",
    "        model_source = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model_fineTune = utils_transfer.FineTuneModel2(model_source).to(device)\n",
    "        optimizer = torch.optim.Adam(model_fineTune.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_loss =[]\n",
    "        val_loss = []\n",
    "        H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "        min_H_true = []\n",
    "        max_H_true = []\n",
    "        num_epochs = NUM_EPOCHS\n",
    "        for epoch in range(num_epochs):\n",
    "            model_fineTune.train()\n",
    "            running_loss = 0.0\n",
    "            if (epoch == num_epochs-1):\n",
    "                i = 0\n",
    "            for inputs, targets, targets_min, targets_max in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fineTune(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "            \n",
    "            # Validation \n",
    "            model_fineTune.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                    val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                    val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                    val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                    val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                    \n",
    "                    val_outputs_real = model_fineTune(val_inputs_real)\n",
    "                    val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                    running_val_loss += val_loss_real.item()\n",
    "                    \n",
    "                    val_outputs_imag = model_fineTune(val_inputs_imag)\n",
    "                    val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                    running_val_loss += val_loss_imag.item()\n",
    "                    \n",
    "                    if (epoch == num_epochs-1): # the results after the last training epoch\n",
    "                        H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                        H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                        \n",
    "                        i = i+val_outputs_imag.size(0)       \n",
    "                        \n",
    "                    \n",
    "            avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "            val_loss.append(avg_val_loss)    \n",
    "                    \n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Val Loss: {avg_val_loss}\")\n",
    "        # end loop epochs\n",
    "        \n",
    "        train_save_path = f'{transferd_save_path}/{snr}dB/train'\n",
    "        os.makedirs(train_save_path, exist_ok=True)\n",
    "        \n",
    "        savemat(f'{train_save_path}/{model_name}_loss.mat', {f'val_loss': val_loss, \n",
    "                                                            f'train_loss': train_loss})\n",
    "        \n",
    "        plotfig.figLoss(train_loss, val_loss, 1, train_save_path, f'_{model_name}_Loss.png')\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model_fineTune.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f'{transferd_save_path}/{snr}dB/{model_name}_model.pth')\n",
    "        \n",
    "        \n",
    "        # Denormalize True Channel\n",
    "        H_val_true = valLabels.cpu()\n",
    "        # convert to complex matrices\n",
    "        H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "        # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "        plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', 1, train_save_path, '_trueChannel.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "\n",
    "        \n",
    "        # CNN Estimated Channel                                                               \n",
    "        H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                            #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                            # valLabel_min == [nVal,1]\n",
    "        H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "        \n",
    "        # NMSE of LS (+ LI) + CNN\n",
    "        H_val_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])# Calculate the NMSE\n",
    "        nmse_NN = utils.calNMSE(H_val_NN_complex, H_val_true_complex)\n",
    "            \n",
    "        if model_name == 'LS_CNN':\n",
    "            nmse_LS_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "        \n",
    "            # NMSE of Linear Interpolation   # just need to calculate this 1 time  --> calculate at case model_name == 'LS_CNN'\n",
    "            H_val_linInterp = H_linear_val.cpu()\n",
    "            # convert to complex matrices\n",
    "            H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "            nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "            \n",
    "            nmse_LS_LI_val.append(nmse_LI.cpu().mean())\n",
    "            print(f\"LS+LI NMSE: {nmse_LI.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                                    nmse_LI[-1], 1, train_save_path, '_LS_LI_estimatedChan.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "                            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            nmse_LI_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+LI+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "    \n",
    "    # end model_phase ['LS_CNN', 'LS_LI_CNN']\n",
    "# end loop SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12           [-1, 1, 612, 14]             801\n",
      "================================================================\n",
      "Total params: 262,211\n",
      "Trainable params: 803\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 35.69\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 36.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_source, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12          [-1, 16, 616, 18]          12,816\n",
      "             Tanh-13          [-1, 16, 616, 18]               0\n",
      "           Conv2d-14           [-1, 8, 614, 16]           1,160\n",
      "             Tanh-15           [-1, 8, 614, 16]               0\n",
      "           Conv2d-16           [-1, 1, 612, 14]              73\n",
      "================================================================\n",
      "Total params: 275,459\n",
      "Trainable params: 14,051\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 39.60\n",
      "Params size (MB): 1.05\n",
      "Estimated Total Size (MB): 40.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_fineTune, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "transferd_model/static/CNN/ver8_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(transferd_save_path, \"NMSE1.png\")) # transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(transferd_save_path, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(transferd_save_path, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
