{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "import utils_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir  = \"../model/static/CNN/BS16/3500_3516/ver14_\"\n",
    "target_data_dir    = \"../../CDL Customization/Data/ver29_\"\n",
    "\n",
    "# Min-max Scaler to [-1 1] range\n",
    "norm_approach = 'minmax'\n",
    "lower_range = -1\n",
    "CNN_DropOut = 0.2\n",
    "CNN_activation = 'Tanh'\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/transfer_v3.ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "1000 samples in target dataset (map-based dataset), 0.9 for training, 0.1 for validating\n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "os.makedirs(os.path.dirname(f'{transferd_save_path}/readme.txt'), exist_ok=True)\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightly applying trained model to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      "LS_CNN model\n",
      "SNR: 0/30, LS_CNN, Epoch 1/50, Loss: 0.39403218935642925 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.4041551612317562\n",
      "SNR: 0/30, LS_CNN, Epoch 2/50, Loss: 0.3875897436269692 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.39763205125927925\n",
      "SNR: 0/30, LS_CNN, Epoch 3/50, Loss: 0.3778821565210819 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3871381878852844\n",
      "SNR: 0/30, LS_CNN, Epoch 4/50, Loss: 0.3649186124759061 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.37678904831409454\n",
      "SNR: 0/30, LS_CNN, Epoch 5/50, Loss: 0.3515024296939373 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.36418914049863815\n",
      "SNR: 0/30, LS_CNN, Epoch 6/50, Loss: 0.3372502268425056 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34978199377655983\n",
      "SNR: 0/30, LS_CNN, Epoch 7/50, Loss: 0.3238975075738771 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34154950082302094\n",
      "SNR: 0/30, LS_CNN, Epoch 8/50, Loss: 0.3078131369714226 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.32005830109119415\n",
      "SNR: 0/30, LS_CNN, Epoch 9/50, Loss: 0.2925285255270345 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31172238290309906\n",
      "SNR: 0/30, LS_CNN, Epoch 10/50, Loss: 0.2770109115434544 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.293153740465641\n",
      "SNR: 0/30, LS_CNN, Epoch 11/50, Loss: 0.2649595098836081 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2674921564757824\n",
      "SNR: 0/30, LS_CNN, Epoch 12/50, Loss: 0.24948262050747871 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.255851574242115\n",
      "SNR: 0/30, LS_CNN, Epoch 13/50, Loss: 0.24269283642726286 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.249703885987401\n",
      "SNR: 0/30, LS_CNN, Epoch 14/50, Loss: 0.2289681796516691 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2401744555681944\n",
      "SNR: 0/30, LS_CNN, Epoch 15/50, Loss: 0.23099425701158388 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.22826490551233292\n",
      "SNR: 0/30, LS_CNN, Epoch 16/50, Loss: 0.23133752095912183 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.22263727523386478\n",
      "SNR: 0/30, LS_CNN, Epoch 17/50, Loss: 0.22243355081549712 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.21627209149301052\n",
      "SNR: 0/30, LS_CNN, Epoch 18/50, Loss: 0.21088556413139617 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.21425599604845047\n",
      "SNR: 0/30, LS_CNN, Epoch 19/50, Loss: 0.2101784579988037 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.21197410114109516\n",
      "SNR: 0/30, LS_CNN, Epoch 20/50, Loss: 0.21355906873941422 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20430152118206024\n",
      "SNR: 0/30, LS_CNN, Epoch 21/50, Loss: 0.2117682086037738 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20276652090251446\n",
      "SNR: 0/30, LS_CNN, Epoch 22/50, Loss: 0.21887899988463946 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20378167554736137\n",
      "SNR: 0/30, LS_CNN, Epoch 23/50, Loss: 0.21012247566665923 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20126955769956112\n",
      "SNR: 0/30, LS_CNN, Epoch 24/50, Loss: 0.20980708580464125 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19791979901492596\n",
      "SNR: 0/30, LS_CNN, Epoch 25/50, Loss: 0.20646632994924272 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1975370179861784\n",
      "SNR: 0/30, LS_CNN, Epoch 26/50, Loss: 0.2125131876340934 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1993150133639574\n",
      "SNR: 0/30, LS_CNN, Epoch 27/50, Loss: 0.205258719889181 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1973000317811966\n",
      "SNR: 0/30, LS_CNN, Epoch 28/50, Loss: 0.21576136297413281 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19696053117513657\n",
      "SNR: 0/30, LS_CNN, Epoch 29/50, Loss: 0.20855795725115708 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1973027903586626\n",
      "SNR: 0/30, LS_CNN, Epoch 30/50, Loss: 0.21627400150256498 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2028803527355194\n",
      "SNR: 0/30, LS_CNN, Epoch 31/50, Loss: 0.21395427228084632 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19687052816152573\n",
      "SNR: 0/30, LS_CNN, Epoch 32/50, Loss: 0.21262338597859656 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19636720418930054\n",
      "SNR: 0/30, LS_CNN, Epoch 33/50, Loss: 0.20508871679859503 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19591540656983852\n",
      "SNR: 0/30, LS_CNN, Epoch 34/50, Loss: 0.22240336372384004 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19574855081737041\n",
      "SNR: 0/30, LS_CNN, Epoch 35/50, Loss: 0.21217142418026924 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19503016956150532\n",
      "SNR: 0/30, LS_CNN, Epoch 36/50, Loss: 0.20605792371290071 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19406460784375668\n",
      "SNR: 0/30, LS_CNN, Epoch 37/50, Loss: 0.2035639187587159 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19593829847872257\n",
      "SNR: 0/30, LS_CNN, Epoch 38/50, Loss: 0.20056574711842196 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19271481037139893\n",
      "SNR: 0/30, LS_CNN, Epoch 39/50, Loss: 0.2123947236686945 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19749047607183456\n",
      "SNR: 0/30, LS_CNN, Epoch 40/50, Loss: 0.21140958634870394 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19423998147249222\n",
      "SNR: 0/30, LS_CNN, Epoch 41/50, Loss: 0.2018083126417228 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1926644742488861\n",
      "SNR: 0/30, LS_CNN, Epoch 42/50, Loss: 0.21196810555245196 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19317736849188805\n",
      "SNR: 0/30, LS_CNN, Epoch 43/50, Loss: 0.2214645573071071 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1963647548109293\n",
      "SNR: 0/30, LS_CNN, Epoch 44/50, Loss: 0.21720381772943906 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19623111747205257\n",
      "SNR: 0/30, LS_CNN, Epoch 45/50, Loss: 0.21068626788577863 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19859438762068748\n",
      "SNR: 0/30, LS_CNN, Epoch 46/50, Loss: 0.20504201416458404 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19350715354084969\n",
      "SNR: 0/30, LS_CNN, Epoch 47/50, Loss: 0.20818124392202922 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.1967617440968752\n",
      "SNR: 0/30, LS_CNN, Epoch 48/50, Loss: 0.2301004132522004 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.20116344653069973\n",
      "SNR: 0/30, LS_CNN, Epoch 49/50, Loss: 0.21627170166799 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19593771174550056\n",
      "SNR: 0/30, LS_CNN, Epoch 50/50, Loss: 0.2098622710577079 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.19577026925981045\n",
      "LS+CNN NMSE: 0.02108924277126789\n",
      "LS+LI NMSE: 0.08269774913787842\n",
      "LS_LI_CNN model\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 1/50, Loss: 0.38891012806977543 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.38808203861117363\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 2/50, Loss: 0.35631950199604034 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.35570600628852844\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3133987252201353 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.31677110120654106\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 4/50, Loss: 0.26616555478956017 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2835459876805544\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 5/50, Loss: 0.23339835527752126 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2702626734972\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 6/50, Loss: 0.22114876418241433 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26962022855877876\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2187577182693141 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2703090999275446\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 8/50, Loss: 0.21823589796466486 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.27065988071262836\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 9/50, Loss: 0.21859971979366882 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2706176657229662\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 10/50, Loss: 0.21841206082275935 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2704717703163624\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 11/50, Loss: 0.21848661319485732 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2702649887651205\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2177346692021404 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2706045154482126\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 13/50, Loss: 0.21773536104176724 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.27004604414105415\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 14/50, Loss: 0.2169260284198182 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2696619853377342\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 15/50, Loss: 0.21752803001020635 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26995467208325863\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 16/50, Loss: 0.21647936691130912 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.27024246379733086\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 17/50, Loss: 0.21586195778633868 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2704458571970463\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 18/50, Loss: 0.21608497468488558 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26980818435549736\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 19/50, Loss: 0.21650216382529056 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26950734853744507\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 20/50, Loss: 0.2160768522215741 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2694795597344637\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 21/50, Loss: 0.21573209203779697 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2694780584424734\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 22/50, Loss: 0.21633173578551837 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2688443809747696\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 23/50, Loss: 0.2156022558254855 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2689221575856209\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 24/50, Loss: 0.21536030434072018 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26845958083868027\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 25/50, Loss: 0.21593751439026423 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26923947036266327\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 26/50, Loss: 0.21454027907124587 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2686488348990679\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 27/50, Loss: 0.21467778219708375 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26908296160399914\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 28/50, Loss: 0.2152948629643236 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2695489600300789\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 29/50, Loss: 0.21481382048555783 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2697438467293978\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 30/50, Loss: 0.21499523759952613 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26824680529534817\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 31/50, Loss: 0.21461374339248454 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2680252678692341\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 32/50, Loss: 0.21376589286540235 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2697615288197994\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 33/50, Loss: 0.21350868525249617 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2675768230110407\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 34/50, Loss: 0.21399719560784952 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2671980746090412\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 35/50, Loss: 0.21248259501797812 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2683602273464203\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 36/50, Loss: 0.21314901858568192 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26686323061585426\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 37/50, Loss: 0.21420153283647128 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2673844192177057\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 38/50, Loss: 0.21374909047569549 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26709851063787937\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 39/50, Loss: 0.21324914933315345 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.267951350659132\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 40/50, Loss: 0.21345761099031993 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2675577159970999\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 41/50, Loss: 0.21292741570089543 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2673379760235548\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 42/50, Loss: 0.21240957347410067 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2680273614823818\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 43/50, Loss: 0.21319880336523056 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2668635118752718\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 44/50, Loss: 0.2135927557413067 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2662665080279112\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 45/50, Loss: 0.21193620589162623 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2665093280375004\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 46/50, Loss: 0.21283479913004807 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26620334573090076\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 47/50, Loss: 0.21172195486724377 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2665661610662937\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 48/50, Loss: 0.21193248831800052 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2657711859792471\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 49/50, Loss: 0.21257649548351765 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2663378156721592\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 50/50, Loss: 0.21218437648245267 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2661307081580162\n",
      "LS+CNN NMSE: 0.03453228250145912\n",
      " SNR: 5/30\n",
      "LS_CNN model\n",
      "SNR: 5/30, LS_CNN, Epoch 1/50, Loss: 0.4012129344046116 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3961419351398945\n",
      "SNR: 5/30, LS_CNN, Epoch 2/50, Loss: 0.3912322132715157 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.38436049968004227\n",
      "SNR: 5/30, LS_CNN, Epoch 3/50, Loss: 0.3758228559579168 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.36651305854320526\n",
      "SNR: 5/30, LS_CNN, Epoch 4/50, Loss: 0.3526637112455709 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.34045909717679024\n",
      "SNR: 5/30, LS_CNN, Epoch 5/50, Loss: 0.32675566364611897 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3137623332440853\n",
      "SNR: 5/30, LS_CNN, Epoch 6/50, Loss: 0.30419269470231874 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2929747737944126\n",
      "SNR: 5/30, LS_CNN, Epoch 7/50, Loss: 0.2896861681448562 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27458906173706055\n",
      "SNR: 5/30, LS_CNN, Epoch 8/50, Loss: 0.274014554385628 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25954299606382847\n",
      "SNR: 5/30, LS_CNN, Epoch 9/50, Loss: 0.26665373146533966 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24654646217823029\n",
      "SNR: 5/30, LS_CNN, Epoch 10/50, Loss: 0.25842867472342085 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2377547062933445\n",
      "SNR: 5/30, LS_CNN, Epoch 11/50, Loss: 0.24763372567083156 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22595820017158985\n",
      "SNR: 5/30, LS_CNN, Epoch 12/50, Loss: 0.24986928408699377 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22114534117281437\n",
      "SNR: 5/30, LS_CNN, Epoch 13/50, Loss: 0.23586599049823626 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2124505415558815\n",
      "SNR: 5/30, LS_CNN, Epoch 14/50, Loss: 0.23227472310619696 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20524090342223644\n",
      "SNR: 5/30, LS_CNN, Epoch 15/50, Loss: 0.23036193794437818 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20414040237665176\n",
      "SNR: 5/30, LS_CNN, Epoch 16/50, Loss: 0.22363701994929994 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19703980162739754\n",
      "SNR: 5/30, LS_CNN, Epoch 17/50, Loss: 0.22484429899070943 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19514465518295765\n",
      "SNR: 5/30, LS_CNN, Epoch 18/50, Loss: 0.21874521752553328 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19105784595012665\n",
      "SNR: 5/30, LS_CNN, Epoch 19/50, Loss: 0.2189331203699112 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18541944958269596\n",
      "SNR: 5/30, LS_CNN, Epoch 20/50, Loss: 0.2107252614306552 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1836045291274786\n",
      "SNR: 5/30, LS_CNN, Epoch 21/50, Loss: 0.21910150721669197 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18218503426760435\n",
      "SNR: 5/30, LS_CNN, Epoch 22/50, Loss: 0.21226412510233267 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1843555774539709\n",
      "SNR: 5/30, LS_CNN, Epoch 23/50, Loss: 0.20477247956608022 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1800116617232561\n",
      "SNR: 5/30, LS_CNN, Epoch 24/50, Loss: 0.21267427025096758 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1787574291229248\n",
      "SNR: 5/30, LS_CNN, Epoch 25/50, Loss: 0.20704713517001697 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17797962855547667\n",
      "SNR: 5/30, LS_CNN, Epoch 26/50, Loss: 0.22983700968325138 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18152692914009094\n",
      "SNR: 5/30, LS_CNN, Epoch 27/50, Loss: 0.20883905488465512 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1780116893351078\n",
      "SNR: 5/30, LS_CNN, Epoch 28/50, Loss: 0.216239154871021 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17835185304284096\n",
      "SNR: 5/30, LS_CNN, Epoch 29/50, Loss: 0.21582821078066314 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17844016291201115\n",
      "SNR: 5/30, LS_CNN, Epoch 30/50, Loss: 0.20953295060566493 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.176727632060647\n",
      "SNR: 5/30, LS_CNN, Epoch 31/50, Loss: 0.20544199459254742 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17665837612003088\n",
      "SNR: 5/30, LS_CNN, Epoch 32/50, Loss: 0.2142196028892483 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17668162286281586\n",
      "SNR: 5/30, LS_CNN, Epoch 33/50, Loss: 0.23263689769165857 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18538650311529636\n",
      "SNR: 5/30, LS_CNN, Epoch 34/50, Loss: 0.21544075517782144 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17847367003560066\n",
      "SNR: 5/30, LS_CNN, Epoch 35/50, Loss: 0.2150790747255087 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1823045201599598\n",
      "SNR: 5/30, LS_CNN, Epoch 36/50, Loss: 0.22666064170854433 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17978110536932945\n",
      "SNR: 5/30, LS_CNN, Epoch 37/50, Loss: 0.2097265621913331 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.178913869895041\n",
      "SNR: 5/30, LS_CNN, Epoch 38/50, Loss: 0.20814829559198447 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17582615464925766\n",
      "SNR: 5/30, LS_CNN, Epoch 39/50, Loss: 0.207898133035217 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17562261130660772\n",
      "SNR: 5/30, LS_CNN, Epoch 40/50, Loss: 0.21705343201756477 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17770996876060963\n",
      "SNR: 5/30, LS_CNN, Epoch 41/50, Loss: 0.20691678127540009 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17825307324528694\n",
      "SNR: 5/30, LS_CNN, Epoch 42/50, Loss: 0.20630377930189883 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17533047311007977\n",
      "SNR: 5/30, LS_CNN, Epoch 43/50, Loss: 0.21601715311408043 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17854406498372555\n",
      "SNR: 5/30, LS_CNN, Epoch 44/50, Loss: 0.22293802776506969 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17617841064929962\n",
      "SNR: 5/30, LS_CNN, Epoch 45/50, Loss: 0.20108929090201855 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17510210815817118\n",
      "SNR: 5/30, LS_CNN, Epoch 46/50, Loss: 0.21561339550784656 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17299266904592514\n",
      "SNR: 5/30, LS_CNN, Epoch 47/50, Loss: 0.21378417313098907 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17935948446393013\n",
      "SNR: 5/30, LS_CNN, Epoch 48/50, Loss: 0.208097728235381 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17507722787559032\n",
      "SNR: 5/30, LS_CNN, Epoch 49/50, Loss: 0.204004045309765 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1745093334466219\n",
      "SNR: 5/30, LS_CNN, Epoch 50/50, Loss: 0.21638830391956226 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.17592209205031395\n",
      "LS+CNN NMSE: 0.023580802604556084\n",
      "LS+LI NMSE: 0.02615349180996418\n",
      "LS_LI_CNN model\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 1/50, Loss: 0.38168671248214586 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.36335331574082375\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 2/50, Loss: 0.34051149657794405 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3143010511994362\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 3/50, Loss: 0.2807654211563723 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.25140014849603176\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 4/50, Loss: 0.2159108178956168 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.198401914909482\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 5/50, Loss: 0.1732835609998022 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17543509416282177\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 6/50, Loss: 0.15812769705163582 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17154431901872158\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 7/50, Loss: 0.15482552535831928 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1712722759693861\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 8/50, Loss: 0.15384414765451634 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17146308906376362\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 9/50, Loss: 0.15349944627710752 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1709296517074108\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 10/50, Loss: 0.1522314137380038 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16990385949611664\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 11/50, Loss: 0.15218613230224168 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16965425945818424\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 12/50, Loss: 0.15247274176882847 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16891976073384285\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 13/50, Loss: 0.1517632994800806 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16993156261742115\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 14/50, Loss: 0.150817966753883 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16866324841976166\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 15/50, Loss: 0.15065788105130196 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16835644096136093\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 16/50, Loss: 0.15029266077492917 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16818061470985413\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 17/50, Loss: 0.1503193723037839 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16741052456200123\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 18/50, Loss: 0.15013692248612642 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16728301160037518\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 19/50, Loss: 0.14962430564420565 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16700147464871407\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 20/50, Loss: 0.1496171091816255 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16650115884840488\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 21/50, Loss: 0.14910730559911048 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16678236797451973\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 22/50, Loss: 0.14919495516057527 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16582745127379894\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 23/50, Loss: 0.14874160223241364 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16557103022933006\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 24/50, Loss: 0.14757800714245864 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1654508076608181\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 25/50, Loss: 0.14838016525443112 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16515542194247246\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 26/50, Loss: 0.14753851028425352 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16480281203985214\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 27/50, Loss: 0.14691550244710275 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1643211580812931\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 28/50, Loss: 0.14710555145783083 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16412274725735188\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 29/50, Loss: 0.1461090867274574 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16453927010297775\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 30/50, Loss: 0.14569627812930516 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1635003685951233\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 31/50, Loss: 0.1455839012882539 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16329572908580303\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 32/50, Loss: 0.14467763807624578 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1630028337240219\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 33/50, Loss: 0.1451952007732221 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16249185986816883\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 34/50, Loss: 0.14511843504650251 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16225925274193287\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 35/50, Loss: 0.14427760389766522 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16204276494681835\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 36/50, Loss: 0.14448622268225467 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16163048893213272\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 37/50, Loss: 0.14371158462017775 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16134455800056458\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 38/50, Loss: 0.14338667557707854 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16122480481863022\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 39/50, Loss: 0.1428530371880957 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1609713714569807\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 40/50, Loss: 0.14316365641674825 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16044440492987633\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 41/50, Loss: 0.14284421982509748 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16057410836219788\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 42/50, Loss: 0.14278892919953382 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16012557223439217\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 43/50, Loss: 0.14253451116383076 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16018212214112282\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 44/50, Loss: 0.14246225490101747 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.159719442948699\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 45/50, Loss: 0.14243697095662355 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1598386075347662\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 46/50, Loss: 0.14177241389240539 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1592569835484028\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 47/50, Loss: 0.14157958262200868 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15922472812235355\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 48/50, Loss: 0.14134648428963764 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15926280990242958\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 49/50, Loss: 0.14106242305466107 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15877074748277664\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 50/50, Loss: 0.14129776135087013 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15881657041609287\n",
      "LS+CNN NMSE: 0.017675651237368584\n",
      " SNR: 10/30\n",
      "LS_CNN model\n",
      "SNR: 10/30, LS_CNN, Epoch 1/50, Loss: 0.38559061022741453 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37250813841819763\n",
      "SNR: 10/30, LS_CNN, Epoch 2/50, Loss: 0.36975908279418945 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3511095456779003\n",
      "SNR: 10/30, LS_CNN, Epoch 3/50, Loss: 0.3491362886769431 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3241572305560112\n",
      "SNR: 10/30, LS_CNN, Epoch 4/50, Loss: 0.32770474201866556 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.29940003529191017\n",
      "SNR: 10/30, LS_CNN, Epoch 5/50, Loss: 0.31291273502366884 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2781055662781\n",
      "SNR: 10/30, LS_CNN, Epoch 6/50, Loss: 0.3021058200725487 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.26514838449656963\n",
      "SNR: 10/30, LS_CNN, Epoch 7/50, Loss: 0.2887426175709282 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.25670343823730946\n",
      "SNR: 10/30, LS_CNN, Epoch 8/50, Loss: 0.28345586199845585 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24447616003453732\n",
      "SNR: 10/30, LS_CNN, Epoch 9/50, Loss: 0.27526715078524183 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.23248796351253986\n",
      "SNR: 10/30, LS_CNN, Epoch 10/50, Loss: 0.26770870573818684 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22834487631917\n",
      "SNR: 10/30, LS_CNN, Epoch 11/50, Loss: 0.25846868274467333 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.21063802018761635\n",
      "SNR: 10/30, LS_CNN, Epoch 12/50, Loss: 0.24930359529597418 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2007343228906393\n",
      "SNR: 10/30, LS_CNN, Epoch 13/50, Loss: 0.24433511256107263 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.19446131959557533\n",
      "SNR: 10/30, LS_CNN, Epoch 14/50, Loss: 0.232732000627688 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.18285361398011446\n",
      "SNR: 10/30, LS_CNN, Epoch 15/50, Loss: 0.22806384414434433 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17776248697191477\n",
      "SNR: 10/30, LS_CNN, Epoch 16/50, Loss: 0.2204775046557188 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17033340130001307\n",
      "SNR: 10/30, LS_CNN, Epoch 17/50, Loss: 0.23411877852465426 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.17424269672483206\n",
      "SNR: 10/30, LS_CNN, Epoch 18/50, Loss: 0.21813518500753812 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.16258467640727758\n",
      "SNR: 10/30, LS_CNN, Epoch 19/50, Loss: 0.21087934289659774 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15885506849735975\n",
      "SNR: 10/30, LS_CNN, Epoch 20/50, Loss: 0.21581465857369558 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15784338302910328\n",
      "SNR: 10/30, LS_CNN, Epoch 21/50, Loss: 0.2230354036603655 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15941305737942457\n",
      "SNR: 10/30, LS_CNN, Epoch 22/50, Loss: 0.20899115263351373 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15653283800929785\n",
      "SNR: 10/30, LS_CNN, Epoch 23/50, Loss: 0.20885856130293437 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1507832109928131\n",
      "SNR: 10/30, LS_CNN, Epoch 24/50, Loss: 0.2019438094326428 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14794156700372696\n",
      "SNR: 10/30, LS_CNN, Epoch 25/50, Loss: 0.2100337746420077 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14963843766599894\n",
      "SNR: 10/30, LS_CNN, Epoch 26/50, Loss: 0.20160752268774168 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14941956661641598\n",
      "SNR: 10/30, LS_CNN, Epoch 27/50, Loss: 0.1999234523890274 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1466648867353797\n",
      "SNR: 10/30, LS_CNN, Epoch 28/50, Loss: 0.19817778082298382 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14193706959486008\n",
      "SNR: 10/30, LS_CNN, Epoch 29/50, Loss: 0.22011718233781202 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15178423840552568\n",
      "SNR: 10/30, LS_CNN, Epoch 30/50, Loss: 0.2015688568353653 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14284104481339455\n",
      "SNR: 10/30, LS_CNN, Epoch 31/50, Loss: 0.21968760634107248 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15496718417853117\n",
      "SNR: 10/30, LS_CNN, Epoch 32/50, Loss: 0.20051610256944383 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1440317127853632\n",
      "SNR: 10/30, LS_CNN, Epoch 33/50, Loss: 0.20408574225647108 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14536527637392282\n",
      "SNR: 10/30, LS_CNN, Epoch 34/50, Loss: 0.2213852328381368 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14562874659895897\n",
      "SNR: 10/30, LS_CNN, Epoch 35/50, Loss: 0.2207691879676921 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.15918884053826332\n",
      "SNR: 10/30, LS_CNN, Epoch 36/50, Loss: 0.2078058927186898 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1471021007746458\n",
      "SNR: 10/30, LS_CNN, Epoch 37/50, Loss: 0.2084557203842061 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14309221040457487\n",
      "SNR: 10/30, LS_CNN, Epoch 38/50, Loss: 0.20201557661805833 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14299278147518635\n",
      "SNR: 10/30, LS_CNN, Epoch 39/50, Loss: 0.19764957204461098 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14772321470081806\n",
      "SNR: 10/30, LS_CNN, Epoch 40/50, Loss: 0.19616418158901588 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1462547006085515\n",
      "SNR: 10/30, LS_CNN, Epoch 41/50, Loss: 0.19885663927665778 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14262982457876205\n",
      "SNR: 10/30, LS_CNN, Epoch 42/50, Loss: 0.20386171021631785 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1457084808498621\n",
      "SNR: 10/30, LS_CNN, Epoch 43/50, Loss: 0.2070570242192064 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14165153726935387\n",
      "SNR: 10/30, LS_CNN, Epoch 44/50, Loss: 0.21059508515255793 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1446506232023239\n",
      "SNR: 10/30, LS_CNN, Epoch 45/50, Loss: 0.21550860814750195 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1504579046741128\n",
      "SNR: 10/30, LS_CNN, Epoch 46/50, Loss: 0.20803366282156535 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14274144358932972\n",
      "SNR: 10/30, LS_CNN, Epoch 47/50, Loss: 0.20630899231348718 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14334531780332327\n",
      "SNR: 10/30, LS_CNN, Epoch 48/50, Loss: 0.20612288559121744 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.14982145465910435\n",
      "SNR: 10/30, LS_CNN, Epoch 49/50, Loss: 0.1948285157393132 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1417707223445177\n",
      "SNR: 10/30, LS_CNN, Epoch 50/50, Loss: 0.20582858286798 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.1591735789552331\n",
      "LS+CNN NMSE: 0.038503047078847885\n",
      "LS+LI NMSE: 0.008259153924882412\n",
      "LS_LI_CNN model\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3766477070748806 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.34708191081881523\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3293254343526704 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.28726914525032043\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 3/50, Loss: 0.26375700293907095 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.20969553291797638\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 4/50, Loss: 0.19049664879483835 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1386533621698618\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 5/50, Loss: 0.13604415713676385 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10022726561874151\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 6/50, Loss: 0.11190964787134103 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08852600399404764\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 7/50, Loss: 0.10580407841397184 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08695792313665152\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 8/50, Loss: 0.10504434444010258 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08690662495791912\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 9/50, Loss: 0.10473508600677763 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08646946214139462\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 10/50, Loss: 0.10408674167203051 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08624292351305485\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 11/50, Loss: 0.10386307165026665 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08623164054006338\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 12/50, Loss: 0.10370424522885255 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08576660230755806\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 13/50, Loss: 0.1033824888457145 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0857685087248683\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 14/50, Loss: 0.1034936938168747 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08553760591894388\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 15/50, Loss: 0.1025778975869928 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08513146452605724\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 16/50, Loss: 0.10260797744350773 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08486277796328068\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 17/50, Loss: 0.10233066836372018 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08448141533881426\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 18/50, Loss: 0.102010551973113 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08432456478476524\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 19/50, Loss: 0.10224784637934395 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08392153959721327\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 20/50, Loss: 0.10227020996223603 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08363949228078127\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 21/50, Loss: 0.10127119566979152 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08333057351410389\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 22/50, Loss: 0.10068745319066304 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08293212484568357\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 23/50, Loss: 0.09987518437472838 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08257061522454023\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 24/50, Loss: 0.10007735740925584 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08225262258201838\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 25/50, Loss: 0.10017459373921156 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08206329215317965\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 26/50, Loss: 0.0993743199588997 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08153515867888927\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 27/50, Loss: 0.09931324462273292 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08134042099118233\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 28/50, Loss: 0.0990286863941167 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08102543791756034\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 29/50, Loss: 0.09845989530107804 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08062963746488094\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 30/50, Loss: 0.09856104897335172 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08034073328599334\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 31/50, Loss: 0.09776313410007528 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0796803398989141\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 32/50, Loss: 0.09687829629651137 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.08002460841089487\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 33/50, Loss: 0.0962388643196651 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07913753809407353\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 34/50, Loss: 0.09683072613552213 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.078996317461133\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 35/50, Loss: 0.09635541009317551 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07856662385165691\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 36/50, Loss: 0.09570653018142496 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0779691282659769\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 37/50, Loss: 0.09571678836696915 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07750339806079865\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 38/50, Loss: 0.09525280499032565 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07736369594931602\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 39/50, Loss: 0.09445691042180572 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07701783813536167\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 40/50, Loss: 0.09454671532980033 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07657236885279417\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 41/50, Loss: 0.094302632513323 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07664691470563412\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 42/50, Loss: 0.09396661931116666 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07617698749527335\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 43/50, Loss: 0.0934035108158631 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07556478586047888\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 44/50, Loss: 0.09294475269104753 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0756531092338264\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 45/50, Loss: 0.09272665477224759 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07524597831070423\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 46/50, Loss: 0.09270334855786391 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07510631810873747\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 47/50, Loss: 0.09228929125570826 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07479281350970268\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 48/50, Loss: 0.09252649252968174 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07476506754755974\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 49/50, Loss: 0.09231782677982535 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07415998680517077\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 50/50, Loss: 0.09138146269002131 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.07440335163846612\n",
      "LS+CNN NMSE: 0.011810730211436749\n",
      " SNR: 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS_CNN model\n",
      "SNR: 15/30, LS_CNN, Epoch 1/50, Loss: 0.37405193011675564 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.39053279906511307\n",
      "SNR: 15/30, LS_CNN, Epoch 2/50, Loss: 0.3509531148842403 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3682011440396309\n",
      "SNR: 15/30, LS_CNN, Epoch 3/50, Loss: 0.3279860370925495 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3472651168704033\n",
      "SNR: 15/30, LS_CNN, Epoch 4/50, Loss: 0.30429145800215857 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.32361305318772793\n",
      "SNR: 15/30, LS_CNN, Epoch 5/50, Loss: 0.2825612636016948 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29728992097079754\n",
      "SNR: 15/30, LS_CNN, Epoch 6/50, Loss: 0.2623802947678736 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2775559797883034\n",
      "SNR: 15/30, LS_CNN, Epoch 7/50, Loss: 0.2424154364104782 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25270153768360615\n",
      "SNR: 15/30, LS_CNN, Epoch 8/50, Loss: 0.2330443598330021 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23900890722870827\n",
      "SNR: 15/30, LS_CNN, Epoch 9/50, Loss: 0.21224937295275076 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22439771331846714\n",
      "SNR: 15/30, LS_CNN, Epoch 10/50, Loss: 0.2193730446909155 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2188546285033226\n",
      "SNR: 15/30, LS_CNN, Epoch 11/50, Loss: 0.20867859864873545 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21411818265914917\n",
      "SNR: 15/30, LS_CNN, Epoch 12/50, Loss: 0.20906574917691095 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21050850860774517\n",
      "SNR: 15/30, LS_CNN, Epoch 13/50, Loss: 0.20360677556267806 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2061961218714714\n",
      "SNR: 15/30, LS_CNN, Epoch 14/50, Loss: 0.20896094239183835 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20797918550670147\n",
      "SNR: 15/30, LS_CNN, Epoch 15/50, Loss: 0.20292500725814275 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2057757657021284\n",
      "SNR: 15/30, LS_CNN, Epoch 16/50, Loss: 0.20205795685095446 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20586666744202375\n",
      "SNR: 15/30, LS_CNN, Epoch 17/50, Loss: 0.19851304391132935 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2017644252628088\n",
      "SNR: 15/30, LS_CNN, Epoch 18/50, Loss: 0.2014492629095912 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20044340379536152\n",
      "SNR: 15/30, LS_CNN, Epoch 19/50, Loss: 0.20078311354986259 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2022083941847086\n",
      "SNR: 15/30, LS_CNN, Epoch 20/50, Loss: 0.19042154108839376 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19912098534405231\n",
      "SNR: 15/30, LS_CNN, Epoch 21/50, Loss: 0.20150077183331763 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19980683270841837\n",
      "SNR: 15/30, LS_CNN, Epoch 22/50, Loss: 0.21015479814793384 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20253108069300652\n",
      "SNR: 15/30, LS_CNN, Epoch 23/50, Loss: 0.21031716971525125 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20231471676379442\n",
      "SNR: 15/30, LS_CNN, Epoch 24/50, Loss: 0.2013599436197962 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20210472121834755\n",
      "SNR: 15/30, LS_CNN, Epoch 25/50, Loss: 0.2068905503089939 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2046504896134138\n",
      "SNR: 15/30, LS_CNN, Epoch 26/50, Loss: 0.19720761105418205 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19957565143704414\n",
      "SNR: 15/30, LS_CNN, Epoch 27/50, Loss: 0.1960249420787607 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19895400013774633\n",
      "SNR: 15/30, LS_CNN, Epoch 28/50, Loss: 0.20099537819623947 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19868606608361006\n",
      "SNR: 15/30, LS_CNN, Epoch 29/50, Loss: 0.20716633754117147 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19933801051229239\n",
      "SNR: 15/30, LS_CNN, Epoch 30/50, Loss: 0.20104060428483145 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20030769053846598\n",
      "SNR: 15/30, LS_CNN, Epoch 31/50, Loss: 0.2004126761374729 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20060613099485636\n",
      "SNR: 15/30, LS_CNN, Epoch 32/50, Loss: 0.19898765720427036 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19997936766594648\n",
      "SNR: 15/30, LS_CNN, Epoch 33/50, Loss: 0.2042275478265115 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20144759863615036\n",
      "SNR: 15/30, LS_CNN, Epoch 34/50, Loss: 0.20011771696486644 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19984274357557297\n",
      "SNR: 15/30, LS_CNN, Epoch 35/50, Loss: 0.1993663805936064 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20059358421713114\n",
      "SNR: 15/30, LS_CNN, Epoch 36/50, Loss: 0.20311660399394377 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20128038804978132\n",
      "SNR: 15/30, LS_CNN, Epoch 37/50, Loss: 0.20228421688079834 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2010320955887437\n",
      "SNR: 15/30, LS_CNN, Epoch 38/50, Loss: 0.19493009974913938 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19801825750619173\n",
      "SNR: 15/30, LS_CNN, Epoch 39/50, Loss: 0.20014721288212708 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19875654112547636\n",
      "SNR: 15/30, LS_CNN, Epoch 40/50, Loss: 0.20716755291713135 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20249786879867315\n",
      "SNR: 15/30, LS_CNN, Epoch 41/50, Loss: 0.2055738376719611 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20488478429615498\n",
      "SNR: 15/30, LS_CNN, Epoch 42/50, Loss: 0.19926566391118936 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20120884664356709\n",
      "SNR: 15/30, LS_CNN, Epoch 43/50, Loss: 0.19213828524308546 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19746968615800142\n",
      "SNR: 15/30, LS_CNN, Epoch 44/50, Loss: 0.1980272148336683 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1993579287081957\n",
      "SNR: 15/30, LS_CNN, Epoch 45/50, Loss: 0.2000909713762147 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1987467296421528\n",
      "SNR: 15/30, LS_CNN, Epoch 46/50, Loss: 0.19188944356782095 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19742554798722267\n",
      "SNR: 15/30, LS_CNN, Epoch 47/50, Loss: 0.18857250615422214 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1966097904369235\n",
      "SNR: 15/30, LS_CNN, Epoch 48/50, Loss: 0.21124509455902235 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19948659744113684\n",
      "SNR: 15/30, LS_CNN, Epoch 49/50, Loss: 0.19630445513342107 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19675856176763773\n",
      "SNR: 15/30, LS_CNN, Epoch 50/50, Loss: 0.19360788206436805 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20183262042701244\n",
      "LS+CNN NMSE: 0.030894188210368156\n",
      "LS+LI NMSE: 0.0025623042602092028\n",
      "LS_LI_CNN model\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37623282255870955 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.36505673453211784\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 2/50, Loss: 0.30632342025637627 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.28354809433221817\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 3/50, Loss: 0.21388883755675384 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1900335494428873\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 4/50, Loss: 0.13103394143815553 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.12230382859706879\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 5/50, Loss: 0.08621392738340157 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.09306030347943306\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 6/50, Loss: 0.07389522909319826 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08659534249454737\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 7/50, Loss: 0.07156397209369711 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08566207205876708\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 8/50, Loss: 0.07119704157646213 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08500163769349456\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 9/50, Loss: 0.07073049945756793 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08449891582131386\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 10/50, Loss: 0.07024392765015364 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08369946526363492\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 11/50, Loss: 0.0696286175932203 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08328236360102892\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 12/50, Loss: 0.06924030111570444 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08307414269074798\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 13/50, Loss: 0.06865739243637238 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08229791652411222\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 14/50, Loss: 0.0684517924008625 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0823381869122386\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 15/50, Loss: 0.06781303350414548 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08167883194983006\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 16/50, Loss: 0.06754386338538357 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08149872161448002\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 17/50, Loss: 0.06673634537894811 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08107094187289476\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 18/50, Loss: 0.06668264159400548 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0806171796284616\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 19/50, Loss: 0.0664135177087571 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08020609430968761\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 20/50, Loss: 0.06601415780772056 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07961370702832937\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 21/50, Loss: 0.06549376255965658 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0792344999499619\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 22/50, Loss: 0.06516367409910474 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07894393475726247\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 23/50, Loss: 0.06495834494541798 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07837812229990959\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 24/50, Loss: 0.06407309789210558 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07799658412113786\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 25/50, Loss: 0.06360605831391045 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07758516538888216\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 26/50, Loss: 0.06344329971554023 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0772199654020369\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 27/50, Loss: 0.06293484545312822 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07619473990052938\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 28/50, Loss: 0.0622815660067967 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07649252703413367\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 29/50, Loss: 0.06203724071383476 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07633385341614485\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 30/50, Loss: 0.061572363400565724 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07535029575228691\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 31/50, Loss: 0.061022338324359486 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0746582648716867\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 32/50, Loss: 0.06086472900850432 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0742753054946661\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 33/50, Loss: 0.06039671819390995 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07426193449646235\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 34/50, Loss: 0.06006228092259595 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07345786644145846\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 35/50, Loss: 0.05955564962433917 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07310871360823512\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 36/50, Loss: 0.05896379249835653 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07223639264702797\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 37/50, Loss: 0.0586650010664016 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07172768888995051\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 38/50, Loss: 0.05810361990838179 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0716111846268177\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 39/50, Loss: 0.058221824666751285 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07153682364150882\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 40/50, Loss: 0.05745857461754765 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0706923813559115\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 41/50, Loss: 0.057352423102461865 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07066816184669733\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 42/50, Loss: 0.05702534783631563 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07006770744919777\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 43/50, Loss: 0.05668523598329297 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06967233587056398\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 44/50, Loss: 0.0561424946146352 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06884408043697476\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 45/50, Loss: 0.05557486607826182 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0689848461188376\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 46/50, Loss: 0.05576729638102863 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06887472048401833\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 47/50, Loss: 0.05535009729542902 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06847458286210895\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 48/50, Loss: 0.05529096117243171 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06819596467539668\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 49/50, Loss: 0.05492008796760014 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06794151943176985\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 50/50, Loss: 0.05464884941466153 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06724611949175596\n",
      "LS+CNN NMSE: 0.00591933261603117\n",
      " SNR: 20/30\n",
      "LS_CNN model\n",
      "SNR: 20/30, LS_CNN, Epoch 1/50, Loss: 0.38599040785006117 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3830457367002964\n",
      "SNR: 20/30, LS_CNN, Epoch 2/50, Loss: 0.3731387220323086 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.36661526560783386\n",
      "SNR: 20/30, LS_CNN, Epoch 3/50, Loss: 0.352239050503288 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3398601599037647\n",
      "SNR: 20/30, LS_CNN, Epoch 4/50, Loss: 0.3246035671659878 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3069746233522892\n",
      "SNR: 20/30, LS_CNN, Epoch 5/50, Loss: 0.3007772902825049 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2808562330901623\n",
      "SNR: 20/30, LS_CNN, Epoch 6/50, Loss: 0.28462615822042736 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2607152499258518\n",
      "SNR: 20/30, LS_CNN, Epoch 7/50, Loss: 0.2722239832260779 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2523541860282421\n",
      "SNR: 20/30, LS_CNN, Epoch 8/50, Loss: 0.2625029728348766 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2350315973162651\n",
      "SNR: 20/30, LS_CNN, Epoch 9/50, Loss: 0.2576991072190659 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23471636325120926\n",
      "SNR: 20/30, LS_CNN, Epoch 10/50, Loss: 0.24666438198515347 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21759125404059887\n",
      "SNR: 20/30, LS_CNN, Epoch 11/50, Loss: 0.23664295274232114 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21178765408694744\n",
      "SNR: 20/30, LS_CNN, Epoch 12/50, Loss: 0.2318519332579204 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20481475442647934\n",
      "SNR: 20/30, LS_CNN, Epoch 13/50, Loss: 0.2284617136631693 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19716444425284863\n",
      "SNR: 20/30, LS_CNN, Epoch 14/50, Loss: 0.22427687075521266 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19199235923588276\n",
      "SNR: 20/30, LS_CNN, Epoch 15/50, Loss: 0.22085187610770976 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18551507592201233\n",
      "SNR: 20/30, LS_CNN, Epoch 16/50, Loss: 0.21580392947154386 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.183995989151299\n",
      "SNR: 20/30, LS_CNN, Epoch 17/50, Loss: 0.21442804964525358 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17728869058191776\n",
      "SNR: 20/30, LS_CNN, Epoch 18/50, Loss: 0.23215308891875402 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.17548639979213476\n",
      "SNR: 20/30, LS_CNN, Epoch 19/50, Loss: 0.21268031267183168 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1711240066215396\n",
      "SNR: 20/30, LS_CNN, Epoch 20/50, Loss: 0.21189311306391442 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16866294760257006\n",
      "SNR: 20/30, LS_CNN, Epoch 21/50, Loss: 0.21365093546254293 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1665556449443102\n",
      "SNR: 20/30, LS_CNN, Epoch 22/50, Loss: 0.2126125767827034 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16263127233833075\n",
      "SNR: 20/30, LS_CNN, Epoch 23/50, Loss: 0.21059416101447173 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16367764584720135\n",
      "SNR: 20/30, LS_CNN, Epoch 24/50, Loss: 0.20523602675114358 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.16095756087452173\n",
      "SNR: 20/30, LS_CNN, Epoch 25/50, Loss: 0.20623493061533996 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15908207185566425\n",
      "SNR: 20/30, LS_CNN, Epoch 26/50, Loss: 0.19391976403338568 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15494687855243683\n",
      "SNR: 20/30, LS_CNN, Epoch 27/50, Loss: 0.20395864014114654 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15407417342066765\n",
      "SNR: 20/30, LS_CNN, Epoch 28/50, Loss: 0.20457880518266133 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15587565302848816\n",
      "SNR: 20/30, LS_CNN, Epoch 29/50, Loss: 0.20923388456659658 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15690170787274837\n",
      "SNR: 20/30, LS_CNN, Epoch 30/50, Loss: 0.20470636364604747 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15546740591526031\n",
      "SNR: 20/30, LS_CNN, Epoch 31/50, Loss: 0.20026816108397075 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15388223435729742\n",
      "SNR: 20/30, LS_CNN, Epoch 32/50, Loss: 0.19895269854792527 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15329189784824848\n",
      "SNR: 20/30, LS_CNN, Epoch 33/50, Loss: 0.18959421291947365 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15105755720287561\n",
      "SNR: 20/30, LS_CNN, Epoch 34/50, Loss: 0.19376489972429617 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15018984954804182\n",
      "SNR: 20/30, LS_CNN, Epoch 35/50, Loss: 0.2193548341414758 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15208216663450003\n",
      "SNR: 20/30, LS_CNN, Epoch 36/50, Loss: 0.19931681720273836 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1505334386602044\n",
      "SNR: 20/30, LS_CNN, Epoch 37/50, Loss: 0.2073858803404229 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1553164180368185\n",
      "SNR: 20/30, LS_CNN, Epoch 38/50, Loss: 0.20467922597059182 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15146993938833475\n",
      "SNR: 20/30, LS_CNN, Epoch 39/50, Loss: 0.20833537381674563 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1543636042624712\n",
      "SNR: 20/30, LS_CNN, Epoch 40/50, Loss: 0.19096811514879977 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.14952991250902414\n",
      "SNR: 20/30, LS_CNN, Epoch 41/50, Loss: 0.19536720801677024 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.152900792658329\n",
      "SNR: 20/30, LS_CNN, Epoch 42/50, Loss: 0.20149125824017183 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1494098547846079\n",
      "SNR: 20/30, LS_CNN, Epoch 43/50, Loss: 0.197898518294096 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.14873156696558\n",
      "SNR: 20/30, LS_CNN, Epoch 44/50, Loss: 0.20102386815207346 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.14947663620114326\n",
      "SNR: 20/30, LS_CNN, Epoch 45/50, Loss: 0.20719538762101106 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15038674138486385\n",
      "SNR: 20/30, LS_CNN, Epoch 46/50, Loss: 0.20802559996289866 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1517185727134347\n",
      "SNR: 20/30, LS_CNN, Epoch 47/50, Loss: 0.21025383046695165 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.15559401642531157\n",
      "SNR: 20/30, LS_CNN, Epoch 48/50, Loss: 0.19713246848966395 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1507438961416483\n",
      "SNR: 20/30, LS_CNN, Epoch 49/50, Loss: 0.19285645947924682 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1487682806327939\n",
      "SNR: 20/30, LS_CNN, Epoch 50/50, Loss: 0.2060137830142464 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.14965592790395021\n",
      "LS+CNN NMSE: 0.026708068326115608\n",
      "LS+LI NMSE: 0.0008158525452017784\n",
      "LS_LI_CNN model\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3762022368609905 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.35707512125372887\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3301857060619763 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.29499130696058273\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 3/50, Loss: 0.25517121117029873 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.20179761946201324\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 4/50, Loss: 0.15969207616789 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.10669125709682703\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 5/50, Loss: 0.08647451669509922 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.055895387195050716\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 6/50, Loss: 0.057926198201520104 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04395690164528787\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 7/50, Loss: 0.052009002272305746 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04200003296136856\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 8/50, Loss: 0.051068658308525174 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.041280196979641914\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 9/50, Loss: 0.05039455492182502 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.040987163316458464\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 10/50, Loss: 0.04985500083837126 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03974609193392098\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 11/50, Loss: 0.04940453737175891 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03994845296256244\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 12/50, Loss: 0.04878320571567331 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.039511254290118814\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 13/50, Loss: 0.048189124857474654 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03852363093756139\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 14/50, Loss: 0.04778151985790048 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03811090183444321\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 15/50, Loss: 0.04724324837193957 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03794637112878263\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 16/50, Loss: 0.04722153501851218 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03744057100266218\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 17/50, Loss: 0.04672720256660666 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03696253662928939\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 18/50, Loss: 0.04619818619851555 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03650157409720123\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 19/50, Loss: 0.045651846432260106 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.036300728330388665\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 20/50, Loss: 0.045275071901934485 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03608034807257354\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 21/50, Loss: 0.04487733799032867 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.035426072077825665\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 22/50, Loss: 0.044825813599995205 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.035123822279274464\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 23/50, Loss: 0.04443523134770138 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03485863679088652\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 24/50, Loss: 0.04391431382724217 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03423256054520607\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 25/50, Loss: 0.043716340292511244 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03381096199154854\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 26/50, Loss: 0.04300547843532903 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.033633773913607\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 27/50, Loss: 0.04278604480038796 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03304757922887802\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 28/50, Loss: 0.0425570150504687 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03280957671813667\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 29/50, Loss: 0.04186564823612571 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03229696676135063\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 30/50, Loss: 0.04173432413621673 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03202599473297596\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 31/50, Loss: 0.04144136840477586 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03161112032830715\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 32/50, Loss: 0.04078292231341558 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.031259814742952585\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 33/50, Loss: 0.04043718859819429 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.030907078413292766\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 34/50, Loss: 0.0404114560556731 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03051494318060577\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 35/50, Loss: 0.03993086337244937 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.030145403346978128\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 36/50, Loss: 0.03976880722413106 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.029809336992911994\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 37/50, Loss: 0.03916367682229195 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.029474206501618028\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 38/50, Loss: 0.038913810692195384 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.029151158640161157\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 39/50, Loss: 0.038485785048188906 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.028807614231482148\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 40/50, Loss: 0.03839831391815096 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.028557359124533832\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 41/50, Loss: 0.03794666672391551 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.028210259275510907\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 42/50, Loss: 0.037795578761558445 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02794620266649872\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 43/50, Loss: 0.037533265771344304 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.027648684452287853\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 44/50, Loss: 0.037214433208906224 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02737527491990477\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 45/50, Loss: 0.03689378406852484 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.027195970411412418\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 46/50, Loss: 0.036660808072026284 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.026893652975559235\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 47/50, Loss: 0.03619814155224178 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02667717880103737\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 48/50, Loss: 0.03614809340797365 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02653998346067965\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 49/50, Loss: 0.03587131850820567 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02631587057840079\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 50/50, Loss: 0.036070274571622055 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.02611155027989298\n",
      "LS+CNN NMSE: 0.0033914358355104923\n",
      " SNR: 25/30\n",
      "LS_CNN model\n",
      "SNR: 25/30, LS_CNN, Epoch 1/50, Loss: 0.3878693979765688 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3764984831213951\n",
      "SNR: 25/30, LS_CNN, Epoch 2/50, Loss: 0.3691760338842869 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.35617809370160103\n",
      "SNR: 25/30, LS_CNN, Epoch 3/50, Loss: 0.34487979326929363 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.331314068287611\n",
      "SNR: 25/30, LS_CNN, Epoch 4/50, Loss: 0.318866739315646 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.31105098873376846\n",
      "SNR: 25/30, LS_CNN, Epoch 5/50, Loss: 0.2975513519985335 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2872788552194834\n",
      "SNR: 25/30, LS_CNN, Epoch 6/50, Loss: 0.2820241257016148 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2664806302636862\n",
      "SNR: 25/30, LS_CNN, Epoch 7/50, Loss: 0.2604485396295786 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.25650970451533794\n",
      "SNR: 25/30, LS_CNN, Epoch 8/50, Loss: 0.2544979535575424 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23803452402353287\n",
      "SNR: 25/30, LS_CNN, Epoch 9/50, Loss: 0.23550780383603914 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22559275664389133\n",
      "SNR: 25/30, LS_CNN, Epoch 10/50, Loss: 0.2249992974102497 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2129508014768362\n",
      "SNR: 25/30, LS_CNN, Epoch 11/50, Loss: 0.21880685218742915 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2011540662497282\n",
      "SNR: 25/30, LS_CNN, Epoch 12/50, Loss: 0.20771125491176332 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19331576116383076\n",
      "SNR: 25/30, LS_CNN, Epoch 13/50, Loss: 0.2159081803900855 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19580873101949692\n",
      "SNR: 25/30, LS_CNN, Epoch 14/50, Loss: 0.2040284744330815 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18665482103824615\n",
      "SNR: 25/30, LS_CNN, Epoch 15/50, Loss: 0.20337961108556815 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1832778863608837\n",
      "SNR: 25/30, LS_CNN, Epoch 16/50, Loss: 0.21386935535286153 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18315482512116432\n",
      "SNR: 25/30, LS_CNN, Epoch 17/50, Loss: 0.19706392847001553 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18039511516690254\n",
      "SNR: 25/30, LS_CNN, Epoch 18/50, Loss: 0.19939750778887952 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17957392800599337\n",
      "SNR: 25/30, LS_CNN, Epoch 19/50, Loss: 0.19661744311451912 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17797880992293358\n",
      "SNR: 25/30, LS_CNN, Epoch 20/50, Loss: 0.20802879892289639 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17911923304200172\n",
      "SNR: 25/30, LS_CNN, Epoch 21/50, Loss: 0.20508636321340287 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17910886742174625\n",
      "SNR: 25/30, LS_CNN, Epoch 22/50, Loss: 0.1978928233895983 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17688367143273354\n",
      "SNR: 25/30, LS_CNN, Epoch 23/50, Loss: 0.20786542285765922 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17752731498330832\n",
      "SNR: 25/30, LS_CNN, Epoch 24/50, Loss: 0.207854923126953 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17779852356761694\n",
      "SNR: 25/30, LS_CNN, Epoch 25/50, Loss: 0.20950477117938654 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17842121794819832\n",
      "SNR: 25/30, LS_CNN, Epoch 26/50, Loss: 0.20437496581247874 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17798142973333597\n",
      "SNR: 25/30, LS_CNN, Epoch 27/50, Loss: 0.20610646943428687 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17711251508444548\n",
      "SNR: 25/30, LS_CNN, Epoch 28/50, Loss: 0.19800594794963086 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1761624440550804\n",
      "SNR: 25/30, LS_CNN, Epoch 29/50, Loss: 0.2086951301566192 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1767682023346424\n",
      "SNR: 25/30, LS_CNN, Epoch 30/50, Loss: 0.20555842561381205 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17752660065889359\n",
      "SNR: 25/30, LS_CNN, Epoch 31/50, Loss: 0.2149017857653754 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18365955539047718\n",
      "SNR: 25/30, LS_CNN, Epoch 32/50, Loss: 0.1943739399846111 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1741328462958336\n",
      "SNR: 25/30, LS_CNN, Epoch 33/50, Loss: 0.19779676518269948 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17446689493954182\n",
      "SNR: 25/30, LS_CNN, Epoch 34/50, Loss: 0.1968292955841337 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17439549043774605\n",
      "SNR: 25/30, LS_CNN, Epoch 35/50, Loss: 0.20322571774678572 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17535516060888767\n",
      "SNR: 25/30, LS_CNN, Epoch 36/50, Loss: 0.19539122602769307 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17499712482094765\n",
      "SNR: 25/30, LS_CNN, Epoch 37/50, Loss: 0.2034250351467303 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17341857962310314\n",
      "SNR: 25/30, LS_CNN, Epoch 38/50, Loss: 0.2137609596497246 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1809489130973816\n",
      "SNR: 25/30, LS_CNN, Epoch 39/50, Loss: 0.2129122351429292 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1774000134319067\n",
      "SNR: 25/30, LS_CNN, Epoch 40/50, Loss: 0.1995322917188917 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17601871769875288\n",
      "SNR: 25/30, LS_CNN, Epoch 41/50, Loss: 0.2078857347369194 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17515557818114758\n",
      "SNR: 25/30, LS_CNN, Epoch 42/50, Loss: 0.1989524034517152 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18074386939406395\n",
      "SNR: 25/30, LS_CNN, Epoch 43/50, Loss: 0.20371525841099875 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17532646842300892\n",
      "SNR: 25/30, LS_CNN, Epoch 44/50, Loss: 0.20391801558434963 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17628951836377382\n",
      "SNR: 25/30, LS_CNN, Epoch 45/50, Loss: 0.19848065823316574 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17826663702726364\n",
      "SNR: 25/30, LS_CNN, Epoch 46/50, Loss: 0.20439860677080496 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1737376358360052\n",
      "SNR: 25/30, LS_CNN, Epoch 47/50, Loss: 0.20159926212259702 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17407404072582722\n",
      "SNR: 25/30, LS_CNN, Epoch 48/50, Loss: 0.20968866348266602 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17588249500840902\n",
      "SNR: 25/30, LS_CNN, Epoch 49/50, Loss: 0.19596850579338415 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17274664342403412\n",
      "SNR: 25/30, LS_CNN, Epoch 50/50, Loss: 0.20396668730037554 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17435151431709528\n",
      "LS+CNN NMSE: 0.029173480346798897\n",
      "LS+LI NMSE: 0.00026153208455070853\n",
      "LS_LI_CNN model\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3809443510004452 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.36215826496481895\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3435235981430326 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3163543939590454\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 3/50, Loss: 0.2816507896142347 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.24113291129469872\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 4/50, Loss: 0.19591478311589786 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.1537026446312666\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 5/50, Loss: 0.11196162671382938 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0835048258304596\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 6/50, Loss: 0.06027657219341823 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.052218401338905096\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 7/50, Loss: 0.042588061752862165 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04441474913619459\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 8/50, Loss: 0.03900195595010051 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.043338515562936664\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 9/50, Loss: 0.0381373992256288 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.042733276495710015\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 10/50, Loss: 0.037783114738496285 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04239642387256026\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 11/50, Loss: 0.037233289530766864 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04216662119142711\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 12/50, Loss: 0.03698330375898097 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.041828671004623175\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 13/50, Loss: 0.03658916575035879 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04156276257708669\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 14/50, Loss: 0.036446204309218695 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04127737507224083\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 15/50, Loss: 0.03597402193450502 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04097458440810442\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 16/50, Loss: 0.03556838505236166 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04067000490613282\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 17/50, Loss: 0.03525965471219804 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04044962488114834\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 18/50, Loss: 0.03496987405898316 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04005751549266279\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 19/50, Loss: 0.03448636776634625 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03978741681203246\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 20/50, Loss: 0.03410112325634275 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03954617981798947\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 21/50, Loss: 0.03391007982593562 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03903737780638039\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 22/50, Loss: 0.03355495089532009 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03905792674049735\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 23/50, Loss: 0.03308207651467195 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03851692448370159\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 24/50, Loss: 0.03272695436940661 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03815612266771495\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 25/50, Loss: 0.032475064641663005 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.037834881572052836\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 26/50, Loss: 0.032118495187855194 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03753074281848967\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 27/50, Loss: 0.031616752268746495 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.037171113304793835\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 28/50, Loss: 0.031249549372919967 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03672322048805654\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 29/50, Loss: 0.030906996756259884 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03642757749184966\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 30/50, Loss: 0.030510110314935446 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03623432363383472\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 31/50, Loss: 0.030152633553370833 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03568942961283028\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 32/50, Loss: 0.029777549040902938 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0351070340257138\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 33/50, Loss: 0.029072989809459875 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03512345300987363\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 34/50, Loss: 0.028719895868562162 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.034299531020224094\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 35/50, Loss: 0.028457004144521698 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03383703832514584\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 36/50, Loss: 0.027899361731085395 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.033379473024979234\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 37/50, Loss: 0.027458483769026185 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03301792521961033\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 38/50, Loss: 0.027140582595685765 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.032984453020617366\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 39/50, Loss: 0.026682993713101105 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03222166933119297\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 40/50, Loss: 0.02649627103736358 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03195276018232107\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 41/50, Loss: 0.025889257667586207 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03152424027211964\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 42/50, Loss: 0.025528547620134696 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.031119982013478875\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 43/50, Loss: 0.025263608716029142 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030841955565847456\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 44/50, Loss: 0.02482848662683474 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030855377903208137\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 45/50, Loss: 0.024495481413656046 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030449580517597497\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 46/50, Loss: 0.02424380640565817 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030384941375814378\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 47/50, Loss: 0.024003009744254605 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029568891157396138\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 48/50, Loss: 0.023714822633857175 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029288155492395163\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 49/50, Loss: 0.023558451511364962 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02935218857601285\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 50/50, Loss: 0.02331114367448858 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.0292612137272954\n",
      "LS+CNN NMSE: 0.0024024690501391888\n",
      " SNR: 30/30\n",
      "LS_CNN model\n",
      "SNR: 30/30, LS_CNN, Epoch 1/50, Loss: 0.39107465903673855 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3956761844456196\n",
      "SNR: 30/30, LS_CNN, Epoch 2/50, Loss: 0.37780221551656723 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3792944774031639\n",
      "SNR: 30/30, LS_CNN, Epoch 3/50, Loss: 0.36175666004419327 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3605474531650543\n",
      "SNR: 30/30, LS_CNN, Epoch 4/50, Loss: 0.34495043967451366 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3431232310831547\n",
      "SNR: 30/30, LS_CNN, Epoch 5/50, Loss: 0.32846489761556896 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3252452611923218\n",
      "SNR: 30/30, LS_CNN, Epoch 6/50, Loss: 0.31368475567017284 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.30622145906090736\n",
      "SNR: 30/30, LS_CNN, Epoch 7/50, Loss: 0.2951599963541542 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2854620963335037\n",
      "SNR: 30/30, LS_CNN, Epoch 8/50, Loss: 0.2855509724467993 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2692407611757517\n",
      "SNR: 30/30, LS_CNN, Epoch 9/50, Loss: 0.2659274523279497 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.25086631439626217\n",
      "SNR: 30/30, LS_CNN, Epoch 10/50, Loss: 0.2492390549076455 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23680981621146202\n",
      "SNR: 30/30, LS_CNN, Epoch 11/50, Loss: 0.2344841861299106 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.21712919883430004\n",
      "SNR: 30/30, LS_CNN, Epoch 12/50, Loss: 0.2262307767357145 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.20326086319983006\n",
      "SNR: 30/30, LS_CNN, Epoch 13/50, Loss: 0.21801403989749296 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.19670002721250057\n",
      "SNR: 30/30, LS_CNN, Epoch 14/50, Loss: 0.2114955567355667 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.19057858362793922\n",
      "SNR: 30/30, LS_CNN, Epoch 15/50, Loss: 0.21716332941183022 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.18525804579257965\n",
      "SNR: 30/30, LS_CNN, Epoch 16/50, Loss: 0.2023904975503683 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17740980722010136\n",
      "SNR: 30/30, LS_CNN, Epoch 17/50, Loss: 0.20856330623584135 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17600060906261206\n",
      "SNR: 30/30, LS_CNN, Epoch 18/50, Loss: 0.19677792436310224 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17115854285657406\n",
      "SNR: 30/30, LS_CNN, Epoch 19/50, Loss: 0.19657285138964653 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16794843971729279\n",
      "SNR: 30/30, LS_CNN, Epoch 20/50, Loss: 0.20115102814244373 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16987932100892067\n",
      "SNR: 30/30, LS_CNN, Epoch 21/50, Loss: 0.20972054504922458 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17003157921135426\n",
      "SNR: 30/30, LS_CNN, Epoch 22/50, Loss: 0.20078178069421224 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16914032399654388\n",
      "SNR: 30/30, LS_CNN, Epoch 23/50, Loss: 0.21504871494003705 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16944316681474447\n",
      "SNR: 30/30, LS_CNN, Epoch 24/50, Loss: 0.200599875833307 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17182319425046444\n",
      "SNR: 30/30, LS_CNN, Epoch 25/50, Loss: 0.19329825296465838 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1648062765598297\n",
      "SNR: 30/30, LS_CNN, Epoch 26/50, Loss: 0.19670859790806258 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16689472924917936\n",
      "SNR: 30/30, LS_CNN, Epoch 27/50, Loss: 0.20623737094657763 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16647702921181917\n",
      "SNR: 30/30, LS_CNN, Epoch 28/50, Loss: 0.21161485223897866 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16876583453267813\n",
      "SNR: 30/30, LS_CNN, Epoch 29/50, Loss: 0.20238966694367783 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17226242274045944\n",
      "SNR: 30/30, LS_CNN, Epoch 30/50, Loss: 0.20540657080709934 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1784281637519598\n",
      "SNR: 30/30, LS_CNN, Epoch 31/50, Loss: 0.20797474895204818 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16849081870168447\n",
      "SNR: 30/30, LS_CNN, Epoch 32/50, Loss: 0.21160500696195023 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17238858994096518\n",
      "SNR: 30/30, LS_CNN, Epoch 33/50, Loss: 0.2026268177266632 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17069237027317286\n",
      "SNR: 30/30, LS_CNN, Epoch 34/50, Loss: 0.20559761114418507 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.167925875633955\n",
      "SNR: 30/30, LS_CNN, Epoch 35/50, Loss: 0.20370291386331832 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16691129188984632\n",
      "SNR: 30/30, LS_CNN, Epoch 36/50, Loss: 0.21047567017376423 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16628279350697994\n",
      "SNR: 30/30, LS_CNN, Epoch 37/50, Loss: 0.2044991602056793 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16788254864513874\n",
      "SNR: 30/30, LS_CNN, Epoch 38/50, Loss: 0.2078243363648653 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16838136035948992\n",
      "SNR: 30/30, LS_CNN, Epoch 39/50, Loss: 0.20377283596566745 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16736241709440947\n",
      "SNR: 30/30, LS_CNN, Epoch 40/50, Loss: 0.21124678371208055 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1717904405668378\n",
      "SNR: 30/30, LS_CNN, Epoch 41/50, Loss: 0.20412986246602877 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16714251041412354\n",
      "SNR: 30/30, LS_CNN, Epoch 42/50, Loss: 0.19750014133751392 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16637947876006365\n",
      "SNR: 30/30, LS_CNN, Epoch 43/50, Loss: 0.2129036925200905 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1698078354820609\n",
      "SNR: 30/30, LS_CNN, Epoch 44/50, Loss: 0.19881397751825197 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16941487416625023\n",
      "SNR: 30/30, LS_CNN, Epoch 45/50, Loss: 0.2012886753571885 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.17219020426273346\n",
      "SNR: 30/30, LS_CNN, Epoch 46/50, Loss: 0.2159297556749412 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16930960398167372\n",
      "SNR: 30/30, LS_CNN, Epoch 47/50, Loss: 0.19891804323664733 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.1677643796429038\n",
      "SNR: 30/30, LS_CNN, Epoch 48/50, Loss: 0.20016132108867168 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16377260349690914\n",
      "SNR: 30/30, LS_CNN, Epoch 49/50, Loss: 0.20642979922039167 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16581042390316725\n",
      "SNR: 30/30, LS_CNN, Epoch 50/50, Loss: 0.20111808367073536 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.16836280934512615\n",
      "LS+CNN NMSE: 0.02678687684237957\n",
      "LS+LI NMSE: 8.269264799309894e-05\n",
      "LS_LI_CNN model\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37319050676056315 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.35826316103339195\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 2/50, Loss: 0.31787390049014774 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.28682100400328636\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 3/50, Loss: 0.23522574827075005 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.19037758372724056\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 4/50, Loss: 0.14346387410270317 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.10320544149726629\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 5/50, Loss: 0.07697861322334834 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.054193833377212286\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 6/50, Loss: 0.046724710413920026 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03784426022320986\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 7/50, Loss: 0.03755233430170587 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.032743697287514806\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 8/50, Loss: 0.03547591928924833 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.031235635513439775\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 9/50, Loss: 0.03420874805721853 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03015256067737937\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 10/50, Loss: 0.033113726847139854 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02914461772888899\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 11/50, Loss: 0.03242042900196144 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02838064427487552\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 12/50, Loss: 0.031854617509192655 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.027852301485836506\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 13/50, Loss: 0.031059248772050654 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.026951761916279793\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 14/50, Loss: 0.030506833855594908 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.026364049408584833\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 15/50, Loss: 0.029821971132020866 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02575828041881323\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 16/50, Loss: 0.02905317415882434 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.025133407674729824\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 17/50, Loss: 0.028568459508408393 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.024762540590018034\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 18/50, Loss: 0.028182015089052066 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.024134965846315026\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 19/50, Loss: 0.027619860633941635 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02370504569262266\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 20/50, Loss: 0.02739186115962054 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02315041027031839\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 21/50, Loss: 0.02665484294162265 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.022744761779904366\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 22/50, Loss: 0.02622285536822996 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02236881759017706\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 23/50, Loss: 0.025844824201028262 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02194175706245005\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 24/50, Loss: 0.025365707464516163 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02151650795713067\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 25/50, Loss: 0.024988863417612656 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.021057086065411568\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 26/50, Loss: 0.02478665125090629 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.020615549758076668\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 27/50, Loss: 0.024196152059760476 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.020197895588353276\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 28/50, Loss: 0.023882778477855027 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.019796053413301706\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 29/50, Loss: 0.02332047263293394 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.019393998314626515\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 30/50, Loss: 0.023106892094282166 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.019041036372072995\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 31/50, Loss: 0.02267496199679694 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01863126631360501\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 32/50, Loss: 0.022442099771329334 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018253845279105008\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 33/50, Loss: 0.022018348265971457 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017980363802053034\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 34/50, Loss: 0.021730841852591505 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017548687872476876\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 35/50, Loss: 0.021232621411659887 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017242805450223386\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 36/50, Loss: 0.020873717464772717 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016887216945178807\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 37/50, Loss: 0.02064083726145327 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016569428727962077\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 38/50, Loss: 0.020273188361898065 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016251434455625713\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 39/50, Loss: 0.020385804353281856 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01594049739651382\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 40/50, Loss: 0.019866251652794226 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015769496676512063\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 41/50, Loss: 0.019523950177244842 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015459368005394936\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 42/50, Loss: 0.01928100561989205 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015128667932003736\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 43/50, Loss: 0.01891090998625649 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014891879400238395\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 44/50, Loss: 0.018760030141233335 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014584067976102233\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 45/50, Loss: 0.018522658476805582 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014342852053232491\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 46/50, Loss: 0.018212675557671382 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.014098076382651925\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 47/50, Loss: 0.018104815373330245 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013908428372815251\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 48/50, Loss: 0.01769070705631748 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013637928292155266\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 49/50, Loss: 0.01779299760736259 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013434144668281078\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 50/50, Loss: 0.017308937227686068 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.013226608745753765\n",
      "LS+CNN NMSE: 0.0015676157781854272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "learning_rate = 1e-5 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    # load target dataset\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_map_data(target_data_dir, device, snr)\n",
    "            \n",
    "    # training at target set\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        \n",
    "        if model_name == 'LS_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "        \n",
    "        # source model\n",
    "        model_source = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model_fineTune = utils_transfer.FineTuneModel(model_source).to(device)\n",
    "        optimizer = torch.optim.Adam(model_fineTune.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_loss =[]\n",
    "        val_loss = []\n",
    "        H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "        min_H_true = []\n",
    "        max_H_true = []\n",
    "        num_epochs = NUM_EPOCHS\n",
    "        for epoch in range(num_epochs):\n",
    "            model_fineTune.train()\n",
    "            running_loss = 0.0\n",
    "            if (epoch == num_epochs-1):\n",
    "                i = 0\n",
    "            for inputs, targets, targets_min, targets_max in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fineTune(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "            \n",
    "            # Validation \n",
    "            model_fineTune.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                    val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                    val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                    val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                    val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                    \n",
    "                    val_outputs_real = model_fineTune(val_inputs_real)\n",
    "                    val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                    running_val_loss += val_loss_real.item()\n",
    "                    \n",
    "                    val_outputs_imag = model_fineTune(val_inputs_imag)\n",
    "                    val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                    running_val_loss += val_loss_imag.item()\n",
    "                    \n",
    "                    if (epoch == num_epochs-1): # the results after the last training epoch\n",
    "                        H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                        H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                        \n",
    "                        i = i+val_outputs_imag.size(0)       \n",
    "                        \n",
    "                    \n",
    "            avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "            val_loss.append(avg_val_loss)    \n",
    "                    \n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Val Loss: {avg_val_loss}\")\n",
    "        # end loop epochs\n",
    "        \n",
    "        train_save_path = f'{transferd_save_path}/{snr}dB/train'\n",
    "        os.makedirs(train_save_path, exist_ok=True)\n",
    "        \n",
    "        savemat(f'{train_save_path}/{model_name}_loss.mat', {f'val_loss': val_loss, \n",
    "                                                            f'train_loss': train_loss})\n",
    "        \n",
    "        plotfig.figLoss(train_loss, val_loss, 1, train_save_path, f'_{model_name}_Loss.png')\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model_fineTune.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f'{transferd_save_path}/{snr}dB/{model_name}_model.pth')\n",
    "        \n",
    "        \n",
    "        # Denormalize True Channel\n",
    "        H_val_true = valLabels.cpu()\n",
    "        # convert to complex matrices\n",
    "        H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "        # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "        plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', 1, train_save_path, '_trueChannel.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "\n",
    "        \n",
    "        # CNN Estimated Channel                                                               \n",
    "        H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                            #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                            # valLabel_min == [nVal,1]\n",
    "        H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "        \n",
    "        # NMSE of LS (+ LI) + CNN\n",
    "        H_val_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])# Calculate the NMSE\n",
    "        nmse_NN = utils.calNMSE(H_val_NN_complex, H_val_true_complex)\n",
    "            \n",
    "        if model_name == 'LS_CNN':\n",
    "            nmse_LS_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "        \n",
    "            # NMSE of Linear Interpolation   # just need to calculate this 1 time  --> calculate at case model_name == 'LS_CNN'\n",
    "            H_val_linInterp = H_linear_val.cpu()\n",
    "            # convert to complex matrices\n",
    "            H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "            nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "            \n",
    "            nmse_LS_LI_val.append(nmse_LI.cpu().mean())\n",
    "            print(f\"LS+LI NMSE: {nmse_LI.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                                    nmse_LI[-1], 1, train_save_path, '_LS_LI_estimatedChan.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "                            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            nmse_LI_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+LI+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "    \n",
    "    # end model_phase ['LS_CNN', 'LS_LI_CNN']\n",
    "# end loop SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12           [-1, 1, 612, 14]             801\n",
      "================================================================\n",
      "Total params: 262,211\n",
      "Trainable params: 803\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 35.69\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 36.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_source, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12          [-1, 16, 612, 14]          12,816\n",
      "             Tanh-13          [-1, 16, 612, 14]               0\n",
      "           Conv2d-14           [-1, 8, 612, 14]           3,208\n",
      "             Tanh-15           [-1, 8, 612, 14]               0\n",
      "           Conv2d-16           [-1, 1, 612, 14]             201\n",
      "================================================================\n",
      "Total params: 277,635\n",
      "Trainable params: 16,227\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 38.83\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 39.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_fineTune, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "transferd_model/static/CNN/ver3_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(transferd_save_path, \"NMSE1.png\")) # transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(transferd_save_path, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(transferd_save_path, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
