{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "import utils_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir  = \"../model/static/CNN/BS16/3500_3516/ver14_\"\n",
    "target_data_dir    = \"../../CDL Customization/Data/ver29_\"\n",
    "\n",
    "# Min-max Scaler to [-1 1] range\n",
    "norm_approach = 'minmax'\n",
    "lower_range = -1\n",
    "CNN_DropOut = 0.2\n",
    "CNN_activation = 'Tanh'\n",
    "train_rate = 0.3\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/transfer_v6.ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "1000 samples in target dataset (map-based dataset), {str(train_rate)} for training, {str(1-train_rate)} for validating and evaluating\n",
    "Finetune models don't have padding at 2 last layers \n",
    "(separate source models)\n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "os.makedirs(os.path.dirname(f'{transferd_save_path}/readme.txt'), exist_ok=True)\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightly applying trained model to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      "LS_CNN model\n",
      "SNR: 0/30, LS_CNN, Epoch 1/50, Loss: 0.4188908835252126 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.41326948222906695\n",
      "SNR: 0/30, LS_CNN, Epoch 2/50, Loss: 0.41248467730151284 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.4066418888776199\n",
      "SNR: 0/30, LS_CNN, Epoch 3/50, Loss: 0.406592286295361 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.400839204373567\n",
      "SNR: 0/30, LS_CNN, Epoch 4/50, Loss: 0.40092073049810195 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.39526640008325165\n",
      "SNR: 0/30, LS_CNN, Epoch 5/50, Loss: 0.39542589088280994 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3898176628610362\n",
      "SNR: 0/30, LS_CNN, Epoch 6/50, Loss: 0.38998200992743176 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3842863848675852\n",
      "SNR: 0/30, LS_CNN, Epoch 7/50, Loss: 0.38418394492732155 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3782882036074348\n",
      "SNR: 0/30, LS_CNN, Epoch 8/50, Loss: 0.37911467419730294 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.37336415765078174\n",
      "SNR: 0/30, LS_CNN, Epoch 9/50, Loss: 0.37355119321081376 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3679288308257642\n",
      "SNR: 0/30, LS_CNN, Epoch 10/50, Loss: 0.3679836375845803 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.36197761867357336\n",
      "SNR: 0/30, LS_CNN, Epoch 11/50, Loss: 0.3630606366528405 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3571267186299614\n",
      "SNR: 0/30, LS_CNN, Epoch 12/50, Loss: 0.35816405879126656 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3520564430433771\n",
      "SNR: 0/30, LS_CNN, Epoch 13/50, Loss: 0.3538060751226213 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.34776776575523877\n",
      "SNR: 0/30, LS_CNN, Epoch 14/50, Loss: 0.3491433213154475 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3431112908798715\n",
      "SNR: 0/30, LS_CNN, Epoch 15/50, Loss: 0.3445572571622001 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33967349581096484\n",
      "SNR: 0/30, LS_CNN, Epoch 16/50, Loss: 0.3409648769431644 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3354171009167381\n",
      "SNR: 0/30, LS_CNN, Epoch 17/50, Loss: 0.3375415388080809 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3320152033930239\n",
      "SNR: 0/30, LS_CNN, Epoch 18/50, Loss: 0.33450472023752 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3290324846039648\n",
      "SNR: 0/30, LS_CNN, Epoch 19/50, Loss: 0.33215846949153477 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3258469078851783\n",
      "SNR: 0/30, LS_CNN, Epoch 20/50, Loss: 0.329422222243415 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.32318190582420514\n",
      "SNR: 0/30, LS_CNN, Epoch 21/50, Loss: 0.3240830037328932 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.32030883172284\n",
      "SNR: 0/30, LS_CNN, Epoch 22/50, Loss: 0.32389334672027165 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31745836980964826\n",
      "SNR: 0/30, LS_CNN, Epoch 23/50, Loss: 0.3230944375197093 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31596776389557385\n",
      "SNR: 0/30, LS_CNN, Epoch 24/50, Loss: 0.3210960543817944 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31469208973905316\n",
      "SNR: 0/30, LS_CNN, Epoch 25/50, Loss: 0.3208295967843797 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3100356168073157\n",
      "SNR: 0/30, LS_CNN, Epoch 26/50, Loss: 0.31777967347039116 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.30723879907442175\n",
      "SNR: 0/30, LS_CNN, Epoch 27/50, Loss: 0.3140714599026574 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.30770759349283966\n",
      "SNR: 0/30, LS_CNN, Epoch 28/50, Loss: 0.3118537763754527 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3040304741133814\n",
      "SNR: 0/30, LS_CNN, Epoch 29/50, Loss: 0.3100455419884788 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3033918343160463\n",
      "SNR: 0/30, LS_CNN, Epoch 30/50, Loss: 0.3114162352350023 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3009830214407133\n",
      "SNR: 0/30, LS_CNN, Epoch 31/50, Loss: 0.3080381353696187 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2970769146214361\n",
      "SNR: 0/30, LS_CNN, Epoch 32/50, Loss: 0.3044819004005856 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.29698380665934604\n",
      "SNR: 0/30, LS_CNN, Epoch 33/50, Loss: 0.30240674482451546 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2941879413050154\n",
      "SNR: 0/30, LS_CNN, Epoch 34/50, Loss: 0.3020511385467317 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2933825092471164\n",
      "SNR: 0/30, LS_CNN, Epoch 35/50, Loss: 0.29643089903725517 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2913167327642441\n",
      "SNR: 0/30, LS_CNN, Epoch 36/50, Loss: 0.29721399479442173 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2896559384206067\n",
      "SNR: 0/30, LS_CNN, Epoch 37/50, Loss: 0.29397039943271214 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28416350062774576\n",
      "SNR: 0/30, LS_CNN, Epoch 38/50, Loss: 0.29397688392135835 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28249892527642456\n",
      "SNR: 0/30, LS_CNN, Epoch 39/50, Loss: 0.2901908970541424 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2804273538615393\n",
      "SNR: 0/30, LS_CNN, Epoch 40/50, Loss: 0.28762741138537723 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2783126011490822\n",
      "SNR: 0/30, LS_CNN, Epoch 41/50, Loss: 0.2886411299308141 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.277989756801854\n",
      "SNR: 0/30, LS_CNN, Epoch 42/50, Loss: 0.290742395652665 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2740120460157809\n",
      "SNR: 0/30, LS_CNN, Epoch 43/50, Loss: 0.29039863331450355 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.27329486932443536\n",
      "SNR: 0/30, LS_CNN, Epoch 44/50, Loss: 0.2779355115360684 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2713601977928825\n",
      "SNR: 0/30, LS_CNN, Epoch 45/50, Loss: 0.2775727982322375 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.26919019319441007\n",
      "SNR: 0/30, LS_CNN, Epoch 46/50, Loss: 0.2769237930576007 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.26596515560927597\n",
      "SNR: 0/30, LS_CNN, Epoch 47/50, Loss: 0.27214610162708497 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2670757789974627\n",
      "SNR: 0/30, LS_CNN, Epoch 48/50, Loss: 0.2765304818749428 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2649840615365816\n",
      "SNR: 0/30, LS_CNN, Epoch 49/50, Loss: 0.2803083293967777 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2587467461176541\n",
      "SNR: 0/30, LS_CNN, Epoch 50/50, Loss: 0.2720588222146034 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2576820636573045\n",
      "LS+CNN NMSE: 0.05507321655750275\n",
      "LS+LI NMSE: 0.08189549297094345\n",
      "LS_LI_CNN model\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 1/50, Loss: 0.40022774206267464 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3929116596346316\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 2/50, Loss: 0.391252973013454 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3839420041312342\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3823067976368798 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.37516527201818384\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 4/50, Loss: 0.37355772654215497 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.36601927099020587\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3643837322791417 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3566672322542771\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 6/50, Loss: 0.35504351556301117 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.34748147557611053\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 7/50, Loss: 0.34550143116050297 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3380815477474876\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 8/50, Loss: 0.33566078378094566 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.32841767824214435\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 9/50, Loss: 0.3257531805170907 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.31905578141627106\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 10/50, Loss: 0.31573447585105896 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3089405868364417\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 11/50, Loss: 0.3055531216992272 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.29934301324512647\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2965500321653154 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.29016952637744986\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 13/50, Loss: 0.28669989274607766 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2815174457171689\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 14/50, Loss: 0.277951267030504 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2727616759745971\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2698441702458594 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26490448739217676\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 16/50, Loss: 0.2616445869207382 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2578525497861531\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 17/50, Loss: 0.2548585856954257 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2517835640388986\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 18/50, Loss: 0.24712438053554958 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.24600132166043573\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 19/50, Loss: 0.24163692858484057 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.24020236924938534\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 20/50, Loss: 0.2367464303970337 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2360012200863465\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 21/50, Loss: 0.23208244807190365 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23233139936042868\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 22/50, Loss: 0.2276836782693863 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22910758658595706\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 23/50, Loss: 0.2249719285302692 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22672102373579275\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 24/50, Loss: 0.22266269309653175 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22435828946206882\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 25/50, Loss: 0.22073410120275286 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22320421590753223\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 26/50, Loss: 0.21925041907363468 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22178798557623572\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 27/50, Loss: 0.21749850114186606 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22073793799980826\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 28/50, Loss: 0.2162458093629943 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22015372922886972\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 29/50, Loss: 0.21603583544492722 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21968151240245157\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 30/50, Loss: 0.21390384518437916 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2196562646523766\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 31/50, Loss: 0.21327208313677046 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2194607423051544\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 32/50, Loss: 0.21348648683892357 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21925734760968582\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 33/50, Loss: 0.21463164024882847 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21892390950866367\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 34/50, Loss: 0.21382843289110395 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21899817819180695\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 35/50, Loss: 0.21403333958652285 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2190320281230885\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 36/50, Loss: 0.21433829681740868 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2192730735177579\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 37/50, Loss: 0.21344033628702164 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21890520012896994\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 38/50, Loss: 0.21433224942949083 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2191951893593954\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 39/50, Loss: 0.21226212051179674 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21899068064015845\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 40/50, Loss: 0.2138608859644996 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21928866531537927\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 41/50, Loss: 0.21478503031863105 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21902352506699768\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 42/50, Loss: 0.2142007259858979 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2195046009576839\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 43/50, Loss: 0.21289904746744368 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21916790015023688\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 44/50, Loss: 0.2130911292301284 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21927510363900143\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 45/50, Loss: 0.21235458966758516 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21898893590854562\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 46/50, Loss: 0.21250390344195896 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21884956308033154\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 47/50, Loss: 0.21325469265381494 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21931531604217447\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 48/50, Loss: 0.21442238158649868 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21921139566794687\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 49/50, Loss: 0.21086279965109295 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21938383741223294\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 50/50, Loss: 0.21437863094939125 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21903569575237192\n",
      "LS+CNN NMSE: 0.034590546041727066\n",
      " SNR: 5/30\n",
      "LS_CNN model\n",
      "SNR: 5/30, LS_CNN, Epoch 1/50, Loss: 0.3954480356640286 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3909272298864696\n",
      "SNR: 5/30, LS_CNN, Epoch 2/50, Loss: 0.3928215305010478 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3888592648765315\n",
      "SNR: 5/30, LS_CNN, Epoch 3/50, Loss: 0.38984717263115776 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3861376280369966\n",
      "SNR: 5/30, LS_CNN, Epoch 4/50, Loss: 0.38730332917637295 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.38364231197730353\n",
      "SNR: 5/30, LS_CNN, Epoch 5/50, Loss: 0.3847028878000047 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.38089074388794275\n",
      "SNR: 5/30, LS_CNN, Epoch 6/50, Loss: 0.3815603769487805 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3776586088149444\n",
      "SNR: 5/30, LS_CNN, Epoch 7/50, Loss: 0.37870319187641144 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.37482901630194293\n",
      "SNR: 5/30, LS_CNN, Epoch 8/50, Loss: 0.3755712972746955 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3718133834393128\n",
      "SNR: 5/30, LS_CNN, Epoch 9/50, Loss: 0.37203554146819645 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.36851226829964184\n",
      "SNR: 5/30, LS_CNN, Epoch 10/50, Loss: 0.36858721739716 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3649233994276627\n",
      "SNR: 5/30, LS_CNN, Epoch 11/50, Loss: 0.3655976355075836 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.36141609497692273\n",
      "SNR: 5/30, LS_CNN, Epoch 12/50, Loss: 0.36162536011801827 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.35800224866556085\n",
      "SNR: 5/30, LS_CNN, Epoch 13/50, Loss: 0.35775408645470935 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3543283952319104\n",
      "SNR: 5/30, LS_CNN, Epoch 14/50, Loss: 0.3545447273386849 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.34987780905288196\n",
      "SNR: 5/30, LS_CNN, Epoch 15/50, Loss: 0.351099474562539 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3466037583091985\n",
      "SNR: 5/30, LS_CNN, Epoch 16/50, Loss: 0.3482665717601776 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3427514556957328\n",
      "SNR: 5/30, LS_CNN, Epoch 17/50, Loss: 0.34294382399982876 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.34012213349342346\n",
      "SNR: 5/30, LS_CNN, Epoch 18/50, Loss: 0.3393523080481423 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.33675983936890314\n",
      "SNR: 5/30, LS_CNN, Epoch 19/50, Loss: 0.33634046382374233 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3319500412629998\n",
      "SNR: 5/30, LS_CNN, Epoch 20/50, Loss: 0.3321348312828276 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3281717164360959\n",
      "SNR: 5/30, LS_CNN, Epoch 21/50, Loss: 0.3290018505520291 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.32351073233977606\n",
      "SNR: 5/30, LS_CNN, Epoch 22/50, Loss: 0.32579612400796676 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3199925325486971\n",
      "SNR: 5/30, LS_CNN, Epoch 23/50, Loss: 0.3224884337849087 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3161695353362871\n",
      "SNR: 5/30, LS_CNN, Epoch 24/50, Loss: 0.31766549083921647 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3140778612831365\n",
      "SNR: 5/30, LS_CNN, Epoch 25/50, Loss: 0.313746851351526 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30982036823811737\n",
      "SNR: 5/30, LS_CNN, Epoch 26/50, Loss: 0.31204801466729903 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30517839543197467\n",
      "SNR: 5/30, LS_CNN, Epoch 27/50, Loss: 0.3160184919834137 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30299494285946305\n",
      "SNR: 5/30, LS_CNN, Epoch 28/50, Loss: 0.3048357102606032 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30122560683799826\n",
      "SNR: 5/30, LS_CNN, Epoch 29/50, Loss: 0.2998320957024892 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2966008856892586\n",
      "SNR: 5/30, LS_CNN, Epoch 30/50, Loss: 0.296133225162824 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.29376830128224\n",
      "SNR: 5/30, LS_CNN, Epoch 31/50, Loss: 0.3010956702960862 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2909507602453232\n",
      "SNR: 5/30, LS_CNN, Epoch 32/50, Loss: 0.2954055021206538 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.284764294391093\n",
      "SNR: 5/30, LS_CNN, Epoch 33/50, Loss: 0.28999758180644775 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.28377681225538254\n",
      "SNR: 5/30, LS_CNN, Epoch 34/50, Loss: 0.2805447305242221 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2799701382932456\n",
      "SNR: 5/30, LS_CNN, Epoch 35/50, Loss: 0.28165360871288514 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27902264439541363\n",
      "SNR: 5/30, LS_CNN, Epoch 36/50, Loss: 0.2775716293189261 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2741789610489555\n",
      "SNR: 5/30, LS_CNN, Epoch 37/50, Loss: 0.2786212315162023 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26879642126352893\n",
      "SNR: 5/30, LS_CNN, Epoch 38/50, Loss: 0.2723794976870219 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26625873828711716\n",
      "SNR: 5/30, LS_CNN, Epoch 39/50, Loss: 0.27937417725721997 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2641073222393575\n",
      "SNR: 5/30, LS_CNN, Epoch 40/50, Loss: 0.26496338182025486 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2597638595363368\n",
      "SNR: 5/30, LS_CNN, Epoch 41/50, Loss: 0.26499169651005006 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2548533231019974\n",
      "SNR: 5/30, LS_CNN, Epoch 42/50, Loss: 0.2664039855202039 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2535829835611841\n",
      "SNR: 5/30, LS_CNN, Epoch 43/50, Loss: 0.25359320143858594 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24851575429024902\n",
      "SNR: 5/30, LS_CNN, Epoch 44/50, Loss: 0.25556153969632256 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24864207661670187\n",
      "SNR: 5/30, LS_CNN, Epoch 45/50, Loss: 0.24960627655188242 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24451349416504736\n",
      "SNR: 5/30, LS_CNN, Epoch 46/50, Loss: 0.2516005403465695 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24069866959167563\n",
      "SNR: 5/30, LS_CNN, Epoch 47/50, Loss: 0.24043592313925424 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23532958620268365\n",
      "SNR: 5/30, LS_CNN, Epoch 48/50, Loss: 0.24327991488907072 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23603991807802863\n",
      "SNR: 5/30, LS_CNN, Epoch 49/50, Loss: 0.24633053690195084 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23069326158450998\n",
      "SNR: 5/30, LS_CNN, Epoch 50/50, Loss: 0.24416694955693352 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2254129035965256\n",
      "LS+CNN NMSE: 0.03976106643676758\n",
      "LS+LI NMSE: 0.025828612968325615\n",
      "LS_LI_CNN model\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 1/50, Loss: 0.39955780075656044 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3930489472720934\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 2/50, Loss: 0.391545703013738 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.38533342338126636\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 3/50, Loss: 0.38361865116490257 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3775133788585663\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3754776418209076 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.36922084183796594\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3668755061096615 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3605863717587098\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 6/50, Loss: 0.35775967604584163 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3515825440054354\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3478340556224187 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3413343546183213\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 8/50, Loss: 0.33729366461435956 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3307916826528052\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 9/50, Loss: 0.32572563820415074 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.319247300858083\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 10/50, Loss: 0.3132930099964142 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.30637344394041144\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 11/50, Loss: 0.30055582688914406 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2941415841164796\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 12/50, Loss: 0.28731463352839154 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2809149736295576\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 13/50, Loss: 0.2736279633310106 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2680049661708915\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 14/50, Loss: 0.2601281214091513 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2546000636142233\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2463893476459715 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2421582457811936\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 16/50, Loss: 0.23315502454837164 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.23037260673616244\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 17/50, Loss: 0.2208839456240336 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.21812769414290137\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 18/50, Loss: 0.20946649379200405 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2076097519501396\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 19/50, Loss: 0.19818716827366087 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.19938578845366187\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 20/50, Loss: 0.18933135684993532 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.18940717662158219\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 21/50, Loss: 0.1800939275158776 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.18254374064829038\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 22/50, Loss: 0.17322994603051078 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17530075655035351\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 23/50, Loss: 0.16689857468008995 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17000219614609427\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 24/50, Loss: 0.1620093004571067 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16524657995804495\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 25/50, Loss: 0.15786731615662575 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16201487604690634\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 26/50, Loss: 0.1534844185743067 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15877184741522954\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 27/50, Loss: 0.15068165709575018 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1565541877694752\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 28/50, Loss: 0.148817152198818 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15464172852428062\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 29/50, Loss: 0.14691300897134674 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1532836860936621\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 30/50, Loss: 0.14510568065775764 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15215123622961665\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 31/50, Loss: 0.14421827097733816 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1514874606028847\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 32/50, Loss: 0.14296010260780653 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15086750248851982\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 33/50, Loss: 0.14311212549606958 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15053541682984517\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 34/50, Loss: 0.14240401983261108 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15028604654514272\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 35/50, Loss: 0.1416504809425937 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15022361051777136\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 36/50, Loss: 0.14101884100172254 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1499143587830274\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 37/50, Loss: 0.1405748145447837 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14988663063749022\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 38/50, Loss: 0.13987283946739304 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1498819544263508\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 39/50, Loss: 0.14084860765271717 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14975932078517\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 40/50, Loss: 0.1408816104133924 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.149712647108928\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 41/50, Loss: 0.14089975961380535 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14980991265696028\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 42/50, Loss: 0.139249281750785 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14980772072854248\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 43/50, Loss: 0.14093716690937677 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14980111190158388\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 44/50, Loss: 0.1408053326110045 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14969695197499316\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 45/50, Loss: 0.14103907429509693 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14968982743828194\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 46/50, Loss: 0.1393064988984002 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1496705718986366\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 47/50, Loss: 0.14093556337886387 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14962171261077342\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 48/50, Loss: 0.1397000402212143 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.149598379821881\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 49/50, Loss: 0.14057068071431583 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.149643595451894\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 50/50, Loss: 0.14113541319966316 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1497383026973061\n",
      "LS+CNN NMSE: 0.017701905220746994\n",
      " SNR: 10/30\n",
      "LS_CNN model\n",
      "SNR: 10/30, LS_CNN, Epoch 1/50, Loss: 0.389216681321462 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3915499597787857\n",
      "SNR: 10/30, LS_CNN, Epoch 2/50, Loss: 0.38679110672738815 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3895652974429338\n",
      "SNR: 10/30, LS_CNN, Epoch 3/50, Loss: 0.38443677955203587 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3874243076728738\n",
      "SNR: 10/30, LS_CNN, Epoch 4/50, Loss: 0.3821209602885776 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38503897449244623\n",
      "SNR: 10/30, LS_CNN, Epoch 5/50, Loss: 0.37972276078330147 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.38263598926689313\n",
      "SNR: 10/30, LS_CNN, Epoch 6/50, Loss: 0.3770647197961807 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3799695547508157\n",
      "SNR: 10/30, LS_CNN, Epoch 7/50, Loss: 0.3743887527121438 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37732731518538104\n",
      "SNR: 10/30, LS_CNN, Epoch 8/50, Loss: 0.37135999732547337 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3744042723075203\n",
      "SNR: 10/30, LS_CNN, Epoch 9/50, Loss: 0.36783213416735333 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3713127815205118\n",
      "SNR: 10/30, LS_CNN, Epoch 10/50, Loss: 0.36469915840360856 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3677946108838786\n",
      "SNR: 10/30, LS_CNN, Epoch 11/50, Loss: 0.36191969282097286 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36458111457202746\n",
      "SNR: 10/30, LS_CNN, Epoch 12/50, Loss: 0.35835377540853286 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3611178126024163\n",
      "SNR: 10/30, LS_CNN, Epoch 13/50, Loss: 0.3552713642517726 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.35789323371389636\n",
      "SNR: 10/30, LS_CNN, Epoch 14/50, Loss: 0.35206440918975407 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.354935083700263\n",
      "SNR: 10/30, LS_CNN, Epoch 15/50, Loss: 0.3480572866068946 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3516806221526602\n",
      "SNR: 10/30, LS_CNN, Epoch 16/50, Loss: 0.3445041626691818 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34756340021672455\n",
      "SNR: 10/30, LS_CNN, Epoch 17/50, Loss: 0.34231234424644047 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34514908946078754\n",
      "SNR: 10/30, LS_CNN, Epoch 18/50, Loss: 0.34160050915347207 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34129999577999115\n",
      "SNR: 10/30, LS_CNN, Epoch 19/50, Loss: 0.335826286011272 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.33984513321648474\n",
      "SNR: 10/30, LS_CNN, Epoch 20/50, Loss: 0.3346320903963513 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3373832326868306\n",
      "SNR: 10/30, LS_CNN, Epoch 21/50, Loss: 0.33286450306574505 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3359005101349043\n",
      "SNR: 10/30, LS_CNN, Epoch 22/50, Loss: 0.3290650231970681 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3314349929923597\n",
      "SNR: 10/30, LS_CNN, Epoch 23/50, Loss: 0.3294209407435523 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3302234586166299\n",
      "SNR: 10/30, LS_CNN, Epoch 24/50, Loss: 0.32294809652699363 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32757245975991955\n",
      "SNR: 10/30, LS_CNN, Epoch 25/50, Loss: 0.32077912324004704 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32408058384190436\n",
      "SNR: 10/30, LS_CNN, Epoch 26/50, Loss: 0.32049878272745347 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3224108867023302\n",
      "SNR: 10/30, LS_CNN, Epoch 27/50, Loss: 0.317466644777192 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31907128186329553\n",
      "SNR: 10/30, LS_CNN, Epoch 28/50, Loss: 0.31270495222674477 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31567975619564886\n",
      "SNR: 10/30, LS_CNN, Epoch 29/50, Loss: 0.3122873587740792 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31668864773667377\n",
      "SNR: 10/30, LS_CNN, Epoch 30/50, Loss: 0.3098694731791814 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31273153812988946\n",
      "SNR: 10/30, LS_CNN, Epoch 31/50, Loss: 0.3070853286319309 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.30874573666116467\n",
      "SNR: 10/30, LS_CNN, Epoch 32/50, Loss: 0.30381785167588127 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.307169105047765\n",
      "SNR: 10/30, LS_CNN, Epoch 33/50, Loss: 0.3044628103574117 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3003000455058139\n",
      "SNR: 10/30, LS_CNN, Epoch 34/50, Loss: 0.301091601451238 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2980237677693367\n",
      "SNR: 10/30, LS_CNN, Epoch 35/50, Loss: 0.3011109944846895 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2967000153401624\n",
      "SNR: 10/30, LS_CNN, Epoch 36/50, Loss: 0.3044508281681273 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.295813814777395\n",
      "SNR: 10/30, LS_CNN, Epoch 37/50, Loss: 0.290965822007921 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.29371943583954935\n",
      "SNR: 10/30, LS_CNN, Epoch 38/50, Loss: 0.29029957784546745 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2932097464799881\n",
      "SNR: 10/30, LS_CNN, Epoch 39/50, Loss: 0.29139238430394065 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2919971146013426\n",
      "SNR: 10/30, LS_CNN, Epoch 40/50, Loss: 0.2842715316348606 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2860005157797233\n",
      "SNR: 10/30, LS_CNN, Epoch 41/50, Loss: 0.2876562260919147 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2846003323793411\n",
      "SNR: 10/30, LS_CNN, Epoch 42/50, Loss: 0.2844812464382913 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27943065892095154\n",
      "SNR: 10/30, LS_CNN, Epoch 43/50, Loss: 0.2778831910755899 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27815659506165463\n",
      "SNR: 10/30, LS_CNN, Epoch 44/50, Loss: 0.2736667642990748 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27513216306333954\n",
      "SNR: 10/30, LS_CNN, Epoch 45/50, Loss: 0.27555375960138107 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2738218514815621\n",
      "SNR: 10/30, LS_CNN, Epoch 46/50, Loss: 0.2747979594601525 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2707414267503697\n",
      "SNR: 10/30, LS_CNN, Epoch 47/50, Loss: 0.2647174331876967 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2665466928611631\n",
      "SNR: 10/30, LS_CNN, Epoch 48/50, Loss: 0.2680718128879865 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2618423813711042\n",
      "SNR: 10/30, LS_CNN, Epoch 49/50, Loss: 0.262531294590897 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.25850542796694714\n",
      "SNR: 10/30, LS_CNN, Epoch 50/50, Loss: 0.26230442110035157 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2581505869393763\n",
      "LS+CNN NMSE: 0.053661178797483444\n",
      "LS+LI NMSE: 0.008226335979998112\n",
      "LS_LI_CNN model\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3815022028154797 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.37946417927742004\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 2/50, Loss: 0.36555590728918713 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.36243567842504254\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3497364471356074 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3462004480154618\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3338073061572181 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3302229837231014\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 5/50, Loss: 0.317360070016649 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.31393168024394824\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3007403314113617 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.29697166771992395\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2834327634837892 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.27862393661685614\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 8/50, Loss: 0.2658965148859554 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.26152563840150833\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 9/50, Loss: 0.24856261826223797 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2437144044948661\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 10/50, Loss: 0.2312514086564382 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.22693686705568564\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 11/50, Loss: 0.21437445200151867 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2107178173635317\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 12/50, Loss: 0.19810610595676634 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1956655373391898\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 13/50, Loss: 0.1827827062871721 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.18065965175628662\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 14/50, Loss: 0.16852724386586082 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.16730007788409357\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 15/50, Loss: 0.15575443042649162 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.15480466041228044\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 16/50, Loss: 0.14361577108502388 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1439562320061352\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 17/50, Loss: 0.1333980311950048 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1354570805054644\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 18/50, Loss: 0.12464345080984963 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.12616787948038266\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 19/50, Loss: 0.1167997382581234 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.12051362592888915\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 20/50, Loss: 0.11052289812101258 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.11517182705195053\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 21/50, Loss: 0.10534568172362116 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.11147298137454884\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 22/50, Loss: 0.10092802718281746 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10763665539738924\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 23/50, Loss: 0.09795684367418289 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10464096514751083\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 24/50, Loss: 0.09527099194626014 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10224183648824692\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 25/50, Loss: 0.09370336929957072 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.10044882981025655\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 26/50, Loss: 0.09210279335578282 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0994321871548891\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 27/50, Loss: 0.09071899991896418 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.098387795743411\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 28/50, Loss: 0.08958751687573062 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09802088311508945\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 29/50, Loss: 0.09020343836810854 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09732535376172999\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 30/50, Loss: 0.08957570998205079 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09669865947216749\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 31/50, Loss: 0.08775093861752087 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09709536972577157\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 32/50, Loss: 0.08873541384107536 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09670331681390172\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 33/50, Loss: 0.08780888033409913 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09634097568366838\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 34/50, Loss: 0.0883127823472023 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09683670204780671\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 35/50, Loss: 0.08736496211753951 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0966214842122534\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 36/50, Loss: 0.08704886978699101 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09589336978514558\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 37/50, Loss: 0.08643528239594565 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.0965179651165786\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 38/50, Loss: 0.08689413881964153 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09611321475518786\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 39/50, Loss: 0.08731034232510461 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09551190050399821\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 40/50, Loss: 0.08736810295118226 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09553849871229866\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 41/50, Loss: 0.0863733295765188 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09559986015538806\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 42/50, Loss: 0.08653835662537152 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09542387622692015\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 43/50, Loss: 0.08669345370597309 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09565136699086946\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 44/50, Loss: 0.08683041669428349 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09564087422483641\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 45/50, Loss: 0.08630154861344232 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09556765327958958\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 46/50, Loss: 0.08675622277789646 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09528370375704506\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 47/50, Loss: 0.08600680550767316 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09521704434376696\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 48/50, Loss: 0.0863978819300731 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09497140647600526\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 49/50, Loss: 0.08672731493910153 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09477463643997908\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 50/50, Loss: 0.08615507971909311 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.09477675515834404\n",
      "LS+CNN NMSE: 0.011680427938699722\n",
      " SNR: 15/30\n",
      "LS_CNN model\n",
      "SNR: 15/30, LS_CNN, Epoch 1/50, Loss: 0.3803499357567893 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.39004223437412927\n",
      "SNR: 15/30, LS_CNN, Epoch 2/50, Loss: 0.37604153487417435 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.38677179942960327\n",
      "SNR: 15/30, LS_CNN, Epoch 3/50, Loss: 0.3715203387869729 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3826522904893626\n",
      "SNR: 15/30, LS_CNN, Epoch 4/50, Loss: 0.3672221038076613 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3781264093906983\n",
      "SNR: 15/30, LS_CNN, Epoch 5/50, Loss: 0.36268575655089486 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.37384288984796277\n",
      "SNR: 15/30, LS_CNN, Epoch 6/50, Loss: 0.3582618667019738 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3691902951053951\n",
      "SNR: 15/30, LS_CNN, Epoch 7/50, Loss: 0.35395902229679954 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.36456662027732184\n",
      "SNR: 15/30, LS_CNN, Epoch 8/50, Loss: 0.349143385887146 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.36010729100393213\n",
      "SNR: 15/30, LS_CNN, Epoch 9/50, Loss: 0.3441106064452065 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3552671172048735\n",
      "SNR: 15/30, LS_CNN, Epoch 10/50, Loss: 0.33954992559221053 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3504555458607881\n",
      "SNR: 15/30, LS_CNN, Epoch 11/50, Loss: 0.33453217811054653 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3460727334022522\n",
      "SNR: 15/30, LS_CNN, Epoch 12/50, Loss: 0.3302215569549137 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3407307649436204\n",
      "SNR: 15/30, LS_CNN, Epoch 13/50, Loss: 0.3265279614263111 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.33569287411544635\n",
      "SNR: 15/30, LS_CNN, Epoch 14/50, Loss: 0.3216031971904967 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.332349916515143\n",
      "SNR: 15/30, LS_CNN, Epoch 15/50, Loss: 0.31653714014424217 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3271234352951464\n",
      "SNR: 15/30, LS_CNN, Epoch 16/50, Loss: 0.31179313196076286 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.322518993978915\n",
      "SNR: 15/30, LS_CNN, Epoch 17/50, Loss: 0.30781331327226424 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.31815364892068115\n",
      "SNR: 15/30, LS_CNN, Epoch 18/50, Loss: 0.30333877934349907 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.31293241874031397\n",
      "SNR: 15/30, LS_CNN, Epoch 19/50, Loss: 0.297728949950801 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.30951052256252454\n",
      "SNR: 15/30, LS_CNN, Epoch 20/50, Loss: 0.2955688734849294 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.30327443519364233\n",
      "SNR: 15/30, LS_CNN, Epoch 21/50, Loss: 0.2929609931177563 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29967877657517145\n",
      "SNR: 15/30, LS_CNN, Epoch 22/50, Loss: 0.2867705358399285 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29551834775053937\n",
      "SNR: 15/30, LS_CNN, Epoch 23/50, Loss: 0.2847012248304155 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29292489005171735\n",
      "SNR: 15/30, LS_CNN, Epoch 24/50, Loss: 0.28195549961593414 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29009669857180637\n",
      "SNR: 15/30, LS_CNN, Epoch 25/50, Loss: 0.2758622293670972 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.28663207169460214\n",
      "SNR: 15/30, LS_CNN, Epoch 26/50, Loss: 0.273555892209212 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.28325940441826114\n",
      "SNR: 15/30, LS_CNN, Epoch 27/50, Loss: 0.27090812226136524 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.276106649118921\n",
      "SNR: 15/30, LS_CNN, Epoch 28/50, Loss: 0.2678183913230896 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2732351040062697\n",
      "SNR: 15/30, LS_CNN, Epoch 29/50, Loss: 0.2645261800951428 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.269707383668941\n",
      "SNR: 15/30, LS_CNN, Epoch 30/50, Loss: 0.2677796267800861 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2688236696564633\n",
      "SNR: 15/30, LS_CNN, Epoch 31/50, Loss: 0.2612926455007659 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.260425456840059\n",
      "SNR: 15/30, LS_CNN, Epoch 32/50, Loss: 0.25184738139311474 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25945316902969195\n",
      "SNR: 15/30, LS_CNN, Epoch 33/50, Loss: 0.2464941276444329 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25310381469519244\n",
      "SNR: 15/30, LS_CNN, Epoch 34/50, Loss: 0.2456371949778663 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2486630454659462\n",
      "SNR: 15/30, LS_CNN, Epoch 35/50, Loss: 0.24166834437184864 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2483491084497908\n",
      "SNR: 15/30, LS_CNN, Epoch 36/50, Loss: 0.23767043898502985 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2398880075501359\n",
      "SNR: 15/30, LS_CNN, Epoch 37/50, Loss: 0.23996690991852018 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23712277218051578\n",
      "SNR: 15/30, LS_CNN, Epoch 38/50, Loss: 0.23072518656651178 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.234369655666144\n",
      "SNR: 15/30, LS_CNN, Epoch 39/50, Loss: 0.25122252934508854 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22981667777766351\n",
      "SNR: 15/30, LS_CNN, Epoch 40/50, Loss: 0.23715393741925558 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2277986935299376\n",
      "SNR: 15/30, LS_CNN, Epoch 41/50, Loss: 0.224666571451558 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22605174617922824\n",
      "SNR: 15/30, LS_CNN, Epoch 42/50, Loss: 0.22329493860403696 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22445467762325122\n",
      "SNR: 15/30, LS_CNN, Epoch 43/50, Loss: 0.21681518769926494 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22235140528367914\n",
      "SNR: 15/30, LS_CNN, Epoch 44/50, Loss: 0.21244594785902235 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21890131286952808\n",
      "SNR: 15/30, LS_CNN, Epoch 45/50, Loss: 0.20949005004432467 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21279771107694376\n",
      "SNR: 15/30, LS_CNN, Epoch 46/50, Loss: 0.21166767842239803 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2119038782042006\n",
      "SNR: 15/30, LS_CNN, Epoch 47/50, Loss: 0.22520911031299168 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21292350635580395\n",
      "SNR: 15/30, LS_CNN, Epoch 48/50, Loss: 0.19892385767565834 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20418280946171802\n",
      "SNR: 15/30, LS_CNN, Epoch 49/50, Loss: 0.20943617241250145 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20224580265905545\n",
      "SNR: 15/30, LS_CNN, Epoch 50/50, Loss: 0.19871861818763945 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19841603675614233\n",
      "LS+CNN NMSE: 0.03530459851026535\n",
      "LS+LI NMSE: 0.0026010889559984207\n",
      "LS_LI_CNN model\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37965970900323653 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3898455947637558\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 2/50, Loss: 0.373331003718906 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.38280635877795843\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 3/50, Loss: 0.36677175760269165 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.37588919958342676\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 4/50, Loss: 0.35979654722743565 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.36849785434163135\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3522401750087738 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3607056024281875\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 6/50, Loss: 0.34399523172113633 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.351787238665249\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 7/50, Loss: 0.33497607873545754 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.34201470211796137\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 8/50, Loss: 0.32499497797754073 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.33207652685434924\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 9/50, Loss: 0.3141879522138172 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.32023633563000226\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 10/50, Loss: 0.30224432713455623 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.30837753998196643\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 11/50, Loss: 0.2894407792223824 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2945412896249605\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2761959599124061 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2807876312214395\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 13/50, Loss: 0.2618953668408924 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2668083685895671\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 14/50, Loss: 0.24740483777390587 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.25130089145639667\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2327421853939692 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.23590025240960327\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 16/50, Loss: 0.21786395957072577 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.22058651207581811\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 17/50, Loss: 0.20316974156432682 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.20608064078766367\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 18/50, Loss: 0.18882405426767138 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1916065999995107\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 19/50, Loss: 0.17475893679592344 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.17760299826445786\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 20/50, Loss: 0.1615066925684611 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.16451232750778613\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 21/50, Loss: 0.1488205281396707 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.15220469430736874\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 22/50, Loss: 0.13716045684284633 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.14218048184462215\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 23/50, Loss: 0.1264504740635554 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.13076530899042668\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 24/50, Loss: 0.11645128536555502 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1198795709920966\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 25/50, Loss: 0.10708877071738243 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.11128786578774452\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 26/50, Loss: 0.09904995933175087 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.1027259400681309\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 27/50, Loss: 0.09192291316058901 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.09579859333841698\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 28/50, Loss: 0.08569836326771313 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08938530241341694\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 29/50, Loss: 0.0802015471789572 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08390550355872382\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 30/50, Loss: 0.07520771957933903 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07887956394773463\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 31/50, Loss: 0.07129127615027958 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07503650418442229\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 32/50, Loss: 0.06764388870861796 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0714106350813223\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 33/50, Loss: 0.06511888280510902 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06943603904674882\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 34/50, Loss: 0.06301037180754873 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0669052928848111\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 35/50, Loss: 0.06093116642700301 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06468387863234333\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 36/50, Loss: 0.05912363467117151 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06286455002491889\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 37/50, Loss: 0.058153800666332245 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.06149398778443751\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 38/50, Loss: 0.05657427778674497 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.060547143139916916\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 39/50, Loss: 0.05624950242539247 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05951383863778218\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 40/50, Loss: 0.05553040322330263 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.058826568010060684\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 41/50, Loss: 0.05540119277106391 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05834635594130858\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 42/50, Loss: 0.05467800940904352 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05782166896792858\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 43/50, Loss: 0.05462877214368847 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057587940650789635\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 44/50, Loss: 0.0545091742856635 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.057505291279243385\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 45/50, Loss: 0.05415243510570791 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05718658297606136\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 46/50, Loss: 0.05349752751903401 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05693813798058292\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 47/50, Loss: 0.05355731646219889 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05664792588061612\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 48/50, Loss: 0.05399752097825209 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.056572692590239254\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 49/50, Loss: 0.05378337742553817 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05643234146839898\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 50/50, Loss: 0.053080865595903665 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.05649145639946927\n",
      "LS+CNN NMSE: 0.005861436482518911\n",
      " SNR: 20/30\n",
      "LS_CNN model\n",
      "SNR: 20/30, LS_CNN, Epoch 1/50, Loss: 0.39069540136390263 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3896519463995229\n",
      "SNR: 20/30, LS_CNN, Epoch 2/50, Loss: 0.38651163544919753 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3854676945054013\n",
      "SNR: 20/30, LS_CNN, Epoch 3/50, Loss: 0.3823080476787355 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.38133184158283734\n",
      "SNR: 20/30, LS_CNN, Epoch 4/50, Loss: 0.37829627096652985 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.376792355724003\n",
      "SNR: 20/30, LS_CNN, Epoch 5/50, Loss: 0.37419983247915906 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3726537247066912\n",
      "SNR: 20/30, LS_CNN, Epoch 6/50, Loss: 0.36975594361623126 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.36834895805172296\n",
      "SNR: 20/30, LS_CNN, Epoch 7/50, Loss: 0.3650090495745341 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3637576297573421\n",
      "SNR: 20/30, LS_CNN, Epoch 8/50, Loss: 0.3607310503721237 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3589948344489802\n",
      "SNR: 20/30, LS_CNN, Epoch 9/50, Loss: 0.3561300453212526 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.353644922375679\n",
      "SNR: 20/30, LS_CNN, Epoch 10/50, Loss: 0.35102394223213196 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.34898162535999133\n",
      "SNR: 20/30, LS_CNN, Epoch 11/50, Loss: 0.3458549661768807 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3436452519634496\n",
      "SNR: 20/30, LS_CNN, Epoch 12/50, Loss: 0.34201110402743023 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3379797443099644\n",
      "SNR: 20/30, LS_CNN, Epoch 13/50, Loss: 0.33624253008100724 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3333365172147751\n",
      "SNR: 20/30, LS_CNN, Epoch 14/50, Loss: 0.3315303987926907 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.327504509816999\n",
      "SNR: 20/30, LS_CNN, Epoch 15/50, Loss: 0.32700737648540074 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.32298314571380615\n",
      "SNR: 20/30, LS_CNN, Epoch 16/50, Loss: 0.32234761118888855 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3182739382204802\n",
      "SNR: 20/30, LS_CNN, Epoch 17/50, Loss: 0.31786253717210555 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3133591160826061\n",
      "SNR: 20/30, LS_CNN, Epoch 18/50, Loss: 0.31274867057800293 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.30877412726049835\n",
      "SNR: 20/30, LS_CNN, Epoch 19/50, Loss: 0.3110723677608702 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.30357346197833185\n",
      "SNR: 20/30, LS_CNN, Epoch 20/50, Loss: 0.3047998630338245 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.30014838181112125\n",
      "SNR: 20/30, LS_CNN, Epoch 21/50, Loss: 0.30306359628836316 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.29464797999547876\n",
      "SNR: 20/30, LS_CNN, Epoch 22/50, Loss: 0.2981286644935608 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2914679805221765\n",
      "SNR: 20/30, LS_CNN, Epoch 23/50, Loss: 0.297876238822937 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.28761678221433057\n",
      "SNR: 20/30, LS_CNN, Epoch 24/50, Loss: 0.2908588780297173 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2844572682743487\n",
      "SNR: 20/30, LS_CNN, Epoch 25/50, Loss: 0.2857431670029958 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2816985200928605\n",
      "SNR: 20/30, LS_CNN, Epoch 26/50, Loss: 0.28576256500350106 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2776791187732116\n",
      "SNR: 20/30, LS_CNN, Epoch 27/50, Loss: 0.27961928728553986 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2741279660359673\n",
      "SNR: 20/30, LS_CNN, Epoch 28/50, Loss: 0.27973681605524486 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2696146482358808\n",
      "SNR: 20/30, LS_CNN, Epoch 29/50, Loss: 0.2767564695742395 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2667597337909367\n",
      "SNR: 20/30, LS_CNN, Epoch 30/50, Loss: 0.27180298003885484 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.26426276758961054\n",
      "SNR: 20/30, LS_CNN, Epoch 31/50, Loss: 0.27238693667782676 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.26111240425835486\n",
      "SNR: 20/30, LS_CNN, Epoch 32/50, Loss: 0.26830392744806075 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.26002809146176215\n",
      "SNR: 20/30, LS_CNN, Epoch 33/50, Loss: 0.27317477100425297 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2548476736182752\n",
      "SNR: 20/30, LS_CNN, Epoch 34/50, Loss: 0.26525600751241046 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2525147381036178\n",
      "SNR: 20/30, LS_CNN, Epoch 35/50, Loss: 0.2601524235473739 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25129160770903464\n",
      "SNR: 20/30, LS_CNN, Epoch 36/50, Loss: 0.25816598037878674 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2476246612875358\n",
      "SNR: 20/30, LS_CNN, Epoch 37/50, Loss: 0.25709067781766254 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24723346077877542\n",
      "SNR: 20/30, LS_CNN, Epoch 38/50, Loss: 0.25951700905958813 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24834390438121298\n",
      "SNR: 20/30, LS_CNN, Epoch 39/50, Loss: 0.25050366752677494 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24170607587565546\n",
      "SNR: 20/30, LS_CNN, Epoch 40/50, Loss: 0.24550534536441168 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.240434762576352\n",
      "SNR: 20/30, LS_CNN, Epoch 41/50, Loss: 0.2685153790646129 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23884925570176996\n",
      "SNR: 20/30, LS_CNN, Epoch 42/50, Loss: 0.24533166156874764 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23647917353588602\n",
      "SNR: 20/30, LS_CNN, Epoch 43/50, Loss: 0.24373326947291693 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23569837795651477\n",
      "SNR: 20/30, LS_CNN, Epoch 44/50, Loss: 0.236076387266318 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23317934151576913\n",
      "SNR: 20/30, LS_CNN, Epoch 45/50, Loss: 0.24354009495841134 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.234703182850195\n",
      "SNR: 20/30, LS_CNN, Epoch 46/50, Loss: 0.24774442778693306 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23174252620209818\n",
      "SNR: 20/30, LS_CNN, Epoch 47/50, Loss: 0.23712235854731667 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22788228710060535\n",
      "SNR: 20/30, LS_CNN, Epoch 48/50, Loss: 0.23616855674319798 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22437612841958585\n",
      "SNR: 20/30, LS_CNN, Epoch 49/50, Loss: 0.23844930860731336 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2204348043255184\n",
      "SNR: 20/30, LS_CNN, Epoch 50/50, Loss: 0.2372351735830307 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22003304245679275\n",
      "LS+CNN NMSE: 0.04508218914270401\n",
      "LS+LI NMSE: 0.0008186895283870399\n",
      "LS_LI_CNN model\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37489007744524216 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3710116912489352\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3598676042424308 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.35551321700863214\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3448605239391327 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.33981448476729187\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 4/50, Loss: 0.32963814669185215 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3239040970802307\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3141280644469791 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3076821831257447\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 6/50, Loss: 0.29832631680700517 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.29321219415768335\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2824985567066405 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.2765574656102968\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 8/50, Loss: 0.2664826015631358 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.26024396749942197\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 9/50, Loss: 0.25058290031221175 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.24397293737401132\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 10/50, Loss: 0.2347140543990665 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.22774624338616495\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 11/50, Loss: 0.21898343165715536 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.21252024692037833\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 12/50, Loss: 0.20354611012670729 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1976911033625188\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 13/50, Loss: 0.18871444546514088 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1820592990388041\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 14/50, Loss: 0.17437510192394257 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1673088264854058\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 15/50, Loss: 0.16041283392243916 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.15404170783965485\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 16/50, Loss: 0.14730442729261187 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1420398897126965\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 17/50, Loss: 0.13513212733798557 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.12914128293809685\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 18/50, Loss: 0.12347214420636494 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.11827141176099362\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 19/50, Loss: 0.11283132309714954 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.10835850076830905\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 20/50, Loss: 0.10299458313319418 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.09825278915788817\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 21/50, Loss: 0.09427599981427193 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.08986842211173929\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 22/50, Loss: 0.08631899870104259 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.08227874824534291\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 23/50, Loss: 0.07910013571381569 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.07503716566640398\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 24/50, Loss: 0.07300181604093975 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06976582660623219\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 25/50, Loss: 0.06761127068764633 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06519785993125128\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 26/50, Loss: 0.06258743877212207 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06030408349698004\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 27/50, Loss: 0.05853903873099221 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05609106855547946\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 28/50, Loss: 0.05530076391167111 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.052487198951775615\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 29/50, Loss: 0.0525858166317145 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05044894624987374\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 30/50, Loss: 0.04998359208305677 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04841459554660579\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 31/50, Loss: 0.048226819994548954 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.046149644433804184\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 32/50, Loss: 0.04662380636566215 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0449337861298219\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 33/50, Loss: 0.044917873210377164 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04364042016475097\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 34/50, Loss: 0.044377805665135384 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.042370782476728375\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 35/50, Loss: 0.04330563089913792 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04133746797299903\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 36/50, Loss: 0.04288864218526416 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04103789523081935\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 37/50, Loss: 0.042408307186431356 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04041222960728666\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 38/50, Loss: 0.0420251629418797 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.04014703882453234\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 39/50, Loss: 0.04119035746488306 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03992815534381763\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 40/50, Loss: 0.04073985469424062 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03922476623531269\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 41/50, Loss: 0.040865942214926086 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.039153014755119446\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 42/50, Loss: 0.04029968794849184 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.039036980911117534\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 43/50, Loss: 0.040944697024921574 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.038896798885062984\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 44/50, Loss: 0.04074378922167751 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03836714472297741\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 45/50, Loss: 0.04038403359138303 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03857389833454205\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 46/50, Loss: 0.040348410399423704 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03849184521190498\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 47/50, Loss: 0.039924328629341393 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03807239667714938\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 48/50, Loss: 0.04004005135761367 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03825418711842402\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 49/50, Loss: 0.03938758994142214 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03817918989807367\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 50/50, Loss: 0.03953339004268249 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.03793214540928602\n",
      "LS+CNN NMSE: 0.004872754216194153\n",
      " SNR: 25/30\n",
      "LS_CNN model\n",
      "SNR: 25/30, LS_CNN, Epoch 1/50, Loss: 0.38918161226643455 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3904751973307651\n",
      "SNR: 25/30, LS_CNN, Epoch 2/50, Loss: 0.38667334119478863 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38837324471577356\n",
      "SNR: 25/30, LS_CNN, Epoch 3/50, Loss: 0.38408705923292374 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38586750820926996\n",
      "SNR: 25/30, LS_CNN, Epoch 4/50, Loss: 0.3812624017397563 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38304939218189404\n",
      "SNR: 25/30, LS_CNN, Epoch 5/50, Loss: 0.37828071415424347 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.37999293013759283\n",
      "SNR: 25/30, LS_CNN, Epoch 6/50, Loss: 0.3749147918489244 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3766113422487093\n",
      "SNR: 25/30, LS_CNN, Epoch 7/50, Loss: 0.3714371389812893 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.37291519149490027\n",
      "SNR: 25/30, LS_CNN, Epoch 8/50, Loss: 0.36789942781130475 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.36935042622296704\n",
      "SNR: 25/30, LS_CNN, Epoch 9/50, Loss: 0.3639347702264786 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3655281695334808\n",
      "SNR: 25/30, LS_CNN, Epoch 10/50, Loss: 0.36014171606964535 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3606980384691902\n",
      "SNR: 25/30, LS_CNN, Epoch 11/50, Loss: 0.3554613259103563 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3568553432174351\n",
      "SNR: 25/30, LS_CNN, Epoch 12/50, Loss: 0.35108720428413814 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.35237999778726825\n",
      "SNR: 25/30, LS_CNN, Epoch 13/50, Loss: 0.34650107224782306 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.34769457708234375\n",
      "SNR: 25/30, LS_CNN, Epoch 14/50, Loss: 0.3423658079571194 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3433871418237686\n",
      "SNR: 25/30, LS_CNN, Epoch 15/50, Loss: 0.33656403919061023 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.33908913316934003\n",
      "SNR: 25/30, LS_CNN, Epoch 16/50, Loss: 0.3330645014842351 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3338821556257165\n",
      "SNR: 25/30, LS_CNN, Epoch 17/50, Loss: 0.3298393223020766 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.33001487864100415\n",
      "SNR: 25/30, LS_CNN, Epoch 18/50, Loss: 0.3253839926587211 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.32781939662021137\n",
      "SNR: 25/30, LS_CNN, Epoch 19/50, Loss: 0.3232956561777327 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.323004435909831\n",
      "SNR: 25/30, LS_CNN, Epoch 20/50, Loss: 0.31610633101728225 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3193039712698563\n",
      "SNR: 25/30, LS_CNN, Epoch 21/50, Loss: 0.3140207413170073 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3139241383127544\n",
      "SNR: 25/30, LS_CNN, Epoch 22/50, Loss: 0.31054627729786766 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3099989978515584\n",
      "SNR: 25/30, LS_CNN, Epoch 23/50, Loss: 0.30701473189724815 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.30617318269999133\n",
      "SNR: 25/30, LS_CNN, Epoch 24/50, Loss: 0.3024660266107983 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.302509018584438\n",
      "SNR: 25/30, LS_CNN, Epoch 25/50, Loss: 0.2972790565755632 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2980362063516741\n",
      "SNR: 25/30, LS_CNN, Epoch 26/50, Loss: 0.2957541843255361 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.29503217339515686\n",
      "SNR: 25/30, LS_CNN, Epoch 27/50, Loss: 0.2941823965973324 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.29402395564576855\n",
      "SNR: 25/30, LS_CNN, Epoch 28/50, Loss: 0.2912741286887063 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28967207896968594\n",
      "SNR: 25/30, LS_CNN, Epoch 29/50, Loss: 0.28854253474209046 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2869682668343834\n",
      "SNR: 25/30, LS_CNN, Epoch 30/50, Loss: 0.2859451389975018 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28138087203969125\n",
      "SNR: 25/30, LS_CNN, Epoch 31/50, Loss: 0.2757251072261069 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2759949513103651\n",
      "SNR: 25/30, LS_CNN, Epoch 32/50, Loss: 0.2755696036749416 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.27501647498296655\n",
      "SNR: 25/30, LS_CNN, Epoch 33/50, Loss: 0.2742510363459587 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2724766941822093\n",
      "SNR: 25/30, LS_CNN, Epoch 34/50, Loss: 0.2684675281246503 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.26517830335575604\n",
      "SNR: 25/30, LS_CNN, Epoch 35/50, Loss: 0.26555869314405656 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2631182667353879\n",
      "SNR: 25/30, LS_CNN, Epoch 36/50, Loss: 0.2635190437237422 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.25972264875536377\n",
      "SNR: 25/30, LS_CNN, Epoch 37/50, Loss: 0.2584936031036907 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.257696405377077\n",
      "SNR: 25/30, LS_CNN, Epoch 38/50, Loss: 0.2608786125977834 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.25510207952364633\n",
      "SNR: 25/30, LS_CNN, Epoch 39/50, Loss: 0.263140475584401 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2516058923109718\n",
      "SNR: 25/30, LS_CNN, Epoch 40/50, Loss: 0.2525768280029297 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24798830728168073\n",
      "SNR: 25/30, LS_CNN, Epoch 41/50, Loss: 0.24715399079852635 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24372642908407294\n",
      "SNR: 25/30, LS_CNN, Epoch 42/50, Loss: 0.24549676643477547 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24191115958535153\n",
      "SNR: 25/30, LS_CNN, Epoch 43/50, Loss: 0.24903705302211973 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23984186772419058\n",
      "SNR: 25/30, LS_CNN, Epoch 44/50, Loss: 0.24848399890793693 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23489114966081537\n",
      "SNR: 25/30, LS_CNN, Epoch 45/50, Loss: 0.23800328042772081 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23332979044188623\n",
      "SNR: 25/30, LS_CNN, Epoch 46/50, Loss: 0.23679571019278634 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22934225849483325\n",
      "SNR: 25/30, LS_CNN, Epoch 47/50, Loss: 0.23388691743214926 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23208336046208505\n",
      "SNR: 25/30, LS_CNN, Epoch 48/50, Loss: 0.2316886062423388 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2256439389741939\n",
      "SNR: 25/30, LS_CNN, Epoch 49/50, Loss: 0.23367377287811703 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22467489281426306\n",
      "SNR: 25/30, LS_CNN, Epoch 50/50, Loss: 0.2254380856951078 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.21830176853615305\n",
      "LS+CNN NMSE: 0.04420952871441841\n",
      "LS+LI NMSE: 0.0002610387746244669\n",
      "LS_LI_CNN model\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3703941024012036 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.36712429575298144\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 2/50, Loss: 0.35837697320514256 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3546616648850234\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3462556054194768 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.34198686804460443\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3336385852760739 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3291329747956732\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3204551703400082 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.31538404070812726\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 6/50, Loss: 0.30642331143220264 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3009003753895345\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2913816355996662 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.2850095875885176\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 8/50, Loss: 0.275522467162874 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.26851617156163504\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 9/50, Loss: 0.2588406569427914 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.25154077747593756\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 10/50, Loss: 0.24144337905777824 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.23387385289306226\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 11/50, Loss: 0.22342665410704082 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.2158759761115779\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2052607105837928 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.19757062164337738\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 13/50, Loss: 0.18689955439832476 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.17857490544733795\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 14/50, Loss: 0.1689766322573026 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.16083550436989122\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 15/50, Loss: 0.1515774503350258 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.14341613083429958\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 16/50, Loss: 0.13507578356398475 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.12745024636387825\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 17/50, Loss: 0.1193690655959977 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.11245877392913985\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 18/50, Loss: 0.1051947751806842 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.09936090186238289\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 19/50, Loss: 0.0920660172899564 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.08685767448142818\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 20/50, Loss: 0.0801413357257843 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.07563359266066033\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 21/50, Loss: 0.06974468442300956 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.06618946312886217\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 22/50, Loss: 0.06081362317005793 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.05715536439548368\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 23/50, Loss: 0.0536192332704862 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.050042191196395004\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 24/50, Loss: 0.046899486954013504 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04443075941146716\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 25/50, Loss: 0.041620594863262445 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.04045479333676074\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 26/50, Loss: 0.03735710670136743 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03630398639032374\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 27/50, Loss: 0.03410174325108528 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03322582533987968\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 28/50, Loss: 0.031234398277269468 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.030944526600448982\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 29/50, Loss: 0.029458864074614313 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02883320143851249\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 30/50, Loss: 0.02753462383730544 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027388818713876863\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 31/50, Loss: 0.0263698807814055 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.026311989964755332\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 32/50, Loss: 0.025477156405233674 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.025692429889560393\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 33/50, Loss: 0.02523342851135466 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.025168929066832945\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 34/50, Loss: 0.02458301895401544 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.024880562838085967\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 35/50, Loss: 0.0239322184998956 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.024504934569172885\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 36/50, Loss: 0.02350075863715675 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.024153850780314078\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 37/50, Loss: 0.023743317410763767 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02404306451385112\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 38/50, Loss: 0.023221411276608706 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02390130252941795\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 39/50, Loss: 0.02307803535626994 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023920980332743213\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 40/50, Loss: 0.023102756900091965 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023904440610710044\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 41/50, Loss: 0.022894349207894668 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02372071956810744\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 42/50, Loss: 0.023225148104959063 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02357333922839683\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 43/50, Loss: 0.022606444182909198 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023485992022830506\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 44/50, Loss: 0.023030893514967628 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023554935362999855\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 45/50, Loss: 0.02304417086351249 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023361410388884986\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 46/50, Loss: 0.02277663288017114 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02329630221483176\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 47/50, Loss: 0.02272530034598377 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02335986276359662\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 48/50, Loss: 0.022686232450521655 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023321679864159745\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 49/50, Loss: 0.022828067135479715 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.023393093112289258\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 50/50, Loss: 0.022323968561573163 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02329459051480112\n",
      "LS+CNN NMSE: 0.002465353813022375\n",
      " SNR: 30/30\n",
      "LS_CNN model\n",
      "SNR: 30/30, LS_CNN, Epoch 1/50, Loss: 0.39534835517406464 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3848403303519539\n",
      "SNR: 30/30, LS_CNN, Epoch 2/50, Loss: 0.39088255994849735 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3809851498707481\n",
      "SNR: 30/30, LS_CNN, Epoch 3/50, Loss: 0.3866218990749783 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.37713925993960834\n",
      "SNR: 30/30, LS_CNN, Epoch 4/50, Loss: 0.38287966781192356 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.37345057207605115\n",
      "SNR: 30/30, LS_CNN, Epoch 5/50, Loss: 0.37807127998934853 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3693233229543852\n",
      "SNR: 30/30, LS_CNN, Epoch 6/50, Loss: 0.373877646194564 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3652883346961892\n",
      "SNR: 30/30, LS_CNN, Epoch 7/50, Loss: 0.36939553419748944 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.36058393120765686\n",
      "SNR: 30/30, LS_CNN, Epoch 8/50, Loss: 0.3649599403142929 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.35655223869759106\n",
      "SNR: 30/30, LS_CNN, Epoch 9/50, Loss: 0.36065270834498936 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.35206386576528137\n",
      "SNR: 30/30, LS_CNN, Epoch 10/50, Loss: 0.35632243090205723 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3479862478764161\n",
      "SNR: 30/30, LS_CNN, Epoch 11/50, Loss: 0.3524559024307463 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.34358853620031604\n",
      "SNR: 30/30, LS_CNN, Epoch 12/50, Loss: 0.34774599803818596 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3400907095359719\n",
      "SNR: 30/30, LS_CNN, Epoch 13/50, Loss: 0.34419435759385425 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.33640364006809564\n",
      "SNR: 30/30, LS_CNN, Epoch 14/50, Loss: 0.3407311025593016 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3326812982559204\n",
      "SNR: 30/30, LS_CNN, Epoch 15/50, Loss: 0.336739397711224 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32962558710056805\n",
      "SNR: 30/30, LS_CNN, Epoch 16/50, Loss: 0.3336975971857707 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3264512309561605\n",
      "SNR: 30/30, LS_CNN, Epoch 17/50, Loss: 0.3326975239647759 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.322996177751085\n",
      "SNR: 30/30, LS_CNN, Epoch 18/50, Loss: 0.33053597145610386 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32103652539460553\n",
      "SNR: 30/30, LS_CNN, Epoch 19/50, Loss: 0.3271320660909017 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3177381896454355\n",
      "SNR: 30/30, LS_CNN, Epoch 20/50, Loss: 0.32355212006304 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.31561535046152445\n",
      "SNR: 30/30, LS_CNN, Epoch 21/50, Loss: 0.32247182064586216 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.31213715089404065\n",
      "SNR: 30/30, LS_CNN, Epoch 22/50, Loss: 0.3170229113764233 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3114480188359385\n",
      "SNR: 30/30, LS_CNN, Epoch 23/50, Loss: 0.3173627042108112 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.30713055639163306\n",
      "SNR: 30/30, LS_CNN, Epoch 24/50, Loss: 0.31352624628278947 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.305359724747098\n",
      "SNR: 30/30, LS_CNN, Epoch 25/50, Loss: 0.31117820408609176 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.30261011389286624\n",
      "SNR: 30/30, LS_CNN, Epoch 26/50, Loss: 0.30832354724407196 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3000983197403991\n",
      "SNR: 30/30, LS_CNN, Epoch 27/50, Loss: 0.308143009742101 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2974658640830413\n",
      "SNR: 30/30, LS_CNN, Epoch 28/50, Loss: 0.30204058355755276 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.29530361618684686\n",
      "SNR: 30/30, LS_CNN, Epoch 29/50, Loss: 0.30446414318349624 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2936624116871668\n",
      "SNR: 30/30, LS_CNN, Epoch 30/50, Loss: 0.29896556337674457 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2911525825443475\n",
      "SNR: 30/30, LS_CNN, Epoch 31/50, Loss: 0.29632601804203457 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.28975595145121863\n",
      "SNR: 30/30, LS_CNN, Epoch 32/50, Loss: 0.2923610458771388 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2880463263262873\n",
      "SNR: 30/30, LS_CNN, Epoch 33/50, Loss: 0.28832417064242893 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2838180068394412\n",
      "SNR: 30/30, LS_CNN, Epoch 34/50, Loss: 0.2922708061006334 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2835068051581797\n",
      "SNR: 30/30, LS_CNN, Epoch 35/50, Loss: 0.28916286097632515 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27830220888490265\n",
      "SNR: 30/30, LS_CNN, Epoch 36/50, Loss: 0.2868218504720264 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27491322030191834\n",
      "SNR: 30/30, LS_CNN, Epoch 37/50, Loss: 0.28458353959851795 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.271781578336073\n",
      "SNR: 30/30, LS_CNN, Epoch 38/50, Loss: 0.28130413260724807 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2715166648444922\n",
      "SNR: 30/30, LS_CNN, Epoch 39/50, Loss: 0.2854497904578845 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26789282067962317\n",
      "SNR: 30/30, LS_CNN, Epoch 40/50, Loss: 0.27485574864678913 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2661063693787741\n",
      "SNR: 30/30, LS_CNN, Epoch 41/50, Loss: 0.2741972373591529 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2648057454954023\n",
      "SNR: 30/30, LS_CNN, Epoch 42/50, Loss: 0.2682826866706212 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26159768648769544\n",
      "SNR: 30/30, LS_CNN, Epoch 43/50, Loss: 0.26798151847389007 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2588399671342062\n",
      "SNR: 30/30, LS_CNN, Epoch 44/50, Loss: 0.2615302817689048 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.25472541542156885\n",
      "SNR: 30/30, LS_CNN, Epoch 45/50, Loss: 0.26415469994147617 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2519709539154302\n",
      "SNR: 30/30, LS_CNN, Epoch 46/50, Loss: 0.2642592580782043 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24880713807499927\n",
      "SNR: 30/30, LS_CNN, Epoch 47/50, Loss: 0.2523854068583912 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24683103094930234\n",
      "SNR: 30/30, LS_CNN, Epoch 48/50, Loss: 0.25194739798704785 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24653516774592193\n",
      "SNR: 30/30, LS_CNN, Epoch 49/50, Loss: 0.25069888515604866 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24269742810207864\n",
      "SNR: 30/30, LS_CNN, Epoch 50/50, Loss: 0.2608930609292454 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23844155539637027\n",
      "LS+CNN NMSE: 0.05102764442563057\n",
      "LS+LI NMSE: 8.414323383476585e-05\n",
      "LS_LI_CNN model\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 1/50, Loss: 0.42337673405806225 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.4044835470292879\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 2/50, Loss: 0.40362487567795646 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3855648636817932\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 3/50, Loss: 0.38449650671746993 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.36677414697149524\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 4/50, Loss: 0.36551236112912494 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3479402447524278\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 5/50, Loss: 0.34634652071528965 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.32872120582539105\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 6/50, Loss: 0.32661834690305924 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.30920402381731116\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3063052064842648 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.28904713495917944\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 8/50, Loss: 0.28546467257870567 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.26786818646866345\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 9/50, Loss: 0.26407963699764675 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.24632786214351654\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 10/50, Loss: 0.24233831216891608 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.22503041216860648\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 11/50, Loss: 0.22060228221946293 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.2039457326350005\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 12/50, Loss: 0.1989579184187783 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.1832487518372743\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 13/50, Loss: 0.17775048977798885 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.16234040130739627\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 14/50, Loss: 0.15762313372559017 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.142643288101839\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 15/50, Loss: 0.13831351904405487 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.12493181503985239\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 16/50, Loss: 0.12052113231685427 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.10781873600638431\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 17/50, Loss: 0.10416050338082844 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0925897495902103\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 18/50, Loss: 0.08919932858811484 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.07874076465225738\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 19/50, Loss: 0.07625100906524393 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.06771264395312122\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 20/50, Loss: 0.06478996057477263 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.056246993334397026\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 21/50, Loss: 0.05521556321117613 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.048032855776988945\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 22/50, Loss: 0.04689435019261307 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.04039544814630695\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 23/50, Loss: 0.04068388479451338 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.034269656176152435\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 24/50, Loss: 0.0346376026670138 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03087819367647171\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 25/50, Loss: 0.030726530071761873 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0262836326804498\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 26/50, Loss: 0.02720769386117657 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.023570104907064335\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 27/50, Loss: 0.02450935087270207 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0212147598883704\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 28/50, Loss: 0.022414542889843386 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01948459542599385\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 29/50, Loss: 0.020554144659803972 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.018557066543270714\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 30/50, Loss: 0.019497755707965955 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.017368888816512797\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 31/50, Loss: 0.018804483219153352 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016802362561144906\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 32/50, Loss: 0.01832693791948259 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016329934476348368\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 33/50, Loss: 0.017470606628598437 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.016108353662749996\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 34/50, Loss: 0.01769150948772828 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01591856125742197\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 35/50, Loss: 0.017435749682287376 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015802642806311665\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 36/50, Loss: 0.017769749897221725 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015580213264278744\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 37/50, Loss: 0.017074767034500837 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015569474598716783\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 38/50, Loss: 0.01727276745562752 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01553595899199338\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 39/50, Loss: 0.016878966759476397 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015478118282297382\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 40/50, Loss: 0.01701732502422399 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01546231305996037\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 41/50, Loss: 0.017142466010732785 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015438198010720636\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 42/50, Loss: 0.01730501310278972 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015424729770292406\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 43/50, Loss: 0.01679596770554781 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015407492386420136\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 44/50, Loss: 0.01676354381359286 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015392571637083007\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 45/50, Loss: 0.016731193237420585 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015369620062815755\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 46/50, Loss: 0.016845499553407233 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015368323570684246\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 47/50, Loss: 0.016887684430306155 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015335988303970384\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 48/50, Loss: 0.016917914307365816 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015316232492256424\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 49/50, Loss: 0.017289744146789115 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.01531382079195717\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 50/50, Loss: 0.016668636144863233 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.015334377449977657\n",
      "LS+CNN NMSE: 0.0018129070522263646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "learning_rate = 1e-5 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    # load target dataset\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_map_data(target_data_dir, device, snr, train_rate=train_rate)\n",
    "            \n",
    "    # training at target set\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        \n",
    "        if model_name == 'LS_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "            # source model\n",
    "            model_source = utils.CNN_Est(dropOut=0, act =CNN_activation).to(device)\n",
    "        \n",
    "            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "            # source model\n",
    "            model_source = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "        \n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model_fineTune = utils_transfer.FineTuneModel2(model_source).to(device)\n",
    "        optimizer = torch.optim.Adam(model_fineTune.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_loss =[]\n",
    "        val_loss = []\n",
    "        H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "        min_H_true = []\n",
    "        max_H_true = []\n",
    "        num_epochs = NUM_EPOCHS\n",
    "        for epoch in range(num_epochs):\n",
    "            model_fineTune.train()\n",
    "            running_loss = 0.0\n",
    "            if (epoch == num_epochs-1):\n",
    "                i = 0\n",
    "            for inputs, targets, targets_min, targets_max in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fineTune(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "            \n",
    "            # Validation \n",
    "            model_fineTune.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                    val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                    val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                    val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                    val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                    \n",
    "                    val_outputs_real = model_fineTune(val_inputs_real)\n",
    "                    val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                    running_val_loss += val_loss_real.item()\n",
    "                    \n",
    "                    val_outputs_imag = model_fineTune(val_inputs_imag)\n",
    "                    val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                    running_val_loss += val_loss_imag.item()\n",
    "                    \n",
    "                    if (epoch == num_epochs-1): # the results after the last training epoch\n",
    "                        H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                        H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                        \n",
    "                        i = i+val_outputs_imag.size(0)       \n",
    "                        \n",
    "                    \n",
    "            avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "            val_loss.append(avg_val_loss)    \n",
    "                    \n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Val Loss: {avg_val_loss}\")\n",
    "        # end loop epochs\n",
    "        \n",
    "        train_save_path = f'{transferd_save_path}/{snr}dB/train'\n",
    "        os.makedirs(train_save_path, exist_ok=True)\n",
    "        \n",
    "        savemat(f'{train_save_path}/{model_name}_loss.mat', {f'val_loss': val_loss, \n",
    "                                                            f'train_loss': train_loss})\n",
    "        \n",
    "        plotfig.figLoss(train_loss, val_loss, 1, train_save_path, f'_{model_name}_Loss.png')\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model_fineTune.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f'{transferd_save_path}/{snr}dB/{model_name}_model.pth')\n",
    "        \n",
    "        \n",
    "        # Denormalize True Channel\n",
    "        H_val_true = valLabels.cpu()\n",
    "        # convert to complex matrices\n",
    "        H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "        # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "        plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', 1, train_save_path, '_trueChannel.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "\n",
    "        \n",
    "        # CNN Estimated Channel                                                               \n",
    "        H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                            #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                            # valLabel_min == [nVal,1]\n",
    "        H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "        \n",
    "        # NMSE of LS (+ LI) + CNN\n",
    "        H_val_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])# Calculate the NMSE\n",
    "        nmse_NN = utils.calNMSE(H_val_NN_complex, H_val_true_complex)\n",
    "            \n",
    "        if model_name == 'LS_CNN':\n",
    "            nmse_LS_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "        \n",
    "            # NMSE of Linear Interpolation   # just need to calculate this 1 time  --> calculate at case model_name == 'LS_CNN'\n",
    "            H_val_linInterp = H_linear_val.cpu()\n",
    "            # convert to complex matrices\n",
    "            H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "            nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "            \n",
    "            nmse_LS_LI_val.append(nmse_LI.cpu().mean())\n",
    "            print(f\"LS+LI NMSE: {nmse_LI.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                                    nmse_LI[-1], 1, train_save_path, '_LS_LI_estimatedChan.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "                            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            nmse_LI_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+LI+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "    \n",
    "    # end model_phase ['LS_CNN', 'LS_LI_CNN']\n",
    "# end loop SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12           [-1, 1, 612, 14]             801\n",
      "================================================================\n",
      "Total params: 262,211\n",
      "Trainable params: 803\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 35.69\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 36.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_source, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12          [-1, 16, 616, 18]          12,816\n",
      "             Tanh-13          [-1, 16, 616, 18]               0\n",
      "           Conv2d-14           [-1, 8, 614, 16]           1,160\n",
      "             Tanh-15           [-1, 8, 614, 16]               0\n",
      "           Conv2d-16           [-1, 1, 612, 14]              73\n",
      "================================================================\n",
      "Total params: 275,459\n",
      "Trainable params: 14,051\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 39.60\n",
      "Params size (MB): 1.05\n",
      "Estimated Total Size (MB): 40.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_fineTune, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "transferd_model/static/CNN/ver10_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(transferd_save_path, \"NMSE1.png\")) # transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(transferd_save_path, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(transferd_save_path, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0346),\n",
       " tensor(0.0177),\n",
       " tensor(0.0117),\n",
       " tensor(0.0059),\n",
       " tensor(0.0049),\n",
       " tensor(0.0025),\n",
       " tensor(0.0018)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmse_LI_NN_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
