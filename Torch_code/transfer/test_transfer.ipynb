{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir = \"../model/static/CNN/BS16/3500_3516/ver5_\"\n",
    "target_data_dir   = \"../../CDL Customization/Data/ver19_\"\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/test_transfer_(...).ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "if not os.path.exists(os.path.dirname(transferd_save_path + '/readme.txt')):\n",
    "    os.makedirs(os.path.dirname(transferd_save_path + '/readme.txt'))\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/0\n",
      "LS_CNN model\n",
      "CNN_Est(\n",
      "  (normalization): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  (activate): ReLU()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      ")\n",
      "LS_LI_CNN model\n",
      "CNN_Est(\n",
      "  (normalization): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  (activate): ReLU()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 20 # 20\n",
    "learning_rate = 0.00001 # 1e-5\n",
    "SNR = [0] # np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        # source model\n",
    "        model_source = utils.CNN_Est().to(device)\n",
    "        optimizer = torch.optim.Adam(model_source.parameters(), lr=learning_rate)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(model_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: normalization.weight, Requires Grad: True\n",
      "Layer: normalization.bias, Requires Grad: True\n",
      "Layer: conv1.weight, Requires Grad: False\n",
      "Layer: conv1.bias, Requires Grad: False\n",
      "Layer: conv2.weight, Requires Grad: False\n",
      "Layer: conv2.bias, Requires Grad: False\n",
      "Layer: conv3.weight, Requires Grad: False\n",
      "Layer: conv3.bias, Requires Grad: False\n",
      "Layer: conv4.weight, Requires Grad: False\n",
      "Layer: conv4.bias, Requires Grad: False\n",
      "Layer: conv5.weight, Requires Grad: True\n",
      "Layer: conv5.bias, Requires Grad: True\n",
      "\n",
      "Total number of trainable parameters: 803\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_source.named_parameters():\n",
    "    print(f\"Layer: {name}, Requires Grad: {param.requires_grad}\")\n",
    "    \n",
    "num_params = sum(p.numel() for p in model_source.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal number of trainable parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: normalization.weight, Requires Grad: True\n",
      "Layer: normalization.bias, Requires Grad: True\n",
      "Layer: conv1.weight, Requires Grad: False\n",
      "Layer: conv1.bias, Requires Grad: False\n",
      "Layer: conv2.weight, Requires Grad: False\n",
      "Layer: conv2.bias, Requires Grad: False\n",
      "Layer: conv3.weight, Requires Grad: False\n",
      "Layer: conv3.bias, Requires Grad: False\n",
      "Layer: conv4.weight, Requires Grad: False\n",
      "Layer: conv4.bias, Requires Grad: False\n",
      "Layer: conv5.weight, Requires Grad: True\n",
      "Layer: conv5.bias, Requires Grad: True\n",
      "\n",
      "Total number of trainable parameters: 803\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_source.named_parameters():\n",
    "    if any(f\"conv{i}\" in name for i in range(1, 5)):\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in model_source.named_parameters():\n",
    "    print(f\"Layer: {name}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "num_params = sum(p.numel() for p in model_source.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal number of trainable parameters: {num_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
