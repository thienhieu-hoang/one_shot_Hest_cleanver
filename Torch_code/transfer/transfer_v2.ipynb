{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create readme.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import savemat\n",
    "\n",
    "sys.path.append(os.path.abspath('../helper'))\n",
    "import config\n",
    "import utils\n",
    "import loader\n",
    "import plotfig\n",
    "import utils_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_models_dir  = \"../model/static/CNN/BS16/3500_3516/ver14_\"\n",
    "target_data_dir    = \"../../CDL Customization/Data/ver27_\"\n",
    "\n",
    "# Min-max Scaler to [-1 1] range\n",
    "norm_approach = 'minmax'\n",
    "lower_range = -1\n",
    "CNN_DropOut = 0.2\n",
    "CNN_activation = 'Tanh'\n",
    "\n",
    "# create readme.txt file\n",
    "content = f\"\"\"Generated by file 'transfer/transfer_v2.ipynb'.\n",
    "Source models were loaded in {source_models_dir},\n",
    "Target training data are loaded in {target_data_dir}\n",
    "300 samples in target dataset (map-based dataset), 0.9 for training, 0.1 for validating\n",
    "\"\"\"\n",
    "\n",
    "idx_save_path = loader.find_incremental_filename('transferd_model/static/CNN', 'ver', '_', '')\n",
    "transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "\n",
    "os.makedirs(os.path.dirname(f'{transferd_save_path}/readme.txt'), exist_ok=True)\n",
    "\n",
    "# Write content to readme.txt\n",
    "with open(transferd_save_path + '/readme.txt', \"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightly applying trained model to target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 0/30\n",
      "LS_CNN model\n",
      "SNR: 0/30, LS_CNN, Epoch 1/50, Loss: 0.3900305852293968 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3941868543624878\n",
      "SNR: 0/30, LS_CNN, Epoch 2/50, Loss: 0.3878735713660717 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3916298821568489\n",
      "SNR: 0/30, LS_CNN, Epoch 3/50, Loss: 0.3853760790079832 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.38890940696001053\n",
      "SNR: 0/30, LS_CNN, Epoch 4/50, Loss: 0.38287144899368286 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3858316019177437\n",
      "SNR: 0/30, LS_CNN, Epoch 5/50, Loss: 0.3799763675779104 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.38232219219207764\n",
      "SNR: 0/30, LS_CNN, Epoch 6/50, Loss: 0.37692437320947647 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3786875680088997\n",
      "SNR: 0/30, LS_CNN, Epoch 7/50, Loss: 0.3734815735369921 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3744363412261009\n",
      "SNR: 0/30, LS_CNN, Epoch 8/50, Loss: 0.3700587581843138 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.370140478014946\n",
      "SNR: 0/30, LS_CNN, Epoch 9/50, Loss: 0.3666979242116213 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3659205734729767\n",
      "SNR: 0/30, LS_CNN, Epoch 10/50, Loss: 0.3631383776664734 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.361596941947937\n",
      "SNR: 0/30, LS_CNN, Epoch 11/50, Loss: 0.3592113275080919 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3579748421907425\n",
      "SNR: 0/30, LS_CNN, Epoch 12/50, Loss: 0.35615564696490765 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.352956622838974\n",
      "SNR: 0/30, LS_CNN, Epoch 13/50, Loss: 0.35387665033340454 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3497640863060951\n",
      "SNR: 0/30, LS_CNN, Epoch 14/50, Loss: 0.3504454027861357 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3467309921979904\n",
      "SNR: 0/30, LS_CNN, Epoch 15/50, Loss: 0.34700983576476574 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3431447893381119\n",
      "SNR: 0/30, LS_CNN, Epoch 16/50, Loss: 0.3464567605406046 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3408559337258339\n",
      "SNR: 0/30, LS_CNN, Epoch 17/50, Loss: 0.3421191293746233 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33676084876060486\n",
      "SNR: 0/30, LS_CNN, Epoch 18/50, Loss: 0.33908029831945896 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.33326298743486404\n",
      "SNR: 0/30, LS_CNN, Epoch 19/50, Loss: 0.33615345880389214 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.32987377792596817\n",
      "SNR: 0/30, LS_CNN, Epoch 20/50, Loss: 0.33398897014558315 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.327771432697773\n",
      "SNR: 0/30, LS_CNN, Epoch 21/50, Loss: 0.33095579966902733 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3230110928416252\n",
      "SNR: 0/30, LS_CNN, Epoch 22/50, Loss: 0.3282575458288193 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.31980301439762115\n",
      "SNR: 0/30, LS_CNN, Epoch 23/50, Loss: 0.3258018456399441 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3167533501982689\n",
      "SNR: 0/30, LS_CNN, Epoch 24/50, Loss: 0.3230473976582289 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.314638152718544\n",
      "SNR: 0/30, LS_CNN, Epoch 25/50, Loss: 0.31990847922861576 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.30894211679697037\n",
      "SNR: 0/30, LS_CNN, Epoch 26/50, Loss: 0.31895999424159527 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3068210929632187\n",
      "SNR: 0/30, LS_CNN, Epoch 27/50, Loss: 0.32457667775452137 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3046215549111366\n",
      "SNR: 0/30, LS_CNN, Epoch 28/50, Loss: 0.3122344557195902 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.3011108785867691\n",
      "SNR: 0/30, LS_CNN, Epoch 29/50, Loss: 0.3072261530905962 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2967424839735031\n",
      "SNR: 0/30, LS_CNN, Epoch 30/50, Loss: 0.3068396579474211 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2930057644844055\n",
      "SNR: 0/30, LS_CNN, Epoch 31/50, Loss: 0.3064510468393564 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2907852828502655\n",
      "SNR: 0/30, LS_CNN, Epoch 32/50, Loss: 0.2992395609617233 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28858616948127747\n",
      "SNR: 0/30, LS_CNN, Epoch 33/50, Loss: 0.29452566616237164 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28508155047893524\n",
      "SNR: 0/30, LS_CNN, Epoch 34/50, Loss: 0.29201292619109154 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.28121668100357056\n",
      "SNR: 0/30, LS_CNN, Epoch 35/50, Loss: 0.29061798844486475 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2778623551130295\n",
      "SNR: 0/30, LS_CNN, Epoch 36/50, Loss: 0.28324696607887745 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.27215080708265305\n",
      "SNR: 0/30, LS_CNN, Epoch 37/50, Loss: 0.29059470538049936 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2695579081773758\n",
      "SNR: 0/30, LS_CNN, Epoch 38/50, Loss: 0.28197255823761225 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.26567553728818893\n",
      "SNR: 0/30, LS_CNN, Epoch 39/50, Loss: 0.27524159103631973 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.263007253408432\n",
      "SNR: 0/30, LS_CNN, Epoch 40/50, Loss: 0.27242191787809134 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.25720231980085373\n",
      "SNR: 0/30, LS_CNN, Epoch 41/50, Loss: 0.28188168350607157 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2550279349088669\n",
      "SNR: 0/30, LS_CNN, Epoch 42/50, Loss: 0.2652588067576289 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.25117919221520424\n",
      "SNR: 0/30, LS_CNN, Epoch 43/50, Loss: 0.2630854258313775 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.24692653864622116\n",
      "SNR: 0/30, LS_CNN, Epoch 44/50, Loss: 0.2630697749555111 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.24215226247906685\n",
      "SNR: 0/30, LS_CNN, Epoch 45/50, Loss: 0.2625944269821048 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.24017513543367386\n",
      "SNR: 0/30, LS_CNN, Epoch 46/50, Loss: 0.2597183287143707 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.2366807907819748\n",
      "SNR: 0/30, LS_CNN, Epoch 47/50, Loss: 0.2515947762876749 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.23313947021961212\n",
      "SNR: 0/30, LS_CNN, Epoch 48/50, Loss: 0.2510610157623887 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.23025790974497795\n",
      "SNR: 0/30, LS_CNN, Epoch 49/50, Loss: 0.24820207059383392 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.22767332196235657\n",
      "SNR: 0/30, LS_CNN, Epoch 50/50, Loss: 0.2511323895305395 \n",
      "SNR: 0/30, LS_CNN, Val Loss: 0.22395431250333786\n",
      "LS+CNN NMSE: 0.04582567512989044\n",
      "LS+LI NMSE: 0.08158905804157257\n",
      "LS_LI_CNN model\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3907501958310604 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.39511028677225113\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 2/50, Loss: 0.38509586825966835 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3888584226369858\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 3/50, Loss: 0.37925323843955994 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.38219937682151794\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3726842440664768 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3748227059841156\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 5/50, Loss: 0.36559590697288513 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3665143698453903\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 6/50, Loss: 0.35719252191483974 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.35725046694278717\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 7/50, Loss: 0.34804390743374825 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.34682701528072357\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 8/50, Loss: 0.3372127190232277 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3351811021566391\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 9/50, Loss: 0.32577921263873577 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.32200246304273605\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 10/50, Loss: 0.3133115954697132 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.3080955445766449\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 11/50, Loss: 0.2999975588172674 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2942482903599739\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2871384359896183 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2801908478140831\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 13/50, Loss: 0.2742511834949255 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.26685356348752975\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 14/50, Loss: 0.26150349900126457 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.25436441972851753\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 15/50, Loss: 0.2503362940624356 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.24336958676576614\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 16/50, Loss: 0.24085194058716297 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.23467091098427773\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 17/50, Loss: 0.233753003180027 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22742006555199623\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 18/50, Loss: 0.22810526564717293 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.22201033681631088\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 19/50, Loss: 0.2237452520057559 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21795756369829178\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 20/50, Loss: 0.22008344903588295 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2153560295701027\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 21/50, Loss: 0.21832942310720682 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21366119757294655\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 22/50, Loss: 0.216373011469841 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2126014083623886\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 23/50, Loss: 0.21583673544228077 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21199915930628777\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 24/50, Loss: 0.21577796153724194 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21162127703428268\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 25/50, Loss: 0.21603091433644295 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21157552674412727\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 26/50, Loss: 0.21403662394732237 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2109396904706955\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 27/50, Loss: 0.21469359286129475 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21135756000876427\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 28/50, Loss: 0.2150083789601922 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21128401160240173\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 29/50, Loss: 0.21568591427057981 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21076495572924614\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 30/50, Loss: 0.21353883855044842 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21098077297210693\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 31/50, Loss: 0.2134866565465927 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21038617938756943\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 32/50, Loss: 0.2158155608922243 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21041803434491158\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 33/50, Loss: 0.21419596299529076 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2107819877564907\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 34/50, Loss: 0.21246104314923286 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21035989001393318\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 35/50, Loss: 0.21458876505494118 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21061748266220093\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 36/50, Loss: 0.2129857772961259 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2106729857623577\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 37/50, Loss: 0.21305967587977648 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21040380373597145\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 38/50, Loss: 0.21403712034225464 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21022214740514755\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 39/50, Loss: 0.2122539710253477 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20987683162093163\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 40/50, Loss: 0.21261161658912897 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21022501587867737\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 41/50, Loss: 0.21270962804555893 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21011004224419594\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 42/50, Loss: 0.21474922355264425 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21007013320922852\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 43/50, Loss: 0.21166532207280397 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.21017678454518318\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 44/50, Loss: 0.21387659013271332 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20963401719927788\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 45/50, Loss: 0.21464842651039362 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20987318828701973\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 46/50, Loss: 0.21377721708267927 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.2095629870891571\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 47/50, Loss: 0.21128080412745476 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20987167209386826\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 48/50, Loss: 0.2128076571971178 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20924904942512512\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 49/50, Loss: 0.21320569328963757 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20912282913923264\n",
      "SNR: 0/30, LS_LI_CNN, Epoch 50/50, Loss: 0.2141743553802371 \n",
      "SNR: 0/30, LS_LI_CNN, Val Loss: 0.20941712707281113\n",
      "LS+CNN NMSE: 0.04107733070850372\n",
      " SNR: 5/30\n",
      "LS_CNN model\n",
      "SNR: 5/30, LS_CNN, Epoch 1/50, Loss: 0.3883076459169388 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3697582259774208\n",
      "SNR: 5/30, LS_CNN, Epoch 2/50, Loss: 0.38461350463330746 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3667874038219452\n",
      "SNR: 5/30, LS_CNN, Epoch 3/50, Loss: 0.3810632526874542 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3634117394685745\n",
      "SNR: 5/30, LS_CNN, Epoch 4/50, Loss: 0.3772069625556469 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.35947006195783615\n",
      "SNR: 5/30, LS_CNN, Epoch 5/50, Loss: 0.3732351213693619 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3553653582930565\n",
      "SNR: 5/30, LS_CNN, Epoch 6/50, Loss: 0.36911497823894024 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3511608764529228\n",
      "SNR: 5/30, LS_CNN, Epoch 7/50, Loss: 0.3642749283462763 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3458871394395828\n",
      "SNR: 5/30, LS_CNN, Epoch 8/50, Loss: 0.3595341742038727 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.34096165001392365\n",
      "SNR: 5/30, LS_CNN, Epoch 9/50, Loss: 0.3543759882450104 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3355991616845131\n",
      "SNR: 5/30, LS_CNN, Epoch 10/50, Loss: 0.3491132818162441 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.32977471500635147\n",
      "SNR: 5/30, LS_CNN, Epoch 11/50, Loss: 0.3440360426902771 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.32411396503448486\n",
      "SNR: 5/30, LS_CNN, Epoch 12/50, Loss: 0.33788689598441124 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.31919635832309723\n",
      "SNR: 5/30, LS_CNN, Epoch 13/50, Loss: 0.33333547227084637 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.31313518434762955\n",
      "SNR: 5/30, LS_CNN, Epoch 14/50, Loss: 0.3283282555639744 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.3069874048233032\n",
      "SNR: 5/30, LS_CNN, Epoch 15/50, Loss: 0.32222846895456314 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.30166227370500565\n",
      "SNR: 5/30, LS_CNN, Epoch 16/50, Loss: 0.3201144263148308 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2948806881904602\n",
      "SNR: 5/30, LS_CNN, Epoch 17/50, Loss: 0.3126364704221487 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.28977499157190323\n",
      "SNR: 5/30, LS_CNN, Epoch 18/50, Loss: 0.30921884812414646 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2833249270915985\n",
      "SNR: 5/30, LS_CNN, Epoch 19/50, Loss: 0.30492317862808704 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2792847193777561\n",
      "SNR: 5/30, LS_CNN, Epoch 20/50, Loss: 0.3009638786315918 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.27240221947431564\n",
      "SNR: 5/30, LS_CNN, Epoch 21/50, Loss: 0.2952697370201349 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26711881533265114\n",
      "SNR: 5/30, LS_CNN, Epoch 22/50, Loss: 0.2929549068212509 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.26553744822740555\n",
      "SNR: 5/30, LS_CNN, Epoch 23/50, Loss: 0.2862176410853863 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2585280053317547\n",
      "SNR: 5/30, LS_CNN, Epoch 24/50, Loss: 0.2798906406387687 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.25214720144867897\n",
      "SNR: 5/30, LS_CNN, Epoch 25/50, Loss: 0.2798515856266022 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24786463752388954\n",
      "SNR: 5/30, LS_CNN, Epoch 26/50, Loss: 0.27383600547909737 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.24351607635617256\n",
      "SNR: 5/30, LS_CNN, Epoch 27/50, Loss: 0.2699572267010808 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23889167606830597\n",
      "SNR: 5/30, LS_CNN, Epoch 28/50, Loss: 0.27243002224713564 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.23285242542624474\n",
      "SNR: 5/30, LS_CNN, Epoch 29/50, Loss: 0.26016576029360294 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2294461987912655\n",
      "SNR: 5/30, LS_CNN, Epoch 30/50, Loss: 0.262825571000576 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2254883386194706\n",
      "SNR: 5/30, LS_CNN, Epoch 31/50, Loss: 0.25639734137803316 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.22172337397933006\n",
      "SNR: 5/30, LS_CNN, Epoch 32/50, Loss: 0.28371296264231205 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.21983294561505318\n",
      "SNR: 5/30, LS_CNN, Epoch 33/50, Loss: 0.24436490144580603 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.2176302708685398\n",
      "SNR: 5/30, LS_CNN, Epoch 34/50, Loss: 0.2486285250633955 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.21487128362059593\n",
      "SNR: 5/30, LS_CNN, Epoch 35/50, Loss: 0.2485356703400612 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.21134250238537788\n",
      "SNR: 5/30, LS_CNN, Epoch 36/50, Loss: 0.2587802251800895 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20990321785211563\n",
      "SNR: 5/30, LS_CNN, Epoch 37/50, Loss: 0.23616686556488276 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20752467587590218\n",
      "SNR: 5/30, LS_CNN, Epoch 38/50, Loss: 0.24013806227594614 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20332419872283936\n",
      "SNR: 5/30, LS_CNN, Epoch 39/50, Loss: 0.2444939110428095 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.20101746171712875\n",
      "SNR: 5/30, LS_CNN, Epoch 40/50, Loss: 0.23251333832740784 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1989368088543415\n",
      "SNR: 5/30, LS_CNN, Epoch 41/50, Loss: 0.23695007991045713 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19610434770584106\n",
      "SNR: 5/30, LS_CNN, Epoch 42/50, Loss: 0.22923737298697233 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.19422584027051926\n",
      "SNR: 5/30, LS_CNN, Epoch 43/50, Loss: 0.22431708127260208 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18985942751169205\n",
      "SNR: 5/30, LS_CNN, Epoch 44/50, Loss: 0.23394662700593472 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18973537534475327\n",
      "SNR: 5/30, LS_CNN, Epoch 45/50, Loss: 0.22386779636144638 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18840543925762177\n",
      "SNR: 5/30, LS_CNN, Epoch 46/50, Loss: 0.22931693773716688 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18509742990136147\n",
      "SNR: 5/30, LS_CNN, Epoch 47/50, Loss: 0.22692277748137712 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18559761345386505\n",
      "SNR: 5/30, LS_CNN, Epoch 48/50, Loss: 0.23617436829954386 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.1841789372265339\n",
      "SNR: 5/30, LS_CNN, Epoch 49/50, Loss: 0.23555815685540438 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18610169738531113\n",
      "SNR: 5/30, LS_CNN, Epoch 50/50, Loss: 0.2260625921189785 \n",
      "SNR: 5/30, LS_CNN, Val Loss: 0.18488295376300812\n",
      "LS+CNN NMSE: 0.029722005128860474\n",
      "LS+LI NMSE: 0.026234017685055733\n",
      "LS_LI_CNN model\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 1/50, Loss: 0.38323384150862694 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.36439643800258636\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3743447791785002 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3541644737124443\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3647381477057934 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3435174524784088\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 4/50, Loss: 0.35395437106490135 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.33143702894449234\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3419848345220089 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.3186536505818367\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 6/50, Loss: 0.32849197275936604 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.30446574091911316\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 7/50, Loss: 0.3134721629321575 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.28874488919973373\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 8/50, Loss: 0.2972695529460907 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.27173056453466415\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 9/50, Loss: 0.280819334089756 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.25423550605773926\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 10/50, Loss: 0.263494648039341 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.23680080845952034\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 11/50, Loss: 0.24608581233769655 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.2193078212440014\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 12/50, Loss: 0.22950034216046333 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.20354007929563522\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 13/50, Loss: 0.21331966668367386 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.18787549808621407\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 14/50, Loss: 0.19928768929094076 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.17347537726163864\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 15/50, Loss: 0.18708717823028564 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.16339369863271713\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 16/50, Loss: 0.17619340494275093 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.15402953699231148\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 17/50, Loss: 0.1686365995556116 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.147049468010664\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 18/50, Loss: 0.16318158525973558 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.14260576851665974\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 19/50, Loss: 0.15914683137089014 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13924447260797024\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 20/50, Loss: 0.1552284611389041 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1367462519556284\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 21/50, Loss: 0.15542250545695424 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1359071023762226\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 22/50, Loss: 0.1538399220444262 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13556278496980667\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 23/50, Loss: 0.15334876347333193 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13485804572701454\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 24/50, Loss: 0.15400935523211956 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1347243171185255\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 25/50, Loss: 0.1529139494523406 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13461230881512165\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 26/50, Loss: 0.15297159040346742 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13479582220315933\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 27/50, Loss: 0.1512634940445423 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13476416654884815\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 28/50, Loss: 0.151641468051821 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1345520243048668\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 29/50, Loss: 0.15192515263333917 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1343586314469576\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 30/50, Loss: 0.15355490846559405 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13425758481025696\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 31/50, Loss: 0.15186618641018867 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13460231758654118\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 32/50, Loss: 0.15345935011282563 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13450018875300884\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 33/50, Loss: 0.15251439530402422 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13466548547148705\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 34/50, Loss: 0.1532056531868875 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13401325047016144\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 35/50, Loss: 0.15138686308637261 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13426672108471394\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 36/50, Loss: 0.15229942835867405 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1342081855982542\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 37/50, Loss: 0.152237209957093 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1339027974754572\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 38/50, Loss: 0.15159800369292498 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13392185419797897\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 39/50, Loss: 0.15108271362259984 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13405890204012394\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 40/50, Loss: 0.15314213698729873 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13373100385069847\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 41/50, Loss: 0.1526582194492221 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13368752598762512\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 42/50, Loss: 0.1518938005901873 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1338247563689947\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 43/50, Loss: 0.15163262747228146 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13420863077044487\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 44/50, Loss: 0.15133119374513626 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1339560765773058\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 45/50, Loss: 0.15173687087371945 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.1336174551397562\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 46/50, Loss: 0.15094633819535375 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13365202024579048\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 47/50, Loss: 0.15206385822966695 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13370138965547085\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 48/50, Loss: 0.15098706353455782 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13371970877051353\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 49/50, Loss: 0.15167424827814102 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13339190557599068\n",
      "SNR: 5/30, LS_LI_CNN, Epoch 50/50, Loss: 0.152720607817173 \n",
      "SNR: 5/30, LS_LI_CNN, Val Loss: 0.13358951546251774\n",
      "LS+CNN NMSE: 0.01662825234234333\n",
      " SNR: 10/30\n",
      "LS_CNN model\n",
      "SNR: 10/30, LS_CNN, Epoch 1/50, Loss: 0.3972262926399708 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.40087441354990005\n",
      "SNR: 10/30, LS_CNN, Epoch 2/50, Loss: 0.39349318854510784 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3973216488957405\n",
      "SNR: 10/30, LS_CNN, Epoch 3/50, Loss: 0.3893610704690218 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.39329203218221664\n",
      "SNR: 10/30, LS_CNN, Epoch 4/50, Loss: 0.3852464612573385 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3889227584004402\n",
      "SNR: 10/30, LS_CNN, Epoch 5/50, Loss: 0.38035495206713676 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3840346708893776\n",
      "SNR: 10/30, LS_CNN, Epoch 6/50, Loss: 0.3761308379471302 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.37915097177028656\n",
      "SNR: 10/30, LS_CNN, Epoch 7/50, Loss: 0.37043581902980804 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3735654726624489\n",
      "SNR: 10/30, LS_CNN, Epoch 8/50, Loss: 0.36517516896128654 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36774833500385284\n",
      "SNR: 10/30, LS_CNN, Epoch 9/50, Loss: 0.3603558111935854 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.36261624842882156\n",
      "SNR: 10/30, LS_CNN, Epoch 10/50, Loss: 0.3548305407166481 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3566226214170456\n",
      "SNR: 10/30, LS_CNN, Epoch 11/50, Loss: 0.35238296538591385 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3522656038403511\n",
      "SNR: 10/30, LS_CNN, Epoch 12/50, Loss: 0.34640134312212467 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.34728432446718216\n",
      "SNR: 10/30, LS_CNN, Epoch 13/50, Loss: 0.34171922504901886 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3424299508333206\n",
      "SNR: 10/30, LS_CNN, Epoch 14/50, Loss: 0.3356111254543066 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3372903913259506\n",
      "SNR: 10/30, LS_CNN, Epoch 15/50, Loss: 0.3316089790314436 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3330942988395691\n",
      "SNR: 10/30, LS_CNN, Epoch 16/50, Loss: 0.325879143550992 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.32851316779851913\n",
      "SNR: 10/30, LS_CNN, Epoch 17/50, Loss: 0.33055286295711994 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3239227682352066\n",
      "SNR: 10/30, LS_CNN, Epoch 18/50, Loss: 0.32199097983539104 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3176402896642685\n",
      "SNR: 10/30, LS_CNN, Epoch 19/50, Loss: 0.31942120008170605 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3146235793828964\n",
      "SNR: 10/30, LS_CNN, Epoch 20/50, Loss: 0.31414495036005974 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.31077365577220917\n",
      "SNR: 10/30, LS_CNN, Epoch 21/50, Loss: 0.31008693389594555 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.3068429157137871\n",
      "SNR: 10/30, LS_CNN, Epoch 22/50, Loss: 0.3061027470976114 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.30398140847682953\n",
      "SNR: 10/30, LS_CNN, Epoch 23/50, Loss: 0.3021358512341976 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2984718531370163\n",
      "SNR: 10/30, LS_CNN, Epoch 24/50, Loss: 0.297085358761251 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2930803820490837\n",
      "SNR: 10/30, LS_CNN, Epoch 25/50, Loss: 0.28965693060308695 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.28806743398308754\n",
      "SNR: 10/30, LS_CNN, Epoch 26/50, Loss: 0.28676955215632915 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2860449254512787\n",
      "SNR: 10/30, LS_CNN, Epoch 27/50, Loss: 0.2809627167880535 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2783273681998253\n",
      "SNR: 10/30, LS_CNN, Epoch 28/50, Loss: 0.2739474168047309 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27520930394530296\n",
      "SNR: 10/30, LS_CNN, Epoch 29/50, Loss: 0.2703893156722188 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.27063846960663795\n",
      "SNR: 10/30, LS_CNN, Epoch 30/50, Loss: 0.26308698579669 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2656833752989769\n",
      "SNR: 10/30, LS_CNN, Epoch 31/50, Loss: 0.284841850399971 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2622833326458931\n",
      "SNR: 10/30, LS_CNN, Epoch 32/50, Loss: 0.2748848218470812 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.26079341024160385\n",
      "SNR: 10/30, LS_CNN, Epoch 33/50, Loss: 0.2564702546223998 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.25652242451906204\n",
      "SNR: 10/30, LS_CNN, Epoch 34/50, Loss: 0.2525774370878935 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2518417686223984\n",
      "SNR: 10/30, LS_CNN, Epoch 35/50, Loss: 0.25199923012405634 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24711811542510986\n",
      "SNR: 10/30, LS_CNN, Epoch 36/50, Loss: 0.24311035498976707 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24388955533504486\n",
      "SNR: 10/30, LS_CNN, Epoch 37/50, Loss: 0.25132385920733213 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.24056939408183098\n",
      "SNR: 10/30, LS_CNN, Epoch 38/50, Loss: 0.229223663918674 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.23540368303656578\n",
      "SNR: 10/30, LS_CNN, Epoch 39/50, Loss: 0.2352092955261469 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2328002005815506\n",
      "SNR: 10/30, LS_CNN, Epoch 40/50, Loss: 0.2269763881340623 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22838659211993217\n",
      "SNR: 10/30, LS_CNN, Epoch 41/50, Loss: 0.23260711133480072 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22506175935268402\n",
      "SNR: 10/30, LS_CNN, Epoch 42/50, Loss: 0.24797704350203276 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22289150580763817\n",
      "SNR: 10/30, LS_CNN, Epoch 43/50, Loss: 0.23421441297978163 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.22209420055150986\n",
      "SNR: 10/30, LS_CNN, Epoch 44/50, Loss: 0.22607714775949717 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.21994558349251747\n",
      "SNR: 10/30, LS_CNN, Epoch 45/50, Loss: 0.22506971843540668 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.21823115646839142\n",
      "SNR: 10/30, LS_CNN, Epoch 46/50, Loss: 0.22320351097732782 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.21407435461878777\n",
      "SNR: 10/30, LS_CNN, Epoch 47/50, Loss: 0.21696362271904945 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2117980159819126\n",
      "SNR: 10/30, LS_CNN, Epoch 48/50, Loss: 0.20990212261676788 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.2095247507095337\n",
      "SNR: 10/30, LS_CNN, Epoch 49/50, Loss: 0.22231803368777037 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.20771968737244606\n",
      "SNR: 10/30, LS_CNN, Epoch 50/50, Loss: 0.2165207378566265 \n",
      "SNR: 10/30, LS_CNN, Val Loss: 0.20693586021661758\n",
      "LS+CNN NMSE: 0.027646763250231743\n",
      "LS+LI NMSE: 0.008105947636067867\n",
      "LS_LI_CNN model\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 1/50, Loss: 0.38621085323393345 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.389555960893631\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 2/50, Loss: 0.37526649236679077 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.3782203570008278\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3640949968248606 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.36658918112516403\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3520551212131977 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.353721022605896\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3385092541575432 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.34057191759347916\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 6/50, Loss: 0.32360823452472687 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.324374683201313\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 7/50, Loss: 0.306270107626915 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.30758264660835266\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 8/50, Loss: 0.28783039934933186 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2887772172689438\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 9/50, Loss: 0.267204693518579 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.2678277865052223\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 10/50, Loss: 0.2453375356271863 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.247031532227993\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 11/50, Loss: 0.22348719462752342 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.22495514899492264\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 12/50, Loss: 0.2017029756680131 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.20493043214082718\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 13/50, Loss: 0.18145335465669632 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.186983160674572\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 14/50, Loss: 0.16310313437134027 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.17123569175601006\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 15/50, Loss: 0.14813754800707102 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1594749428331852\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 16/50, Loss: 0.13575200131163 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1508953757584095\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 17/50, Loss: 0.12697967793792486 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.14409593492746353\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 18/50, Loss: 0.12007625913247466 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1389982234686613\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 19/50, Loss: 0.116188142914325 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1366449072957039\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 20/50, Loss: 0.11347833136096597 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13528250716626644\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 21/50, Loss: 0.11153128929436207 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1344217248260975\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 22/50, Loss: 0.11096000438556075 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13458426855504513\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 23/50, Loss: 0.11068915901705623 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1344142071902752\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 24/50, Loss: 0.11075550504028797 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13439367897808552\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 25/50, Loss: 0.1099217957817018 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13431444019079208\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 26/50, Loss: 0.11006084596738219 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13414697349071503\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 27/50, Loss: 0.11043064761906862 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1341246571391821\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 28/50, Loss: 0.10925133130513132 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13418466970324516\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 29/50, Loss: 0.10959884338080883 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13395635783672333\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 30/50, Loss: 0.1103776590898633 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1337923388928175\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 31/50, Loss: 0.10980370501056314 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13388232700526714\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 32/50, Loss: 0.10943680070340633 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13403426855802536\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 33/50, Loss: 0.11012258566915989 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1339623499661684\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 34/50, Loss: 0.10964499413967133 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13382006622850895\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 35/50, Loss: 0.10856062779203057 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13341783918440342\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 36/50, Loss: 0.10976209817454219 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13356800563633442\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 37/50, Loss: 0.10839270241558552 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13321514427661896\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 38/50, Loss: 0.10965435160323977 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13361156359314919\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 39/50, Loss: 0.10923397727310658 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1334104035049677\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 40/50, Loss: 0.10970434127375484 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13327196426689625\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 41/50, Loss: 0.10888712690211833 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13322868384420872\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 42/50, Loss: 0.10858532600104809 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13274316862225533\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 43/50, Loss: 0.10857233358547091 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13303020782768726\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 44/50, Loss: 0.10844758665189147 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13299174420535564\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 45/50, Loss: 0.10867281816899776 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13294271007180214\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 46/50, Loss: 0.10934282280504704 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13290019892156124\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 47/50, Loss: 0.1092229406349361 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1323799304664135\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 48/50, Loss: 0.10885155014693737 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13277015089988708\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 49/50, Loss: 0.1080465316772461 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.13250082731246948\n",
      "SNR: 10/30, LS_LI_CNN, Epoch 50/50, Loss: 0.10671091917902231 \n",
      "SNR: 10/30, LS_LI_CNN, Val Loss: 0.1325885932892561\n",
      "LS+CNN NMSE: 0.014946364797651768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thien/Hprediction/one_shot_Hest_cleanver/Torch_code/helper/plotfig.py:30: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SNR: 15/30\n",
      "LS_CNN model\n",
      "SNR: 15/30, LS_CNN, Epoch 1/50, Loss: 0.39333452843129635 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.38740189373493195\n",
      "SNR: 15/30, LS_CNN, Epoch 2/50, Loss: 0.3893930856138468 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.38369060307741165\n",
      "SNR: 15/30, LS_CNN, Epoch 3/50, Loss: 0.3851874303072691 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.37885963171720505\n",
      "SNR: 15/30, LS_CNN, Epoch 4/50, Loss: 0.38005509972572327 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3735457807779312\n",
      "SNR: 15/30, LS_CNN, Epoch 5/50, Loss: 0.3741908576339483 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.366792693734169\n",
      "SNR: 15/30, LS_CNN, Epoch 6/50, Loss: 0.36831107176840305 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3598073497414589\n",
      "SNR: 15/30, LS_CNN, Epoch 7/50, Loss: 0.36152083054184914 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3518664687871933\n",
      "SNR: 15/30, LS_CNN, Epoch 8/50, Loss: 0.3539342228323221 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3432225212454796\n",
      "SNR: 15/30, LS_CNN, Epoch 9/50, Loss: 0.3452809490263462 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.3339812606573105\n",
      "SNR: 15/30, LS_CNN, Epoch 10/50, Loss: 0.33659613132476807 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.32501542568206787\n",
      "SNR: 15/30, LS_CNN, Epoch 11/50, Loss: 0.3293140344321728 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.31558043509721756\n",
      "SNR: 15/30, LS_CNN, Epoch 12/50, Loss: 0.3235434051603079 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.30788153409957886\n",
      "SNR: 15/30, LS_CNN, Epoch 13/50, Loss: 0.314202006906271 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.29960570484399796\n",
      "SNR: 15/30, LS_CNN, Epoch 14/50, Loss: 0.3091607987880707 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2918475493788719\n",
      "SNR: 15/30, LS_CNN, Epoch 15/50, Loss: 0.3016129247844219 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.28418881073594093\n",
      "SNR: 15/30, LS_CNN, Epoch 16/50, Loss: 0.29507671669125557 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.27764443680644035\n",
      "SNR: 15/30, LS_CNN, Epoch 17/50, Loss: 0.2933985199779272 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.27091184258461\n",
      "SNR: 15/30, LS_CNN, Epoch 18/50, Loss: 0.2861408172175288 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2648601643741131\n",
      "SNR: 15/30, LS_CNN, Epoch 19/50, Loss: 0.2822549603879452 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2585914731025696\n",
      "SNR: 15/30, LS_CNN, Epoch 20/50, Loss: 0.28020588867366314 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.25345122814178467\n",
      "SNR: 15/30, LS_CNN, Epoch 21/50, Loss: 0.2728883530944586 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24766889214515686\n",
      "SNR: 15/30, LS_CNN, Epoch 22/50, Loss: 0.26967449113726616 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.24281375110149384\n",
      "SNR: 15/30, LS_CNN, Epoch 23/50, Loss: 0.2698113154619932 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23863208293914795\n",
      "SNR: 15/30, LS_CNN, Epoch 24/50, Loss: 0.2600159989669919 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.23255633562803268\n",
      "SNR: 15/30, LS_CNN, Epoch 25/50, Loss: 0.2549830377101898 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22959622740745544\n",
      "SNR: 15/30, LS_CNN, Epoch 26/50, Loss: 0.26280182879418135 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22434567287564278\n",
      "SNR: 15/30, LS_CNN, Epoch 27/50, Loss: 0.2511412799358368 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.22133637964725494\n",
      "SNR: 15/30, LS_CNN, Epoch 28/50, Loss: 0.24309027660638094 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2168552652001381\n",
      "SNR: 15/30, LS_CNN, Epoch 29/50, Loss: 0.2450430803000927 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.21350756660103798\n",
      "SNR: 15/30, LS_CNN, Epoch 30/50, Loss: 0.23954799119383097 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.208453968167305\n",
      "SNR: 15/30, LS_CNN, Epoch 31/50, Loss: 0.24271150585263968 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20502788946032524\n",
      "SNR: 15/30, LS_CNN, Epoch 32/50, Loss: 0.2545415526255965 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20454732701182365\n",
      "SNR: 15/30, LS_CNN, Epoch 33/50, Loss: 0.23951957933604717 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.2037123590707779\n",
      "SNR: 15/30, LS_CNN, Epoch 34/50, Loss: 0.2329434771090746 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.20199645310640335\n",
      "SNR: 15/30, LS_CNN, Epoch 35/50, Loss: 0.22680455539375544 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19686570391058922\n",
      "SNR: 15/30, LS_CNN, Epoch 36/50, Loss: 0.23077121190726757 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19309202209115028\n",
      "SNR: 15/30, LS_CNN, Epoch 37/50, Loss: 0.22807962074875832 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1904441975057125\n",
      "SNR: 15/30, LS_CNN, Epoch 38/50, Loss: 0.2316914051771164 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18910402059555054\n",
      "SNR: 15/30, LS_CNN, Epoch 39/50, Loss: 0.2237996608018875 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18743045255541801\n",
      "SNR: 15/30, LS_CNN, Epoch 40/50, Loss: 0.23868210148066282 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1871042586863041\n",
      "SNR: 15/30, LS_CNN, Epoch 41/50, Loss: 0.2693099966272712 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18665675818920135\n",
      "SNR: 15/30, LS_CNN, Epoch 42/50, Loss: 0.2143882317468524 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.19005423411726952\n",
      "SNR: 15/30, LS_CNN, Epoch 43/50, Loss: 0.22508020512759686 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18721120059490204\n",
      "SNR: 15/30, LS_CNN, Epoch 44/50, Loss: 0.2140582436695695 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18671242520213127\n",
      "SNR: 15/30, LS_CNN, Epoch 45/50, Loss: 0.21507544349879026 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1853613778948784\n",
      "SNR: 15/30, LS_CNN, Epoch 46/50, Loss: 0.21109977178275585 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18122851476073265\n",
      "SNR: 15/30, LS_CNN, Epoch 47/50, Loss: 0.2651233430951834 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18060465902090073\n",
      "SNR: 15/30, LS_CNN, Epoch 48/50, Loss: 0.24662222061306238 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18113062158226967\n",
      "SNR: 15/30, LS_CNN, Epoch 49/50, Loss: 0.22076069097965956 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.18440328910946846\n",
      "SNR: 15/30, LS_CNN, Epoch 50/50, Loss: 0.2222830466926098 \n",
      "SNR: 15/30, LS_CNN, Val Loss: 0.1821029856801033\n",
      "LS+CNN NMSE: 0.03365465626120567\n",
      "LS+LI NMSE: 0.002592506818473339\n",
      "LS_LI_CNN model\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3741628061980009 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.362835168838501\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 2/50, Loss: 0.36250282637774944 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.34839393198490143\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 3/50, Loss: 0.34994896687567234 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.33419816195964813\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3360146563500166 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.3189719319343567\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 5/50, Loss: 0.32045502215623856 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.30090663582086563\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3027665335685015 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.2814558371901512\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 7/50, Loss: 0.2830526437610388 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.25946246460080147\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 8/50, Loss: 0.26129697170108557 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.23762142285704613\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 9/50, Loss: 0.23819422256201506 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.21142179891467094\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 10/50, Loss: 0.21378405392169952 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.18698009476065636\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 11/50, Loss: 0.18928696308284998 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.16278791055083275\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 12/50, Loss: 0.16637958586215973 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.13896124064922333\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 13/50, Loss: 0.14464563643559813 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.12016699276864529\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 14/50, Loss: 0.126863828394562 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.10444589518010616\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 15/50, Loss: 0.11266434518620372 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.09299263544380665\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 16/50, Loss: 0.10273355199024081 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08506902121007442\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 17/50, Loss: 0.09597561648115516 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.08025839738547802\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 18/50, Loss: 0.09150387183763087 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07785915210843086\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 19/50, Loss: 0.0885532929096371 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07633078470826149\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 20/50, Loss: 0.08750353031791747 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07566939108073711\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 21/50, Loss: 0.08655262202955782 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07575777731835842\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 22/50, Loss: 0.08598757046274841 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07551532983779907\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 23/50, Loss: 0.08607708918862045 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07546988315880299\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 24/50, Loss: 0.08557590004056692 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07524387538433075\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 25/50, Loss: 0.08538741222582757 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07494606636464596\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 26/50, Loss: 0.08535603038035333 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0749980304390192\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 27/50, Loss: 0.08500882051885128 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07468688860535622\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 28/50, Loss: 0.08517105551436543 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07467195019125938\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 29/50, Loss: 0.08460234804078937 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07442269567400217\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 30/50, Loss: 0.0841085675638169 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07450964488089085\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 31/50, Loss: 0.08428487693890929 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07428449764847755\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 32/50, Loss: 0.08356792386621237 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07416991330683231\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 33/50, Loss: 0.08375557512044907 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07409131620079279\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 34/50, Loss: 0.08377897809259593 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0740743400529027\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 35/50, Loss: 0.08355510467663407 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07377798389643431\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 36/50, Loss: 0.08327266434207559 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07358828838914633\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 37/50, Loss: 0.08341352012939751 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07352134305983782\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 38/50, Loss: 0.08302156277932227 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07344564143568277\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 39/50, Loss: 0.08340154145844281 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07329964078962803\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 40/50, Loss: 0.08261799113824964 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07317185681313276\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 41/50, Loss: 0.08277271618135273 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07304242253303528\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 42/50, Loss: 0.08238322101533413 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07293684594333172\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 43/50, Loss: 0.0823918276000768 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07270653825253248\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 44/50, Loss: 0.08193141990341246 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07267170585691929\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 45/50, Loss: 0.08193494705483317 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07254742085933685\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 46/50, Loss: 0.08168120472691953 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07246005721390247\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 47/50, Loss: 0.08102496294304729 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07228619512170553\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 48/50, Loss: 0.08173342747613788 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07226251065731049\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 49/50, Loss: 0.08138465648517013 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.07208424992859364\n",
      "SNR: 15/30, LS_LI_CNN, Epoch 50/50, Loss: 0.08151764189824462 \n",
      "SNR: 15/30, LS_LI_CNN, Val Loss: 0.0719695845618844\n",
      "LS+CNN NMSE: 0.010832095518708229\n",
      " SNR: 20/30\n",
      "LS_CNN model\n",
      "SNR: 20/30, LS_CNN, Epoch 1/50, Loss: 0.38764883391559124 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3941992074251175\n",
      "SNR: 20/30, LS_CNN, Epoch 2/50, Loss: 0.3810162227600813 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3876497372984886\n",
      "SNR: 20/30, LS_CNN, Epoch 3/50, Loss: 0.37538323551416397 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.381165586411953\n",
      "SNR: 20/30, LS_CNN, Epoch 4/50, Loss: 0.3684331625699997 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.37389449030160904\n",
      "SNR: 20/30, LS_CNN, Epoch 5/50, Loss: 0.36123393289744854 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3651672303676605\n",
      "SNR: 20/30, LS_CNN, Epoch 6/50, Loss: 0.35237809643149376 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3550202399492264\n",
      "SNR: 20/30, LS_CNN, Epoch 7/50, Loss: 0.343509066849947 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.34602876007556915\n",
      "SNR: 20/30, LS_CNN, Epoch 8/50, Loss: 0.33445623703300953 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.33468610793352127\n",
      "SNR: 20/30, LS_CNN, Epoch 9/50, Loss: 0.3253540173172951 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.32270875573158264\n",
      "SNR: 20/30, LS_CNN, Epoch 10/50, Loss: 0.3164339978247881 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.31178687512874603\n",
      "SNR: 20/30, LS_CNN, Epoch 11/50, Loss: 0.30936508625745773 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.3011804670095444\n",
      "SNR: 20/30, LS_CNN, Epoch 12/50, Loss: 0.3077505435794592 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2933633252978325\n",
      "SNR: 20/30, LS_CNN, Epoch 13/50, Loss: 0.2955238651484251 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.28574441373348236\n",
      "SNR: 20/30, LS_CNN, Epoch 14/50, Loss: 0.2931328732520342 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2777111791074276\n",
      "SNR: 20/30, LS_CNN, Epoch 15/50, Loss: 0.28247576765716076 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.27154776453971863\n",
      "SNR: 20/30, LS_CNN, Epoch 16/50, Loss: 0.27325071580708027 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2636334076523781\n",
      "SNR: 20/30, LS_CNN, Epoch 17/50, Loss: 0.26858810894191265 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.25702228397130966\n",
      "SNR: 20/30, LS_CNN, Epoch 18/50, Loss: 0.2651253854855895 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24949073046445847\n",
      "SNR: 20/30, LS_CNN, Epoch 19/50, Loss: 0.2580546149984002 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24621230736374855\n",
      "SNR: 20/30, LS_CNN, Epoch 20/50, Loss: 0.270394254475832 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.24322935193777084\n",
      "SNR: 20/30, LS_CNN, Epoch 21/50, Loss: 0.26032408978790045 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2388969585299492\n",
      "SNR: 20/30, LS_CNN, Epoch 22/50, Loss: 0.25095615070313215 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.23302341252565384\n",
      "SNR: 20/30, LS_CNN, Epoch 23/50, Loss: 0.2545889029279351 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22902506962418556\n",
      "SNR: 20/30, LS_CNN, Epoch 24/50, Loss: 0.2516006026417017 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22577163577079773\n",
      "SNR: 20/30, LS_CNN, Epoch 25/50, Loss: 0.24652678426355124 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.22531821578741074\n",
      "SNR: 20/30, LS_CNN, Epoch 26/50, Loss: 0.24205078836530447 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21976643055677414\n",
      "SNR: 20/30, LS_CNN, Epoch 27/50, Loss: 0.2450030166655779 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21739797294139862\n",
      "SNR: 20/30, LS_CNN, Epoch 28/50, Loss: 0.23200508393347263 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2131802961230278\n",
      "SNR: 20/30, LS_CNN, Epoch 29/50, Loss: 0.23028593976050615 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.21021977812051773\n",
      "SNR: 20/30, LS_CNN, Epoch 30/50, Loss: 0.23112637922167778 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20577387511730194\n",
      "SNR: 20/30, LS_CNN, Epoch 31/50, Loss: 0.2698682686313987 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.205686267465353\n",
      "SNR: 20/30, LS_CNN, Epoch 32/50, Loss: 0.2514421371743083 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.2093224935233593\n",
      "SNR: 20/30, LS_CNN, Epoch 33/50, Loss: 0.22668157517910004 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20723265036940575\n",
      "SNR: 20/30, LS_CNN, Epoch 34/50, Loss: 0.22747625410556793 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20385532081127167\n",
      "SNR: 20/30, LS_CNN, Epoch 35/50, Loss: 0.2415754236280918 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20186808705329895\n",
      "SNR: 20/30, LS_CNN, Epoch 36/50, Loss: 0.2196185290813446 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19948780164122581\n",
      "SNR: 20/30, LS_CNN, Epoch 37/50, Loss: 0.2659880258142948 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.20115143805742264\n",
      "SNR: 20/30, LS_CNN, Epoch 38/50, Loss: 0.22214156575500965 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19883031025528908\n",
      "SNR: 20/30, LS_CNN, Epoch 39/50, Loss: 0.22683560941368341 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19510570541024208\n",
      "SNR: 20/30, LS_CNN, Epoch 40/50, Loss: 0.23503881506621838 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1948949545621872\n",
      "SNR: 20/30, LS_CNN, Epoch 41/50, Loss: 0.22453325148671865 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19288816303014755\n",
      "SNR: 20/30, LS_CNN, Epoch 42/50, Loss: 0.22877265140414238 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1929875947535038\n",
      "SNR: 20/30, LS_CNN, Epoch 43/50, Loss: 0.22823310643434525 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19144025072455406\n",
      "SNR: 20/30, LS_CNN, Epoch 44/50, Loss: 0.21821860875934362 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.19014259055256844\n",
      "SNR: 20/30, LS_CNN, Epoch 45/50, Loss: 0.22694539744406939 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18786630034446716\n",
      "SNR: 20/30, LS_CNN, Epoch 46/50, Loss: 0.21680946182459593 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18729602545499802\n",
      "SNR: 20/30, LS_CNN, Epoch 47/50, Loss: 0.21475450415164232 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18489282950758934\n",
      "SNR: 20/30, LS_CNN, Epoch 48/50, Loss: 0.22682124376296997 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.1835585068911314\n",
      "SNR: 20/30, LS_CNN, Epoch 49/50, Loss: 0.2226507617160678 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18290849961340427\n",
      "SNR: 20/30, LS_CNN, Epoch 50/50, Loss: 0.20847990922629833 \n",
      "SNR: 20/30, LS_CNN, Val Loss: 0.18188832513988018\n",
      "LS+CNN NMSE: 0.03807311877608299\n",
      "LS+LI NMSE: 0.000832608318887651\n",
      "LS_LI_CNN model\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 1/50, Loss: 0.3957235272973776 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.40164249390363693\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 2/50, Loss: 0.38543193601071835 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3902074098587036\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3745642378926277 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3777454122900963\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 4/50, Loss: 0.3621720280498266 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3632776439189911\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 5/50, Loss: 0.34764546900987625 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3464030623435974\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3305687066167593 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3258674889802933\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 7/50, Loss: 0.310612628236413 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.3035591244697571\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 8/50, Loss: 0.2881969567388296 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.27775483578443527\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 9/50, Loss: 0.263027005828917 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.2502627857029438\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 10/50, Loss: 0.23620904982089996 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.2206857167184353\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 11/50, Loss: 0.2083347663283348 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1925644837319851\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 12/50, Loss: 0.1814779806882143 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.1640412099659443\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 13/50, Loss: 0.15609886776655912 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.13903724029660225\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 14/50, Loss: 0.1330627710558474 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.11587155796587467\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 15/50, Loss: 0.11354192858561873 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.09803932718932629\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 16/50, Loss: 0.09747725492343307 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.08456885814666748\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 17/50, Loss: 0.08512945473194122 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.07368205580860376\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 18/50, Loss: 0.07635145098902285 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0667260093614459\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 19/50, Loss: 0.07062079641036689 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.06150532886385918\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 20/50, Loss: 0.06662003695964813 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05875562131404877\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 21/50, Loss: 0.06455471366643906 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05736124515533447\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 22/50, Loss: 0.06307618506252766 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05678780982270837\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 23/50, Loss: 0.06186211225576699 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05601163627579808\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 24/50, Loss: 0.0617529118899256 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.055806223303079605\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 25/50, Loss: 0.06114434590563178 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05574554158374667\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 26/50, Loss: 0.060299927834421396 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.055524707306176424\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 27/50, Loss: 0.0602355832234025 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05546948313713074\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 28/50, Loss: 0.060456522507593036 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05513967480510473\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 29/50, Loss: 0.059847107622772455 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.054667865857481956\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 30/50, Loss: 0.0601155913900584 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05449408246204257\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 31/50, Loss: 0.05921180977020413 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.054125018417835236\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 32/50, Loss: 0.059617302380502224 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.054177208337932825\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 33/50, Loss: 0.05906600737944245 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.054241732228547335\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 34/50, Loss: 0.059212926775217056 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05433358158916235\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 35/50, Loss: 0.05898580956272781 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05362836364656687\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 36/50, Loss: 0.05838119285181165 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05354322260245681\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 37/50, Loss: 0.05839991196990013 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.053467986173927784\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 38/50, Loss: 0.058155514067038894 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.053439551033079624\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 39/50, Loss: 0.05800562631338835 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05310211284086108\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 40/50, Loss: 0.05817110068164766 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05312323663383722\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 41/50, Loss: 0.05779888899996877 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.053019220009446144\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 42/50, Loss: 0.058012550696730614 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05282861739397049\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 43/50, Loss: 0.057298647705465555 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05265328707173467\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 44/50, Loss: 0.05728877731598914 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05246432777494192\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 45/50, Loss: 0.05732662416994572 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05245015071704984\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 46/50, Loss: 0.05689846770837903 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05200724117457867\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 47/50, Loss: 0.05728430312592536 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.0519808828830719\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 48/50, Loss: 0.05686596920713782 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05163752008229494\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 49/50, Loss: 0.05705209309235215 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05134365102276206\n",
      "SNR: 20/30, LS_LI_CNN, Epoch 50/50, Loss: 0.05629432387650013 \n",
      "SNR: 20/30, LS_LI_CNN, Val Loss: 0.05133015243336558\n",
      "LS+CNN NMSE: 0.008179458789527416\n",
      " SNR: 25/30\n",
      "LS_CNN model\n",
      "SNR: 25/30, LS_CNN, Epoch 1/50, Loss: 0.39458964578807354 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3995679169893265\n",
      "SNR: 25/30, LS_CNN, Epoch 2/50, Loss: 0.39217306673526764 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.39728551357984543\n",
      "SNR: 25/30, LS_CNN, Epoch 3/50, Loss: 0.38971763476729393 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.39395737648010254\n",
      "SNR: 25/30, LS_CNN, Epoch 4/50, Loss: 0.3870009630918503 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3900255486369133\n",
      "SNR: 25/30, LS_CNN, Epoch 5/50, Loss: 0.38405502773821354 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38579779863357544\n",
      "SNR: 25/30, LS_CNN, Epoch 6/50, Loss: 0.3803460132330656 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.38094254583120346\n",
      "SNR: 25/30, LS_CNN, Epoch 7/50, Loss: 0.37611919455230236 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3752049654722214\n",
      "SNR: 25/30, LS_CNN, Epoch 8/50, Loss: 0.37164674140512943 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3686130419373512\n",
      "SNR: 25/30, LS_CNN, Epoch 9/50, Loss: 0.36656867526471615 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3619486019015312\n",
      "SNR: 25/30, LS_CNN, Epoch 10/50, Loss: 0.3622112534940243 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3542051315307617\n",
      "SNR: 25/30, LS_CNN, Epoch 11/50, Loss: 0.3563604708760977 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.34606605023145676\n",
      "SNR: 25/30, LS_CNN, Epoch 12/50, Loss: 0.3502478916198015 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3377533033490181\n",
      "SNR: 25/30, LS_CNN, Epoch 13/50, Loss: 0.344018179923296 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3288429006934166\n",
      "SNR: 25/30, LS_CNN, Epoch 14/50, Loss: 0.3399790655821562 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3189939185976982\n",
      "SNR: 25/30, LS_CNN, Epoch 15/50, Loss: 0.3340241312980652 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.3122369647026062\n",
      "SNR: 25/30, LS_CNN, Epoch 16/50, Loss: 0.3297189362347126 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.30432628095149994\n",
      "SNR: 25/30, LS_CNN, Epoch 17/50, Loss: 0.326462646946311 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.29594993591308594\n",
      "SNR: 25/30, LS_CNN, Epoch 18/50, Loss: 0.31598158180713654 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.28851349651813507\n",
      "SNR: 25/30, LS_CNN, Epoch 19/50, Loss: 0.3134912736713886 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.27924834936857224\n",
      "SNR: 25/30, LS_CNN, Epoch 20/50, Loss: 0.30211107432842255 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2729004770517349\n",
      "SNR: 25/30, LS_CNN, Epoch 21/50, Loss: 0.29662247002124786 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2646978832781315\n",
      "SNR: 25/30, LS_CNN, Epoch 22/50, Loss: 0.2962569836527109 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2561717554926872\n",
      "SNR: 25/30, LS_CNN, Epoch 23/50, Loss: 0.2854024162515998 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24897272139787674\n",
      "SNR: 25/30, LS_CNN, Epoch 24/50, Loss: 0.2853154158219695 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.24160340428352356\n",
      "SNR: 25/30, LS_CNN, Epoch 25/50, Loss: 0.2760555427521467 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.23520710691809654\n",
      "SNR: 25/30, LS_CNN, Epoch 26/50, Loss: 0.279211382381618 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22825174033641815\n",
      "SNR: 25/30, LS_CNN, Epoch 27/50, Loss: 0.2762361653149128 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22261353209614754\n",
      "SNR: 25/30, LS_CNN, Epoch 28/50, Loss: 0.2688231663778424 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.22015132382512093\n",
      "SNR: 25/30, LS_CNN, Epoch 29/50, Loss: 0.25347812846302986 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2139233723282814\n",
      "SNR: 25/30, LS_CNN, Epoch 30/50, Loss: 0.25232751946896315 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.2073645442724228\n",
      "SNR: 25/30, LS_CNN, Epoch 31/50, Loss: 0.252612704411149 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.201155424118042\n",
      "SNR: 25/30, LS_CNN, Epoch 32/50, Loss: 0.2630499266088009 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19577892869710922\n",
      "SNR: 25/30, LS_CNN, Epoch 33/50, Loss: 0.2480881791561842 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19463199004530907\n",
      "SNR: 25/30, LS_CNN, Epoch 34/50, Loss: 0.25632064137607813 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.19086075201630592\n",
      "SNR: 25/30, LS_CNN, Epoch 35/50, Loss: 0.23618953954428434 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.188177190721035\n",
      "SNR: 25/30, LS_CNN, Epoch 36/50, Loss: 0.24086009617894888 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.18395927920937538\n",
      "SNR: 25/30, LS_CNN, Epoch 37/50, Loss: 0.2468315940350294 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1844087429344654\n",
      "SNR: 25/30, LS_CNN, Epoch 38/50, Loss: 0.2450127061456442 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17876623570919037\n",
      "SNR: 25/30, LS_CNN, Epoch 39/50, Loss: 0.2384771816432476 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17865711450576782\n",
      "SNR: 25/30, LS_CNN, Epoch 40/50, Loss: 0.22666680626571178 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17633140087127686\n",
      "SNR: 25/30, LS_CNN, Epoch 41/50, Loss: 0.22581591084599495 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.17287644743919373\n",
      "SNR: 25/30, LS_CNN, Epoch 42/50, Loss: 0.22728887293487787 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16683655977249146\n",
      "SNR: 25/30, LS_CNN, Epoch 43/50, Loss: 0.22550178226083517 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16423167660832405\n",
      "SNR: 25/30, LS_CNN, Epoch 44/50, Loss: 0.22612179443240166 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16113433614373207\n",
      "SNR: 25/30, LS_CNN, Epoch 45/50, Loss: 0.2372691435739398 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1577106211334467\n",
      "SNR: 25/30, LS_CNN, Epoch 46/50, Loss: 0.2252762308344245 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16329338029026985\n",
      "SNR: 25/30, LS_CNN, Epoch 47/50, Loss: 0.23187267407774925 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16654471307992935\n",
      "SNR: 25/30, LS_CNN, Epoch 48/50, Loss: 0.23626437783241272 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16426001861691475\n",
      "SNR: 25/30, LS_CNN, Epoch 49/50, Loss: 0.22930648364126682 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.16382388770580292\n",
      "SNR: 25/30, LS_CNN, Epoch 50/50, Loss: 0.2267373502254486 \n",
      "SNR: 25/30, LS_CNN, Val Loss: 0.1593335084617138\n",
      "LS+CNN NMSE: 0.04400893673300743\n",
      "LS+LI NMSE: 0.0002552444930188358\n",
      "LS_LI_CNN model\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 1/50, Loss: 0.39095017313957214 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3941808044910431\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 2/50, Loss: 0.37766056321561337 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3782728239893913\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 3/50, Loss: 0.36346833780407906 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3610677197575569\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 4/50, Loss: 0.34790392592549324 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.3425763174891472\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 5/50, Loss: 0.33075141720473766 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.32199470698833466\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 6/50, Loss: 0.3118485361337662 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.2999567613005638\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 7/50, Loss: 0.29132080636918545 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.27423200011253357\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 8/50, Loss: 0.26897495333105326 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.2494576945900917\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 9/50, Loss: 0.24543197732418776 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.22281401231884956\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 10/50, Loss: 0.22092943917959929 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.19530033692717552\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 11/50, Loss: 0.19630632735788822 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.16876520961523056\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 12/50, Loss: 0.1717900736257434 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.14181005954742432\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 13/50, Loss: 0.14831297378987074 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.11635009199380875\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 14/50, Loss: 0.12687470111995935 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.09484554827213287\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 15/50, Loss: 0.10751143470406532 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.07597283646464348\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 16/50, Loss: 0.09144631354138255 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.06104075536131859\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 17/50, Loss: 0.07743911747820675 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.048656390979886055\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 18/50, Loss: 0.06711971177719533 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03987277299165726\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 19/50, Loss: 0.059558365726843476 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.034415457397699356\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 20/50, Loss: 0.05436448031105101 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.03102561691775918\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 21/50, Loss: 0.050828034174628556 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.029247870668768883\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 22/50, Loss: 0.049284264096058905 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.028322688303887844\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 23/50, Loss: 0.04762476868927479 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027641817927360535\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 24/50, Loss: 0.04672205890528858 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02752435440197587\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 25/50, Loss: 0.04614884499460459 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027494346257299185\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 26/50, Loss: 0.04586631606798619 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027662822045385838\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 27/50, Loss: 0.04612759710289538 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027599067892879248\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 28/50, Loss: 0.04586913401726633 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027536212000995874\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 29/50, Loss: 0.045481773326173425 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027491129469126463\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 30/50, Loss: 0.04536568943876773 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027275816537439823\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 31/50, Loss: 0.04556252178736031 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027094359509646893\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 32/50, Loss: 0.04521916573867202 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027356430422514677\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 33/50, Loss: 0.04452833719551563 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027270025108009577\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 34/50, Loss: 0.04513004014734179 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027272569481283426\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 35/50, Loss: 0.04512703977525234 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.027202438097447157\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 36/50, Loss: 0.045039211749099195 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02716274978592992\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 37/50, Loss: 0.04504989890847355 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.026883656159043312\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 38/50, Loss: 0.04498908529058099 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02699004439637065\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 39/50, Loss: 0.04525605135131627 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.026926576159894466\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 40/50, Loss: 0.04483347700443119 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.026783316861838102\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 41/50, Loss: 0.04452323273289949 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.026700238697230816\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 42/50, Loss: 0.04493917466606945 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02671531494706869\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 43/50, Loss: 0.044527192832902074 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02641102857887745\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 44/50, Loss: 0.044690017588436604 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02638479322195053\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 45/50, Loss: 0.04434969159774482 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02648865943774581\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 46/50, Loss: 0.04446137370541692 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02621359145268798\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 47/50, Loss: 0.04414424777496606 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02596122259274125\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 48/50, Loss: 0.04389425599947572 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.025981873739510775\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 49/50, Loss: 0.04383384808897972 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.02595988754183054\n",
      "SNR: 25/30, LS_LI_CNN, Epoch 50/50, Loss: 0.04431559087242931 \n",
      "SNR: 25/30, LS_LI_CNN, Val Loss: 0.025783743243664503\n",
      "LS+CNN NMSE: 0.0070611461997032166\n",
      " SNR: 30/30\n",
      "LS_CNN model\n",
      "SNR: 30/30, LS_CNN, Epoch 1/50, Loss: 0.3912110887467861 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.39075425267219543\n",
      "SNR: 30/30, LS_CNN, Epoch 2/50, Loss: 0.38709091022610664 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.38761185854673386\n",
      "SNR: 30/30, LS_CNN, Epoch 3/50, Loss: 0.3829894885420799 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3837248235940933\n",
      "SNR: 30/30, LS_CNN, Epoch 4/50, Loss: 0.3786713946610689 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.38016732037067413\n",
      "SNR: 30/30, LS_CNN, Epoch 5/50, Loss: 0.37327555753290653 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3758961111307144\n",
      "SNR: 30/30, LS_CNN, Epoch 6/50, Loss: 0.3685283213853836 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.37118541449308395\n",
      "SNR: 30/30, LS_CNN, Epoch 7/50, Loss: 0.3622925914824009 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3663344457745552\n",
      "SNR: 30/30, LS_CNN, Epoch 8/50, Loss: 0.35648233629763126 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.36215391755104065\n",
      "SNR: 30/30, LS_CNN, Epoch 9/50, Loss: 0.3504851143807173 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3571367636322975\n",
      "SNR: 30/30, LS_CNN, Epoch 10/50, Loss: 0.3448902051895857 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.35318613797426224\n",
      "SNR: 30/30, LS_CNN, Epoch 11/50, Loss: 0.33957414887845516 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3491346538066864\n",
      "SNR: 30/30, LS_CNN, Epoch 12/50, Loss: 0.33470929227769375 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3459305614233017\n",
      "SNR: 30/30, LS_CNN, Epoch 13/50, Loss: 0.33019349351525307 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3426819369196892\n",
      "SNR: 30/30, LS_CNN, Epoch 14/50, Loss: 0.32926560193300247 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.34012237936258316\n",
      "SNR: 30/30, LS_CNN, Epoch 15/50, Loss: 0.3254298623651266 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.33845800906419754\n",
      "SNR: 30/30, LS_CNN, Epoch 16/50, Loss: 0.3200604971498251 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.33568431064486504\n",
      "SNR: 30/30, LS_CNN, Epoch 17/50, Loss: 0.31834002025425434 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3321234881877899\n",
      "SNR: 30/30, LS_CNN, Epoch 18/50, Loss: 0.3148463126271963 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3296780548989773\n",
      "SNR: 30/30, LS_CNN, Epoch 19/50, Loss: 0.3127660918980837 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32649802416563034\n",
      "SNR: 30/30, LS_CNN, Epoch 20/50, Loss: 0.3090588264167309 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3237948939204216\n",
      "SNR: 30/30, LS_CNN, Epoch 21/50, Loss: 0.30686268024146557 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.32048070803284645\n",
      "SNR: 30/30, LS_CNN, Epoch 22/50, Loss: 0.3030619639903307 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.31818391382694244\n",
      "SNR: 30/30, LS_CNN, Epoch 23/50, Loss: 0.3008728828281164 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3175935111939907\n",
      "SNR: 30/30, LS_CNN, Epoch 24/50, Loss: 0.29694705829024315 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3125550337135792\n",
      "SNR: 30/30, LS_CNN, Epoch 25/50, Loss: 0.2959784474223852 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.31023696064949036\n",
      "SNR: 30/30, LS_CNN, Epoch 26/50, Loss: 0.2930929698050022 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3072829619050026\n",
      "SNR: 30/30, LS_CNN, Epoch 27/50, Loss: 0.2926540756598115 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.30373506247997284\n",
      "SNR: 30/30, LS_CNN, Epoch 28/50, Loss: 0.2899959608912468 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.3020157441496849\n",
      "SNR: 30/30, LS_CNN, Epoch 29/50, Loss: 0.28190460707992315 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2984571270644665\n",
      "SNR: 30/30, LS_CNN, Epoch 30/50, Loss: 0.2780932802706957 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2946041077375412\n",
      "SNR: 30/30, LS_CNN, Epoch 31/50, Loss: 0.2829917389899492 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2905607782304287\n",
      "SNR: 30/30, LS_CNN, Epoch 32/50, Loss: 0.2714545540511608 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2882653586566448\n",
      "SNR: 30/30, LS_CNN, Epoch 33/50, Loss: 0.268092923797667 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2856769636273384\n",
      "SNR: 30/30, LS_CNN, Epoch 34/50, Loss: 0.2639615871012211 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.28082437068223953\n",
      "SNR: 30/30, LS_CNN, Epoch 35/50, Loss: 0.2634620675817132 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27783632278442383\n",
      "SNR: 30/30, LS_CNN, Epoch 36/50, Loss: 0.265378400683403 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2762981876730919\n",
      "SNR: 30/30, LS_CNN, Epoch 37/50, Loss: 0.2611324032768607 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.27188972756266594\n",
      "SNR: 30/30, LS_CNN, Epoch 38/50, Loss: 0.2560430681332946 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26552022993564606\n",
      "SNR: 30/30, LS_CNN, Epoch 39/50, Loss: 0.2534179724752903 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.26358843222260475\n",
      "SNR: 30/30, LS_CNN, Epoch 40/50, Loss: 0.24745614361017942 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2622404396533966\n",
      "SNR: 30/30, LS_CNN, Epoch 41/50, Loss: 0.2613832037895918 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2554442845284939\n",
      "SNR: 30/30, LS_CNN, Epoch 42/50, Loss: 0.2466357620432973 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2555587999522686\n",
      "SNR: 30/30, LS_CNN, Epoch 43/50, Loss: 0.24312059301882982 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.252572949975729\n",
      "SNR: 30/30, LS_CNN, Epoch 44/50, Loss: 0.2396790748462081 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.24713202193379402\n",
      "SNR: 30/30, LS_CNN, Epoch 45/50, Loss: 0.23766473215073347 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2455962337553501\n",
      "SNR: 30/30, LS_CNN, Epoch 46/50, Loss: 0.23957034200429916 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23907139897346497\n",
      "SNR: 30/30, LS_CNN, Epoch 47/50, Loss: 0.23195422161370516 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23941240459680557\n",
      "SNR: 30/30, LS_CNN, Epoch 48/50, Loss: 0.23682926502078772 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23809614032506943\n",
      "SNR: 30/30, LS_CNN, Epoch 49/50, Loss: 0.2425734205171466 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.23467105254530907\n",
      "SNR: 30/30, LS_CNN, Epoch 50/50, Loss: 0.2363621024414897 \n",
      "SNR: 30/30, LS_CNN, Val Loss: 0.2329624928534031\n",
      "LS+CNN NMSE: 0.03811843693256378\n",
      "LS+LI NMSE: 8.608803182141855e-05\n",
      "LS_LI_CNN model\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 1/50, Loss: 0.37562836334109306 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.375089131295681\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 2/50, Loss: 0.3624687362462282 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3612832576036453\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 3/50, Loss: 0.3485521376132965 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.346198245882988\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 4/50, Loss: 0.33297672867774963 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3291562646627426\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 5/50, Loss: 0.3151004631072283 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.3097321391105652\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 6/50, Loss: 0.2946528196334839 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.28768880292773247\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 7/50, Loss: 0.27141216956079006 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.26257501170039177\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 8/50, Loss: 0.24556411243975163 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.23520461842417717\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 9/50, Loss: 0.2175306612625718 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.20628689229488373\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 10/50, Loss: 0.18867911770939827 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.17608263716101646\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 11/50, Loss: 0.15987381525337696 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.14681732468307018\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 12/50, Loss: 0.13254064181819558 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.12100876308977604\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 13/50, Loss: 0.10820957366377115 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0967432539910078\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 14/50, Loss: 0.08720178343355656 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0774230184033513\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 15/50, Loss: 0.07080483995378017 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0627994704991579\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 16/50, Loss: 0.05790304997935891 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.051414801739156246\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 17/50, Loss: 0.049650812055915594 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.043994161766022444\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 18/50, Loss: 0.04410344432108104 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03919200366362929\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 19/50, Loss: 0.040373619995079935 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03686875989660621\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 20/50, Loss: 0.03874326928053051 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03547342540696263\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 21/50, Loss: 0.03759142057970166 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.034444624092429876\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 22/50, Loss: 0.03728095139376819 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03353832382708788\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 23/50, Loss: 0.03659916284959763 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03336606966331601\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 24/50, Loss: 0.03666613344103098 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03335035126656294\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 25/50, Loss: 0.0363817474571988 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.032938279677182436\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 26/50, Loss: 0.03635956265497953 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03217678237706423\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 27/50, Loss: 0.03597944893408567 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.032391298562288284\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 28/50, Loss: 0.03598215105012059 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03314958559349179\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 29/50, Loss: 0.035514347604475915 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.032324994914233685\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 30/50, Loss: 0.03573880856856704 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.0319462432526052\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 31/50, Loss: 0.03534307167865336 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03165462240576744\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 32/50, Loss: 0.035256504896096885 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03119745058938861\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 33/50, Loss: 0.03522892319597304 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.031241988763213158\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 34/50, Loss: 0.03514697577338666 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03152682771906257\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 35/50, Loss: 0.034850699827075005 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.031039466150105\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 36/50, Loss: 0.03514077700674534 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03125341236591339\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 37/50, Loss: 0.03466101654339582 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.03078101947903633\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 38/50, Loss: 0.03416885167825967 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.030500325839966536\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 39/50, Loss: 0.03430826182011515 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.030707828234881163\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 40/50, Loss: 0.0342129475902766 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.030307522974908352\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 41/50, Loss: 0.033901688060723245 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.030276028905063868\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 42/50, Loss: 0.0338272136868909 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.029965081252157688\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 43/50, Loss: 0.03373410226777196 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02989988075569272\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 44/50, Loss: 0.033319500274956226 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.029834759421646595\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 45/50, Loss: 0.03390217665582895 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02957377815619111\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 46/50, Loss: 0.033244211110286415 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02923379186540842\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 47/50, Loss: 0.033954053302295506 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.029237656388431787\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 48/50, Loss: 0.033273556968197227 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02918807463720441\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 49/50, Loss: 0.03334055840969086 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.02918053511530161\n",
      "SNR: 30/30, LS_LI_CNN, Epoch 50/50, Loss: 0.03325461654458195 \n",
      "SNR: 30/30, LS_LI_CNN, Val Loss: 0.029327692463994026\n",
      "LS+CNN NMSE: 0.004916300997138023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuration\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32 #64  # Batch size\n",
    "NUM_EPOCHS = 50 # 20\n",
    "learning_rate = 1e-5 # 1e-5\n",
    "SNR = np.arange(0, 31, 5) # 0:5:30 dB\n",
    "\n",
    "nmse_LS_LI_val   = []\n",
    "nmse_LS_NN_val   = []\n",
    "nmse_LI_NN_val   = []\n",
    "\n",
    "for snr in SNR:\n",
    "    print(f\" SNR: {snr}/{SNR[-1]}\")\n",
    "    # load target dataset\n",
    "    [trainLabels, valLabels], [H_equal_train, H_linear_train, H_practical_train], [H_equal_val, H_linear_val, H_practical_val] = loader.load_map_data(target_data_dir, device, snr)\n",
    "            \n",
    "    # training at target set\n",
    "    for model_name in ['LS_CNN', 'LS_LI_CNN']:\n",
    "        print(f'{model_name} model')\n",
    "        \n",
    "        if model_name == 'LS_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_equal_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_equal_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            train_loader, trainLabel_min, trainLabel_max = loader.genLoader(H_linear_train, trainLabels, BATCH_SIZE, device, 'train', True, norm_approach, lower_range=lower_range)\n",
    "            val_loader,     valLabel_min,   valLabel_max = loader.genLoader(H_linear_val,     valLabels, BATCH_SIZE, device, 'valid', False, norm_approach, lower_range=lower_range)\n",
    "            # no shuffle in validation so valLabel_min and valLable_max remain the min and max arrays\n",
    "                                                                                        # of valLabels\n",
    "            # train_loader, val_loader are already normalized by their own min, max\n",
    "            # scale to range [0 1] or [-1 1]\n",
    "        \n",
    "        # source model\n",
    "        model_source = utils.CNN_Est(dropOut=CNN_DropOut, act =CNN_activation).to(device)\n",
    "        \n",
    "        checkpoint = torch.load(os.path.join(source_models_dir, f'{snr}dB', f'CNN_1_{model_name}_model.pth'))\n",
    "        model_source.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        model_fineTune = utils_transfer.FineTuneModel(model_source).to(device)\n",
    "        optimizer = torch.optim.Adam(model_fineTune.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_loss =[]\n",
    "        val_loss = []\n",
    "        H_NN_val = torch.empty_like(valLabels) # [nVal, 2, 612, 14]\n",
    "        min_H_true = []\n",
    "        max_H_true = []\n",
    "        num_epochs = NUM_EPOCHS\n",
    "        for epoch in range(num_epochs):\n",
    "            model_fineTune.train()\n",
    "            running_loss = 0.0\n",
    "            if (epoch == num_epochs-1):\n",
    "                i = 0\n",
    "            for inputs, targets, targets_min, targets_max in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model_fineTune(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            avg_train_loss = running_loss / len(train_loader)\n",
    "            train_loss.append(avg_train_loss)\n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss} \")\n",
    "            \n",
    "            # Validation \n",
    "            model_fineTune.eval()\n",
    "            running_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_targets, val_targetsMin, val_targetsMax in val_loader:\n",
    "                    val_inputs_real = val_inputs[:,0,:,:].unsqueeze(1)\n",
    "                    val_inputs_imag = val_inputs[:,1,:,:].unsqueeze(1)\n",
    "                    val_targets_real = val_targets[:,0,:,:].unsqueeze(1)\n",
    "                    val_targets_imag = val_targets[:,1,:,:].unsqueeze(1)\n",
    "                    \n",
    "                    val_outputs_real = model_fineTune(val_inputs_real)\n",
    "                    val_loss_real = criterion(val_outputs_real, val_targets_real)\n",
    "                    running_val_loss += val_loss_real.item()\n",
    "                    \n",
    "                    val_outputs_imag = model_fineTune(val_inputs_imag)\n",
    "                    val_loss_imag = criterion(val_outputs_imag, val_targets_imag)\n",
    "                    running_val_loss += val_loss_imag.item()\n",
    "                    \n",
    "                    if (epoch == num_epochs-1): # the results after the last training epoch\n",
    "                        H_NN_val[i:i+val_outputs_real.size(0),0,:,:].unsqueeze(1).copy_(val_outputs_real)\n",
    "                        H_NN_val[i:i+val_outputs_imag.size(0),1,:,:].unsqueeze(1).copy_(val_outputs_imag)\n",
    "                        \n",
    "                        i = i+val_outputs_imag.size(0)       \n",
    "                        \n",
    "                    \n",
    "            avg_val_loss = running_val_loss / (len(val_loader)*2)\n",
    "            val_loss.append(avg_val_loss)    \n",
    "                    \n",
    "            print(f\"SNR: {snr}/{SNR[-1]}, {model_name}, Val Loss: {avg_val_loss}\")\n",
    "        # end loop epochs\n",
    "        \n",
    "        train_save_path = f'{transferd_save_path}/{snr}dB/train'\n",
    "        os.makedirs(train_save_path, exist_ok=True)\n",
    "        \n",
    "        savemat(f'{train_save_path}/{model_name}_loss.mat', {f'val_loss': val_loss, \n",
    "                                                            f'train_loss': train_loss})\n",
    "        \n",
    "        plotfig.figLoss(train_loss, val_loss, 1, train_save_path, f'_{model_name}_Loss.png')\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': model_fineTune.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f'{transferd_save_path}/{snr}dB/{model_name}_model.pth')\n",
    "        \n",
    "        \n",
    "        # Denormalize True Channel\n",
    "        H_val_true = valLabels.cpu()\n",
    "        # convert to complex matrices\n",
    "        H_val_true_complex = torch.complex(H_val_true[:,0,:,:], H_val_true[:,1,:,:])\n",
    "        # variables['H_val_true'] = H_val_true # (nVal, 2, 612, 14)\n",
    "        plotfig.figTrueChan(H_val_true[-1,0,:,:], 'True Channel', 1, train_save_path, '_trueChannel.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "\n",
    "        \n",
    "        # CNN Estimated Channel                                                               \n",
    "        H_val_NN_denormd = utils.deNorm(H_NN_val, valLabel_min, valLabel_max, norm_approach, lower_range=lower_range)\n",
    "                            #     H_NN_val == [nVal, 2, 612, 14] \n",
    "                            # valLabel_min == [nVal,1]\n",
    "        H_val_NN_denormd = H_val_NN_denormd.cpu()\n",
    "        \n",
    "        # NMSE of LS (+ LI) + CNN\n",
    "        H_val_NN_complex = torch.complex(H_val_NN_denormd[:,0,:,:], H_val_NN_denormd[:,1,:,:])# Calculate the NMSE\n",
    "        nmse_NN = utils.calNMSE(H_val_NN_complex, H_val_true_complex)\n",
    "            \n",
    "        if model_name == 'LS_CNN':\n",
    "            nmse_LS_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "        \n",
    "            # NMSE of Linear Interpolation   # just need to calculate this 1 time  --> calculate at case model_name == 'LS_CNN'\n",
    "            H_val_linInterp = H_linear_val.cpu()\n",
    "            # convert to complex matrices\n",
    "            H_val_linInterp_complex = torch.complex(H_val_linInterp[:,0,:,:], H_val_linInterp[:,1,:,:]) # [?, 612, 14]\n",
    "            nmse_LI = utils.calNMSE(H_val_linInterp_complex, H_val_true_complex)\n",
    "            \n",
    "            nmse_LS_LI_val.append(nmse_LI.cpu().mean())\n",
    "            print(f\"LS+LI NMSE: {nmse_LI.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_linInterp[-1,0,:,:], 'LS + Interpolate Estimated Channel',\n",
    "                                    nmse_LI[-1], 1, train_save_path, '_LS_LI_estimatedChan.png')\n",
    "                            # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "                            \n",
    "        elif model_name == 'LS_LI_CNN':\n",
    "            nmse_LI_NN_val.append(nmse_NN.cpu().mean())\n",
    "            print(f\"LS+CNN NMSE: {nmse_NN.cpu().mean()}\")\n",
    "            \n",
    "            plotfig.figPredChan(H_val_NN_denormd[-1,0,:,:], 'LS+LI+CNN Estimated Channel',\n",
    "                                    nmse_NN[-1], 1, train_save_path, '_LS_LI_CNN_estimatedChan.png')\n",
    "                                # train_save_path = f'transferd_model/static/CNN/ver{idx_save_path}_/{snr}dB/train'\n",
    "    \n",
    "    # end model_phase ['LS_CNN', 'LS_LI_CNN']\n",
    "# end loop SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12           [-1, 1, 612, 14]             801\n",
      "================================================================\n",
      "Total params: 262,211\n",
      "Trainable params: 803\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 35.69\n",
      "Params size (MB): 1.00\n",
      "Estimated Total Size (MB): 36.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model_source, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 1, 612, 14]               2\n",
      "            Conv2d-2          [-1, 64, 612, 14]           5,248\n",
      "              Tanh-3          [-1, 64, 612, 14]               0\n",
      "            Conv2d-4          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-5          [-1, 64, 612, 14]               0\n",
      "           Dropout-6          [-1, 64, 612, 14]               0\n",
      "            Conv2d-7          [-1, 64, 612, 14]         102,464\n",
      "              Tanh-8          [-1, 64, 612, 14]               0\n",
      "            Conv2d-9          [-1, 32, 612, 14]          51,232\n",
      "             Tanh-10          [-1, 32, 612, 14]               0\n",
      "          Dropout-11          [-1, 32, 612, 14]               0\n",
      "           Conv2d-12          [-1, 16, 612, 14]          12,816\n",
      "             Tanh-13          [-1, 16, 612, 14]               0\n",
      "           Conv2d-14           [-1, 8, 612, 14]           3,208\n",
      "             Tanh-15           [-1, 8, 612, 14]               0\n",
      "           Conv2d-16           [-1, 1, 612, 14]             201\n",
      "================================================================\n",
      "Total params: 277,635\n",
      "Trainable params: 16,227\n",
      "Non-trainable params: 261,408\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 38.83\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 39.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_fineTune, input_size=(1,612,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved at \n",
      "transferd_model/static/CNN/ver2_/NMSE1.png\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SNR, nmse_LS_LI_val, label='LS+LI')\n",
    "plt.plot(SNR, nmse_LS_NN_val, label='LS+CNN')\n",
    "plt.plot(SNR, nmse_LI_NN_val, label='LS+LI+CNN')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Average NMSE over SNR')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(transferd_save_path, \"NMSE1.png\")) # transferd_save_path = f\"transferd_model/static/CNN/ver{idx_save_path}_\"\n",
    "plt.show()\n",
    "print('Figure saved at ')\n",
    "print(os.path.join(transferd_save_path, \"NMSE1.png\"))\n",
    "\n",
    "savemat(os.path.join(transferd_save_path, 'NMSE.mat'), {'nmse_LS_LI_val': nmse_LS_LI_val, 'nmse_LS_NN_val':nmse_LS_NN_val, 'nmse_LI_NN_val':nmse_LI_NN_val})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
